---
title: SAM2模型-探析(深度学习)
date: 2024-08-02 15:44:11
tags:
  - AI
categories:
  - 人工智能
mathjax:
  tex:
    tags: 'ams'
  svg:
    exFactor: 0.03
---

[`SAM2(Segment Anything Model 2)`](https://ai.meta.com/research/publications/sam-2-segment-anything-in-images-and-videos/)是`Meta AI`最新发布的图像和视频分割模型,是`Segment Anything Model(SAM)`的下一代模型。`SAM2`是一个统一的模型,可以同时处理**图像**和**视频**的**分割任务**。这种统一的架构简化了部署,并在不同媒体类型中实现了一致的性能。`SAM2`采用了**提示式视觉分割**(`Promptable Visual Segmentation, PVS`)的方法。用户可以通过**点击**、**边界框**或**掩码**等方式在视频的任何帧上提供提示,模型会立即生成相应的分割掩码,并将其传播到整个视频中。
<!-- more -->

`SAM2`还可以分割任何视频或图像中的任何对象（通常称为**零样本泛化**），这意味着它可以应用于以前从未见过的视觉内容，而无需进行自定义调整。
{% asset_img s_1.png  "SAM2模型在SA-V的数据集上进行训练，主要解决基于提示的视觉分割任务" %}

**图像分割**：`Segment Anything`（`Kirillov`等人，`2023`年）引入了一种可以提示的图像分割任务，其目标是在给定输入提示（例如边界框或指向感兴趣对象的点）的情况下输出有效的分割掩码。在`SA-1B`数据集上训练的`SAM`允许使用灵活提示进行零样本分割，从而使其能够应用于广泛的下游应用。最近的工作通过提高其质量扩展了`SAM`。例如，`HQ-SAM`（`Ke`等人，`2024`年）通过引入高质量输出`token`并在细粒度掩码上训练模型来增强`SAM`。另一项工作重点是提高`SAM`的效率，使其在现实世界和移动应用中得到更广泛的应用，例如`EfficientSAM`（`Xiong`等人，`2023`年）、`MobileSAM`（`Zhang`等人，`2023`年）和`FastSAM`（`Zhao`等人，`2023`年）。

**交互式视频对象分割**(`iVOS`)：交互式视频对象分割已成为一项关键任务，可在用户指导下有效获得视频中的对象分割(`masklets`)，通常以涂鸦、点击或边界框的形式出现。一些早期方法 (`Wang`等人，`2005`年；`Bai & Sapiro`，`2007`年；`Fan`等人，`2015`年) 部署基于图的优化来指导分割注释过程。较新的方法 (`Heo`等人，`2020`年；`Cheng`等人，`2021`年；`Delatolas`等人，`2024`年) 通常采用模块化设计，将用户输入转换为单个帧上的掩码表示，然后将其传播到其他帧。在视频中分割对象并实现良好的交互体验，并且我们建立了一个强大的模型和一个庞大而多样化的数据集来实现这一目标。具体来说，`DAVIS`交互式基准 (`Caelles`等人，`2018`年) 允许通过多帧上的涂鸦输入以交互方式分割对象。然而，这些方法有局限性：跟踪器可能无法适用于所有对象，`SAM`可能无法很好地处理视频中的图像帧，并且除了使用`SAM`从头开始​​对错误帧进行重新注释并从那里重新启动跟踪之外，没有其他机制可以交互地改进模型的错误。

**半监督视频对象分割**(`VOS`)。半监督`VOS`通常以第一帧中的对象掩码作为输入开始，必须在整个视频中准确跟踪该掩码(`Pont-Tuset`等，`2017`)。之所以被称为“半监督”，是因为**输入掩码**看作是仅适用于第一帧的对象轮廓的监督信号。这项任务因其与各种应用的相关性而引起了广泛关注，包括视频编辑、机器人技术和自动背景去除。半监督`VOS`可以看作是**可提示视觉分割**(`PVS`)任务的一个特例，因为它相当于仅在第一个视频帧中提供掩码提示。然而，在第一帧中注释高质量的对象掩码实际上具有挑战性且耗时。

**视频分割数据集**：已经提出了许多数据集来支持`VOS`任务。然而当前的视频分割数据集缺乏足够的覆盖范围来实现“分割视频中的所有内容”的能力。它们的注释通常覆盖整个对象（而不是部分），数据集通常以特定对象类别为中心，例如人、车辆和动物。与这些数据集相比，当前发布的`SA-V`数据集不仅关注整个对象，还广泛覆盖对象的子部分，并包含超过一个数量级的掩码。
{% asset_img s_2.png %}

使用`SAM2`进行交互式分割：
- 步骤1（选择）：我们在第`1`帧中提示`SAM2`获取目标对象（舌头）的片段。绿点/红点分别表示正/负提示。`SAM2`自动将片段传播到后续帧（蓝色箭头）以形成`masklet`。如果`SAM2`丢失了对象（第2帧之后），我们可以通过在新帧（红色箭头）中提供额外提示来更正`masklet`。
- 步骤2（细化）：在第`3`帧中单击一次就足以恢复对象并传播它以获得正确的`masklet`。分离的`SAM`+ 视频跟踪器方法需要在第`3`帧（如第`1`帧）中单击几次才能在从头开始重新开始正确地分割并重新注释对象。借助`SAM2`的内存，单击一次即可恢复舌头。

