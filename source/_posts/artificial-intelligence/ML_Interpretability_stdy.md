---
title: 机器学习可解释性（特征可视化 & 对抗性示例 & 差值）
date: 2024-07-26 14:10:11
tags:
  - AI
categories:
  - 人工智能
mathjax:
  tex:
    tags: 'ams'
  svg:
    exFactor: 0.03
---

**可解释机器学习**是指使机器学习系统的行为和预测可以被人类理解的方法和模型。**数据集**是包含机器学习数据的表格。数据集包含特征和要预测的目标。当用于建立模型时，数据集称为**训练数据**。**实例**是数据集中的一行。“**实例**”的其他名称是：（数据）点、示例。**实例**由特征值组成以及目标结果。**特征**是用于预测或分类的输入。特征是数据集中的一列。**特征**被认为是可解释的，这意味着很容易理解它们的含义，例如某一天的温度或一个人的身高。特征的可解释性是一个很大的假设。但如果很难理解输入特征，那么理解模型的作用就更难了。**目标**是机器学习预测的信息。在数学公式中，对于单个实例来说，**目标**通常称为{% mathjax %}y{% endmathjax %}或者{% mathjax %}y_i{% endmathjax %}。**机器学习任务**是具有特征的数据集和目标的组合。根据目标的类型，**任务**可以是分类、回归、聚类或异常值检测等。**预测**是机器学习模型根据给定的特征“猜测”目标值应该是什么。模型预测表示为{% mathjax %}\hat{F}(x^{(i)}){% endmathjax %}或者{% mathjax %}\hat{y}{% endmathjax %}。
<!-- more -->

**可解释性**是人类理解决策原因的程度。另一个定义是：**可解释性**是人类能够一致预测模型结果的程度。机器学习模型的**可解释性**越高，人们就越容易理解为什么做出某些决策或预测。如果一个模型的决策比其他模型的决策更容易被人类理解，那么该模型的可解释性就比另一个模型更好。

**可解释性**的需求源于**问题形式化的不完整性**(`Doshi-Velez`和`Kim 2017`)，这意味着对于某些问题或任务，仅仅获得预测（是什么）是不够的。模型还必须解释它是如何得出预测的（为什么），因为正确的预测只能部分解决您的原始问题。机器学习模型只有在可解释时才能进行调试和审核。即使在电影推荐等低风险环境中，解释能力在研发阶段以及部署后都很有价值。之后，当模型用于产品时，可能会出错。对错误预测的解释有助于了解错误的原因。它为如何修复系统提供了方向。考虑一个哈士奇与狼分类器的例子，它将一些哈士奇误归类为狼。使用可解释的机器学习方法，您会发现错误分类是由于图像上的雪造成的。如果你能确保机器学习模型能够解释决策,那你可以轻松检查以下特征：
- 公平性：确保预测不带偏见，不会隐性或显性地歧视代表性不足的群体。可解释的模型可以告诉你为什么它决定某个人不应该获得贷款，而人类更容易判断该决定是否基于习得的人口统计学（例如种族）偏见。
- 隐私：确保数据中的敏感信息受到保护。
- 可靠性或稳健性：确保输入的微小变化不会导致预测的重大变化。
- 因果关系：检查是否只存在因果关系。
- 信任：与黑匣子相比，人类更容易信任能够解释其决策的系统。

