---
title: 深度学习(DL)(三) — 探析
date: 2024-09-08 12:15:11
tags:
  - AI
categories:
  - 人工智能
mathjax:
  tex:
    tags: 'ams'
  svg:
    exFactor: 0.03
---

#### 介绍

假设您要输入一个法语句子，如`Jane visite I'Afrique Septembre`，并且要将其翻译成英语句子，`Jane is visiting Africa in September`。我们使用{% mathjax %}x^{<1>},\ldots,x^{<5>}{% endmathjax %}来表示单词和输入序列，我们将使用{% mathjax %}y^{<1>},\ldots,y^{<6>}{% endmathjax %}来表示输出序列中的单词。您如何训练神经网络来输入序列{% mathjax %}x{% endmathjax %}并输出序列{% mathjax %}y{% endmathjax %}？首先，让我们建立一个网络，称之为**编码器网络**，将其构建`RNN`，这可能是`GRU`或`LSTM`，一次一个单词地输入法语单词。在获取输入序列后，`RNN`会输出一个表示输入句子的向量。之后，您可以构建一个**解码器网络**。**编码器网络**的编码输出作为输入，然后可以训练一次一个单词地输出翻译。最后，识别出序列的结尾和解码器停止的句子标记，这样它们在使用语言模型合成文本时保持在之前的序列中。深度学习最显著的成果之一是模型有效性。给定足够多的法语和英语句子对，如果你训练一个模型来输入法语句子并输出相应的英语翻译，这很有效。这个模型只使用一个**编码器网络**，找到输入法语句子的编码，然后使用一个**解码器网络**生成相应的英语翻译。
<!-- more -->

#### 序列->序列

机器翻译模型如下所示，我将使用两种不同的颜色，绿色和紫色，分别表示绿色的**编码器网络**和紫色的**解码器网络**。您会注意到，**解码器网络**看起来与上面的语言模型几乎完全相同。因此，机器翻译模型与语言模型非常相似，只是它不是从全零向量开始，而是有一个**编码器网络**，可以找出输入句子的一些表示，它获取该输入句子，并从输入句子的表示而不是全零的表示开始解码网络。所以，这就是将其称为条件语言模型的原因，它不是对任何句子的**概率**进行建模，而是对输出英语翻译的概率进行建模，条件是输入一些法语句子。例如，翻译为“`Jane is visite l'Afrique en septembre`”的概率是多少，但输入的法语句子的条件是“`Jane visite l'Afrique en septembre`”。这实际上是英语句子以输入的法语句子为条件的概率，这就是为什么它是一个条件语言模型。如果想应用此模型将句子从法语翻译成英语，给定这个输入的法语句子，该模型会告诉您相应的英语翻译存在差异的概率。{% mathjax %}x{% endmathjax %}是法语句子“`Jane visite l'Afrique en septembre`”。并且，不希望随机抽样输出。如果从这个分布中抽取单词，给定{% mathjax %}\mathbf{P}(\hat{y}^{<1>},\ldots,\hat{y}^{<T_y>}|x){% endmathjax %}，也许会得到一个相当不错的翻译，“`Jane is visite l'Afrique en septembre`”。但是，也许另一次你会得到不同的翻译，这听起来有点别扭，但不是一个糟糕的翻译，只是不是最好的。当使用这个模型进行机器翻译时，你并不是从这个分布中随机抽样。相反，你想要的是找到最大化条件概率的英语句子{% mathjax %}y{% endmathjax %}。在开发机器翻译系统时，你需要做的事情就是想出一个算法，可以真正找到最大化这个{% mathjax %}y{% endmathjax %}值。最常见的算法称为**定向搜索**，为什么不直接使用**贪婪搜索**呢？什么是贪婪搜索？**贪婪搜索**是一种计算机算法，它表示要生成第一个单词，只需根据条件语言模型选择最有可能的第一个单词即可。进入机器翻译模型，在选择第一个单词后，选择看起来最有可能的第二个单词，然后选择看起来最有可能的第三个单词。这种算法称为**贪婪搜索**。而你真正想要的是选择整个单词序列，{% mathjax %}y^{<1>},y^{<2>},\ldots,y^{<T_y>}{% endmathjax %}，这可以最大化整个单词的**联合概率**。贪婪方法并不奏效，即只选择最佳的第一个单词，然后在选择最佳的第一个单词后，尝试选择最佳的第二个单词，在此之后，尝试选择最佳的第三个单词。为了证明这一点，让我们考虑以下两个翻译。第一个翻译更好，所以希望在我们的机器翻译中翻译模型会说，对于第一个句子，{% mathjax %}\mathbf{P}(y){% endmathjax %}更高。这只是对法语输入的更好、更简洁的翻译。第二个翻译并不差，只是更冗长，有更多不必要的单词。但是，如果算法选择“`Jane is`”作为前两个单词，因为“`going`”是一个更常见的英语单词，那么在法语输入的情况下，“`Jane is going`”的概率实际上可能高于在法语句子的情况下“`Jane is visit`”的概率。如果最大化前三个单词的概率来选择第三个单词，那么最终可能会选择第二个选项。但是，这最终会导致句子不太理想，根据该模型对{% mathjax %}\mathbf{P}(y|x){% endmathjax %}的测量，句子不太好。如果你想找到单词序列{% mathjax %}y^{<1>},y^{<2>}{% endmathjax %}一直到最后一个单词，使概率最大化，那么一次只选择一个单词并不总是最佳选择。当然，英语句子中单词组合的总数要大得多。如果字典里只有`10,000`个单词，你正在考虑翻译长度不超过`10`个单词，那么就有{% mathjax %}10000^{10}{% endmathjax %}个可能的句子，长度为`10`个单词。从词汇量中挑选单词，字典大小为`10,000`个单词。这是一个巨大句子空间，不可能对它们全部进行评级，这就是为什么最常见的做法是使用**近似搜索算法**。**近似搜索算法**的作用是选择使条件概率最大化的句子{% mathjax %}y{% endmathjax %}。即使不能保证找到使这个值最大化的{% mathjax %}y{% endmathjax %}值，它通常也能做得很好。

##### 集束搜索

**集束搜索**(`Beam Search`)算法是一种**启发式搜索算法**，主要用于处理解空间较大的问题，尤其在自然语言处理(`NLP`)领域的序列生成任务中，如机器翻译、文本摘要和语音识别等。让我们使用法语句子“`Jane, visite l'Afrique en Septembre`”的运行示例尝试**集束搜索**。希望翻译成“`Jane, visits Africa in September`”。**集束搜索**要做的第一件事是选择英语翻译的第一个单词输出。这里列出了`10,000`个单词到词汇表中。为了简化问题，将忽略大写。把所有单词都用小写字母列出来。在**集束搜索**(`Beam Search`)的第一步中，使用这个网络片段，**编码器**用绿色表示，**解码器**用紫色表示，来评估第一个单词的概率。给定输入句子{% mathjax %}x{% endmathjax %}法语输入，第一个输出{% mathjax %}y{% endmathjax %}的概率是多少。**贪婪搜索**只会选择一个最有可能的单词继续前进，而**集束搜索**(`Beam Search`)则可以考虑多种替代方案。**集束搜索**(`Beam Search`)算法有一个参数称为{% mathjax %}B{% endmathjax %}，称为**波束宽度**，在这个例子中，{% mathjax %}B = 3{% endmathjax %}。**集束搜索**(`Beam Search`)会同时考虑三种可能性。假设对第一个单词的不同选择评估这个概率，发现`Jane`和`September`是英语输出中第一个单词最有可能的三种可能性。**集束搜索**(`Beam Search`)会尝试这三个单词的信息隐藏在计算机内存中，如果**集束宽度**参数的设置不同，{% mathjax %}B = 10{% endmathjax %}，那么跟踪第一个单词最有可能的`10`个选项，而不是`3`个。为了执行**集束搜索**(`Beam Search`)的第一步，需要做的是将输入的法语句子通过**编码器网络**运行，这是一个总共`10,000`种可能性的`softmax`输出。然后将获取这`10,000`个可能的输出，并将其中的前三个输出保存在内存中。**集束搜索**(`Beam Search`)的第二步。在选择了`in、Jane`和`September`作为第一个单词最有可能的三个选项之后，**集束搜索**(`Beam Search`)现在要做的是，针对这三个选项中的每一个，考虑第二个单词应该是什么，所以在“`in`”之后，第二个单词可能是“`a`”，可能是`September`，列表中有`visit`，然后一直到`z`，最后一个单词是`zulu`。为了评估第二个单词的概率，它将使用此神经网络片段，其中绿色的是`coder`，对于**解码器**部分，**解码器**首先输出{% mathjax %}\hat{y}^{<1>}{% endmathjax %}。把这个{% mathjax %}\hat{y}^{<1>}{% endmathjax %}设置为单词“`in`”。然后它将输出是{% mathjax %}\hat{y}^{<2>}{% endmathjax %}。通过{% mathjax %}\hat{y}{% endmathjax %}，这里的输入实际上是第一个单词“`in`”，这个网络片段可用于评估给定输入法语句子的第二个单词的概率，以及翻译的第一个单词是否是单词“`in`”。现在请注意，我们最终关心的是在这个第二步的**集束搜索**(`Beam Search`)中，找到最有可能的第一个单词和第二个单词的配对，而不仅仅是第二个单词，其中最有可能的是第一个单词和第二个单词的配对，而最有可能的是**条件概率规则**。这可以表示为{% mathjax %}\mathbf{P}(y^{<1>}|x^{<1>})\mathbf{P}(y^{<2>}|x^{<2>}){% endmathjax %}。这是从这个网络片段中获得的，如果对于选择的三个单词“`in`”、“`Jane`”和“`September`”，您保存了这个概率，那么您可以将它们乘以第二个概率以获得第一个单词和第二个单词的概率。所以现在你已经看到了如果第一个单词是“`in`”，你如何评估第二个单词的概率。一开始是“`Jane`”。句子可以是“`Jane a`”、“`Jane Aaron`”，等等，直到“`Jane is`”、“`Jane visits`”等等。你会在神经网络片段中使用它，在这里你会硬连线，{% mathjax %}\hat{y}^{<1>}{% endmathjax %}是`Jane`。所以第一个单词{% mathjax %}y{% endmathjax %}被硬连线为 `Jane`，那么网络片段就可以告诉您第二个单词的概率。假设第一个单词是“`Jane`”。与上述相同，{% mathjax %}\mathbf{P}(y^{<1>},y^{<2>}|x) = \mathbf{P}(y^{<1>}|x)\mathbf{P}(y^{<2>}|x,y^{<1>}){% endmathjax %}。最后对`September`执行相同的操作，从`a`到`Zulu`的所有单词，并使用这个网络片段。第一个单词是否是`September`。第二个单词最有可能的选项是什么。对于第二步的**集束搜索**(`Beam Search`)，继续使用{% mathjax %}B = 3{% endmathjax %}束宽度，词汇表中有`10,000`个单词，最终会考虑{% mathjax %}3\times 10000{% endmathjax %}种可能性，因为这里有{% mathjax %}10000\times 10000{% endmathjax %}个单词数，您要做的是根据可能的第一个和第二个单词评估这`30,000`个选项，然后选择前三个。因此，经过缩减，这`30,000`个可能性再次减少到`3`，**集束宽度**再次四舍五入，假设`30,000`个选项中最有可能的是`September`，如果**集束搜索**(`Beam Search`)确定最有可能的选择是第一个和第二个单词是`in September、Jane is`或`Jane visits`。那么它现在拒绝 `September`作为输出英语翻译的第一个单词的候选，现在只剩下两个单词的可能性，但仍然{% mathjax %}B = 3{% endmathjax %}，用于跟踪{% mathjax %}y^{<1>},y^{<2>}{% endmathjax %}对的三个选择，最后进入**集束搜索**(`Beam Search`)的第三步。由于{% mathjax %}B = 3{% endmathjax %}，每一步你都会实例化三个网络副本来评估这些部分句子片段和输出。正是因为{% mathjax %}B = 3{% endmathjax %}，才有三个网络副本，对于第一个单词有不同的选择，但这三个网络副本可以非常有效地用于评估第二个单词的所有`30,000`个选项。不要实例化`30,000`个网络副本或三个网络副本来快速地评估该`softmax`输出的`10,000`个可能的输出，假设前两个单词最有可能的选择是`in September、Jane is 和 Jane visits`，对于这些单词对，我们应该在计算机内存中保存{% mathjax %}By^{<1>}{% endmathjax %}和{% mathjax %}y^{<2>}{% endmathjax %}的概率，给定输入{% mathjax %}x{% endmathjax %}。现在要考虑第三个单词是什么。那么`in September a？In September Aaron？`一直到`in September Zulu`，为了评估第三个单词的可能选择，可以使用这个网络片段，其中将第一个单词硬连线为第二个单词`September`。因此，这个网络片段允许您评估第三个单词的概率，给定输入法语句子{% mathjax %}x{% endmathjax %}，给定前两个单词`in September`和英语输出。然后对第二个片段执行相同的操作。就像这样。对`Jane visits`执行相同的操作，**集束搜索**(`Beam Search`)将再次选择前三个可能，可能是`September`。`Jane`是可能的结果，或者`Jane is visiting`是可能的，或者`Jane visits Africa`是可能的，这是前三个词，然后进入第四步，即**定向搜索**，再加一个词，然后继续。这个过程的结果是，希望每次添加一个词，**定向搜索**将决定这一点。`Jane visits Africa in September`将在句子结尾符号处终止。对于三个**定向搜索**一次考虑三种可能性。注意，如果定向宽度等于`1`，那么本质上就变成了**贪婪搜索算法**，但同时考虑多种可能性，比如说三个、十个或其他数字，**定向搜索**通常会找到比**贪婪搜索**更好的输出句子。

**集束搜索**以最大化{% mathjax %}\text{arg}\;\underset{y}{\max}\prod_{t=1}^{T_y}\mathbf{P}(y^{<t>}|x,y^{<1>},\ldots,y^{<t-1>}){% endmathjax %}概率。这些概率都是小于`1`的数字，将许多小于`1`的数字相乘会得到一个很小的数字，对于计算机中浮点表示来说，这个数字太小，无法准确存储。在实践中，不会最大化这个乘积，而是取对数，如果你在那里插入一个对数，那么乘积的对数就变成了对数的总和，最大化这个对数概率的总和应该会在选择最可能的句子给你相同的结果({% mathjax %}\text{arg}\;\underset{y}{\max}\prod_{t=1}^{T_y}\log\mathbf{P}(y^{<t>}|x,y^{<1>},\ldots,y^{<t-1>}){% endmathjax %})。通过取对数，你最终会得到一个更稳定的算法，它不太容易出现数值舍入错误。因为对数函数是一个单调递增的函数，我们知道，给定{% mathjax %}\log\mathbf{P}(y|x){% endmathjax %}的结果，给定{% mathjax %}\mathbf{P}(y|x){% endmathjax %}，{% mathjax %}y{% endmathjax %}的值相同。跟踪概率对数的总和，而不是概率的乘积。这个目标函数还有另一个变化，使机器翻译算法工作得更好。如果参考上面的目标，如果有一个很长的句子，那么这个句子的概率会很低，因为这里乘以了很多项，很多小于`1`的数字来估计这个句子的概率。如果你将小于`1`的数字的对数相乘，你最终会得到一个较小的概率。这个**目标函数**有一个不良影响，它可能倾向于选择非常短的翻译输出，因为短句子的概率只是通过乘以这些数字中小于`1`的数，乘积不会那么小。同样的事情也适用于这种情况，概率的对数总是小于或等于`1`，对数的范围是这样的，所以加在一起的项越多，这个对数就越负。还有另一个改变算法的方法，那就是不要用这个作为最大化的目标。根据翻译中的单词数量进行**归一化**，这样就可以取每个单词概率对数的平均值，这确实可以显著降低输出较长翻译的惩罚。在实践中，作为一种启发式方法，而不是用{% mathjax %}T_y{% endmathjax %}除以输出句子中的单词数量，有时你会使用更温和的方法，我们有{% mathjax %}T_y^{\alpha}{% endmathjax %}，其中{% mathjax %}\alpha = 0.7{% endmathjax %}。如果{% mathjax %} \alpha = 1{% endmathjax %}，那么完全按长度**归一化**，如果{% mathjax %}\alpha = 0{% endmathjax %}，那么{% mathjax %}T_y^{0} = 1{% endmathjax %}，根本没有**归一化**，这介于完全归一化和无归一化之间。{% mathjax %}\alpha{% endmathjax %}是另一个超参数。以这种方式使用{% mathjax %}\alpha{% endmathjax %}，这是启发式方法还是一种破解方法？它没有很好的理论依据，但人们发现它效果很好，可以尝试不同的{% mathjax %}\alpha{% endmathjax %}值，看看哪一个能给你最好的结果。总结一下，如何进行**定向搜索**，当您运行**定向搜索**时，会看到很多句子的长度{% mathjax %}T_y =\{1,2,3,\ldots,30\}{% endmathjax %}。输出句子并根据这个分数对它们进行评分，这样你就可以选出最热门的句子，然后通过**集束搜索**计算这个**目标函数**。在你用这种方式评估的所有这些句子中，你选择一个在归一化低概率目标上达到最高值的句子，有时它被称为**归一化对数似然目标**，这将是输出的最终翻译。这就是实现**集束搜索**的方式。最后，您如何选择束宽度？如果束宽度非常大，往往会得到更好的结果。内存需求也会增加，计算速度也会更慢。而如果使用非常小的束宽度，那么会得到更糟糕的结果，因为只记住了更少的可能性，但会更快地得到结果，内存需求也会更低。

假设当你在学习到的`RNN`模型和翻译模型上运行**定向搜索**时，它最终会得到这样的翻译{% mathjax %}\hat{y}{% endmathjax %}，`Jane visits Africa in September`，这是法语的一个更糟糕的翻译。它改变了含义，所以这不是一个好的翻译。你的模型有两个主要组成部分。一个是**神经网络模型**，即**序列到序列模型**(`RNN`)。它实际上是一个**编码器**和一个**解码器**。你有**定向搜索算法**，定向宽度为{% mathjax %}b{% endmathjax %}。是`RNN`还是神经网络的问题，还是定向搜索算法的问题？但就像获得更多训练数据可能无法达到想要的性能水平一样。同样地，增加束宽可能无法让您达到想要的目标。但如何改进搜索算法？如何将问题分解并找出利用时间的方法。现在，`RNN`，神经网络，编码器和解码器。例如，对于一个句子，插入`Jane visits Africa in September`。现在最有用的事情就是使用这个模型计算{% mathjax %}\mathbf{P}(y|x) < \mathbf{P}(y){% endmathjax %}，使用`RNN`模型计算{% mathjax %}\mathbf{P}(\hat{y}|x){% endmathjax %}。然后看看这两个中哪个更大。所以左边可能比右边大。{% mathjax %}\mathbf{P}(y^{\ast}){% endmathjax %}，根据可以将这个特定的错误归咎于`RNN`或**集束搜索**算法中存在错误。计算{% mathjax %}\mathbf{P}(y^{\ast}|x){% endmathjax %}和{% mathjax %}\mathbf{P}(\hat{y}|x){% endmathjax %}，看看这两个中哪个更大。所以会有两种情况。在情况`1`中，`RNN`模型输出的{% mathjax %}\mathbf{P}(y^{\ast}|x) > \mathbf{P}(\hat{y}|x){% endmathjax %}。**定向搜索算法**选择了{% mathjax %}\hat{y}{% endmathjax %}，有一个计算 {% mathjax %}\mathbf{P}(y|x){% endmathjax %}的`RNN`。**定向搜索**的工作是找到一个使该参数最大的{% mathjax %}y{% endmathjax %}值。但在这种情况下，{% mathjax %}y^{\ast}{% endmathjax %}比 {% mathjax %}\hat{y}{% endmathjax %}获得了更高的{% mathjax %}\mathbf{P}(y|x){% endmathjax %}值。因此，**定向搜索**无法提供最大化{% mathjax %}\mathbf{P}(y|x){% endmathjax %}值，**定向搜索**的工作是找到这个非常大的{% mathjax %}y{% endmathjax %}值。{% mathjax %}y^{\ast}{% endmathjax %}获得了更大的值。可以得出结论，**定向搜索**有问题。在情况`2`中，{% mathjax %}\mathbf{P}(y^{\ast}|x) \leq \mathbf{P}(\hat{y}|x){% endmathjax %}。在例子中，{% mathjax %}y^{\ast}{% endmathjax %}比{% mathjax %}\hat{y}{% endmathjax %}翻译得更好。根据`RNN`，{% mathjax %}\mathbf{P}(y^{\ast}) \leq \mathbf{P}(\hat{y}){% endmathjax %}，因此说{% mathjax %}y^{\ast}{% endmathjax %}是比{% mathjax %}\hat{y}{% endmathjax %}输出的概率更低。

机器翻译面临的挑战是，给定一个法语句子，会有多个英语翻译与该法语句子表现的一样好。如果有多个一样好的翻译结果，如何评估机器翻译系统呢？这不同于图像识别，后者只有一个正确结果。你只需测量准确度。如果有多个一样好的结果，你如何测量准确度？传统方法是通过`BLEU`分数来完成的。假设有一个法语句子`Le chat est sur le tapis`。你获得了一个人工生成的翻译，`the cat is on the mat`。但是这个句子有多个不错的翻译。所以不同的人可能会把它翻译成：`there is a cat on the mat`。这两个都是对法语句子的完美翻译。`BLEU`分数的作用是，给定一个机器翻译，它允许您自动计算一个分数来衡量机器翻译的好坏。只要机器生翻译非常接近人类提供的参考，它就会得到一个很高的`BLEU`分数。`BLEU`代表双语评估。虽然可以让人类评估者评估机器翻译系统，但`BLEU`分数可以替代让人类评估机器翻译系统的每个输出。所以`BLEU`分数是`Kishore Papineni、Salim Roukos、Todd Ward`和`Wei-Jing Zhu`的功劳。这篇论文具有很高的影响力。查看机器生成的输出，看看它生成的单词类型是否出现在至少有一个人工生成的参考文献中。这些人工生成的参考文献将作为开发集或测试集的一部分被提供。现在，让我们看一个有点极端的例子。假设机器翻译系统简称**机器翻译**`MT`。因此，机器翻译输出是`the the the the the the the`。这显然是一个非常糟糕的翻译。衡量机器翻译输出好坏的一种方法是查看输出中的每个单词，看看它是否出现在参考文献中。这将被称为机器翻译输出的精度。在这种情况下，机器翻译输出中有`7`个单词都出现在参考文献`1`或参考文献`2`中，单词`the`出现在两个参考文献中。因此，其精度为`7/7`。看起来精度很高。因此，**精度测量**是机器翻译输出中有多少单词也出现在参考文献中。这不是一个特别有效的测量方法。接下来将使用一种经过修改的精度测量方法，我们将只给每个单词在参考句子中出现的最大次数的**信用**。在参考文献`1`中，单词`the`出现了`2`次。在参考文献`2`中，单词`the`只出现了`1`次。因此单词`the`最多获得两次**信用**。使用经过修改的精度，它在`7`个单词中得到`2`分。这里的分母是单词`the`在总共`7`个单词中出现的次数。分子是单词出现的次数`2`，即`2/7`。我们截取这个计数，取最大值，或者将这个计数截取为 `2`。这样我们就得到了修改后的精度测量。到目前为止，我们一直在孤立地查看单词。`BLEU`分数中，不想只查看孤立的单词。可能还想查看成对的单词。让我们根据二元组定义`BLEU`分数。二元组指成对出现的单词。让我们看看如何使用二元组来定义`BLEU`分数。`The cat the cat on the mat`。这仍然不是很好的翻译，但可能比上一个好。所以这里，可能的二元组是`cat`。然后是`cat the`，这是另一个二元组。然后`cat on`是下一个。然后是`on the`，以及`the mat`。这些是机器翻译输出中的二元组。让我们计算一下，每个二元组出现了多少次。`The cat`出现了`2`次，`cat the`出现了`1`次，其他的都只出现了`1`次。最后，定义剪裁计数即{% mathjax %}\text{count}_{\text{clip}}{% endmathjax %}。二元语法在参考文献`1`或参考文献`2`中出现的最大次数。`cat`在任一参考文献中最多出现`1`次。所以把这个剪裁计数为`1`。这些是剪裁后的计数。我们取所有计数并进行剪裁，将它们减少到不超过该二元语法在至少一个参考文献中出现的次数。最后，我们修改后的二元语法精度将是剪裁后的计数之和。所以这是`1、2、3、4`除以二元语法的总数。即`2、3、4、5、6`，因此`2/3`是二元组的修正精度。根据我们在单元组上所取得的成果，我们将计算单元组的修正精度定义为{% mathjax %}\mathbf{P}_1 = \frac{\sum_{\text{unigram}\in\hat{y}}\text{Count}_{\text{clip}}(\text{unigram})}{\sum_{\text{\unigram}}\text{Count}(\text{\ungram})}{% endmathjax %}。{% mathjax %}\mathbf{P}{% endmathjax %}代表精度，这里的下标`1`表示单元组。这表示对机器翻译输出中出现的单词的总和。这称该单元组的计数{% mathjax %}\hat{y}{% endmathjax %}。除以机器翻译输出中单元组的总和，即该单元组的计数数量？这里的`1`指的是单元组。如果机器翻译输出与参考文献`1`或参考文献`2`完全相同，那么所有这些值{% mathjax %}\mathbf{P}_1,\mathbf{P}_2{% endmathjax %}都将等于`1.0`。有时即使翻译输出与参考文献不完全相同，也可以实现这一点。最后，把它们放在一起形成最终的`BLEU`分数。{% mathjax %}\mathbf{P}_n = \frac{\sum_{\text{n-gram}\in\hat{y}}\text{Count}_{\text{clip}}(\text{n-gram})}{\sum_{\text{n-gram}\in\hat{y}}\text{Count}(\text{n-gram})}{% endmathjax %}是基于`n-gram`计算的`BLEU`分数。也是基于`n-gram`计算的修改后的精度。按照惯例，需要计算{% mathjax %}\mathbf{P}_1,\mathbf{P}_2,\mathbf{P}_3{% endmathjax %}和{% mathjax %}\mathbf{P}_4{% endmathjax %}，然后使用以下公式将它们组合在一起。它将是平均值，因此将{% mathjax %}\text{exp}(\frac{\sum_{n=1}^4\mathbf{P}_n}{4}){% endmathjax %}。取平均值。`BLEU`分数定义为，然后是指数和线性运算，指数是单调递增的运算，然后用`BP`惩罚来调整它。`BP`代表简洁性惩罚。如果你输出非常短的翻译，更容易获得高精度。因为你输出的大多数单词可能都出现在参考文献中。但我们不想要非常短的翻译。因此，`BP`是一个**调整因子**，它惩罚输出太短翻译的翻译系统。简洁性惩罚的公式如下图所示。如果机器翻译系统输出的内容比人工生成的参考文献更长，则它等于`1`。
{% asset_img dl_1.png %}
