---
title: 机器学习(ML)(十二) — 推荐系统探析
date: 2024-10-22 15:37:11
tags:
  - AI
categories:
  - 人工智能
mathjax:
  tex:
    tags: 'ams'
  svg:
    exFactor: 0.03
---

#### 概念介绍

**推荐系统**(`Recommendation system`)的链路包括两个重要的步骤：**检索**（称**召回**）和**排名**（分为**粗排**，**精排**和**重排**）**检索**或**召回**主要用于衡量系统从全量信息中找出相关内容的能力。它的核心目的是在用户查询的背景下，尽可能多地返回与之相关的信息。如下图所示：
{% asset_img ml_1.png "推荐系统的链路" %}
<!-- more -->

**推荐系统**(`Recommendation system`)的目标是从物品的数据库中取出几十个物品展示给用户。**推荐系统**链路上的第一环是**检索**或**召回**，就是从数据库中快速取回一些物品，在实践中，**推荐系统**有很多条**召回通道**（如**协同过滤**、**双塔模型**、**关注的作者**等等），每条**召回通道**取回几百个物品。这些**召回通道**一共返回几千个物品，然后**推荐系统**会融合这些物品，并且做去重和过滤，过滤的意思是排除掉不喜欢的物品，召回几千个物品之后，下一步是**排序**，**排序**要用机器学习模型预估用户对物品的兴趣，保留评分最高的物品，如果用一个大规模神经网络逐一对几千个物品打分，花费的代价会很大，为了解决计算量的问题，通常把排序分为**粗排**和**精排**。**粗排**一般使用比较简单的模型，快速给几千个物品打分，保留分数最高的几百个物品；**精排**用一个较大的**神经网络**给几百个物品打分，不用做截断。**精排模型**比**粗排模型**大很多，用的特征也更多，所以**精排模型**打的分数也更可靠。但是**精排模型**的计算量也很大，这就是为什么我们用**粗排模型**先做筛选，然后才用**精排模型**，这样做可以很好的平衡**计算量**和**准确性**。做完**粗排**和**精排**得到几百个物品，每个物品都有一个分数，表示用户多物品的兴趣有多高。可以直接把物品按照打的分数排序，然后展示给用户，但此时的结果还是会存在一些不足，需要做一些调整，这一步叫做**重排**。**重排**主要是考虑**多样性**，要根据多样性进行随机抽样，从几百个物品中选择出几十个物品，然后还要使用规则把相似的物品打散，**重排**的结果就是展示给用户的物品。比如把`top50`的物品（包含广告）展示给用户。如下图所示：
{% asset_img ml_2.png "推荐系统：排序" %}

**精排**与**粗排**的唯一区别就是**精排**用的模型更大，特征更多，模型的输入包括用户特征、物品特征、统计特征。假如要判断用户对某个物品感兴趣，我们就要把该用户的特征、物品的特征和统计特征输入**神经网络**，神经网络会输出很多数值，比如点击率、点赞率、收藏率、转发率等等，这些数值都是神经网络对用户行为的预估。这些数值越大说明用户对该物品越感兴趣，最后把多个预估值做融合，得到最终的分数。比如求加权和，这个分数决定了这个物品会不会展示给用户，以及物品展示的位置是靠前还是靠后，请注意，这只是对一个物品的打分，**粗排**要对几千个物品打分，**精排**要对几百个物品打分。每个物品都用多个预估分数融合成一个分数作为给这个物品排序的依据。**推荐系统**链路上的最后一环是**重排**，重排最重要的能力是**多样性抽样**（比如`MMR`、`DPP`），需要从几百个物品中选出几十个物品。**多样性抽样**的时候有两个依据：一个依据是**精排**分数的大小，另一个依据是**多样性**。做完**多样性抽样**之后会根据规则将相似物品打散。重排的另一个目的是插入广告、运营推广的内容，根据生态要求调整排序。
{% asset_img ml_3.png "精排、粗排" %}

#### A/B测试

做`A/B`测试需要对用户做**随机分桶**，比如把用户随机分成`10`个桶，每个桶中有`10%`的用户，如果用户的数量足够大，那么每个桶的`DAU`留存、点击率这些指标都是相等的。具体分桶的方法是：首先用哈希函数吧用户`ID`映射成某个区间内的整数，然后把这些整数均匀随机分成{% mathjax %}b{% endmathjax %}个桶。我们把用户随机分成`10`个桶，每个桶有`10%`的用户，接下来才用这样的桶来做`A/B`测试。比如我们想要考察`GNN`(**图神经网络**)对**召回通道**指标的影响。有`1、2、3`号桶作为三个实验组，但是`GNN`的参数不一样，三个桶的神经网络分别是一层、两层、三层。用`4`号桶作为对照组，这四个桶唯一的区别就是前三个桶用了`GNN`召回通道，`4`号桶没有用`GNN`。如果一个用户落在`1`号桶，那么给它做推荐的时候，会使用一层的`GNN`神经网络做召回；如果另一个用户落在了`4`号桶，那么给它做推荐的时候，则不使用`GNN`做召回。分别计算每个桶的业务指标，比如`DAU`、人均使用推荐时长、点击率等等。如果过某个实验组的指标显著优于对照组，则说明对应的策略有效，值得推全（意思是把流量扩大到`100%`）。

**分层实验**的目标就是解决流量不够用的问题。主要是因为信息流产品的公司有很多部门和团队，大家都需要做`A/B`测试，比如：推荐系统（召回、粗排、精排、重排）、用户界面、广告等。如果把用户随机分成`10`组，`1`组作对照，`9`组做实验，那么只能同时做`9`组实验。这样会导致流量资源完全不够用。解决方案就是**分层实验**，把实验分成很多层，比如分成：召回、粗排、精排、重排、用户界面、广告等等（例如`GNN`召回通道就属于**召回层**）。**同层之间的实验需要互斥**，例如：`GNN`实验占了召回层的`4`个桶，其它召回实验只能使用剩下的`6`个桶。**同层互斥**的目的是避免一个用户同时被两个召回实验影响，加入两个实验相互干扰，实验结果会变的不可控；**不同层之间流量正交**：每一层独立随机对用户做分桶。每一层都可以独立用`100%`的用户做实验。召回和粗排的用户是随机划分的。召回的2号桶和粗排的2号桶交集很小，举个例子召回层和精排层各自独立随机把用户分成十个桶，分别是{% mathjax %}u_1,u_2,\ldots,u_{10}{% endmathjax %}和{% mathjax %}v_1,v_2,\ldots,v_{10}{% endmathjax %}。设系统共有{% mathjax %}n{% endmathjax %}个用户，那么{% mathjax %}|u_i| = |v_i| = \frac{n}{10}{% endmathjax %}。召回桶{% mathjax %}u_i{% endmathjax %}和召回桶{% mathjax %}u_j{% endmathjax %}交集为{% mathjax %}u_i \cap u_j = \varnothing{% endmathjax %}。所以同一层实验之间是互斥的，两个召回实验不会作用的一个用户上。召回桶{% mathjax %}u_i{% endmathjax %}和精排桶{% mathjax %}v_j{% endmathjax %}交集的大小为{% mathjax %}|u_i\cap v_j| = \frac{n}{100}{% endmathjax %}。一个用户不能同时受两个召回实验的影响。但可以同时受一个召回实验和一个精排实验的影响，一个召回实验和一个精排实验各自作用在{% mathjax %}\frac{n}{10}{% endmathjax %}个用户上，那么有{% mathjax %}\frac{n}{100}{% endmathjax %}的用户同时受两个实验的影响。也就是说，**同层互斥，不同层正交**。如果所有实验都正交，则可以同时做无数组实验。但是同类策略天然互斥（例如精排模型的两种结构），对于一个用户，只能用其中一种；同类策略（例如添加两条召回通道）效果会相互增强(`1+1 > 2`)或相互抵消(`1+1 < 2`)，互斥可以避免**同类策略**相互干扰；不同类型的策略（例如添加召回通道、优化粗排模型）通常不会相互干扰(`1+1 = 2`)，可以作为正交的两层。

#### 召回 — ItemCF

**基于物品的协同过滤**(`ItemCF`)的基本思想：如果用户喜欢物品{% mathjax %}\text{item}_1{% endmathjax %}，而且物品{% mathjax %}\text{item}_1{% endmathjax %}与{% mathjax %}\text{item}_2{% endmathjax %}相似，那么用户很可能喜欢物品{% mathjax %}\text{item}_2{% endmathjax %}。每个物品都交互过若干物品，比如点击、点赞、收藏、转发过的物品，可以量化用户对物品的兴趣，如点击、点赞、收藏、转发各站`1`分，在这个例子中，用户对四个物品的兴趣分数分别是`2,1,4,3`，这里有一个没有跟用户交互过得物品，我们要决定是否要把这个物品推荐给用户。假设我们知道物品两两之间的相似度，比如它们的相似度分别是：`0.1、0.4、0.2、0.6`。使用如下公式：{% mathjax %}\sum_j \text{like}(\text{user},\text{item}_j) \times \text{sim}(\text{item}_j, \text{item}){% endmathjax %}来预估用户对候选物品的兴趣。这一项{% mathjax %}\text{like}(\text{user},\text{item}_j){% endmathjax %}是用户对第{% mathjax %}j{% endmathjax %}个物品的兴趣，这一项{% mathjax %}\text{sim}(\text{item}_j, \text{item}){% endmathjax %}是第{% mathjax %}j{% endmathjax %}个物品与候选物品的相似度。把这两项相乘，再把所有的乘积相加，得到总分，总分表示用户对候选物品的兴趣，在这个例子中从用户到候选物品有`4`条路径，所以要计算4个分数，然后把它们相加，预估用户对候选物品的兴趣：{% mathjax %}2\times 0.1 + 1\times 0.4 + 4\times 0.2 + 3\times 0.6 = 3.2{% endmathjax %}。
{% asset_img ml_4.png "预估用户对候选物品的兴趣：2x0.2 + 1x0.4 + 4x0.2 = 3.2" %}

举个例子有`2000`个候选物品，我们逐一计算用户对候选物品的兴趣分数，然后返回分数最高的`100`个物品，如何计算两个物品之间的相似度？计算物品相似度的思路是这样的，两个物品受众重合度越高，两个物品越相似。我们可以从数据中挖掘出物品的相似度，把喜欢物品{% mathjax %}i_1{% endmathjax %}的用户记作集合{% mathjax %}w_1{% endmathjax %}，{% mathjax %}w_1{% endmathjax %}是用户的集合；把喜欢物品{% mathjax %}i_2{% endmathjax %}的用户记作集合{% mathjax %}w_2{% endmathjax %}，把交集{% mathjax %}v{% endmathjax %}定义为{% mathjax %}v = w_1 \cap w_2{% endmathjax %}，{% mathjax %}v{% endmathjax %}表示同时喜欢物品{% mathjax %}i_1,i_2{% endmathjax %}的用户，则两个物品{% mathjax %}i_1,i_2{% endmathjax %}的相似度定义为{% mathjax %}\text{sim}(i_1,i_2) = \frac{|v|}{\sqrt{|w_1|\cdot |w_2|}}{% endmathjax %}。分子表示对两个物品{% mathjax %}i_1,i_2{% endmathjax %}都感兴趣的用户人数，分母表示集合{% mathjax %}w_1,w_2{% endmathjax %}大小的乘积再取根号，这样计算出的相似度一定是介于`0~1`之间的数，值越大表示两个物品越相似。为什么相似度是介于`0~1`之间的呢？这是集合{% mathjax %}v{% endmathjax %}比集合{% mathjax %}w_1,w_2{% endmathjax %}都要小。注意，这个公式没有考虑喜欢的程度，用这个公式只要是喜欢都看作`1`，不喜欢都看做`0`。如果想用到喜欢的程度，需要改一下这个公式。比如点击、点赞、收藏、转发各自算1分，喜欢物品的程度最多可以是4分。现在我们考虑用户喜欢物品的程度，则公式更改为{% mathjax %}\text{sim}(i_1,i_2) = \frac{\sum_{c\in v}\text{like}(c,i_1)\cdot \text{like}(c,i_2)}{\sqrt{\sum_{u_1\in w_1}\text{like}^2(u_1,i_1)}\cdot\sqrt{\sum_{u_2\in w_2}\text{like}^2(u_2,i_2)}}{% endmathjax %}。分子把用户{% mathjax %}c{% endmathjax %}对物品{% mathjax %}i_1,i_2{% endmathjax %}喜欢的分数相乘并连加，连加是关于用户{% mathjax %}c{% endmathjax %}取得同时喜欢两个物品。如果兴趣分数的取值是`0`或`1`，那么分子就是同时喜欢两个物品的人数就是集合{% mathjax %}v{% endmathjax %}的大小，分母是两个根号的乘积，第一项是用户对物品{% mathjax %}i_1{% endmathjax %}的兴趣分数，关于所有用户连加开根号，第二项是用户对物品{% mathjax %}i_2{% endmathjax %}的兴趣分数，关于所有用户连加开根号。这个公式计算的数值介于`0~1`之间，表示两个物品的相似度，其实这个公式就是**余弦相似度**(`cosine similatity`)。把一个物品表示为一个**稀疏向量**，向量每个元素对应一个用户，元素的值就是用户物品的兴趣分数，两个向量夹角的余弦就是这个这个公式。

**基于物品的协同过滤**(`ItemCF`)召回的完整流程：为了能在线上做到实时的推荐，系统必须事先做离线计算，建立两个索引，一个索引是”用户 -> 物品“索引，记录每个用户最近点击、交互过的物品`ID`。有了这个索引之后，给定任意用户`ID`，可以找到它近期感兴趣的物品列表。另一个索引是”物品 -> 物品“索引，我们首先要计算物品之间两两相似度，这个计算量会比较大，对于每个物品，索引它最相似的{% mathjax %}k{% endmathjax %}个物品，比如{% mathjax %}k = 10{% endmathjax %}，有了这个索引之后，给定任意物品`ID`，可以快速的找到它最相似的{% mathjax %}k{% endmathjax %}个物品，而且知道相似度分数。如下图所示：
{% asset_img ml_5.png "左侧：用户->物品的索引，右侧：物品->物品的索引" %}

有了索引之后我们以在线上给用户做实时推荐，比如系统知道用户的`ID`，首先查看用户—>物品的索引，可以快速找到用户近期感兴趣的物品列表(`last-n`)，对于`last-n`列表中的每一个物品，利用物品—>物品的索引，找到`top-k`相似物品。用户最近有{% mathjax %}n{% endmathjax %}个感兴趣的物品，我们又找到了每个物品的`top-k`相似物品。那么一共取回{% mathjax %}n\times k{% endmathjax %}个物品，对于取回的{% mathjax %}n\times k{% endmathjax %}个相似物品，用公式预估用户对物品的兴趣分数。按照分数从高到低对物品排序，返回分数最高的`100`个物品作为推荐结果。这`100`个物品就是这个`ItemCF`召回通道的输出，会跟其它召回通道的输出融合起来，然后做排序，最终展示给用户。为什么要使用索引呢？数据库中有上亿个物品，如果挨个用公式计算对所用物品的兴趣分数，计算量会爆炸，索引的意义在避免枚举所有的物品。加入我们记录用户最近感兴趣的{% mathjax %}n = 200{% endmathjax %}个物品，取回每个物品最相似的{% mathjax %}k = 10{% endmathjax %}个物品。那么一共取回{% mathjax %}n\times k = 2000{% endmathjax %}个物品打分（用户对物品的兴趣）。用公式给这`2000`个物品打分，也就是分别预估对这`2000`个物品的兴趣分数，返回分数最高的`100`个物品作为`ItemCF`召回通道的输出。这样的计算量是很小的，可以做到在线实时计算。总结一下，用索引，离线计算量大，线上计算量小。好处是每次线上召回速度都很快，只需要给`2000`个物品打分，不需要访问上亿个物品。

整个流程是用户登录之后，系统给用户做推荐，知道用户的`ID`，利用”用户 -> 物品“的索引，找到用户近期感兴趣的物品列表，这个列表记录了用户`ID`和用户对该物品的兴趣的分数。接下来我们要利用物品->物品的索引，找到每个物品的`top-k`相似的物品，知道物品的ID我们要取回与它相似的{% mathjax %}k{% endmathjax %}个物品，这些就是`top-k`相似物品`ID`和相似度。用同样的方法，根据物品->物品的索引，找到每个物品的`top-k`相似物品，`top-k`相似可以召回很多物品，可以用公式{% mathjax %}\text{sim}(i_1,i_2) = \frac{\sum_{c\in v}\text{like}(c,i_1)\cdot \text{like}(c,i_2)}{\sqrt{\sum_{u_1\in w_1}\text{like}^2(u_1,i_1)}\cdot\sqrt{\sum_{u_2\in w_2}\text{like}^2(u_2,i_2)}}{% endmathjax %}计算用户对召回物品的兴趣分数。根据算出的分数做排序，返回排在`top-100`的物品，做计算的时候需要用到这些列表里的数值，用到上面列表用户对物品的兴趣分数，用到下面列表物品对物品相似度分数，把兴趣分数和相似度分数相乘，如果取回的物品`ID`有重复的，就选择去重，最后把分数加起来。线上召回流程如下图所示：
{% asset_img ml_6.png "线上召回流程" %}

#### Swing模型

`Swing`模型的原理就是给用户设置权重，解决小圈子的问题。把用户{% mathjax %}u_1{% endmathjax %}喜欢的物品记作集合{% mathjax %}J_1{% endmathjax %}，把用户{% mathjax %}u_2{% endmathjax %}喜欢的物品记作集合{% mathjax %}J_2{% endmathjax %}，定义两个用户的**重合度**为：{% mathjax %}\text{overlap}(u_1,u_2) = |J_1\cap J_2|{% endmathjax %}。这个值越大说明两个用户{% mathjax %}u_1{% endmathjax %}和{% mathjax %}u_2{% endmathjax %}的重合度高，则它们可能来自一个小圈子，则要降低它们的权重。在计算物品相似度的时候，会把{% mathjax %}\text{overlap}(u_1,u_2){% endmathjax %}放在分母上，把喜欢物品{% mathjax %}i_1{% endmathjax %}的用户记作集合{% mathjax %}W_1{% endmathjax %}，把喜欢物品{% mathjax %}i_2{% endmathjax %}的用户记作集合{% mathjax %}W_2{% endmathjax %}。集合{% mathjax %}V{% endmathjax %}是{% mathjax %}V = W_1\cap W_2{% endmathjax %}。如果一个用户既喜欢物品{% mathjax %}i_1{% endmathjax %}，也喜欢物品{% mathjax %}i_2{% endmathjax %}，那么这个用户就在集合{% mathjax %}V{% endmathjax %}。下面是计算两个物品相似度的公式：{% mathjax %}\text{sim}(i_1,i_2) = \sum\limits_{u_1\in V}\sum\limits_{u_2\in V}\frac{1}{\alpha + \text{overlap}(u_1,u_2)}{% endmathjax %}。`Swing`和`ItemCF`是非常相似的方法，它们之间唯一的区别在于物品相似度。`ItemCF`考察两个物品的重合的受众比例有多高，如果很多用户同时喜欢两个物品，则判定两个物品相似。`ItemCF`会额外考虑重合的用户是否来自同一个小圈子，把同时喜欢两个物品的用户记作集合{% mathjax %}V{% endmathjax %}。对于集合{% mathjax %}V{% endmathjax %}中的用户{% mathjax %}u_1{% endmathjax %}和{% mathjax %}u_2{% endmathjax %}，把两个用户的重合度记作{% mathjax %}\text{overlap}(u_1,u_2) {% endmathjax %}，两个用户重合度大，则可能来自同一个小圈子，权重降低。总而言之，`Swing`和`ItemCF`的区别就是计算物品相似度的时候要降低用户小圈子的影响。

#### 召回 — UserCF

**基于用户的协同过滤**(`UserCF`)与**基于物品的协同过滤**(`ItemCF`)有很多相似之处，`ItemCF`是基于物品之间的相似性做推荐，而`UserCF`是基于用户之间的相似性做推荐。`UserCF`的原理：比如有很多跟我兴趣非常相似的网友，今天跟我兴趣相似的某个网友看了某个物品，他很感兴趣，对物品点赞、转发。于是系统就知道他喜欢这个物品，而我还没有看到这个物品，那么推荐系统就可能给我推荐这个物品。推荐的理由就是跟我兴趣爱好相似的网友喜欢这个物品。推荐系统如何找到跟我兴趣相似的网友呢？一种方法是：判断两个人感兴趣（点击、点赞、收藏、转发）的物品有多少重合，每个用户都有一个列表，上面存储了用户点击、点赞、收藏、转发的物品`ID`，对比两个用户的列表，就知道有多大的重合，重合雨多则说明两个人的兴趣越相似。另一种方法是：不是看物品的重合，而是看关注的作者的重合，每个用户都会关注一些作者，对比两个用户关注作者的列表，就知道有多少关注的作者是重合的。关注的作者重合越多，说明两个人的兴趣越相似。

在用`UserCF`做推荐之前，需要先离线算好每两个用户之间的相似度，例如我们在给左边的用户做推荐，中间是最相似的四个用户，这些分数{% mathjax %}\text{sim}(\text{user},\text{user}_j) = \{0.9,0.7,0.7,0.4\}{% endmathjax %}表示用户之间的相似度，数值越大表示用户越相似。右边的候选物品，左边的用户还没有看过这个候选物品，我们想要预估左边的用户对右边的候选物品兴趣分数有多大。历史数据反映了用户对物品的兴趣，比如点击、点赞、收藏、转发的四种行为各算`1`分，四位用户对候选物品的兴趣分数分别是{% mathjax %}\text{like}(\text{user}_j, \text{item}) = \{0,1,3,0\}{% endmathjax %}，分数越大表示用户对分数越感兴趣，`0`表示用户没有看过该物品，或者对物品不感兴趣。最后用这个公式{% mathjax %}\sum_j \text{sim}(\text{user},\text{user}_j)\times \text{like}(\text{user}_j, \text{item}){% endmathjax %}来预估用户对候选物品的兴趣。这一项{% mathjax %}\text{sim}(\text{user},\text{user}_j){% endmathjax %}是代表左边用户与第{% mathjax %}j{% endmathjax %}个用户的相似度，这一项{% mathjax %}\text{like}(\text{user}_j, \text{item}){% endmathjax %}是第{% mathjax %}j{% endmathjax %}个用户对候选物品的兴趣，把相似度与兴趣分数相乘，在把所有乘积加起来得到总分，表示用户对候选物品的兴趣。从这个例子中，从左边的用户到右边的候选物品一共有四条路径，所以要计算`4`个分数，然后把它们相加：{% mathjax %}0.9\times 0 + 0.7\times 1 + 0.7\times 3 + 0.4\times 0 = 2.8{% endmathjax %}(左边用户对候选物品的兴趣)。举个例子有`2000`个候选物品，计算用户对候选物品的兴趣分数，然后返回分数最高的`top-100`个物品，如下图所示：
{% asset_img ml_7.png "预估用户对候选物品的兴趣：0.9x0 + 0.7x1 + 0.7x3 + 0.4x0 = 2.8" %}

先举例说明两个用户相似和不相似，这两个用户喜欢的物品没有重合，所以不相似。另外两个用户喜欢的物品重合度高，所以判定这两个用户相似。两个用户的相似度是这样计算的，把用户{% mathjax %}u_1{% endmathjax %}喜欢的物品记作集合{% mathjax %}J_1{% endmathjax %}，把用户{% mathjax %}u_2{% endmathjax %}喜欢的物品记作集合{% mathjax %}J_2{% endmathjax %}。把集合{% mathjax %}I = J_1\cap J_2{% endmathjax %}的交集记作{% mathjax %}I{% endmathjax %}，集合{% mathjax %}I{% endmathjax %}包含两个用户共同喜欢的物品，用这个公式{% mathjax %}\text{sim}(u_1,u_2) = \frac{|I|}{\sqrt{|J_1|\cdot |J_2|}}{% endmathjax %}计算{% mathjax %}u_1,u_2{% endmathjax %}的相似度。公式中的分子是集合{% mathjax %}I{% endmathjax %}的大小，几两个用户共同喜欢的物品的个数，公式中的分母是{% mathjax %}J_1,J_2{% endmathjax %}大小的乘积取根号，这样计算出的相似度是介于`0~1`之间的数，数值越接近1表示两个用户越相似。刚才的公式有个不足之处，当公式同等对待热门和冷门的物品，这是不对的，拿书籍推荐举个例子：《哈利波特》是非常热门的物品，不论是大学教授还是中学生都喜欢看《哈利波特》，既然所有人都喜欢看哈利波特，那么哈利波特对于计算用户相似度是没有价值的，越热门的物品越无法反映出用户独特的兴趣，对计算相似就越没有用。重合的物品越冷门，越能反映出用户的兴趣，如果两个用都喜欢《`Deep Learning`》这本书，两个人很可能是同行，如果两个用户都喜欢更冷门一些的书，比如《深度学习在语音识别中的应用》，说明两个人是小同行，为了更好的计算用户兴趣的相似度，我们需要降低热门物品的权重，计算用户相似度的公式可以改写为：{% mathjax %}\text{sim}(u_1,u_2) = \frac{\sum_{l\in I} 1}{\sqrt{|J_1|\cdot |J_2|}}{% endmathjax %}，这里的分子还是集合{% mathjax %}I{% endmathjax %}的大小，只不过换了一种写法，写成了对`1`的连加，其中的{% mathjax %}l{% endmathjax %}表示物品的序号，`1`是物品的权重。所有物品的权重都相同，不论是冷门，还是热门，物品的重要应该跟物品的权重相关，越热门的物品权重应该更低，我们把分子中的1改写为{% mathjax %}\text{sim}(u_1,u_2) = \frac{\sum_{l\in I} \frac{1}{\log(1 + n_l)}}{\sqrt{|J_1|\cdot |J_2|}}{% endmathjax %}，{% mathjax %}\frac{1}{\log(1 + n_l)}{% endmathjax %}表示第{% mathjax %}l{% endmathjax %}个物品的权重，{% mathjax %}n_l{% endmathjax %}是喜欢物品{% mathjax %}l{% endmathjax %}的用户数量，反应物品的热门程度。喜欢《哈利波特》的人数很多，{% mathjax %}n_l{% endmathjax %}就会很大，物品越热门，{% mathjax %}n_l{% endmathjax %}就越大，{% mathjax %}\frac{1}{\log(1 + n_l)}{% endmathjax %}也就越小，也就是说物品的权重越小。这样一来《哈利波特》就会对用户相似度的贡献越小，而冷门物品的贡献就比较大。

