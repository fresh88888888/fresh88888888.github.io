---
title: 机器学习(ML)(十二) — 推荐系统探析
date: 2024-10-22 15:37:11
tags:
  - AI
categories:
  - 人工智能
mathjax:
  tex:
    tags: 'ams'
  svg:
    exFactor: 0.03
---

#### 概念介绍

**推荐系统**(`Recommendation system`)的链路包括两个重要的步骤：**检索**（称**召回**）和**排名**（分为**粗排**，**精排**和**重排**）**检索**或**召回**主要用于衡量系统从全量信息中找出相关内容的能力。它的核心目的是在用户查询的背景下，尽可能多地返回与之相关的信息。如下图所示：
{% asset_img ml_1.png "推荐系统的链路" %}
<!-- more -->

**推荐系统**(`Recommendation system`)的目标是从物品的数据库中取出几十个物品展示给用户。**推荐系统**链路上的第一环是**检索**或**召回**，就是从数据库中快速取回一些物品，在实践中，**推荐系统**有很多条**召回通道**（如**协同过滤**、**双塔模型**、**关注的作者**等等），每条**召回通道**取回几百个物品。这些**召回通道**一共返回几千个物品，然后**推荐系统**会融合这些物品，并且做去重和过滤，过滤的意思是排除掉不喜欢的物品，召回几千个物品之后，下一步是**排序**，**排序**要用机器学习模型预估用户对物品的兴趣，保留评分最高的物品，如果用一个大规模神经网络逐一对几千个物品打分，花费的代价会很大，为了解决计算量的问题，通常把排序分为**粗排**和**精排**。**粗排**一般使用比较简单的模型，快速给几千个物品打分，保留分数最高的几百个物品；**精排**用一个较大的**神经网络**给几百个物品打分，不用做截断。**精排模型**比**粗排模型**大很多，用的特征也更多，所以**精排模型**打的分数也更可靠。但是**精排模型**的计算量也很大，这就是为什么我们用**粗排模型**先做筛选，然后才用**精排模型**，这样做可以很好的平衡**计算量**和**准确性**。做完**粗排**和**精排**得到几百个物品，每个物品都有一个分数，表示用户多物品的兴趣有多高。可以直接把物品按照打的分数排序，然后展示给用户，但此时的结果还是会存在一些不足，需要做一些调整，这一步叫做**重排**。**重排**主要是考虑**多样性**，要根据多样性进行随机抽样，从几百个物品中选择出几十个物品，然后还要使用规则把相似的物品打散，**重排**的结果就是展示给用户的物品。比如把`top50`的物品（包含广告）展示给用户。如下图所示：
{% asset_img ml_2.png "推荐系统：排序" %}

**精排**与**粗排**的唯一区别就是**精排**用的模型更大，特征更多，模型的输入包括用户特征、物品特征、统计特征。假如要判断用户对某个物品感兴趣，我们就要把该用户的特征、物品的特征和统计特征输入**神经网络**，神经网络会输出很多数值，比如点击率、点赞率、收藏率、转发率等等，这些数值都是神经网络对用户行为的预估。这些数值越大说明用户对该物品越感兴趣，最后把多个预估值做融合，得到最终的分数。比如求加权和，这个分数决定了这个物品会不会展示给用户，以及物品展示的位置是靠前还是靠后，请注意，这只是对一个物品的打分，**粗排**要对几千个物品打分，**精排**要对几百个物品打分。每个物品都用多个预估分数融合成一个分数作为给这个物品排序的依据。**推荐系统**链路上的最后一环是**重排**，重排最重要的能力是**多样性抽样**（比如`MMR`、`DPP`），需要从几百个物品中选出几十个物品。**多样性抽样**的时候有两个依据：一个依据是**精排**分数的大小，另一个依据是**多样性**。做完**多样性抽样**之后会根据规则将相似物品打散。重排的另一个目的是插入广告、运营推广的内容，根据生态要求调整排序。
{% asset_img ml_3.png "精排、粗排" %}

#### A/B测试

做`A/B`测试需要对用户做**随机分桶**，比如把用户随机分成`10`个桶，每个桶中有`10%`的用户，如果用户的数量足够大，那么每个桶的`DAU`留存、点击率这些指标都是相等的。具体分桶的方法是：首先用哈希函数吧用户`ID`映射成某个区间内的整数，然后把这些整数均匀随机分成{% mathjax %}b{% endmathjax %}个桶。我们把用户随机分成`10`个桶，每个桶有`10%`的用户，接下来才用这样的桶来做`A/B`测试。比如我们想要考察`GNN`(**图神经网络**)对**召回通道**指标的影响。有`1、2、3`号桶作为三个实验组，但是`GNN`的参数不一样，三个桶的神经网络分别是一层、两层、三层。用`4`号桶作为对照组，这四个桶唯一的区别就是前三个桶用了`GNN`召回通道，`4`号桶没有用`GNN`。如果一个用户落在`1`号桶，那么给它做推荐的时候，会使用一层的`GNN`神经网络做召回；如果另一个用户落在了`4`号桶，那么给它做推荐的时候，则不使用`GNN`做召回。分别计算每个桶的业务指标，比如`DAU`、人均使用推荐时长、点击率等等。如果过某个实验组的指标显著优于对照组，则说明对应的策略有效，值得推全（意思是把流量扩大到`100%`）。

**分层实验**的目标就是解决流量不够用的问题。主要是因为信息流产品的公司有很多部门和团队，大家都需要做`A/B`测试，比如：推荐系统（召回、粗排、精排、重排）、用户界面、广告等。如果把用户随机分成`10`组，`1`组作对照，`9`组做实验，那么只能同时做`9`组实验。这样会导致流量资源完全不够用。解决方案就是**分层实验**，把实验分成很多层，比如分成：召回、粗排、精排、重排、用户界面、广告等等（例如`GNN`召回通道就属于**召回层**）。**同层之间的实验需要互斥**，例如：`GNN`实验占了召回层的`4`个桶，其它召回实验只能使用剩下的`6`个桶。**同层互斥**的目的是避免一个用户同时被两个召回实验影响，加入两个实验相互干扰，实验结果会变的不可控；**不同层之间流量正交**：每一层独立随机对用户做分桶。每一层都可以独立用`100%`的用户做实验。召回和粗排的用户是随机划分的。召回的2号桶和粗排的2号桶交集很小，举个例子召回层和精排层各自独立随机把用户分成十个桶，分别是{% mathjax %}u_1,u_2,\ldots,u_{10}{% endmathjax %}和{% mathjax %}v_1,v_2,\ldots,v_{10}{% endmathjax %}。设系统共有{% mathjax %}n{% endmathjax %}个用户，那么{% mathjax %}|u_i| = |v_i| = \frac{n}{10}{% endmathjax %}。召回桶{% mathjax %}u_i{% endmathjax %}和召回桶{% mathjax %}u_j{% endmathjax %}交集为{% mathjax %}u_i \cap u_j = \varnothing{% endmathjax %}。所以同一层实验之间是互斥的，两个召回实验不会作用的一个用户上。召回桶{% mathjax %}u_i{% endmathjax %}和精排桶{% mathjax %}v_j{% endmathjax %}交集的大小为{% mathjax %}|u_i\cap v_j| = \frac{n}{100}{% endmathjax %}。一个用户不能同时受两个召回实验的影响。但可以同时受一个召回实验和一个精排实验的影响，一个召回实验和一个精排实验各自作用在{% mathjax %}\frac{n}{10}{% endmathjax %}个用户上，那么有{% mathjax %}\frac{n}{100}{% endmathjax %}的用户同时受两个实验的影响。也就是说，**同层互斥，不同层正交**。如果所有实验都正交，则可以同时做无数组实验。但是同类策略天然互斥（例如精排模型的两种结构），对于一个用户，只能用其中一种；同类策略（例如添加两条召回通道）效果会相互增强(`1+1 > 2`)或相互抵消(`1+1 < 2`)，互斥可以避免**同类策略**相互干扰；不同类型的策略（例如添加召回通道、优化粗排模型）通常不会相互干扰(`1+1 = 2`)，可以作为正交的两层。

#### 召回 — ItemCF

**基于物品的协同过滤**(`ItemCF`)的基本思想：如果用户喜欢物品{% mathjax %}\text{item_1}{% endmathjax %}，而且物品{% mathjax %}\text{item}_1{% endmathjax %}与{% mathjax %}\text{item}_2{% endmathjax %}相似，那么用户很可能喜欢物品{% mathjax %}\text{item}_2{% endmathjax %}。每个物品都交互过若干物品，比如点击、点赞、收藏、转发过的物品，可以量化用户对物品的兴趣，如点击、点赞、收藏、转发各站`1`分，在这个例子中，用户对四个物品的兴趣分数分别是`2,1,4,3`，这里有一个没有跟用户交互过得物品，我们要决定是否要把这个物品推荐给用户。假设我们知道物品两两之间的相似度，比如它们的相似度分别是：`0.1、0.4、0.2、0.6`。使用如下公式{% mathjax %}\sum_j \text{like}(\text{user},\text{item}_j) \times \text{sim}(\text{item}_j, \text{item}){% endmathjax %}来预估用户对候选物品的兴趣。这一项{% mathjax %}\text{like}(\text{user},\text{item}_j){% endmathjax %}是用户对第{% mathjax %}j{% endmathjax %}个物品的兴趣，这一项{% mathjax %}\text{sim}(\text{item}_j, \text{item}){% endmathjax %}是第{% mathjax %}j{% endmathjax %}个物品与候选物品的相似度。把这两项相乘，再把所有的乘积相加，得到总分，总分表示用户对候选物品的兴趣，在这个例子中从用户到候选物品有`4`条路径，所以要计算4个分数，然后把它们相加，预估用户对候选物品的兴趣：{% mathjax %}2\times 0.1 + 1\times 0.4 + 4\times 0.2 + 3\times 0.6 = 3.2{% endmathjax %}。
{% asset_img ml_4.png "预估用户对候选物品的兴趣：2x0.2 + 1x0.4 + 4x0.2 = 3.2" %}

举个例子有`2000`个候选物品，我们逐一计算用户对候选物品的兴趣分数，然后返回分数最高的`100`个物品，如何计算两个物品之间的相似度？计算物品相似度的思路是这样的，两个物品受众重合度越高，两个物品越相似。我们可以从数据中挖掘出物品的相似度，把喜欢物品{% mathjax %}i_1{% endmathjax %}的用户记作集合{% mathjax %}w_1{% endmathjax %}，{% mathjax %}w_1{% endmathjax %}是用户的集合；把喜欢物品{% mathjax %}i_2{% endmathjax %}的用户记作集合{% mathjax %}w_2{% endmathjax %}，把交集{% mathjax %}v{% endmathjax %}定义为{% mathjax %}v = w_1 \cap w_2{% endmathjax %}，{% mathjax %}v{% endmathjax %}表示同时喜欢物品{% mathjax %}i_1,i_2{% endmathjax %}的用户，则两个物品{% mathjax %}i_1,i_2{% endmathjax %}的相似度定义为{% mathjax %}\text{sim}(i_1,i_2) = \frac{|v|}{\sqrt{|w_1|\cdot |w_2|}}{% endmathjax %}。分子表示对两个物品{% mathjax %}i_1,i_2{% endmathjax %}都感兴趣的用户人数，分母表示集合{% mathjax %}w_1,w_2{% endmathjax %}大小的乘积再取根号，这样计算出的相似度一定是介于`0~1`之间的数，值越大表示两个物品越相似。为什么相似度是介于`0~1`之间的呢？这是集合{% mathjax %}v{% endmathjax %}比集合{% mathjax %}w_1,w_2{% endmathjax %}都要小。注意，这个公式没有考虑喜欢的程度，用这个公式只要是喜欢都看作`1`，不喜欢都看做`0`。如果想用到喜欢的程度，需要改一下这个公式。比如点击、点赞、收藏、转发各自算1分，喜欢物品的程度最多可以是4分。现在我们考虑用户喜欢物品的程度，则公式更改为{% mathjax %}\text{sim}(i_1,i_2) = \frac{\sum_{c\in v}\text{like}(c,i_1)\cdot \text{like}(c,i_2)}{\sqrt{\sum_{u_1\in w_1}\text{like}^2(u_1,i_1)}\cdot\sqrt{\sum_{u_2\in w_2}\text{like}^2(u_2,i_2)}}{% endmathjax %}。分子把用户{% mathjax %}c{% endmathjax %}对物品{% mathjax %}i_1,i_2{% endmathjax %}喜欢的分数相乘并连加，连加是关于用户{% mathjax %}c{% endmathjax %}取得同时喜欢两个物品。如果兴趣分数的取值是`0`或`1`，那么分子就是同时喜欢两个物品的人数就是集合{% mathjax %}v{% endmathjax %}的大小，分母是两个根号的乘积，第一项是用户对物品{% mathjax %}i_1{% endmathjax %}的兴趣分数，关于所有用户连加开根号，第二项是用户对物品{% mathjax %}i_2{% endmathjax %}的兴趣分数，关于所有用户连加开根号。这个公式计算的数值介于`0~1`之间，表示两个物品的相似度，其实这个公式就是**余弦相似度**(`cosine similatity`)。把一个物品表示为一个向量，向量每个元素对应一个用户，元素的值就是用户物品的兴趣分数，两个向量夹角的余弦就是这个这个公式。





