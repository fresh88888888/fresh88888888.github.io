---
title: 机器学习(ML)(十二) — 推荐系统探析
date: 2024-10-22 15:37:11
tags:
  - AI
categories:
  - 人工智能
mathjax:
  tex:
    tags: 'ams'
  svg:
    exFactor: 0.03
---

#### 概念介绍

**推荐系统**(`Recommendation system`)的链路包括两个重要的步骤：**检索**（称**召回**）和**排名**（分为**粗排**，**精排**和**重排**）**检索**或**召回**主要用于衡量系统从全量信息中找出相关内容的能力。它的核心目的是在用户查询的背景下，尽可能多地返回与之相关的信息。如下图所示：
{% asset_img ml_1.png "推荐系统的链路" %}
<!-- more -->

**推荐系统**(`Recommendation system`)的目标是从物品的数据库中取出几十个物品展示给用户。**推荐系统**链路上的第一环是**检索**或**召回**，就是从数据库中快速取回一些物品，在实践中，**推荐系统**有很多条**召回通道**（如**协同过滤**、**双塔模型**、**关注的作者**等等），每条**召回通道**取回几百个物品。这些**召回通道**一共返回几千个物品，然后**推荐系统**会融合这些物品，并且做去重和过滤，过滤的意思是排除掉不喜欢的物品，召回几千个物品之后，下一步是**排序**，**排序**要用机器学习模型预估用户对物品的兴趣，保留评分最高的物品，如果用一个大规模神经网络逐一对几千个物品打分，花费的代价会很大，为了解决计算量的问题，通常把排序分为**粗排**和**精排**。**粗排**一般使用比较简单的模型，快速给几千个物品打分，保留分数最高的几百个物品；**精排**用一个较大的**神经网络**给几百个物品打分，不用做截断。**精排模型**比**粗排模型**大很多，用的特征也更多，所以**精排模型**打的分数也更可靠。但是**精排模型**的计算量也很大，这就是为什么我们用**粗排模型**先做筛选，然后才用**精排模型**，这样做可以很好的平衡**计算量**和**准确性**。做完**粗排**和**精排**得到几百个物品，每个物品都有一个分数，表示用户多物品的兴趣有多高。可以直接把物品按照打的分数排序，然后展示给用户，但此时的结果还是会存在一些不足，需要做一些调整，这一步叫做**重排**。**重排**主要是考虑**多样性**，要根据多样性进行随机抽样，从几百个物品中选择出几十个物品，然后还要使用规则把相似的物品打散，**重排**的结果就是展示给用户的物品。比如把`top50`的物品（包含广告）展示给用户。如下图所示：
{% asset_img ml_2.png "推荐系统：排序" %}

**精排**与**粗排**的唯一区别就是**精排**用的模型更大，特征更多，模型的输入包括用户特征、物品特征、统计特征。假如要判断用户对某个物品感兴趣，我们就要把该用户的特征、物品的特征和统计特征输入**神经网络**，神经网络会输出很多数值，比如点击率、点赞率、收藏率、转发率等等，这些数值都是神经网络对用户行为的预估。这些数值越大说明用户对该物品越感兴趣，最后把多个预估值做融合，得到最终的分数。比如求加权和，这个分数决定了这个物品会不会展示给用户，以及物品展示的位置是靠前还是靠后，请注意，这只是对一个物品的打分，**粗排**要对几千个物品打分，**精排**要对几百个物品打分。每个物品都用多个预估分数融合成一个分数作为给这个物品排序的依据。**推荐系统**链路上的最后一环是**重排**，重排最重要的能力是**多样性抽样**（比如`MMR`、`DPP`），需要从几百个物品中选出几十个物品。**多样性抽样**的时候有两个依据：一个依据是**精排**分数的大小，另一个依据是**多样性**。做完**多样性抽样**之后会根据规则将相似物品打散。重排的另一个目的是插入广告、运营推广的内容，根据生态要求调整排序。
{% asset_img ml_3.png "精排、粗排" %}

#### A/B测试

做`A/B`测试需要对用户做**随机分桶**，比如把用户随机分成`10`个桶，每个桶中有`10%`的用户，如果用户的数量足够大，那么每个桶的`DAU`留存、点击率这些指标都是相等的。具体分桶的方法是：首先用哈希函数吧用户`ID`映射成某个区间内的整数，然后把这些整数均匀随机分成{% mathjax %}b{% endmathjax %}个桶。我们把用户随机分成`10`个桶，每个桶有`10%`的用户，接下来才用这样的桶来做`A/B`测试。比如我们想要考察`GNN`(深度神经网络)对**召回通道**指标的影响。有`1、2、3`号桶作为三个实验组，但是`GNN`的参数不一样，三个桶的神经网络分别是一层、两层、三层。用`4`号桶作为对照组，这四个桶唯一的区别就是前三个桶用了`GNN`召回通道，`4`号桶没有用`GNN`。如果一个用户落在`1`号桶，那么给它做推荐的时候，会使用一层的`GNN`神经网络做召回；如果另一个用户落在了`4`号桶，那么给它做推荐的时候，则不使用`GNN`做召回。分别计算每个桶的业务指标，比如`DAU`、人均使用推荐时长、点击率等等。如果过某个实验组的指标显著优于对照组，则说明对应的策略有效，值得推全（意思是把流量扩大到`100%`）。

**分层实验**的目标就是解决流量不够用的问题。主要是因为信息流产品的公司有很多部门和团队，大家都需要做`A/B`测试，比如：推荐系统（召回、粗排、精排、重排）、用户界面、广告等。如果把用户随机分成`10`组，`1`组作对照，`9`组做实验，那么只能同时做`9`组实验。这样会导致流量资源完全不够用。解决方案就是**分层实验**，把实验分成很多层，比如分成：召回、粗排、精排、重排、用户界面、广告等等（例如`GNN`召回通道就属于**召回层**）。**同层之间的实验需要互斥**，例如：`GNN`实验占了召回层的`4`个桶，其它召回实验只能使用剩下的`6`个桶。**同层互斥**的目的是避免一个用户同时被两个召回实验影响，加入两个实验相互干扰，实验结果会变的不可控；**不同层之间流量正交**：每一层独立随机对用户做分桶。每一层都可以独立用`100%`的用户做实验。召回和粗排的用户是随机划分的。召回的2号桶和粗排的2号桶交集很小，举个例子召回层和精排层各自独立随机把用户分成十个桶，分别是{% mathjax %}u_1,u_2,\ldots,u_{10}{% endmathjax %}和{% mathjax %}v_1,v_2,\ldots,v_{10}{% endmathjax %}。设系统共有{% mathjax %}n{% endmathjax %}个用户，那么{% mathjax %}|u_i| = |v_i| = \frac{n}{10}{% endmathjax %}。召回桶{% mathjax %}u_i{% endmathjax %}和召回桶{% mathjax %}u_j{% endmathjax %}交集为{% mathjax %}u_i \cap u_j = \varnothing{% endmathjax %}。所以同一层实验之间是互斥的，两个召回实验不会作用的一个用户上。召回桶{% mathjax %}u_i{% endmathjax %}和精排桶{% mathjax %}v_j{% endmathjax %}交集的大小为{% mathjax %}|u_i\cap v_j| = \frac{n}{100}{% endmathjax %}。一个用户不能同时受两个召回实验的影响。但可以同时受一个召回实验和一个精排实验的影响，一个召回实验和一个精排实验各自作用在{% mathjax %}\frac{n}{10}{% endmathjax %}个用户上，那么有{% mathjax %}\frac{n}{100}{% endmathjax %}的用户同时受两个实验的影响。也就是说，**同层互斥，不同层正交**。如果所有实验都正交，则可以同时做无数组实验。但是同类策略天然互斥（例如精排模型的两种结构），对于一个用户，只能用其中一种；同类策略（例如添加两条召回通道）效果会相互增强(`1+1 > 2`)或相互抵消(`1+1 < 2`)，互斥可以避免**同类策略**相互干扰；不同类型的策略（例如添加召回通道、优化粗排模型）通常不会相互干扰(`1+1 = 2`)，可以作为正交的两层。

