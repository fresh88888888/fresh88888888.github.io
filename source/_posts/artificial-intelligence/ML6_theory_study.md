---
title: 机器学习(ML)(六) — 探析
date: 2024-09-24 12:24:11
tags:
  - AI
categories:
  - 人工智能
mathjax:
  tex:
    tags: 'ams'
  svg:
    exFactor: 0.03
---

#### 偏差和方差

开发**机器学习系统**的典型工作流程是什么？当训练**机器学习模型**时。在给定数据集，如果想用直线去**拟合**它，可能做得并不好。我们说这个算法有很高的**偏差**，或者它对这个数据集的**拟合不足**，也可以称为**欠拟合**。如果要拟合一个四阶多项式，那么它有很高的**方差**，或者称为**过拟合**。如果拟合一个二次多项式，那么它看起来相当不错。如下图所示：
<!-- more -->
{% asset_img ml_1.png %}

但是如果有很多特征，就无法绘制图形来查看，不如诊断或查找算法在训练集和交叉验证集上是否具有**高偏差**、**高方差**来的更有效。让我们看一个例子。如果要计算{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}，从上图可看出这里的{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}很高，因为真实值和预测值之间存在相当大的误差。算法在它以前没有见过的例子上也表现不佳，所以{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}会很高。具有**高偏差**（**欠拟合**）的算法的一个特征是它在训练集上的表现不是很好。当{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}很高时，这是该算法具有**高偏差**的显性指标。如果要计算{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}，它在训练集上实际上表现很好。与训练数据非常吻合。这里的{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}值会很低。但是如果你在训练集中没有的样本上评估这个模型，你会发现**交叉验证误差**({% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %})很高。你的算法具有高方差的特征签名将会使{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}比{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}高得多。换句话说，它在见过的数据上的表现比没见过的数据上要好得多。这是该算法具有**高方差**的显性指标。再次强调，这样做的目的是计算{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}和{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}，看看{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}是否很高，或者{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}是否比{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}高很多。即使无法绘制函数{% mathjax %}f{% endmathjax %}，也能了解算法是具有**高偏差**还是**高方差**。最后，如果查看{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}的值非常低，因此在训练集上表现相当不错。如果查看**交叉验证集**的示例，您会发现{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}也非常低。{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}不太高表明它没有**高偏差**问题，而{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}不比{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}高很多，这表明它也没有**高方差**的问题。总结一下，当线性多项式的{% mathjax %}d=1{% endmathjax %}时，{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}很高，{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}也很高。当{% mathjax %}d = 4{% endmathjax %}时，{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}较低，但{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}较高。当{% mathjax %}d = 2{% endmathjax %}时，两者都相当低。

如下图所示，其中横轴是{% mathjax %}d{% endmathjax %}，是拟合数据的多项式的次数。在左边，将对应{% mathjax %}d{% endmathjax %}的一个小值，比如{% mathjax %}d = 1{% endmathjax %}，这对应于拟合直线。在右边，将对应{% mathjax %}d = 4{% endmathjax %}。会发现，当拟合次数越来越高的多项式时，这里我假设不使用正则化，训练误差会趋于下降，当有一个非常简单的线性函数时，它不能很好地拟合训练数据，当拟合二次函数或三阶多项式或四阶多项式时，拟合数据越来越好。随着多项式的次数增加，{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}通常会下降。我们看到，当{% mathjax %}d = 1{% endmathjax %}时，当多项式的次数非常低时，{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}很高，因为它**欠拟合**，所以它在**交叉验证集**上表现不佳。如果改变多项式的次数，你实际上会得到一条像这样的曲线，先下降然后又上升。如果多项式的次数太低，它就会**欠拟合**，因此无法进行**交叉验证集**；如果次数太高，它就会**过拟合**，在**交叉验证集**上的表现也不会很好。只有当它处于中间位置时，它才是恰到好处的，这就是为什么我们例子中的二阶多项式最终会得到较低的**交叉验证误差**，既不会出现**高偏差**也不会出现**高方差**的原因。
{% asset_img ml_2.png %}

总结一下，你如何诊断是否具有高偏差？如果你的学习算法有**高偏差**的数据，关键指标将是{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}是否很高。这对应于曲线的最左边部分，也就是{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}很高的地方。你如何诊断是否有**高方差**？而高方差的关键指标将是{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}是否大于{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}的两倍。当我们将一个非常高阶多项式拟合到这个小数据集时，就会发生这种情况。在某些情况下，同时存在**高偏差**和**高方差**是可能的。对于**线性回归**，你不会看到这种情况发生，如果训练一个神经网络，有些场景下存在**高偏差**和**高方差**。如果{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}很高，那么在训练集上的表现就不是很好，**交叉验证误差**远大于训练集。**高偏差**意味着在训练集上的表现都不好，而**高方差**意味着在**交叉验证集**上的表现比训练集差得多。

让我们看看**正则化**，特别是正则化参数{% mathjax %}\lambda{% endmathjax %}的选择如何去影响**偏差**和**方差**，从而影响算法的整体性能。当您想要为算法选择一个**正则化**参数{% mathjax %}\lambda{% endmathjax %}值时，将会起到很大的作用。在这个例子中，使用四阶多项式{% mathjax %}f_{\vec{w},b}(x) = w_1x + w_2x^2 + w_3x^3 + w_4x^4 + b{% endmathjax %}，使用**正则化**来**拟合**这个模型{% mathjax %}\mathbf{J}(\vec{w},b) = \frac{1}{2m}\sum_{i=1}^m (f_{\vec{w},b}(\vec{x}^{(i)}) - y^{(i)})^2 + \frac{\lambda}{2m}\sum_{j = 1}^n w_j^2{% endmathjax %}。这里的{% mathjax %}\lambda{% endmathjax %}值是**正则化参数**。假设{% mathjax %}\lambda = 10000{% endmathjax %}。当{% mathjax %}\lambda{% endmathjax %}非常大，那么算法就会倾向于将这些参数{% mathjax %}w{% endmathjax %}保持在非常小的水平，因此会得到{% mathjax %}w_1,w_2{% endmathjax %}，实际上所有这些参数都非常接近于零。模型最终会得到{% mathjax %}f(x) \approx b{% endmathjax %}近似于{% mathjax %}b{% endmathjax %}一个常数值。这个模型显然具有很高的**偏差**，并且它与训练数据不相符，因为它在训练集上的表现不好，而且{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}很大。让我们看看另一个极端。假设{% mathjax %}\lambda{% endmathjax %}设置为一个非常小的值。事实上，在{% mathjax %}\lambda{% endmathjax %}值很小的情况下，将{% mathjax %}\lambda{% endmathjax %}设置为零。选择这种{% mathjax %}\lambda{% endmathjax %}时，没有正则化，只是**拟合**一个没有**正则化**的四阶多项式，最终会得到之前看到的**过度拟合**数据的曲线。当拥有这样的一个模型时，{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}很小，但{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}比{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}大得多。这表明**方差**很大，并且**过度拟合**了数据。那么您如何选择一个好的{% mathjax %}\lambda{% endmathjax %}值？这将类似于使用**交叉验证**选择多项式的次数的过程。具体来说，假设尝试使用{% mathjax %}\lambda = 0{% endmathjax %}来拟合模型。我们将使用{% mathjax %}\lambda = 0{% endmathjax %}来最小化**成本函数**，最终得到一些参数{% mathjax %}w_1,b_1{% endmathjax %}，然后可以计算**交叉验证误差**{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}。假设尝{% mathjax %}\lambda = 0.01{% endmathjax %}。然后，最小化成本函数提供第二组参数{% mathjax %}w^{<2>},b^{<2>}{% endmathjax %}，依此类推。在这个例子中，当{% mathjax %}\lambda = 0.02{% endmathjax %}，这样得到{% mathjax %}w^{<3>},b^{<3>}{% endmathjax %}的{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}，依此类推。经过多次加倍后，{% mathjax %}\lambda = 10{% endmathjax %}，将提供参数 {% mathjax %}w^{<12>},b^{<12>}{% endmathjax %}。通过尝试{% mathjax %}\lambda{% endmathjax %}的大量可能值，使用这些不同的**正则化参数**拟合参数，然后评估**交叉验证集**上的性能。让我们看看**训练误差**和**交叉验证误差**如何随参数{% mathjax %}\lambda{% endmathjax %}的变化而变化。

在下图中，再次更改了{% mathjax %}x{% endmathjax %}轴。这里的{% mathjax %}x{% endmathjax %}轴标注的是**正则化参数**{% mathjax %}\lambda{% endmathjax %}值，因此最终得到了这条非常弯曲的曲线。如果 {% mathjax %}\lambda{% endmathjax %}很小，甚至为零，在这种情况下，有一个**高方差模型**，{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}会很小，而{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}会很大，它在训练数据上表现很好。假设{% mathjax %}\lambda = 10000{% endmathjax %}，最终会拟合出一个看起来像这样的模型。这具有很高的**偏差**，它与数据不相符，结果是{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}会很高，{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}也会很高。事实上，你会发现{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}会像这样上升，因为在优化**成本函数**中，{% mathjax %}\lambda{% endmathjax %}越大，**正则化项**的权重越大，因此对训练集上表现良好的关注就越少。越试图保持参数很小，它在最小化训练误差方面做得越差。这就是为什么随着{% mathjax %}\lambda{% endmathjax %}的增加，训练误差{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}会趋于增加。**交叉验证误差**会怎么样？如果{% mathjax %}\lambda{% endmathjax %}太小或太大，那么它在**交叉验证集**上的表现就越差。它要么在左侧**过度拟合**，要么在右侧**欠拟合**。{% mathjax %}\lambda{% endmathjax %}会有一些中间值，使算法表现最佳。**交叉验证**所做的就是尝试许多不同的{% mathjax %}\lambda{% endmathjax %}值。尝试许多不同的{% mathjax %}\lambda{% endmathjax %}值，并评估许多不同点的**交叉验证误差**，然后选择一个具有较低**交叉验证误差**的值。这条曲线的左侧部分对应于欠拟合和高偏差，右侧部分对应于过拟合和高方差。而在这个图中，**高方差**在左边，**高偏差**在右边。但这就是为什么这两个图像有点像彼此的镜像。但在这两种情况下，**交叉验证**评估不同的值都可以帮助你选择一个好的{% mathjax %}\lambda{% endmathjax %}值。这就是**正则化参数**{% mathjax %}\lambda{% endmathjax %}选择如何影响算法的**偏差**和**方差**以及整体性能过程，掌握了如何使用**交叉验证**来为**正则化参数**{% mathjax %}\lambda{% endmathjax %}做出一个好的选择。
{% asset_img ml_3.png %}

让我们看看{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}和{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}的具体数值，看看如何判断学习算法是具有**高偏差**还是**高方差**的。许多在手机上进行搜索的用户会使用**语音识别**，而不是在手机的小键盘上打字，因为对着手机说话通常比打字更快。比如“今天的天气怎么样？”或者像这样，“我附近的咖啡店。”语音识别算法的工作就是输出为文本。现在，如果要训练语音识别系统并测量训练误差，训练误差意味着训练集中，算法无法正确转录的音频片段的百分比是多少。假设此数据集的训练误差为`10.8%`，意味着它可以完美转录`89.2%`的训练集，但会犯`10.8%`的训练集错误。如果您还要在单独的**交叉验证集**上测量语音识别算法的性能，假设其错误率为`14.8%`。你会发现训练误差非常高，错误率为`10%`，然后**交叉验证误差**更高，但即使训练集有`10%`的错误，这个错误率似乎相当高。它具有很高的**偏差**，但事实证明，在分析语音识别时，测量另一件事也很有用，那就是人类的表现水平如何？换句话说，人类从这些音频片段中转录语音的准确程度如何？具体来说，假设你测量了流利说话者转录音频片段的能力，发现人类水平的表现达到了`10.6%`的错误率。为什么人类水平的错误率这么高？对于网络搜索，有很多音频片段有很多嘈杂的音频，由于音频中的噪音，实际上没有人能够准确地转录所说的内容。如果连人类都会犯`10.6%`的错误率，那么似乎很难指望学习算法能做得更好。为了判断训练错误是否很高，看看训练错误是否远远高于人类水平的表现会更有用，在这个例子中，它的表现只比人类差`0.2%`。但相比之下，{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}和{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}之间的差距要大得多。实际上，两者之间的差距为`4%`。当我们将其与人类水平的表现进行比较时，我们发现该算法在训练集上的表现实际上相当不错，但更大的问题是**交叉验证误差**远高于训练误差，这就是为什么我会得出结论，该算法实际上存在更多的**方差问题**而不是**偏差问题**。判断训练误差是否高通常有助于确定性能的基准水平，而我所说的性能基准水平是指学习算法最终达到的错误水平。确定**性能基准水平**的一种常见方法是衡量人类在这项任务上的表现如何，因为人类非常擅长理解语音数据、处理图像或理解文本。当您使用非结构化数据（例如：音频、图像或文本）时，人类水平的表现通常是一个很好的基准。估计基准性能水平的另一种方法是，如果存在某种竞争算法，可能是其他人已经实现的先前实现，甚至是竞争对手的算法，那么如果可以测量基准性能水平，则可以建立基准性能水平。如果可以访问此基准性能水平，那么可以合理地希望达到的错误水平是多少？然后，在判断算法是否具有**高偏差**或**方差**时，查看**基准性能水平**、**训练误差**和**交叉验证误差**。然后要测量的两个关键数值是：训练误差与希望获得的基准水平之间的差异是多少？如果这个数值很大，那么会是一个**高偏差**问题。然后查看训练误差和交叉验证误差之间的差异是多少？如果这个差异很大，那么会是一个**高方差问题**。第二个例子，如果基准水平的表现；即人类水平的表现，**训练误差**和**交叉验证误差**差距是`4.4%`。训练误差远高于人类所能达到的水平和我们希望达到的水平，而交叉验证误差只比训练误差大一点。这个算法有**高偏差问题**。通过查看训练误差和交叉验证误差可以直观地了解算法有**高偏差**或**高方差**问题的程度。有时，性能的基准水平可能是`0%`。如果目标是实现比基准水平更好的性能，那么性能的基准水平可能是`0%`，但对于某些应用程序（例如语音识别应用程序），其中一些音频只是嘈杂的，那么性能的基准水平可能远高于零。您的算法可能存在**高偏差**和**高方差**。基线和训练误差之间的差距`4.4%`，训练误差和交叉验证误差之间的差距是`4.7%`。则算法具有**高偏差**和**高方差**。总而言之，查看训练误差是否很大是判断算法是否具有**高偏差**的一种方法，但数据有时只是嘈杂且无法期望获得零误差，建立这个**基准性能水平**很有用。同样，查看交叉验证误差是否比训练误差大得多，可以让您了解算法是否存在**高方差问题**。

**学习曲线**是一种帮助理解学习算法并如何根据其经验量（例如，它拥有的训练示例数量）来执行的方法。如下图所示，绘制一个适合二次函数模型的**学习曲线**。绘制{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}**交叉验证误差**）和{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}（**训练误差**）。
{% asset_img ml_4.png %}

在上图中，横轴是{% mathjax %}m_{\text{train}}{% endmathjax %}。代表训练集大小。纵轴代表误差（{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}或{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}）。随着{% mathjax %}m_{\text{train}}{% endmathjax %}（训练集大小）变大，这将学习到更好的模型，因此**交叉验证误差**会下降。现在绘制{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}，**训练误差**随着训练集大小变大会增加。从一个例子开始，当你只有一个训练示例时。如果用二次模型拟合直线，你的训练误差将为零。如果有两个这样的训练示例呢？可以再次拟合一条直线并实现零训练误差。事实上，如果有三个训练示例，二次函数仍然可以很好地拟合它并获得几乎为零的**训练误差**，但现在训练集稍微大一点，比如说有四个训练示例，那么完美地拟合所有四个示例就会变得有点困难。当将训练集大小增加到`4`时，**训练误差**会稍微增加一点。假设有`5`个训练样本，要完美拟合所有样本就更难了。总结一下，当你只有很少的训练样本，比如`1、2、3`个时，相对容易得到零或非常小的**训练误差**，但是当有更大的训练集时，二次函数很难完美拟合所有训练样本。这就是为什么随着训练集变大，**训练误差**会增加，因为完美拟合所有训练样本变得更加困难。请注意，**交叉验证误差**通常会高于**训练误差**，因为将参数拟合到训练集上。期望在训练集上的表现至少会比在**交叉验证集**上的表现好一点，或者当`m`较小时，甚至可能会好很多。现在让我们看看**高偏差**和**高方差**的**学习曲线**是什么样的？先从**高偏差**的情况开始。如果绘制**训练误差**，那么**训练误差**就会像预期的那样上升。这条**训练误差曲线**可能会开始趋于平缓。我们称之为**平台期**，意思是一段时间后趋于平缓。这是因为在拟合简单的线性函数时，随着得到越来越多的训练样本，模型实际上并没有发生太大的变化。这就是为什么平均训练误差在一段时间后趋于平缓的原因。同样，交叉验证误差也会在一段时间后下降并变大，这就是为什么{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}再次高于{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}，但{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}会在超过某个点后，即使获得再多的样本示例，拟合的直线也不会发生太大变化。因为模型太简单了，无法适应这么多数据。这就是为什么这两条曲线，{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}和{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}一段时间后都会趋于平坦的原因。如果您对该基准水平的表现有一个**衡量标准**，例如人类水平的表现，那么它们往往会低于当下的{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}和{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}。基准水平和{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}之间存在很大差距，这是我们对该算法具有**高偏差**的指标。也就是说，如果能够拟合一个比直线更复杂的函数，模型做的更加好。如果这里有更大的训练集，情况会怎样？如果将这两条曲线向右延伸，它们都会变平，而且它们可能都会一直保持这种平坦状态。无论向图表右侧延伸多远，这两条曲线都永远不会以某种方式下降到人类水平的表现，无论训练集有多大，它们几乎都会永远保持这种平坦状态。
{% asset_img ml_5.png %}

这得出了一个结论，如果你的算法具有**高偏差**，那么唯一能做的就是向其投入更多训练数据，但这永远不会将**错误率**降到很低。这就是为什么在投入大量精力收集更多训练数据之前，需要检查你的**学习算法**是否具有**高偏差**。**高方差**的学习曲线又会是什么样的？如果用{% mathjax %}\lambda = 0{% endmathjax %}来拟合四阶多项式，那么会得到一条看起来像这样的曲线，即使它非常适合训练数据，但它并不具有**泛化能力**。{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}会随着训练集大小的增加而上升，所以你会得到一条看起来像这样的曲线，而{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}会高得多，所以**交叉验证误差**比**训练误差**高得多。这种**高方差**在训练集上的表现比在**交叉验证集**上要好得多。如果要绘制一个基准水平的表现，比如人类水平的表现，可能会发现，{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}有时甚至低于人类水平的表现。但是**过度拟合**可能会很好地拟合训练集，得到一个不切实际的低误差，当方差较大时，增加训练集大小有很大帮助，**训练误差**继续上升，**交叉验证误差**下降并接近{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}。因此，在这种情况下，可能只需增加训练集大小即可降低交叉验证误差并使算法的表现越来越好。总而言之，如果学习算法存在**高方差**，那么获取更多训练数据确实会有所帮助。因为会发现{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}会继续下降。在这个例子中，只需获取更多训练数据，算法就可以从相对较高的**交叉验证误差**转变为更接近人类水平的表现。如果你正在构建机器学习模型，可以根据需要绘制**学习曲线**，也就是说，可以采用训练集的不同子集（有`1,000`个训练示例，可以仅使用100个训练示例训练模型并查看训练误差和交叉验证误差，然后使用`200`个示例训练模型，保留`800`个示例并暂时不使用它们），然后绘制{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}和{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}等重复并绘制**学习曲线**。以这种方式将其可视化，应该是另一种查看**学习曲线**是**高偏差**还是**高方差**的方法。但有一个缺点是，使用不同大小的训练集子集来训练如此多不同的模型在计算上非常昂贵，因此在实践中，并不经常这样做。

通过查看{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}和{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}，即**训练误差**和**交叉验证误差**，或者绘制**学习曲线**，可以了解学习算法是否具有**高偏差**或**高方差**。这将帮助我更好地决定下一步该做什么，来提高学习算法的性能。可以看一个例子，线性回归来预测房价，但算法在预测中产生了不可接受的错误，接下来应该怎么做？想到的方法是获取更多训练示例，尝试少量特征，附加特征等等。如果学习算法有**高偏差**，或**高方差**，第一个方法是获得更多的训练样本。如果算法有**高偏差**，那么唯一能做的就是获得更多的训练数据，但这对于高偏差不起作用。相反，如果算法有**高方差**，比如说它对一个非常小的训练集**过度拟合**，那么获得更多的训练样本将大有帮助。第一个方法（获得更多的训练样本）有助于解决**高方差问题**。第二个方法是减少特征数量，如果学习算法有太多的特征，那么它会给算法带来太多的灵活性，而适应非常复杂的模型。这有点像{% mathjax %}x,x^2,x^3,x^4,x^5{% endmathjax %}等等。如果消除其中的几个，那么模型就不会变得那么复杂，也不会有那么高的方差。减少特征数量将有助于降低算法**过度拟合**数据的灵活性。这是一种可以帮助解决**高方差**的策略。第三种方法是添加额外的特征。这将帮助您解决**高偏差问题**。举一个具体的例子，如果仅根据房屋大小来预测房屋的价格，但事实证明房屋的价格也取决于卧室数量、楼层数量和房屋年龄，那么除非添加这些额外的特征，否则算法永远不会做得更好。这是一个**高偏差问题**，添加额外的特征是解决**高偏差问题**的一种方法。第四种方法是添加额外的多项式特征可以在训练集上做得更好，是一种解决**高偏差问题**的方法。第五种方法是降低{% mathjax %}\lambda{% endmathjax %}（正则化参数值）将减少对这个项的关注，而更多地关注其它项，这有助于你解决**高偏差问题**。最后，第六种方式是增加{% mathjax %}\lambda{% endmathjax %}值，如果过度拟合训练集，增加{% mathjax %}\lambda{% endmathjax %}是有意义的，只是投入了太多的**注意力**来拟合训练集，但以牺牲对新示例的推广为代价，因此增加{% mathjax %}\lambda{% endmathjax %}会使算法拟合的更平滑，这有助于解决**高方差问题**。

如果你发现算法存在**高方差**，那么主要的方法是：要么获得更多的训练数据，要么简化模型。简化模型的意思是，要么获取一组较小的特征，要么增加正则化参数{% mathjax %}\lambda{% endmathjax %}。相反，如果算法存在**高偏差**，主要的方法是让模型更灵活地拟合更复杂或更弯曲的函数。添加额外的特征或添加多项式特征，或者降低正则化参数{% mathjax %}\lambda{% endmathjax %}值。如果减少训练集的大小，训练集的拟合效果会更好，但这往往会降低**交叉验证误差**和学习算法的性能，因此不要为了解决**高偏差问题**而随意丢弃训练样本。**偏差**和**方差**是非常强大的概念之一。

我们发现**高偏差**或**高方差**都是不好的，因为它们会损害算法的性能。如果用不同阶的多项式拟合一个数据集，一个非常简单的模型，它可能有**高偏差**，而如果要拟合一个复杂的模型，它可能有**高方差**。偏差和方差之间存在这种权衡，选择二阶多项式可以帮助做出权衡。如果你的模型太简单，偏差就会很高，如果模型太复杂，方差就会很高。这时必须在它们之间找到一个权衡，才能找到最好的结果。但神经网络提供了一种摆脱这种必须权衡**偏差**和**方差**的困境的方法，大型神经网络在小型中等规模的数据集上训练时是低偏差。如果你你的神经网络足够大，总是可以很好地拟合训练集。可以根据需要尝试减少偏差或减少方差，而无需在两者之间进行权衡。

首先在训练集上训练算法，然后询问它在训练集上的表现是否良好。测量{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}并查看它是否很高（高是指相对于人类水平的表现或某些基准水平的表现，如果它表现不佳，那么你就有高偏差问题，高训练误差）。减少偏差的一种方法是使用更大的神经网络，更大的神经网络是指更多的**隐藏层**或每层更多的**隐藏单元**。然后，继续这个循环，神经网络越来越大，直到它在训练集中达到的错误水平大致与希望达到的目标错误水平相当，这可能是人类水平的表现。{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}和{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}之间的巨大差距表明存在**高方差问题**，如果存在高方差问题，那么尝试修复它的一种方法是获取更多数据。获取更多数据并返回并重新训练模型，然后仔细检查，只需要训练集吗？如果不是，则使用更大的网络，或者看看它在交叉验证集上是否确实如此，如果不是，则获取更多数据。如果继续循环往复，直到最终它在**交叉验证集**上表现良好。当然，这种方法的应用存在局限性，训练更大的神经网络不会减少偏差，但在某些时候它确实会消耗大量计算资源。这就是为什么神经网络的兴起确实得益于超高速计算机的兴起，尤其是`GPU`。它对加速神经网络也非常有用。但即使使用硬件加速器，超过一定程度，神经网络也会变得非常庞大，需要很长时间进行训练，变得不可行。当然，另一个限制是更多的数据。有时只能获得这么多数据，超过一定程度就很难获得更多数据。但在增加**神经网络**之后，会发现方差很大，在这种情况下，可能会收集更多数据。当您训练神经网络时，经过精心选择的正则化的大型神经网络通常与小型神经网络一样好或更好。有一个警告，那就是当训练**大型神经网络**时，它的计算成本会更高。所以它的主要坏处是，它会减慢训练和推理过程，并且非常短暂地对神经网络进行**正则化**。如果**神经网络**的成本函数是平均损失，所以这里的损失可能是**平方误差**或**逻辑损失**。

然后，神经网络**的正则化**项看起来与期望的非常相似，即{% mathjax %}\mathbf{J}(\mathbf{W,B}) = \frac{1}{m}\sum_{i=1}^m L(f(\vec{x}^{(i)}),y^{(i)}) + \frac{\lambda}{2m}\sum_{\text{all weights}\;\mathbf{W}} (w^2){% endmathjax %}，其中这是神经网络中所有权重{% mathjax %}\mathbf{W}{% endmathjax %}的总和，与**线性回归**和**逻辑回归**的**正则化**类似，通常不会对**神经网络**中的参数进行**正则化**。在`TensorFlow`中实现正则化的方式是回想一下，手写数字分类模型的代码。创建三个层，其中包含多个拟合**单元激活**，然后创建一个包含三个层的顺序模型。添加正则化`L2(0.001)`，为了简单起见，可以为所有权重和所有不同的层选择相同的{% mathjax %}\lambda{% endmathjax %}值。首先适当地进行正则化，拥有更大的神经网络几乎不会有什么坏处。一个警告是，拥有更大的神经网络会减慢你的算法。其次，只要训练集不是太大。那么更大的神经网络通常是低偏差的。所以深度学习的兴起确实改变了机器学习从业者对**偏差**和**方差**的看法。
```python
import tensorflow as tf
from tensorflow.keras import Sequential
from tensorflow.keras.layouts import Dense

model = Squential([
    Dense(units = 25,activation='relu', kernel_regularizer = L2(0.01)),          # layer 1
    Dense(units = 15,activation='relu', kernel_regularizer = L2(0.01)),          # layer 2
    Dense(units = 1, activation='sigmoid', kernel_regularizer = L2(0.01))])      # layer 3

```
#### 开发流程

开发**机器学习模型**，首先，要决定系统的整体架构。选择**机器学习模型**以及决定使用哪些数据，也许还要选择超参数等等。然后，根据这些决定，训练模型。正如之前提到的，当第一次训练模型时，它几乎永远不会按照希望的那样工作。建议下一步是查看一些诊断，例如查看算法的**偏差**和**方差**以及误差分析。根据诊断结果做出决定，例如是否要扩大**神经网络**、变更{% mathjax %}\lambda{% endmathjax %}**正则化参数**、添加更多数据、添加更多特征、减少特征等。然后，使用新选择的架构再次进行此循环，并且通常需要多次迭代才能达到所需的性能。让我们看一个构建电子邮件垃圾邮件分类器的示例。左侧的示例是垃圾邮件的典型样子。本周特价，劳力士手表。垃圾邮件发送者有时会故意拼错这些单词，例如手表、药品和抵押贷款，以试图让垃圾邮件识别器出错。相比之下，右边的这封电子邮件是真实电子邮件。如何构建分类器来识别垃圾邮件和非垃圾邮件？一种方法是训练监督学习算法，其中输入特征{% mathjax %}x{% endmathjax %}将是电子邮件的特征，输出标签{% mathjax %}y{% endmathjax %}将是`1`或`0`，具体取决于它是垃圾邮件还是非垃圾邮件。构建电子邮件特征的一种方法是，取出英语或其他词典中的前`10,000`个单词，并使用它们来定义特征{% mathjax %}x_1,x_2,\ldots,x_{10000}{% endmathjax %}。例如，右侧的电子邮件有以下单词列表`a、Andrew buy deal discount`等等。将这些特征设置为`0`或`1`，具体取决于该词是否出现。构建特征向量的方法有很多。另一种方法是让这些数字不仅仅是`1`或`0`，而是计算给定单词在电子邮件中出现的次数。如果`buy`出现了两次，将其设置为`2`，有了这些特征，您就可以训练分类算法（例如**逻辑回归模型**或**神经网络**）来根据这些特征{% mathjax %}x{% endmathjax %}来预测{% mathjax %}y{% endmathjax %}。训练完初始模型后，如果它的效果不如您所愿，可能会有多种改进学习算法性能的想法。例如，收集更多数据。例如，如果算法具有高偏差而不是高方差，花费数月时间收集数据效果甚微。但如果您的算法具有高方差，那么收集更多数据可能会大有帮助。

假设有{% mathjax %}m_{\text{cv}} = 500{% endmathjax %}个**交叉验证**示例，并且算法错误分类了其中`100`个交叉验证示例。**误差分析**过程只是手动查看这`100`个示例并了解算法出错的地方。从交叉验证集中找到一组算法错误分类的示例，并将它们分组为共同的属性或共同的特征。例如，如果注意到错误分类的垃圾邮件是药品销售，试图销售药品或药物，假设有`21`封电子邮件是药品垃圾邮件。假设通过电子邮件路由信息，发现`7`个具有不寻常的电子邮件路由，`18`封电子邮件试图窃取密码或钓鱼电子邮件。垃圾邮件有时也不会在电子邮件正文中编写垃圾邮件，而是创建图像，然后将垃圾邮件写入电子邮件中的图像中。这使得学习算法更难弄清楚。也许其中一些电子邮件是嵌入图像的垃圾邮件。即使构建了非常复杂的算法来查找故意的拼写错误，也只能解决`100`个错误分类示例中的`3`个。例如，可能有一个具有不寻常路由的医药垃圾邮件，或者一个具有故意拼写错误的密码，并且也在试图进行网络钓鱼攻击。一封电子邮件可以算入多个类别。在这个例子中，算法错误分类了`100`个示例。如果有一个更大的**交叉验证集**，假设我们有`5,000`个交叉验证示例，如果算法错误分类了其中的`1,000`个，可能没有时间手动查看算法错误分类的`1,000`个示例。在这种情况下，通常会随机抽取一个子集，通常大约`100`个，因为这是可以在合理的时间内查看的数量。希望查看大约`100`个示例将为您提供足够的统计数据，了解最常见的错误类型。经过此分析，如果发现很多错误都是医药垃圾邮件，那么这可能会给您一些灵感，让您知道下一步该做什么。例如，您可能决定收集更多数据，但不是收集所有内容的数据，而只是找到更多有关医药垃圾邮件的数据，以便学习算法能够更好地识别这些医药垃圾邮件。或者，您可能决定提出一些与垃圾邮件发送者试图销售的药品的具体名称相关的新特征，以帮助学习算法更好地识别此类医药垃圾邮件。然后，这可能会启发检测网络钓鱼电子邮件相关的算法进行特定更改。例如，查看电子邮件中的`URL`并编写特殊代码以添加额外特征，以查看它是否链接到可疑的`URL`。或者，获取更多钓鱼电子邮件的数据，以帮助学习算法更好地识别它们。此**误差分析**的重点是手动检查算法错误分类或错误标记的一组示例。通常，这会为下一步尝试提供灵感，有时它还可以告诉您某些类型的错误非常罕见，因此不值得花费太多时间去修复。总的来说，**偏差方差诊断**以及**误差分析**对于筛选模型非常有帮助。**误差分析**的一个限制是，对于人类擅长的问题，它更容易做到。对于人类不擅长的任务，**误差分析**可能会更难一些。

如果**误差分析**发现制药垃圾邮件是一个问题，可以采取更有针对性的措施，而不是获取有关所有类型的更多数据，而是专注于获取更多有关制药垃圾邮件的示例。而且，以更适中的成本，来添加所需的电子邮件。如果您有大量未标记的电子邮件数据，比如闲置的电子邮件，但没有人费心将其标记为垃圾邮件或非垃圾邮件，可以让人工快速浏览未标记的数据并找到更多示例，特别是与制药相关的垃圾邮件。这可以大大提高学习算法性能，而不仅仅是尝试添加更多各种电子邮件的数据。但如果有一些方法可以添加更多数据。如果**误差分析**表明算法在某些数据子集上表现特别差。而想要提高性能，那么只需获取做得更好的类型的数据。无论是更多的制药垃圾邮件示例还是更多的网络钓鱼垃圾邮件示例或其他内容。这可能是一种更有效的方法，只需添加一点点数据，但可以大大提高算法性能。不仅仅是获得全新的训练示例。还有一种技术被广泛使用，特别是用于图像和音频数据，它可以显著增加训练集大小。这种技术称为**数据增强**。我们要做的是利用现有的训练示例来创建一个新的训练示例。例如，如果你试图识别从`A~Z`的字母，以解决`OCR`光学字符识别问题。给定这样的图像，通过稍微旋转图像来创建一个新的训练示例。或者通过稍微放大图像或缩小图像或通过改变图像的对比度。这些是图像扭曲的例子，但不会改变它仍然是字母`A`的事实。对于某些字母，可以获取字母的镜像，它仍然看起来像字母`A`。但这仅适用于某些字母，但这些将是获取训练示例{% mathjax %}x,y{% endmathjax %}的方法。并对输入{% mathjax %}x{% endmathjax %}应用扭曲或变换，以便得出另一个相同标签的示例。通过这样做，你告诉算法，字母`A`旋转了一点、放大了一点或缩小了一点，它仍然是字母`A`。创建这样的额外示例可以让学习算法更好地学习如何识别字母`A`。对于数据增强的更高级示例，还可以取字母`A`，并在其上方放置一个网格。通过引入此网格的随机扭曲，你可以取字母`A`。并引入`A`的扭曲，以创建一个更丰富的字母`A`示例库。然后，扭曲这些示例的过程将一个示例的图像变成了训练示例，你可以将其提供给学习算法，希望它能够更稳健地学习。**数据增强**的这个想法也适用于语音识别。假设对于语音搜索，有一个原始音频剪辑，可以将**数据增强**应用于语音数据的一种方法是获取嘈杂的背景音频。例如，这是人群的声音。事实证明，如果将这两个音频剪辑加在一起，听起来像有人在说今天的天气怎么样。但他们是在背景中吵闹的人群中说这句话的。如果您要获取不同的背景噪音，比如车里的人，这就是汽车的背景噪音。如果您想将原始音频剪辑添加到汽车噪音中，好像说话者是从车里说的。更高级的数据增强步骤是，让原始音频听起来像是在手机连接不良的情况下录制的。这实际上是一种非常关键的技术，可以人为地增加训练数据的大小，从而构建更准确的语音识别器。**数据增强**的一个技巧是，数据所做的更改或扭曲应该代表测试集中的噪音或扭曲类型。相反，在数据中增加纯随机无意义的噪声通常没有多大帮助。例如，你取字母`A`，如果只向每个像素添加噪声，它们最终会得到像这样的图像。但如果这不能代表你在测试集中看到的内容，因为你在测试集中通常不会得到这样的图像，那么这实际上就没那么有用了。因此，考虑**数据增强**的一种方法是，如何修改、扭曲数据，或在数据中制造更多噪声。现在，**数据增强**采用现有的训练示例并对其进行修改以创建另一个训练示例。其中一种技术是**数据合成**，你可以从头开始制作全新的示例。不是通过修改现有示例，而是通过创建全新的示例。以照片`OCR`为例。照片`OCR`或照片光学字符识别是指查看这样的图像并让计算机自动读取图像中出现的文本的问题。这张图片中有很多文本。如何训练`OCR`算法来读取图像中的文本？照片`OCR`任务的一个关键步骤是能够查看这样的小图像并识别中间的字母。因此，中间有`T`，中间有字母`L`，中间有字母`C` 等等。因此，为这项任务创建人工数据的一种方法是，进入计算机的文本编辑器，会发现它有很多不同的字体，使用这些字体并在文本编辑器中输入随机文本。并使用不同的颜色、不同的对比度和非常不同的字体进行截图，你会得到像右边这样的合成数据。左边的图像是从世界上拍摄的真实照片中获取的真实数据。右边的图像是使用计算机上的字体合成的，实际上看起来非常逼真。因此，使用这样的合成数据，可以为照片`OCR`任务生成大量图像或示例。编写代码为给定应用程序生成逼真的合成数据可能需要大量工作。但是它有时可以帮助你为应用程序生成大量数据，并极大地提升你的算法性能。**合成数据**生成最有可能用于计算机视觉任务，而较少用于其他应用。有时花更多时间采用以数据为中心的方法会更有成效，这种方法专注于设计算法使用的数据。如果这是**误差分析**告诉你需要更多这方面的数据。使用**数据增强**来生成更多图像和音频，或使用**数据合成**来创建更多训练示例。

对于没有那么多数据的应用，**迁移学习**是一种很棒的技术，它允许使用来自不同任务的数据来帮助您的应用。让我们来看看**迁移学习**是如何工作的。**迁移学习**的工作原理如下。假设您想要识别从`0~9`的手写数字，但是没有那么多手写数字的标记数据。假设找到一个非常大的数据集，其中包含一百万张猫、狗、汽车、人等图片，一千个类别。然后，在这个包含一百万张图像和一千个不同类别的大型数据集上训练**神经网络**，以图像{% mathjax %}x{% endmathjax %}作为输入，并学习识别这`1,000`个不同类别中的任何一个。在此过程中，学习神经网络第一层的参数{% mathjax %}W^{[1]},b^{[1]}{% endmathjax %}，第二层的参数{% mathjax %}W^{[2]},b^{[2]}{% endmathjax %}，依此类推，输出层的参数{% mathjax %}W^{[3]},b^{[3]},W^{[4]},b^{[4]}{% endmathjax %}和{% mathjax %}W^{[5]},b^{[5]}{% endmathjax %}。要使用**迁移学习**，必须复制此**神经网络**，并在其中保留参数 {% mathjax %}W^{[1]},b^{[1]},W^{[2]},b^{[2]},W^{[3]},b^{[3]},W^{[4]},b^{[4]}{% endmathjax %}。但对于最后一层，需要消除输出层并将其替换为一个只有`10`个输出单元（而不是`1,000`个）的**输出层**。这 `10`个输出单元将对应于**神经网络**识别的类别{% mathjax %}0,1,\ldots,9{% endmathjax %}。请注意，参数{% mathjax %}W^{[5]},b^{[5]}{% endmathjax %}无法复制，因为此层的维度已更改，需要计算新的参数 并从头开始训练，而不是直接从前一个**神经网络**中复制。在**迁移学习**中，可以使用前四层的参数（实际上是除最终输出层之外的所有层）作为参数的起点，然后执行优化算法（例如梯度下降或`Adam`优化算法），并使用来自顶层神经网络的值初始化参数。
{% asset_img ml_6.png %}

具体来说，有两种方式可以训练这个神经网络参数。选项`1`是只训练输出层参数。可以将参数{% mathjax %}W^{[1]},b^{[1]},W^{[2]},b^{[2]},W^{[3]},b^{[3]},W^{[4]},b^{[4]}{% endmathjax %}作为顶层的值，并将它们固定，并使用**随机梯度下降**或`Adam`优化算法仅更新{% mathjax %}W^{[5]},b^{[5]}{% endmathjax %}，以降低从{% mathjax %}0,1,\ldots,9{% endmathjax %}的小训练集中学习识别{% mathjax %}0,1,\ldots,9{% endmathjax %}这些数字时使用**成本函数**。选项`2`是训练**神经网络**中的所有参数，包括{% mathjax %}W^{[1]},b^{[1]},W^{[2]},b^{[2]},W^{[3]},b^{[3]},W^{[4]},b^{[4]},W^{[5]},b^{[5]}{% endmathjax %}，但前四层参数将使用顶层训练过的值进行初始化。如果训练集非常小，那么选项`1`可能会更好一些，但是如果训练集稍大一些，那么选项`2`可能会更好一些。这种算法之所以被称为**迁移学习**，是因为通过学习识别猫、狗、牛、人等等。希望它已经学会了一些合理的参数集，用于处理图像输入的早期层。然后通过将这些参数转移到新的**神经网络**，新的**神经网络**会从更好的参数开始，这样我们就可以进行进一步的学习。希望它最终能得到一个相当不错的模型。这两个步骤，首先在大型数据集上进行训练，然后在较小的数据集上进一步调整参数，第一步被称为**监督预训练**。然后第二步称为微调，从监督预训练中获得的参数，然后进一步运行**梯度下降**来**微调权重**。如果有一个小型数据集，即使只有几十、几百、几千或几万张手写数字图像，能够从这些与任务不太相关的数百万张图像中学习，实际上可以大大提高学习算法的性能。**迁移学习**的一个好处是不需要亲自进行**监督式预训练**。对于许多神经网络，已经有研究人员在大型图像上训练了一个神经网络，并将训练好的神经网络发布在互联网上，任何人都可以免费下载和使用。意味着你不必自己执行第一步，只需下载别人可能花了数周时间训练的神经网络，然后替换输出即可。将层与自己的输出层组合，并执行选项`1`或选项`2`来微调其他人已经进行过**监督预训练**的**神经网络**，只需进行**微调**，就可以快速获得一个表现良好的**神经网络**。但为什么迁移学习会有效？如果正在训练**神经网络**来检测图像中的不同物体，那么**神经网络**的第一层可能会学习检测图像的边缘。我们认为这些是图像中用于检测边缘的低级特征。这些方块中的每一个都是单个神经元学会检测的可视化，学会将像素组合在一起以找到图像中的边缘。神经网络的下一层然后学习将边缘组合在一起以检测角点。这些方块中的每一个都是单个神经元可能学会检测的可视化，必须学会技术性的、简单的形状，如像这样的角点形状。神经网络的下一层可能已经学会检测一些更复杂但仍然是通用的形状，如基本曲线或像这样的较小形状。这就是为什么通过学习检测大量不同的图像，从而教授**神经网络**检测边缘、角点和基本形状。这对许多计算机视觉任务很有用，例如识别手写数字。不过预训练的一个限制是，**预训练**和**微调**步骤中的图像类型{% mathjax %}x{% endmathjax %}必须相同。相反，构建语音识别系统来处理音频，那么在图像上预训练的神经网络可能不会在音频上发挥太大作用。需要一个在音频数据上**预训练**的神经网络，然后在音频数据集上进行**微调**。

以**语音识别**为例来说明机器学习项目的整个开发周期。机器学习项目的第一步是确定项目范围（你想做什么）。决定要做什么之后，接下来需要收集数据。决定需要什么数据来训练机器学习系统。在完成初始数据收集后，就可以开始训练模型了。在这里，训练语音识别系统并进行**误差分析**，然后迭代改进模型。在对训练模型进行**误差分析**或**偏差方差分析**后，接下来可能需要回去收集更多数据，或者只收集更多特定类型的数据。训练出高性能机器学习模型（例如语音识别模型）后，部署模型的常见方法是将机器学习模型部署到服务器中，一般将这个服务器称为**推理服务器**，它的工作是调用**机器学习模型**（即训练好的模型）进行预测。机器学习中有一个不断发展的领域，称为`MLOps`。代表机器学习操作。这指的是如何系统地构建、部署和维护机器学习系统的实践。为了确保机器学习模型可靠、可扩展、具有良好的规律、受到监控，然后根据需要对模型进行更新以使其运行良好。

