---
title: 机器学习(ML)(六) — 探析
date: 2024-09-24 12:24:11
tags:
  - AI
categories:
  - 人工智能
mathjax:
  tex:
    tags: 'ams'
  svg:
    exFactor: 0.03
---

#### 偏差和方差

开发**机器学习系统**的典型工作流程是什么？当训练**机器学习模型**时。在给定数据集，如果想用直线去**拟合**它，可能做得并不好。我们说这个算法有很高的**偏差**，或者它对这个数据集的**拟合不足**，也可以称为**欠拟合**。如果要拟合一个四阶多项式，那么它有很高的**方差**，或者称为**过拟合**。如果拟合一个二次多项式，那么它看起来相当不错。如下图所示：
<!-- more -->
{% asset_img ml_1.png %}

但是如果有很多特征，就无法绘制图形来查看，不如诊断或查找算法在训练集和交叉验证集上是否具有**高偏差**、**高方差**来的更有效。让我们看一个例子。如果要计算{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}，从上图可看出这里的{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}很高，因为真实值和预测值之间存在相当大的误差。算法在它以前没有见过的例子上也表现不佳，所以{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}会很高。具有**高偏差**（**欠拟合**）的算法的一个特征是它在训练集上的表现不是很好。当{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}很高时，这是该算法具有**高偏差**的显性指标。如果要计算{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}，它在训练集上实际上表现很好。与训练数据非常吻合。这里的{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}值会很低。但是如果你在训练集中没有的样本上评估这个模型，你会发现**交叉验证误差**({% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %})很高。你的算法具有高方差的特征签名将会使{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}比{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}高得多。换句话说，它在见过的数据上的表现比没见过的数据上要好得多。这是该算法具有**高方差**的显性指标。再次强调，这样做的目的是计算{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}和{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}，看看{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}是否很高，或者{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}是否比{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}高很多。即使无法绘制函数{% mathjax %}f{% endmathjax %}，也能了解算法是具有**高偏差**还是**高方差**。最后，如果查看{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}的值非常低，因此在训练集上表现相当不错。如果查看**交叉验证集**的示例，您会发现{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}也非常低。{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}不太高表明它没有**高偏差**问题，而{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}不比{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}高很多，这表明它也没有**高方差**的问题。总结一下，当线性多项式的{% mathjax %}d=1{% endmathjax %}时，{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}很高，{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}也很高。当{% mathjax %}d = 4{% endmathjax %}时，{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}较低，但{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}较高。当{% mathjax %}d = 2{% endmathjax %}时，两者都相当低。

如下图所示，其中横轴是{% mathjax %}d{% endmathjax %}，是拟合数据的多项式的次数。在左边，将对应{% mathjax %}d{% endmathjax %}的一个小值，比如{% mathjax %}d = 1{% endmathjax %}，这对应于拟合直线。在右边，将对应{% mathjax %}d = 4{% endmathjax %}。会发现，当拟合次数越来越高的多项式时，这里我假设不使用正则化，训练误差会趋于下降，当有一个非常简单的线性函数时，它不能很好地拟合训练数据，当拟合二次函数或三阶多项式或四阶多项式时，拟合数据越来越好。随着多项式的次数增加，{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}通常会下降。我们看到，当{% mathjax %}d = 1{% endmathjax %}时，当多项式的次数非常低时，{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}很高，因为它**欠拟合**，所以它在**交叉验证集**上表现不佳。如果改变多项式的次数，你实际上会得到一条像这样的曲线，先下降然后又上升。如果多项式的次数太低，它就会**欠拟合**，因此无法进行**交叉验证集**；如果次数太高，它就会**过拟合**，在**交叉验证集**上的表现也不会很好。只有当它处于中间位置时，它才是恰到好处的，这就是为什么我们例子中的二阶多项式最终会得到较低的**交叉验证误差**，既不会出现**高偏差**也不会出现**高方差**的原因。
{% asset_img ml_2.png %}

总结一下，你如何诊断是否具有高偏差？如果你的学习算法有**高偏差**的数据，关键指标将是{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}是否很高。这对应于曲线的最左边部分，也就是{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}很高的地方。你如何诊断是否有**高方差**？而高方差的关键指标将是{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}是否大于{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}的两倍。当我们将一个非常高阶多项式拟合到这个小数据集时，就会发生这种情况。在某些情况下，同时存在**高偏差**和**高方差**是可能的。对于**线性回归**，你不会看到这种情况发生，如果训练一个神经网络，有些场景下存在**高偏差**和**高方差**。如果{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}很高，那么在训练集上的表现就不是很好，**交叉验证误差**远大于训练集。**高偏差**意味着在训练集上的表现都不好，而**高方差**意味着在**交叉验证集**上的表现比训练集差得多。

让我们看看**正则化**，特别是正则化参数{% mathjax %}\lambda{% endmathjax %}的选择如何去影响**偏差**和**方差**，从而影响算法的整体性能。当您想要为算法选择一个**正则化**参数{% mathjax %}\lambda{% endmathjax %}值时，将会起到很大的作用。在这个例子中，使用四阶多项式{% mathjax %}f_{\vec{w},b}(x) = w_1x + w_2x^2 + w_3x^3 + w_4x^4 + b{% endmathjax %}，使用**正则化**来**拟合**这个模型{% mathjax %}\mathbf{J}(\vec{w},b) = \frac{1}{2m}\sum_{i=1}^m (f_{\vec{w},b}(\vec{x}^{(i)}) - y^{(i)})^2 + \frac{\lambda}{2m}\sum_{j = 1}^n w_j^2{% endmathjax %}。这里的{% mathjax %}\lambda{% endmathjax %}值是**正则化参数**。假设{% mathjax %}\lambda = 10000{% endmathjax %}。当{% mathjax %}\lambda{% endmathjax %}非常大，那么算法就会倾向于将这些参数{% mathjax %}w{% endmathjax %}保持在非常小的水平，因此会得到{% mathjax %}w_1,w_2{% endmathjax %}，实际上所有这些参数都非常接近于零。模型最终会得到{% mathjax %}f(x) \approx b{% endmathjax %}近似于{% mathjax %}b{% endmathjax %}一个常数值。这个模型显然具有很高的**偏差**，并且它与训练数据不相符，因为它在训练集上的表现不好，而且{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}很大。让我们看看另一个极端。假设{% mathjax %}\lambda{% endmathjax %}设置为一个非常小的值。事实上，在{% mathjax %}\lambda{% endmathjax %}值很小的情况下，将{% mathjax %}\lambda{% endmathjax %}设置为零。选择这种{% mathjax %}\lambda{% endmathjax %}时，没有正则化，只是**拟合**一个没有**正则化**的四阶多项式，最终会得到之前看到的**过度拟合**数据的曲线。当拥有这样的一个模型时，{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}很小，但{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}比{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}大得多。这表明**方差**很大，并且**过度拟合**了数据。那么您如何选择一个好的{% mathjax %}\lambda{% endmathjax %}值？这将类似于使用**交叉验证**选择多项式的次数的过程。具体来说，假设尝试使用{% mathjax %}\lambda = 0{% endmathjax %}来拟合模型。我们将使用{% mathjax %}\lambda = 0{% endmathjax %}来最小化**成本函数**，最终得到一些参数{% mathjax %}w_1,b_1{% endmathjax %}，然后可以计算**交叉验证误差**{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}。假设尝{% mathjax %}\lambda = 0.01{% endmathjax %}。然后，最小化成本函数提供第二组参数{% mathjax %}w^{<2>},b^{<2>}{% endmathjax %}，依此类推。在这个例子中，当{% mathjax %}\lambda = 0.02{% endmathjax %}，这样得到{% mathjax %}w^{<3>},b^{<3>}{% endmathjax %}的{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}，依此类推。经过多次加倍后，{% mathjax %}\lambda = 10{% endmathjax %}，将提供参数 {% mathjax %}w^{<12>},b^{<12>}{% endmathjax %}。通过尝试{% mathjax %}\lambda{% endmathjax %}的大量可能值，使用这些不同的**正则化参数**拟合参数，然后评估**交叉验证集**上的性能。让我们看看**训练误差**和**交叉验证误差**如何随参数{% mathjax %}\lambda{% endmathjax %}的变化而变化。

在下图中，再次更改了{% mathjax %}x{% endmathjax %}轴。这里的{% mathjax %}x{% endmathjax %}轴标注的是**正则化参数**{% mathjax %}\lambda{% endmathjax %}值，因此最终得到了这条非常弯曲的曲线。如果 {% mathjax %}\lambda{% endmathjax %}很小，甚至为零，在这种情况下，有一个**高方差模型**，{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}会很小，而{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}会很大，它在训练数据上表现很好。假设{% mathjax %}\lambda = 10000{% endmathjax %}，最终会拟合出一个看起来像这样的模型。这具有很高的**偏差**，它与数据不相符，结果是{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}会很高，{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}也会很高。事实上，你会发现{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}会像这样上升，因为在优化**成本函数**中，{% mathjax %}\lambda{% endmathjax %}越大，**正则化项**的权重越大，因此对训练集上表现良好的关注就越少。越试图保持参数很小，它在最小化训练误差方面做得越差。这就是为什么随着{% mathjax %}\lambda{% endmathjax %}的增加，训练误差{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}会趋于增加。**交叉验证误差**会怎么样？如果{% mathjax %}\lambda{% endmathjax %}太小或太大，那么它在**交叉验证集**上的表现就越差。它要么在左侧**过度拟合**，要么在右侧**欠拟合**。{% mathjax %}\lambda{% endmathjax %}会有一些中间值，使算法表现最佳。**交叉验证**所做的就是尝试许多不同的{% mathjax %}\lambda{% endmathjax %}值。尝试许多不同的{% mathjax %}\lambda{% endmathjax %}值，并评估许多不同点的**交叉验证误差**，然后选择一个具有较低**交叉验证误差**的值。这条曲线的左侧部分对应于欠拟合和高偏差，右侧部分对应于过拟合和高方差。而在这个图中，**高方差**在左边，**高偏差**在右边。但这就是为什么这两个图像有点像彼此的镜像。但在这两种情况下，**交叉验证**评估不同的值都可以帮助你选择一个好的{% mathjax %}\lambda{% endmathjax %}值。这就是**正则化参数**{% mathjax %}\lambda{% endmathjax %}选择如何影响算法的**偏差**和**方差**以及整体性能过程，掌握了如何使用**交叉验证**来为**正则化参数**{% mathjax %}\lambda{% endmathjax %}做出一个好的选择。
{% asset_img ml_3.png %}

让我们看看{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}和{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}的具体数值，看看如何判断学习算法是具有**高偏差**还是**高方差**的。许多在手机上进行搜索的用户会使用**语音识别**，而不是在手机的小键盘上打字，因为对着手机说话通常比打字更快。比如“今天的天气怎么样？”或者像这样，“我附近的咖啡店。”语音识别算法的工作就是输出为文本。现在，如果要训练语音识别系统并测量训练误差，训练误差意味着训练集中，算法无法正确转录的音频片段的百分比是多少。假设此数据集的训练误差为`10.8%`，意味着它可以完美转录`89.2%`的训练集，但会犯`10.8%`的训练集错误。如果您还要在单独的**交叉验证集**上测量语音识别算法的性能，假设其错误率为`14.8%`。你会发现训练误差非常高，错误率为`10%`，然后**交叉验证误差**更高，但即使训练集有`10%`的错误，这个错误率似乎相当高。它具有很高的**偏差**，但事实证明，在分析语音识别时，测量另一件事也很有用，那就是人类的表现水平如何？换句话说，人类从这些音频片段中转录语音的准确程度如何？具体来说，假设你测量了流利说话者转录音频片段的能力，发现人类水平的表现达到了`10.6%`的错误率。为什么人类水平的错误率这么高？对于网络搜索，有很多音频片段有很多嘈杂的音频，由于音频中的噪音，实际上没有人能够准确地转录所说的内容。如果连人类都会犯`10.6%`的错误率，那么似乎很难指望学习算法能做得更好。为了判断训练错误是否很高，看看训练错误是否远远高于人类水平的表现会更有用，在这个例子中，它的表现只比人类差`0.2%`。但相比之下，{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}和{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}之间的差距要大得多。实际上，两者之间的差距为`4%`。当我们将其与人类水平的表现进行比较时，我们发现该算法在训练集上的表现实际上相当不错，但更大的问题是**交叉验证误差**远高于训练误差，这就是为什么我会得出结论，该算法实际上存在更多的**方差问题**而不是**偏差问题**。判断训练误差是否高通常有助于确定性能的基准水平，而我所说的性能基准水平是指学习算法最终达到的错误水平。确定**性能基准水平**的一种常见方法是衡量人类在这项任务上的表现如何，因为人类非常擅长理解语音数据、处理图像或理解文本。当您使用非结构化数据（例如：音频、图像或文本）时，人类水平的表现通常是一个很好的基准。估计基准性能水平的另一种方法是，如果存在某种竞争算法，可能是其他人已经实现的先前实现，甚至是竞争对手的算法，那么如果可以测量基准性能水平，则可以建立基准性能水平。如果可以访问此基准性能水平，那么可以合理地希望达到的错误水平是多少？然后，在判断算法是否具有**高偏差**或**方差**时，查看**基准性能水平**、**训练误差**和**交叉验证误差**。然后要测量的两个关键数值是：训练误差与希望获得的基准水平之间的差异是多少？如果这个数值很大，那么会是一个**高偏差**问题。然后查看训练误差和交叉验证误差之间的差异是多少？如果这个差异很大，那么会是一个**高方差问题**。第二个例子，如果基准水平的表现；即人类水平的表现，**训练误差**和**交叉验证误差**差距是`4.4%`。训练误差远高于人类所能达到的水平和我们希望达到的水平，而交叉验证误差只比训练误差大一点。这个算法有**高偏差问题**。通过查看训练误差和交叉验证误差可以直观地了解算法有**高偏差**或**高方差**问题的程度。有时，性能的基准水平可能是`0%`。如果目标是实现比基准水平更好的性能，那么性能的基准水平可能是`0%`，但对于某些应用程序（例如语音识别应用程序），其中一些音频只是嘈杂的，那么性能的基准水平可能远高于零。您的算法可能存在**高偏差**和**高方差**。基线和训练误差之间的差距`4.4%`，训练误差和交叉验证误差之间的差距是`4.7%`。则算法具有**高偏差**和**高方差**。总而言之，查看训练误差是否很大是判断算法是否具有**高偏差**的一种方法，但数据有时只是嘈杂且无法期望获得零误差，建立这个**基准性能水平**很有用。同样，查看交叉验证误差是否比训练误差大得多，可以让您了解算法是否存在**高方差问题**。

**学习曲线**是一种帮助理解学习算法并如何根据其经验量（例如，它拥有的训练示例数量）来执行的方法。如下图所示，绘制一个适合二次函数模型的**学习曲线**。绘制{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}**交叉验证误差**）和{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}（**训练误差**）。
{% asset_img ml_4.png %}

在上图中，横轴是{% mathjax %}m_{\text{train}}{% endmathjax %}。代表训练集大小。纵轴代表误差（{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}或{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}）。随着{% mathjax %}m_{\text{train}}{% endmathjax %}（训练集大小）变大，这将学习到更好的模型，因此**交叉验证误差**会下降。现在绘制{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}，**训练误差**随着训练集大小变大会增加。从一个例子开始，当你只有一个训练示例时。如果用二次模型拟合直线，你的训练误差将为零。如果有两个这样的训练示例呢？可以再次拟合一条直线并实现零训练误差。事实上，如果有三个训练示例，二次函数仍然可以很好地拟合它并获得几乎为零的**训练误差**，但现在训练集稍微大一点，比如说有四个训练示例，那么完美地拟合所有四个示例就会变得有点困难。当将训练集大小增加到`4`时，**训练误差**会稍微增加一点。假设有`5`个训练样本，要完美拟合所有样本就更难了。总结一下，当你只有很少的训练样本，比如`1、2、3`个时，相对容易得到零或非常小的**训练误差**，但是当有更大的训练集时，二次函数很难完美拟合所有训练样本。这就是为什么随着训练集变大，**训练误差**会增加，因为完美拟合所有训练样本变得更加困难。请注意，**交叉验证误差**通常会高于**训练误差**，因为将参数拟合到训练集上。期望在训练集上的表现至少会比在**交叉验证集**上的表现好一点，或者当`m`较小时，甚至可能会好很多。现在让我们看看**高偏差**和**高方差**的**学习曲线**是什么样的？先从**高偏差**的情况开始。如果绘制**训练误差**，那么**训练误差**就会像预期的那样上升。这条**训练误差曲线**可能会开始趋于平缓。我们称之为**平台期**，意思是一段时间后趋于平缓。这是因为在拟合简单的线性函数时，随着得到越来越多的训练样本，模型实际上并没有发生太大的变化。这就是为什么平均训练误差在一段时间后趋于平缓的原因。同样，交叉验证误差也会在一段时间后下降并变大，这就是为什么{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}再次高于{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}，但{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}会在超过某个点后，即使获得再多的样本示例，拟合的直线也不会发生太大变化。因为模型太简单了，无法适应这么多数据。这就是为什么这两条曲线，{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}和{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}一段时间后都会趋于平坦的原因。如果您对该基准水平的表现有一个**衡量标准**，例如人类水平的表现，那么它们往往会低于当下的{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}和{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}。基准水平和{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}之间存在很大差距，这是我们对该算法具有**高偏差**的指标。也就是说，如果能够拟合一个比直线更复杂的函数，模型做的更加好。如果这里有更大的训练集，情况会怎样？如果将这两条曲线向右延伸，它们都会变平，而且它们可能都会一直保持这种平坦状态。无论向图表右侧延伸多远，这两条曲线都永远不会以某种方式下降到人类水平的表现，无论训练集有多大，它们几乎都会永远保持这种平坦状态。
{% asset_img ml_5.png %}

这得出了一个结论，如果你的算法具有**高偏差**，那么唯一能做的就是向其投入更多训练数据，但这永远不会将**错误率**降到很低。这就是为什么在投入大量精力收集更多训练数据之前，需要检查你的**学习算法**是否具有**高偏差**。**高方差**的学习曲线又会是什么样的？如果用{% mathjax %}\lambda = 0{% endmathjax %}来拟合四阶多项式，那么会得到一条看起来像这样的曲线，即使它非常适合训练数据，但它并不具有**泛化能力**。{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}会随着训练集大小的增加而上升，所以你会得到一条看起来像这样的曲线，而{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}会高得多，所以**交叉验证误差**比**训练误差**高得多。这种**高方差**在训练集上的表现比在**交叉验证集**上要好得多。如果要绘制一个基准水平的表现，比如人类水平的表现，可能会发现，{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}有时甚至低于人类水平的表现。但是**过度拟合**可能会很好地拟合训练集，得到一个不切实际的低误差，当方差较大时，增加训练集大小有很大帮助，**训练误差**继续上升，**交叉验证误差**下降并接近{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}。因此，在这种情况下，可能只需增加训练集大小即可降低交叉验证误差并使算法的表现越来越好。总而言之，如果学习算法存在**高方差**，那么获取更多训练数据确实会有所帮助。因为会发现{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}会继续下降。在这个例子中，只需获取更多训练数据，算法就可以从相对较高的**交叉验证误差**转变为更接近人类水平的表现。如果你正在构建机器学习模型，可以根据需要绘制**学习曲线**，也就是说，可以采用训练集的不同子集（有`1,000`个训练示例，可以仅使用100个训练示例训练模型并查看训练误差和交叉验证误差，然后使用`200`个示例训练模型，保留`800`个示例并暂时不使用它们），然后绘制{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}和{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}等重复并绘制**学习曲线**。以这种方式将其可视化，应该是另一种查看**学习曲线**是**高偏差**还是**高方差**的方法。但有一个缺点是，使用不同大小的训练集子集来训练如此多不同的模型在计算上非常昂贵，因此在实践中，并不经常这样做。

通过查看{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}和{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}，即**训练误差**和**交叉验证误差**，或者绘制**学习曲线**，可以了解学习算法是否具有**高偏差**或**高方差**。这将帮助我更好地决定下一步该做什么，来提高学习算法的性能。可以看一个例子，线性回归来预测房价，但算法在预测中产生了不可接受的错误，接下来应该怎么做？想到的方法是获取更多训练示例，尝试少量特征，附加特征等等。如果学习算法有**高偏差**，或**高方差**，第一个方法是获得更多的训练样本。如果算法有**高偏差**，那么唯一能做的就是获得更多的训练数据，但这对于高偏差不起作用。相反，如果算法有**高方差**，比如说它对一个非常小的训练集**过度拟合**，那么获得更多的训练样本将大有帮助。第一个方法（获得更多的训练样本）有助于解决**高方差问题**。第二个方法是减少特征数量，如果学习算法有太多的特征，那么它会给算法带来太多的灵活性，而适应非常复杂的模型。这有点像{% mathjax %}x,x^2,x^3,x^4,x^5{% endmathjax %}等等。如果消除其中的几个，那么模型就不会变得那么复杂，也不会有那么高的方差。减少特征数量将有助于降低算法**过度拟合**数据的灵活性。这是一种可以帮助解决**高方差**的策略。第三种方法是添加额外的特征。这将帮助您解决**高偏差问题**。举一个具体的例子，如果仅根据房屋大小来预测房屋的价格，但事实证明房屋的价格也取决于卧室数量、楼层数量和房屋年龄，那么除非添加这些额外的特征，否则算法永远不会做得更好。这是一个**高偏差问题**，添加额外的特征是解决**高偏差问题**的一种方法。第四种方法是添加额外的多项式特征可以在训练集上做得更好，是一种解决**高偏差问题**的方法。第五种方法是降低{% mathjax %}\lambda{% endmathjax %}（正则化参数值）将减少对这个项的关注，而更多地关注其它项，这有助于你解决**高偏差问题**。最后，第六种方式是增加{% mathjax %}\lambda{% endmathjax %}值，如果过度拟合训练集，增加{% mathjax %}\lambda{% endmathjax %}是有意义的，只是投入了太多的**注意力**来拟合训练集，但以牺牲对新示例的推广为代价，因此增加{% mathjax %}\lambda{% endmathjax %}会使算法拟合的更平滑，这有助于解决**高方差问题**。

如果你发现算法存在**高方差**，那么主要的方法是：要么获得更多的训练数据，要么简化模型。简化模型的意思是，要么获取一组较小的特征，要么增加正则化参数{% mathjax %}\lambda{% endmathjax %}。相反，如果算法存在**高偏差**，主要的方法是让模型更灵活地拟合更复杂或更弯曲的函数。添加额外的特征或添加多项式特征，或者降低正则化参数{% mathjax %}\lambda{% endmathjax %}值。如果减少训练集的大小，训练集的拟合效果会更好，但这往往会降低**交叉验证误差**和学习算法的性能，因此不要为了解决**高偏差问题**而随意丢弃训练样本。**偏差**和**方差**是非常强大的概念之一。

我们发现**高偏差**或**高方差**都是不好的，因为它们会损害算法的性能。如果用不同阶的多项式拟合一个数据集，一个非常简单的模型，它可能有**高偏差**，而如果要拟合一个复杂的模型，它可能有**高方差**。偏差和方差之间存在这种权衡，选择二阶多项式可以帮助做出权衡。如果你的模型太简单，偏差就会很高，如果模型太复杂，方差就会很高。这时必须在它们之间找到一个权衡，才能找到最好的结果。但神经网络提供了一种摆脱这种必须权衡**偏差**和**方差**的困境的方法，大型神经网络在小型中等规模的数据集上训练时是低偏差。如果你你的神经网络足够大，总是可以很好地拟合训练集。可以根据需要尝试减少偏差或减少方差，而无需在两者之间进行权衡。

首先在训练集上训练算法，然后询问它在训练集上的表现是否良好。测量{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}并查看它是否很高（高是指相对于人类水平的表现或某些基准水平的表现，如果它表现不佳，那么你就有高偏差问题，高训练误差）。减少偏差的一种方法是使用更大的神经网络，更大的神经网络是指更多的**隐藏层**或每层更多的**隐藏单元**。然后，继续这个循环，神经网络越来越大，直到它在训练集中达到的错误水平大致与希望达到的目标错误水平相当，这可能是人类水平的表现。{% mathjax %}\mathbf{J}_{\text{cv}}{% endmathjax %}和{% mathjax %}\mathbf{J}_{\text{train}}{% endmathjax %}之间的巨大差距表明存在**高方差问题**，如果存在高方差问题，那么尝试修复它的一种方法是获取更多数据。获取更多数据并返回并重新训练模型，然后仔细检查，只需要训练集吗？如果不是，则使用更大的网络，或者看看它在交叉验证集上是否确实如此，如果不是，则获取更多数据。如果继续循环往复，直到最终它在**交叉验证集**上表现良好。当然，这种方法的应用存在局限性，训练更大的神经网络不会减少偏差，但在某些时候它确实会消耗大量计算资源。这就是为什么神经网络的兴起确实得益于超高速计算机的兴起，尤其是`GPU`。它对加速神经网络也非常有用。但即使使用硬件加速器，超过一定程度，神经网络也会变得非常庞大，需要很长时间进行训练，变得不可行。当然，另一个限制是更多的数据。有时只能获得这么多数据，超过一定程度就很难获得更多数据。但在增加**神经网络**之后，会发现方差很大，在这种情况下，可能会收集更多数据。当您训练神经网络时，经过精心选择的正则化的大型神经网络通常与小型神经网络一样好或更好。有一个警告，那就是当训练**大型神经网络**时，它的计算成本会更高。所以它的主要坏处是，它会减慢训练和推理过程，并且非常短暂地对神经网络进行**正则化**。如果**神经网络**的成本函数是平均损失，所以这里的损失可能是**平方误差**或**逻辑损失**。

然后，神经网络**的正则化**项看起来与期望的非常相似，即{% mathjax %}\mathbf{J}(\mathbf{W,B}) = \frac{1}{m}\sum_{i=1}^m L(f(\vec{x}^{(i)}),y^{(i)}) + \frac{\lambda}{2m}\sum_{\text{all weights}\;\mathbf{W}} (w^2){% endmathjax %}，其中这是神经网络中所有权重{% mathjax %}\mathbf{W}{% endmathjax %}的总和，与**线性回归**和**逻辑回归**的**正则化**类似，通常不会对**神经网络**中的参数进行**正则化**。在`TensorFlow`中实现正则化的方式是回想一下，手写数字分类模型的代码。创建三个层，其中包含多个拟合**单元激活**，然后创建一个包含三个层的顺序模型。添加正则化`L2(0.001)`，为了简单起见，可以为所有权重和所有不同的层选择相同的{% mathjax %}\lambda{% endmathjax %}值。首先适当地进行正则化，拥有更大的神经网络几乎不会有什么坏处。一个警告是，拥有更大的神经网络会减慢你的算法。其次，只要训练集不是太大。那么更大的神经网络通常是低偏差的。所以深度学习的兴起确实改变了机器学习从业者对**偏差**和**方差**的看法。
```python
import tensorflow as tf
from tensorflow.keras import Sequential
from tensorflow.keras.layouts import Dense

model = Squential([
    Dense(units = 25,activation='relu', kernel_regularizer = L2(0.01)),          # layer 1
    Dense(units = 15,activation='relu', kernel_regularizer = L2(0.01)),          # layer 2
    Dense(units = 1, activation='sigmoid', kernel_regularizer = L2(0.01))])      # layer 3

```
#### 开发流程

开发**机器学习模型**，首先，要决定系统的整体架构。选择**机器学习模型**以及决定使用哪些数据，也许还要选择超参数等等。然后，根据这些决定，训练模型。正如之前提到的，当第一次训练模型时，它几乎永远不会按照希望的那样工作。建议下一步是查看一些诊断，例如查看算法的**偏差**和**方差**。根据诊断结果做出决定，例如是否要扩大**神经网络**、变更{% mathjax %}\lambda{% endmathjax %}**正则化参数**、添加更多数据、添加更多特征、减少特征等。然后，使用新选择的架构再次进行此循环，并且通常需要多次迭代才能达到所需的性能。让我们看一个构建电子邮件垃圾邮件分类器的示例。左侧的示例是垃圾邮件的典型样子。本周特价，劳力士手表。垃圾邮件发送者有时会故意拼错这些单词，例如手表、药品和抵押贷款，以试图让垃圾邮件识别器出错。相比之下，右边的这封电子邮件是真实电子邮件。如何构建分类器来识别垃圾邮件和非垃圾邮件？一种方法是训练监督学习算法，其中输入特征{% mathjax %}x{% endmathjax %}将是电子邮件的特征，输出标签{% mathjax %}y{% endmathjax %}将是`1`或`0`，具体取决于它是垃圾邮件还是非垃圾邮件。构建电子邮件特征的一种方法是，取出英语或其他词典中的前`10,000`个单词，并使用它们来定义特征{% mathjax %}x_1,x_2,\ldots,x_10000{% endmathjax %}。例如，右侧的电子邮件有以下单词列表`a、Andrew buy deal discount`等等。将这些特征设置为`0`或`1`，具体取决于该词是否出现。构建特征向量的方法有很多。另一种方法是让这些数字不仅仅是`1`或`0`，而是计算给定单词在电子邮件中出现的次数。如果`buy`出现了两次，将其设置为`2`，有了这些特征，您就可以训练分类算法（例如**逻辑回归模型**或**神经网络**）来根据这些特征{% mathjax %}x{% endmathjax %}来预测{% mathjax %}y{% endmathjax %}。训练完初始模型后，如果它的效果不如您所愿，可能会有多种改进学习算法性能的想法。例如，收集更多数据。例如，如果算法具有高偏差而不是高方差，花费数月时间收集数据效果甚微。但如果您的算法具有高方差，那么收集更多数据可能会大有帮助。
