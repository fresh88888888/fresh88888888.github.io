---
title: 机器学习(ML)(十七) — 搜索引擎探析
date: 2024-11-15 16:10:11
tags:
  - AI
categories:
  - 人工智能
mathjax:
  tex:
    tags: 'ams'
  svg:
    exFactor: 0.03
---

#### 介绍

**搜索引擎**是一种根据用户需求，通过特定算法和策略从互联网上检索信息并反馈给用户的系统。**搜索引擎**可以被定义为一个自动化系统，它通过计算机程序从互联网收集信息，经过组织和处理后，为用户提供**检索服务**。**搜索引擎**的发展经历了多个阶段：第一代搜索引擎(`1994`)：以人工分类为主，代表有`Yahoo`；第二代搜索引擎：利用**关键字**进行查询，`Google`是其代表；第三代搜索引擎：强调个性化和智能化，结合**人工智能**技术；第四代搜索引擎：应对信息**多元化**，采用更精确的**特征提取**和**文本处理技术**。
<!-- more -->

**搜索引擎**的工作过程可以分为以下几个主要步骤：
- **爬虫**(`Crawl`)：网络爬虫自动在互联网上抓取网页信息，并存储到数据库中。
- **解析**(`Analyze`)：对抓取到的数据进行格式化处理和清洗。
- **索引**(`Index`)：将处理后的数据构建索引，以便快速检索。
- **检索**(`Search`)：根据用户输入的查询内容，从索引中找到相关文档。
- **排序**(`Rank`)：根据相关性等因素对检索结果进行排序，并返回给用户。

决定**搜索引擎**的用户满意度包括`3`个因素：**相关性**、**内容质量**、**时效性**、**个性化**。
- `相关性`(`Relevance`)：在搜索中，相关性指的是查询词{% mathjax %}q{% endmathjax %}与文档{% mathjax %}d{% endmathjax %}两者的关系。相关性是一个客观的标准，不带有个性化，相关性只取决于{% mathjax %}q{% endmathjax %}和{% mathjax %}d{% endmathjax %}，而不取决于用户{% mathjax %}u{% endmathjax %}（如果大多数有背景知识的人认为{% mathjax %}(q,d){% endmathjax %}相关，则判定为相关）。**相关性**是语义上的，不是字面上的（相关是指{% mathjax %}d{% endmathjax %}能满足{% mathjax %}q{% endmathjax %}的需求或回答{% mathjax %}q{% endmathjax %}提出的问题）。查询词{% mathjax %}q{% endmathjax %}可能有多重意图，只要{% mathjax %}d{% endmathjax %}命中{% mathjax %}q{% endmathjax %}的一种主要意图，则{% mathjax %}(q,d){% endmathjax %}算相关。**搜索引擎**链路上有召回、粗排、精排这些环节，每个环节都需要计算**相关性**，搜索召回得到的文档数量很大，至少有几万，在输入排序之前需要进行初步的筛选，过滤掉相**关性很**低的文档，这个过程叫做**召回海选**，这里可以用很简单的办法计算相关性，比如文本匹配分数或双塔`BERT`模型粗略地估计相关性。粗排阶段候选文档数量为几千，用双塔`BERT`模型或浅层交叉`BERT`模型计算**相关性**。精排阶段候选文档数量是几百，用交叉`BERT`模型计算相关性。`EAT`是谷歌提出的内容质量评价标准，相关文档，请参考：[`search quality evaluator guidelines`](https://static.googleusercontent.com/media/guidelines.raterhub.com/en//searchqualityevaluatorguidelines.pdf)，对于`your money or your life`方面的查询词，`EAT`是排序的重要因子。`you money`包括：金融理财（保险、报税、投资、贷款、转账等）、电商、购物；`your life`包括：医疗健康（诊断建议、用药建议、医院介绍、减肥等）、法律等严肃主题（诉讼、移民、选举、离婚、收养）、对人生产生重大影响的主题（高考、择校、出国、就业）。对于严肃和重要的主题，搜索排序应该给`EAT`很高的权重，如果不重视`EAT`，搜索引擎损失的不只是用户的体验和主观感受，甚至会造成危害。
- `内容质量`：一方面是文章本身的价值，文章是否清晰、全面，事实是否准确，信息是否有用；另一方面是作者的态度和水平，写作是否认真、写作的专业程度、写作的技巧。最后还有文章的意图（有益、有害）。图片质量（视频质量），分辨率、有无水印、是不是截图、图片是否清晰、图片的美学等。内容质量不是一个分数，而是有很多个分数，都会在搜索排序中起作用。对于每个文本质量分数，都有一个专门训练的模型（可以是`BERT`等`NLP`模型、`CLIP`等多模态模型）。训练模型的数据是人工标注的，手下按指定分档规则，比如文本质量分为高、中、低`3`个档位，然后让人工做标注，给每个定义一个档位。有了了数据就可以训练模型，通常来说模型首先要做预训练，然后采用人工标注的数据做**微调**，人工标注的数据可多可少，文本质量分数都是静态的，只需要训练一次就够了。在文档发布、或被检索的时候，用模型打分，分数存入文档画像中（搜索排序的时直接读取文档画像）。
- `时效性`：如果查询词是`query = `“最新房贷政策”、“美元汇率”，这时文档的年龄很重要；`query = `“泰国旅游”、“网红探店”，它们有时效性需求，但是此需求不强。**查询词**对时效性需求越强，那么文档的年龄权重也就越大。可以看出，优化**搜索时效性**的关键是识别**查询词**的时效性意图（即查询词对“新”的需求）。工业界通常对时效性做个分类：突发时效性、一般时效性（强、中、弱、无）、周期时效性。搜索引擎主要通过数据挖掘、语义模型来识别这几种时效性意图。**突发时效性**，若查询词涉及突发新闻、热点事件，则查询词就带有突发时效性。如果查询词带有突发时效性意图，那么用户大概率是想看最近发布的文档。**搜索引擎**识别突发时效性的方法是通过数据挖掘为主，比如挖掘站内搜索量激增的查询词；挖掘站内发布量激增的关键词；抓取其他网站的热词。只能通过数据挖掘来判断突发时效性。**一般时效性**，只看查询词字面意思就可以判断时效性意图的强弱。一般时效性可以根据需求的强弱，分为强、中、弱、无，搜索引擎会使用`BERT`等语义模型来识别一般时效性。**周期时效性**，在每年特定的时间表现为突发时效性，在其他时间表现为无时效性，例如双十一、春晚小品、高考作文、奥斯卡等。周期时效性可以不做任何处理（当查询词表现为突发时效性时，会被算法挖掘到），可以做人工标注、数据挖掘识别周期时效性查询词。
- `个性化`：**搜索引擎**可以带有个性化，考虑到不同用户有不同的偏好，在排序的时候，**搜索引擎**可以根据用户特征做排序（类似**推荐系统**）。查询词越宽泛，就越需要个性化排序；预估点击率和交互率有利于提升相关性和内容质量。

最后**搜索引擎**会结合相关性、内容质量、时效性、个性化（预估点击率和交互率）等因子对候选文档做排序。

#### 评价指标

**搜索引擎**的评价指标分为`3`类：**北极星指标**，包括用户规模（`DAU`、`MAU`、搜索渗透率 `= Search DAU / DAU`）、留存（次日留存、`LT7`、`LT30`）；**中间指标**，包括文档点击率、有点比、首屏有点比、首点位置、主动换词率、交互指标；**人工体验评估**，包括`side by side`评估、月度评估。`side by side`评估的指标是`Good Same Bad (GSB)`，如果新策略更优记作`Good(G)`；如果两者持平，记作`Same(S)`；如果旧策略更优，记作`Bad(B)`，月度评估的指标是`Discounted Cumulative Gain (DCG)`，每个月随机抽取一批搜索日志，每条搜索日志包含查询词{% mathjax %}q{% endmathjax %}、用户{% mathjax %}u{% endmathjax %}、场景{% mathjax %}c{% endmathjax %}、排名前{% mathjax %}k{% endmathjax %}的文档{% mathjax %}d_1,\ldots,d_k{% endmathjax %}。随机抽样搜索日志时，需要覆盖高频、中频、低频查询词，文档的数量{% mathjax %}k{% endmathjax %}取决于平均下滑深度，比如{% mathjax %}k = 20{% endmathjax %}，标注员评估每一篇文档，打分{% mathjax %}score(q,u,c,d_i){% endmathjax %}，这个分数越大，搜索结果越好。可以单独给相关性、内容质量、时效性分别打分，独立考察各个维度，这样可以得出具体的结论，用`DCG`评价一次搜索{% mathjax %}(q,u,c,d_1,\ldots,d_k){% endmathjax %}结果的好坏，{% mathjax %}\text{DCG} = \sum_{i=1}^k \frac{score(q,u,c,d_i)}{\log_2 (i+1)}{% endmathjax %}。搜索结果页整体越好，`DCG`值就越大。一个`DCG`分数是对一个收缩结果页的评价，如果每个月随机抽取`2000`个搜索结果页，那么就有`2000`个`DCG`分数，去这些`DCG`分数的均值，作为月度评估的结果。月度评估可以自我对比，看本月的`DCG`是否由于历史上往期的`DCG`，可以通过`DCG`分数考察搜索团队有没有让用户体验逐渐变好，也可以用`DCG`分数来来评价竞争对手。

#### 搜索链路

**搜索引擎**的链路主要分为`3`个环节（如下图所示）：分别是**查询词处理**、**召回**、**排序**。当用户输入查询词之后，首先做**查询词处理**，**查询词处理**包含很多模块，包括分词、词权重、类目识别、意图识别、查询词改写。链路上的第二个环节是召回，从海量的文档中找出与查询词相关的几万篇文档，这里会有几十条召回通道同时运行，各自有一些配额。召回结束之后，会用简单的规则做初步的筛选，把文档数量降低到几千，然后再送去排序服务器。搜索链路上最后一个环节是排序，它决定搜索结果页上文档展示的顺序，排序比较复杂，需要计算相关性、点击率等很多分数，然后用规则和模型融合这些分数，给出最终的排序。**搜索引擎**的排序比**推荐系统**的排序要复杂很多。推荐系统的排序主要靠预估点击率和交互率，搜索引擎的排序也要预估点击率和交互率，把它们作为个性化分数，此外还需要相关性、内容质量、时效性等分数。要综合所有这些分数做排序，在这些分数中，相关性的分数是最重要的。
{% asset_img ml_1.png %}

**搜索引擎**的链路各环节详细介绍：
- **查询词处理**：用户搜索查询词之后，系统会调用很多个查询词处理的服务，包括分词、词权重、类目识别、意图识别、查询词改写等。这些模块输出的结果会被下游的**召回**用到，查询词处理的重要性不高，只要有分词就可以做文本召回，搜索引擎就能勉强工作了，如果有向量召回，那么连分词都不需要。查询词有一个缓存，查询词命中缓存，就直接读取缓存中的查询词处理结果，不需要调用各个服务做计算。对于通用搜索引擎，几百万个高频查询层就能覆盖每天大部分搜索请求，也就是说，对几百万个高频查询词作缓存，就能避免查询词处理环节大部分的计算。查询词处理中必不可少的模块是**分词**(`Tokenization`)，例如用户输入查询词：“冬季卫衣推荐 -> 冬季/卫衣/推荐”，搜索引擎为什么做分词呢？**分词**(`Tokenization`)主要是给文本召回使用，查询词被切成多个`term`之后，会用这些`term`在倒排索引中检索文档。倒排索引的`key`大多是“冬季”、“卫衣”、“推荐”等这样的常用词，数量不大。假如不做分词，则倒排索引的`key`是“冬季卫衣推荐”这样的词，倒排索引会过于巨大，带来工程上的困难。所以作文本召回，必须将查询词切分成多个`term`。**词权重**(`Term Weight`)也是查询词处理的一个模块，**词权重**(`Term Weight`)不是必要的，但是对搜索引擎很有用。例如查询词还是：“冬季卫衣推荐 -> 冬季/卫衣/推荐”，分词切成了`3`个`term`，这`3`个`term`的重要性不同，词权重：“卫衣 > 冬季 > 推荐”。搜索引擎为什么要计算词权重呢？主要是为了给召回使用。如果查询词太长，没有文档可以同时包含其中所有词，所以需要丢弃不重要的`term`。计算查询词与文档的相关性时，可以用词权重做加权。**类目识别**，查询词还需要做类目识别，每个平台都有各自的多级类目体系。搜索引擎会使用`NLP`技术识别文档、查询词的类目。这属于多标签分类问题，一篇文档或查询词有可能属于多个类目，**文档类目识别**是在文档发布的时候离线做；而**查询词类目识别**是在用户做搜索的时候在线做。类目识别的结果会给下游的召回、排序用，召回模型、排序模型将文档、查询词类目作为特征。**查询词意图识别**，首先是**时效性意图**：查询词对文档“新”的需求，召回和排序均要考虑文档的年龄；**地域性意图**：对于地域性意图的查询词，召回、排序不止需要文本的相关性，还需要结合用户定位地点，查询词提及的地点、文档定位的地点；**用户名意图**：如果用户想要找平台的某位用户，输入的查询词是用户名或`ID`字符串，如果搜索引擎判定查询词带有用户名意图，就应当检索用户名的数据库，而非检索文档数据库；**求购意图**，用户可能想要购买商品，需要同时在文档库、商品库中做检索；**查询词改写**：如果把查询词改写做好，搜索引擎的评价指标会提高很多，用户输入查询词{% mathjax %}q{% endmathjax %}，算法将其查询词改写成多个查询词{% mathjax %}q'_1,\ldots,q'_k{% endmathjax %}（独立用{% mathjax %}q'_1,\ldots,q'_k{% endmathjax %}做召回，对召回的文档取并集）。查询词改写有什么用呢？第一，解决语义匹配、但文本不匹配的问题；第二，是解决召回文档数量过少的问题，如果查询词的表达不规范、或查询词太长，会导致召回结果很少。
- **召回**：给定查询词{% mathjax %}q{% endmathjax %}，从文档库（数亿篇文档）中快速检索数万篇可能与{% mathjax %}q{% endmathjax %}相关的文档{% mathjax %}\{d\}{% endmathjax %}。这里同时有几十条召回通道，这些召回通道都有不同的配额。**文本召回**：就是最简单的文本匹配，借助倒排索引匹配{% mathjax %}q{% endmathjax %}中的词与{% mathjax %}d{% endmathjax %}中的词，文本召回是最传统的搜索引擎技术。在深度学习之前，搜索引擎只有文本召回。现在向量召回的重要性已经超过了文本召回；**向量召回**：就是用BERT这样的深度学习技术，将{% mathjax %}q{% endmathjax %}和{% mathjax %}d{% endmathjax %}表征为向量{% mathjax %}x_q{% endmathjax %}和{% mathjax %}z_d{% endmathjax %},给定查询词的向量{% mathjax %}x_q{% endmathjax %}，在向量数据库中做`ANN`查找，召回向量相似度高的文档{% mathjax %}z_d{% endmathjax %}，除了文本召回、向量召回，搜索引擎还有一些构造的`KV`索引，主要用于高频查询词的召回。`KV`**召回**：对于高频查询词{% mathjax %}q{% endmathjax %}，离线建立{% mathjax %}q\rightarrow\;\text{List}(d){% endmathjax %}这样的`key-value`索引，把查询词作为`key`，把文档列表作为`value`，在线上如果查询词命中索引，就可以直接读取索引上存储的文档。
- **排序**：排序的依据，**相关性**：重要性最高，在线上用`BERT`模型实时计算查询词和文档的相关性；**内容质量**：指文档的文本和图片质量，以及作者网站的EAT。算法离线分析文档的内容质量，把多个分数写到文档画像中；**时效性**：主要指查询词对“新”的需求，查询词处理分析时效性，把结果传递给排序服务器；**个性化**：在不同的搜索引擎中，个性化的重要性各不相同。在线上用多目标模型预估点击率和交互率。

**文本召回流程**：离线处理文档，建立倒排索引（给定词{% mathjax %}t{% endmathjax %}，可以快速找到包含{% mathjax %}t{% endmathjax %}的文档）在线上，给定查询次{% mathjax %}q{% endmathjax %}，做分词得到多个词{% mathjax %}t_1,\ldots,t_k{% endmathjax %}，对于每个词{% mathjax %}t_i{% endmathjax %}，检索倒排索引，得到文档的集合{% mathjax %}\mathcal{D}_i{% endmathjax %}，这些文档全都包含{% mathjax %}t_i{% endmathjax %}，然后求{% mathjax %}k{% endmathjax %}个集合的交集{% mathjax %}\mathcal{D}_1\cap\ldots\cap\mathcal{D}_k{% endmathjax %}，作为文本召回的结果，这里可能交集很小，可能为空，因此需要对查询词{% mathjax %}q{% endmathjax %}做丢词或改写。
{% asset_img ml_2.png %}

**向量召回流程**：借助深度学习技术，把查询词和文档表征为向量。在线上通过最近邻查找，检索与查询词相关的文档，如下图所示，左右两边各有一个神经网络，这种模型叫做双塔模型，左边的网络将查询词表征为向量，神经网络的输入是查询词文本，以及查询词类目等特征；右边的神经网络将文档表征为向量，它的输入是文档文本，以及文档类目等特征。两个神经网络输出形状相同的向量，于是可以计算两个向量的内积或余弦相似度，训练模型的时候用相关性、点击作为预测的目标。文档的向量表征是离线计算好的，存入了向量数据库。查询词的向量表征是线上实时计算得，查询词很短，所以左边神经网络推理代价不大。在线上做召回的时候，给定查询词的向量表征，在向量数据库中做`ANN`查找，找到相似度最高的一批文档，作为召回的结果。
{% asset_img ml_3.png %}

`KV`**召回**：如下图所示，图上画的是离线建立的索引，索引上的`key`是高频查询词，这些都是用户真实搜过的查询词，再过去一段时间内，搜索的次数高于某个阈值，索引的`value`是文档列表，每个查询词都对应很多篇文档，由于离线做过筛选，上面的查询词与下面的文档具有高相关性。当用户在线上输入一个查询词，要去下面检索索引，如果用户搜索的是一个高频查询词，就会命中索引，线面这些文档就是对应召回的结果，构造索引的时候做过筛选，索引存的文档都与查询词高相关，这样做召回的效率很高。
{% asset_img ml_4.png %}

#### 相关性 - 定义与分档

工业界做搜索**相关性**有一套比较成熟的流程（制定标注规则 -> 标注数据 -> 训练模型 -> 线上推理），首先是制定相关性的标注规则，然后人工标注数据，在做监督学习训练模型，最终把模型部署在线上做推理。通常是由搜索产品和搜索算法团队来定义**相关性**标注规则，制定规则的时候，人为将{% mathjax %}(q,d){% endmathjax %}的相关性划分为4个（或5个）档位，制定相关性分档规则非常重要，假如日后有大幅变动，需要重新标注数据，从而丢弃积累的数据。有产品和算法团队监督指导标注团队的工作，积累数十万、数百万{% mathjax %}(q,d){% endmathjax %}样本。标注数据的目的是为了训练相关性模型，只要标注的质量合格，标注的数据越多，训练出来的模型就越好。相关性档位划分，如下图所示：
{% asset_img ml_5.png %}

标注员首先判断{% mathjax %}(q,d){% endmathjax %}是否相关，分成两个大的档位，一个是相关、另一个是不相关，对于每个大的档位在细分成两个小的档位，这样就一共得到4个档位（高、中、低、无），相关性档位的划分就是这样。相关性是指文档{% mathjax %}d{% endmathjax %}能否满足查询词{% mathjax %}q{% endmathjax %}的需求，或回答{% mathjax %}q{% endmathjax %}提出的问题。相关性不是字面匹配，而是需求匹配。哪怕文档{% mathjax %}d{% endmathjax %}不包含任何查询词{% mathjax %}q{% endmathjax %}的任何分词，两者也可以被判定为相关。即使{% mathjax %}q{% endmathjax %}和{% mathjax %}d{% endmathjax %}字面匹配，两者也可能不相关。相关性的标注只考虑相关性，不考虑内容质量、时效性等因素。相关性标注的时候，经常会遇到多意图的查询词，这时文档只要命中一种意图就算相关。搜上位词，出下位词，则判定为相关；而搜下位词，出上位词，则判定为不相关。如果丢失核心词，则判定为不相关。丢失重要限定词，则判定为不相关。丢失不重要的限定词，则判定为相关。具体要看文档{% mathjax %}d{% endmathjax %}能否满足查询词{% mathjax %}q{% endmathjax %}的主要需求或回答{% mathjax %}q{% endmathjax %}提出的问题。

**档位细分**：给定查询词{% mathjax %}q{% endmathjax %}和文档{% mathjax %}d{% endmathjax %}，记作{% mathjax %}(q,d){% endmathjax %}，根据前面讲的各种规则，判定{% mathjax %}q{% endmathjax %}与{% mathjax %}d{% endmathjax %}是否相关。如果相关再进一步判定相关内容在文档中的占比，如果内容占比大于`50%`，则判定为高相关性，否则判定为中相关性；如果不相关，就进一步判定内容是否具有参考价值，如果有参考价值，则判定为低相关，否则判定为不相关和参考价值。

#### 相关性 - 评价指标

**相关性**的评价指标，包括`Pointwise`**评价指标**：`Area Under the Curve` (`AUC`)、`Pairwise`**评价指标**：正逆序比(`Positive to Negative Ratio, PNR`)、`Listwise`**评价指标**：`Discounted Cumulative Gain` (`DCG`)。用`AUC`和`PNR`作为离线评价指标，用`DCG`评价模型在线上的排序效果。
- `Pointwise`**评价指标**：用`Pointwise`评价相关性的时候，会把相关性看做二分类问题，训练集还是用4个小档位，但是测试集只用2个大档位。测试集的标签只有0/1，把高、中两档合并，作为标签{% mathjax %}y = 1{% endmathjax %}；把低、无两档合并，作为标签{% mathjax %}y = 0{% endmathjax %}。以及训练好的相关性模型输出预测值{% mathjax %}p\in [0,1]{% endmathjax %}。{% mathjax %}p{% endmathjax %}指越大，模型认为查询词与文档越有可能相关，评价二分类的指标有很多种，工业界最常用AUC来评价搜索相关性。
- `Pairwise`**评价指标**：意思是每次取2个二元组作对比，**正逆序比**(`PNR`)是`Pairwise`评价指标，实际做排序的时候，给定一个查询词和很多文档，让模型根据查询词估计每篇文档的相关性，根据估计的分数对文档做排序。注意一下，排序使用的模型估计的分数，不是真实的相关性分数。给定一个查询词和{% mathjax %}k{% endmathjax %}篇文档，对文档做两两组合，则有{% mathjax %}\left( \begin{array}{ccc}k \\2\end{array}\right) = \frac{k!}{2!\times (k-2)!}{% endmathjax %}种组合，一个二元组可以是正序对，也可以是逆序对。
- `Listwise`**评价指标**：设有{% mathjax %}n{% endmathjax %}篇候选文档，根据模型打分做降序排列，把排序好的文档，记作{% mathjax %}d_1,\ldots,d_n{% endmathjax %}，{% mathjax %}d_1,\ldots,d_n{% endmathjax %}真是相关性分数为{% mathjax %}y_1,\ldots,y_n{% endmathjax %}（人工标注相关性档位，档位映射到`[0,1]`之间的实数），如果模型的排序是正确的，那么{% mathjax %}y_1,\ldots,y_n{% endmathjax %}降序排列，也就是说模型的排序与真实的排序是一致的，这种情况下，`Pairwise`与`Listwise`指标都最大化，如果出现逆序对，`Pairwise`与`Listwise`指标都减小，逆序对越多，则指标越差。对于`Pairwise`指标来说，逆序对出现在哪里都无所谓，逆序对出现的位置不影响`Pairwise`指标，只有逆序对数量才会影响`Pairwise`指标。但是逆序对出现的位置会对`Listwise`指标有影响。逆序对越靠前，对`Listwise`指标造成损失就越大。`Cumulative Gain（CG）`：设有{% mathjax %}n{% endmathjax %}篇候选文档，根据模型打分做降序排列，他们真实的相关性分数为{% mathjax %}y_1,\ldots,y_n{% endmathjax %}。但一般只关注排在前{% mathjax %}k{% endmathjax %}的文档，它们最有可能获得曝光，对用户的体验影响最大。`Cumulative Gain`记作{% mathjax %}\text{CG} = \sum_{i=1}^k y_i{% endmathjax %}。CG可以评价排序做的准不准，CG何时最大化？真实相关性分数{% mathjax %}y{% endmathjax %}最高的{% mathjax %}k{% endmathjax %}篇文档被模型排在前{% mathjax %}k{% endmathjax %}，那么`CG`指标会最大化。前{% mathjax %}k{% endmathjax %}篇文档的序不重要，它们之间可以存在逆序对。这些逆序对不影响模型指标。DCG：设有{% mathjax %}n{% endmathjax %}篇候选文档，根据模型打分做降序排列，他们真实的相关性分数为{% mathjax %}y_1,\ldots,y_n{% endmathjax %}。`Discounted Cumulative Gain`记作{% mathjax %}\text{DCG} = \sum_{i=1}^k \frac{y_i}{\log_2 (i+1)}{% endmathjax %}，`DCG`何时最大化？真实相关性分数{% mathjax %}y{% endmathjax %}最高的{% mathjax %}k{% endmathjax %}篇文档被模型排在前{% mathjax %}k{% endmathjax %}，前{% mathjax %}k{% endmathjax %}篇文档不允许存在逆序对。

**离线评价指标**：事先准备人工标注的数据，划分为训练集和测试集。完成训练之后计算测试集上的`AUC`和`PNR`。**线上评价指标**：一个搜索`session`，用户搜索{% mathjax %}q{% endmathjax %}，搜索结果页上按顺序展示文档{% mathjax %}d_1,\ldots,d_n{% endmathjax %}，做评估的时候，从搜索日志中随机抽取一批`session`，覆盖高、中、低频查询词。对于每个搜索`session`，只保留排序最高的{% mathjax %}k{% endmathjax %}篇文档{% mathjax %}d_1,\ldots,d_k{% endmathjax %}，其中{% mathjax %}k{% endmathjax %}是一个参数，具体指取决于浏览深度。高频查询词{% mathjax %}k{% endmathjax %}值设的较大（比如{% mathjax %}k = 40{% endmathjax %}），低频查询词{% mathjax %}k{% endmathjax %}值设的较小（比如{% mathjax %}k = 20{% endmathjax %}）。然后需要人工标注查询次与文档的相关性，记作{% mathjax %}y_1,\ldots,y_k{% endmathjax %}，做标注之后就可以计算`DCG`（{% mathjax %}\text{DCG} = \sum_{i=1}^k \frac{y_i}{\log_2 (i+1)}{% endmathjax %}），每一个搜索`session`都有一个`DCG`分数，分数越高，你就说明相关性越好。把所有的搜索`session`取平均，就能反应线上相关性模型的好坏。

#### 相关性 - 文本匹配

**搜索引擎**的召回都需要计算查询词与文档的**相关性**，召回结束之后，会做一个简单简单的排序，也叫作“**召回海选**”，有几万篇候选文档，需要计算它们与查询词的**相关性**，由于打分量很大，需要模型足够快，比如用文本匹配 + 线性模型计算**相关性**分数，也可以用双塔`BERT`模型，推理代价不大。**召回海选**之后，有几篇文档需要进行**粗排**，粗排可以用单塔`BERT`、双塔`BERT`模型，单塔`BERT`也叫交叉`BERT`模型，双塔的推理代价很小，准确性不高；单塔模型推理代价大，但准确性好。最后是**精排**，只给几百篇文档打分，可以用较大的模型，业界通常用单塔`BERT`模型，可以是`4`、`6`、`12`层。

传统的**搜索引擎**使用几十种人工设计的**文本匹配**分数，作为线性模型或树模型的特征，模型预测**相关性**分数。文本匹配包括：**词匹配分数**(`TF-IDF`、`BM25`)、**词距分数**(`OKaTP`、`BM25TP`)、类目匹配和核心词匹配等，目前搜索排序普遍放弃**文本匹配**，改用`BERT`模型，仅剩文本召回使用**文本匹**配做“海选”。
- **词匹配分数**(`TF-IDF`、`BM25`)：对于中文来说，想要计算词匹配分数，首先要分词，把查询词和文档切分成很多小字符串。每个小字符串是一个词，称为`term`。比如这个查询词{% mathjax %}q = \{\text{好莱坞电影推荐}\}{% endmathjax %}，分词得到：{% mathjax %}\mathcal{Q} = \{\text{好莱坞,电影、推荐}\}{% endmathjax %}，{% mathjax %}\mathcal{Q}{% endmathjax %}中的`term`在文档{% mathjax %}d{% endmathjax %}中出现的越多，则{% mathjax %}q{% endmathjax %}与{% mathjax %}d{% endmathjax %}越可能相关。分词结果记作{% mathjax %}\mathcal{Q}{% endmathjax %}，例如：{% mathjax %}\mathcal{Q} = \{\text{好莱坞,电影、推荐}\}{% endmathjax %}，{% mathjax %}t \in \mathcal{Q}{% endmathjax %}是一个词(`term`)，每次只看一个`term`，例如{% mathjax %}t = \{\text{电影}\}{% endmathjax %}，{% mathjax %}t{% endmathjax %}在文档{% mathjax %}d{% endmathjax %}出现的次数叫做**词频**，记作{% mathjax %}tf_{t,d}{% endmathjax %}，词频{% mathjax %}tf_{t,d}{% endmathjax %}越大，说明{% mathjax %}t{% endmathjax %}与{% mathjax %}d{% endmathjax %}越可能相关。查询词{% mathjax %}q{% endmathjax %}中包含多个`term`，我们可以计算每个`term`在文档中的词频，然后再把它们相加，记作{% mathjax %}\sum_{t\in\mathcal{Q}} tf_{t,d}{% endmathjax %}，{% mathjax %}\sum_{t\in\mathcal{Q}} tf_{t,d}{% endmathjax %}越大，则{% mathjax %}t{% endmathjax %}与{% mathjax %}d{% endmathjax %}越可能相关。用词频{% mathjax %}tf_{t,d}{% endmathjax %}衡量相关性有一个缺陷：文档{% mathjax %}d{% endmathjax %}越长，则{% mathjax %}tf_{t,d}{% endmathjax %}越大。解决方法：用文档{% mathjax %}d{% endmathjax %}的长度（记作{% mathjax %}l_{d}{% endmathjax %}）对词频做归一化。将原有的{% mathjax %}\sum_{t\in\mathcal{Q}} tf_{t,d}{% endmathjax %}改为{% mathjax %}\sum_{t\in\mathcal{Q}} \frac{tf_{t,d}}{l_d}{% endmathjax %}，消除文档长度的影响。但是{% mathjax %}\sum_{t\in\mathcal{Q}} \frac{tf_{t,d}}{l_d}{% endmathjax %}衡量相关性任然有缺陷，加和同等对待所有{% mathjax %}t{% endmathjax %}，查询词中的各个`term`重要性各不相同，`term`不该被同等对待。应该根据`term`的重要性设置权重，对词频`term`加权求和。那么如何设置每个`term`的权重？最好的方法是根据**语义重要性**(`term weight`)来设定。**语义重要性**(`term weight`)由查询词处理环节来负责计算。词频`term`在多少文档中出现过，记作{% mathjax %}df_t{% endmathjax %}，假设数据集一共有{% mathjax %}N{% endmathjax %}篇文档，{% mathjax %}df_t{% endmathjax %}的大小介于`0~N`之间，如果一个`term`的{% mathjax %}df_t{% endmathjax %}很大，说明这个`term`在很多个文档中出现过，说明这个`term`判别能力较弱，应当设置较小的权重。`Inverse Document Frequency(IDF)`定义为{% mathjax %}idf_t = \log\frac{N}{df_t}{% endmathjax %}，每个`term`都有自己的`IDF`，`IDF`只取决于文档的数据集。对于人工智能论文数据集，“深度学习”的`IDF`很小，对于维基百科数据集，“深度学习”的`IDF`很大。{% mathjax %}idf_t{% endmathjax %}可以衡量`term`的重要性，{% mathjax %}idf_t{% endmathjax %}越大，词频`term`越重要。原本用{% mathjax %}\sum_{t\in\mathcal{Q}} \frac{tf_{t,d}}{l_d}{% endmathjax %}衡量相关性，改用加权和{% mathjax %}\sum_{t\in\mathcal{Q}} \frac{tf_{t,d}}{l_d}\cdot idf_t{% endmathjax %}。`TF-IDF`的全称为`Term Frequency——Inverse Document Frequency`，查询词{% mathjax %}q{% endmathjax %}的分词结果记作{% mathjax %}\mathcal{Q}{% endmathjax %}，它与文档{% mathjax %}d{% endmathjax %}的相关性可以用`TF-IDF`来衡量：{% mathjax %}\text{TFIDF}(\mathcal{Q},d) = \sum_{t\in\mathcal{Q}} \frac{tf_{t,d}}{l_d}\cdot idf_t{% endmathjax %}。`BM25`：如果学习一个线性模型或树模型预测相关性，那么`BM25`的相关性的特征权重是最高的，可以把`BM25`看作是`TF-IDF`的一个变体：{% mathjax %}\sum_{t\in\mathcal{Q}}\frac{tf_{t,d}\cdot (k+1)}{tf_{t,d} + k\cdot (1-b + b\cdot \frac{l_d}{\text{maen}(l_d)})}\cdot \ln(1 + \frac{N - df_t + 0.5}{df_t + 0.5}){% endmathjax %}，其中{% mathjax %}k{% endmathjax %}和{% mathjax %}b{% endmathjax %}是参数，通常设置{% mathjax %}k\in [1.2,2]{% endmathjax %}和{% mathjax %}b = 0.75{% endmathjax %}。`BM25`对传统的搜索相关性很重要。`TF-IDF`、`BM25`都属于**词袋模型**，它们都隐含了词袋模型的假设：只考虑词频，不考虑词的顺序和上下文。**词袋模型**的缺点：它完全忽略了词序和上下文，不利于准确计算**相关性**。在**深度学习**之前有很多**词袋模型**，例如`Latent Semantic Analysis(LSA)`、`Latent Dirichlet Allocation(LDA)`。它们可以使查询词映射成向量，`RNN`、`BERT`、`GPT`都不是**词袋模型**，它们会考虑词的顺序和上下文，更好的理解查询词和文档的语义，做出更准确的预测。`BERT`和`GPT`是当前最优的模型，在**自然语言**任务上远优于各种**词袋模型**。
- **词距分数**(`OKaTP`、`BM25TP`)：例如查询词是{% mathjax %}\mathcal{Q} = \{\text{亚马逊,雨林}\}{% endmathjax %}，文档{% mathjax %}d{% endmathjax %}是“我在亚马逊网购了一本书，介绍东南亚热带雨林的植物群落...”，文档{% mathjax %}d{% endmathjax %}同时包含亚马逊、雨林两个词，会被文本召回检索到，虽然查询词{% mathjax %}\mathcal{Q}{% endmathjax %}与文档{% mathjax %}d{% endmathjax %}的文本匹配，但文档并没有满足查询的需求，所以两者不相关。如果用**词匹配分数**(`TF-IDF`、`BM25`)计算相关性，会得出错误的结论。想要避免这类错误，需要用到**词距**。**词距**：查询词{% mathjax %}q{% endmathjax %}中的两个词出现在文档{% mathjax %}d{% endmathjax %}中，两个term中间间隔多少term。两个term间隔越小，也就是词距越小，则{% mathjax %}q{% endmathjax %}与{% mathjax %}d{% endmathjax %}越相关。计算词距方法有`OKaTP`、`BM25TP`。`OKaTP`：词{% mathjax %}t{% endmathjax %}在文档{% mathjax %}d{% endmathjax %}中出现的位置记作集合{% mathjax %}\mathcal{O}(t,d){% endmathjax %}，假设{% mathjax %}t{% endmathjax %}出现在文档{% mathjax %}d{% endmathjax %}中第`27`、`84`、`98`位置上，那么{% mathjax %}\mathcal{O}(t,d) = \{27,84,98\}{% endmathjax %}。这个集合{% mathjax %}\mathcal{O}(t,d){% endmathjax %}大小等于词频：{% mathjax %}|\mathcal{O}(t,d)| = tf_{t,d}{% endmathjax %}。设{% mathjax %}t,t'{% endmathjax %}是查询词{% mathjax %}q{% endmathjax %}中的两个词，它们的词距分数为：{% mathjax %}\text{tp}(t,t',d) = \sum_{o\in \mathcal{O}(t,d)} \sum_{o'\in \mathcal{O}(t',d)}\frac{1}{(o-o')^2}{% endmathjax %}。根据上面公式中的定义，查询词中的{% mathjax %}t,t'\in \mathcal{Q}{% endmathjax %}在文档{% mathjax %}d{% endmathjax %}中出现次数越多、距离越近，则**词距分数**{% mathjax %}\text{tp}(t,t',d){% endmathjax %}越大。`OKaTP`定义为：{% mathjax %}\sum_{t,t'\in\mathcal{Q},t\neq t'}\frac{tp(t,t',d)\cdot (k+1)}{tp(t,t',d) + k\cdot (1-b + b\cdot \frac{l_d}{\text{maen}(l_d)})}\cdot \min(idf_t,idf_{t'}){% endmathjax %}。

#### 相关性 - BERT模型

