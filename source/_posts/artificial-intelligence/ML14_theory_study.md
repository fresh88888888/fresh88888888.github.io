---
title: 机器学习(ML)(十四) — 推荐系统探析
date: 2024-11-04 09:30:11
tags:
  - AI
categories:
  - 人工智能
mathjax:
  tex:
    tags: 'ams'
  svg:
    exFactor: 0.03
---

#### 排序 - 多目标模型

我们先回顾一下**推荐系统**的链路，分为召回，粗排、精排、重排。有很多条召回通道，从几亿个物品选出几千个物品，做完召回之后，要从中选出用户最感兴趣的物品，这就要用到粗排和精排，粗排会给召回的物品逐一打分，保留分数最高的几百个物品，然后使用精排模型给粗排选中的几百个物品打分但不做截断，让几百个物品全都带着精排分数进入重排，最后一步是重排，做多样性抽样，并且把相似内容打散，最终由几十个物品被选中展示给用户。
<!-- more -->

**排序**的主要依据是用户对物品的兴趣，兴趣可以反映在用户与物品的交互上，对于每个物品，系统会记录下面几个统计量：**曝光次数**(`number of impressions`)，就是一个物品被展示给多少用户，展示之后，才会有点击等行为；**点击次数**(`number of clicks`)，就是一个物品被多少用户点开；**点赞次数**(`number of likes`)、**收藏次数**(`number of collects`)、**转发次数**(`number of shares`)。点击率 = 点击次数 / 曝光次数、点赞率 = 点赞次数 / 点击次数、收藏率 = 收藏次数 / 点击次数、转发率 = 转发次数 / 点击次数。排序的依据：排序模型通过机器学习预估点击率、点赞量、收藏率、转发率等，做完预估之后，要对这些预估分数做融合（比如加权和），最后按照融合的分数对物品做排序、截断，保留分数最高的物品。

**多目标模型**：排序模型的输入是各种各样的特征，**用户特征**主要是用户`ID`和用户画像；**物品特征**主要是物品`ID`、物品画像和作者信息；**统计特征**：包括**用户统计特征**和**物品统计特征**，比如用户在过去`30`天曝光了多少物品，点击了多少物品，点赞了多少物品，比如物品在过去获得了多少次曝光、点击、点赞等等；**场景特征**：是随着用户请求传过来的，不如按当前的时间和用户所在的地点。这些信息对推荐很有用，把这些特征做融合(`concatenation`)，输入神经网咯，神经网络可以是简单的全连接网络，也可以是更复杂的结构，神经网络会输出一个向量，这个向量在输入`4`个神经网络，每个神经网络有`2-3`个全连接层和输出层的**激活函数**是`Sigmoid`，`4`个神经网络分别输出点击率、点赞率、收藏率和转发率的预估值。`4`个预估值都是实数，介于`0~1`之间，**推荐系统**排序就主要靠这4个预估值，它们反映出用户对物品的兴趣。如下图所示：
{% asset_img ml_1.png "多目标模型" %}

把模型输出的点击率、点赞率、收藏率和转发率，分别记作{% mathjax %}p_1,p_2,p_3,p_4{% endmathjax %}。它们都是模型做出的预估，做训练的时候，要让这些预估值去拟合真实的目标。把真实的目标记作{% mathjax %}y_1,y_2,y_3,y_4{% endmathjax %}，分别对应：点击、点赞、收藏和转发的行为。{% mathjax %}y{% endmathjax %}要么是0、要么是1，举个例子，{% mathjax %}y_1 = 1,y_2 = 0,y_3 = 0,y_4 = 1{% endmathjax %}，表示用户对物品有点击、没点赞、没收藏和有转发。这些是用户的真实的行为，被记录下来。用这样的数据来训练模型，训练是要鼓励模型的预测接近目标，其实就是二元分类，就是判定用户是否会点击物品，有点击、点赞、收藏和转发4个任务，每个任务都是一个二元分类，可以使用**交叉熵损失函数**。对于点击这个任务使用{% mathjax %}y_1{% endmathjax %}和{% mathjax %}p_1{% endmathjax %}的**交叉熵作为损失函数**，记作{% mathjax %}\text{CrossEntropy}(y_1,p_1) = -(y_1\ln p_1 + (1 - y_1)\ln (1 - p_1)){% endmathjax %}，{% mathjax %}p_1{% endmathjax %}越接近{% mathjax %}y_1{% endmathjax %}，那么交叉熵损失就越小。我们把4个函数的加权和作为总的损失函数，记作{% mathjax %}\sum_{i=1}^4 \alpha_i \cdot \text{CrossEntropy}(y_i,p_i){% endmathjax %}，其中权重{% mathjax %}\alpha{% endmathjax %}是根据经验设置的。在收集的历史数据上训练神经网络的参数，最小化损失函数，损失函数越小，说明模型的预测越接近真实目标。做训练的时候，把**损失函数**关于**神经网络**的参数求**梯度**，做**梯度下降**更新**神经网络**的参数。

实际的训练中会有很多困难：做训练的时候存在类别不平衡的问题，**正样本少，负样本多**。比如说每`100`次曝光，约有`10`次点击，`90`次无点击。点击的是正样本，没有点击的负样本。要太多的负样本用途不大，白白浪费计算资源。解决方案就是负样本的降采样(`down-sampling`)，只保留其中一小部分负样本，让正负样本数量保持平衡，降低训练的计算代价。给定用户特征、物品特征，用神经网络预估出点击率、点赞率等之后，就要对这些预估分数做校准，做完校准之后才能把这些预估值做排序。为什么要做校准？首先设正样本、负样本的数量为{% mathjax %}n_{+}{% endmathjax %}和{% mathjax %}n_{-}{% endmathjax %}，以点击为例，曝光之后有点击就是正样本，否则就是负样本，负样本数量通常远大于正样本，在训练的时候要对负样本做降采样，抛弃一部分负样本，这样会使正、负样本的差距不太悬殊，把采样率记作{% mathjax %}\alpha{% endmathjax %}，它介于0~1之间，使用负样本的数量等于{% mathjax %}\alpha\cdot n_{-}{% endmathjax %}，由于减少了负样本的数量，模型预估点击率大于真实点击率，{% mathjax %}\alpha{% endmathjax %}越小，负样本越少，模型对点击率高估就会越严重，把真实的点击率记作{% mathjax %}p_{\text{true}} = \frac{n_{+}}{n_{+} + n_{-}}{% endmathjax %}，样本的总数等于{% mathjax %}n_{+} + n_{-}{% endmathjax %}，预估的点击率记作{% mathjax %}p_{\text{pred}} = \frac{n_{+}}{n_{+} + \alpha\cdot n_{-}}{% endmathjax %}，把上面两个公式合起来，记作{% mathjax %}p_{\text{true}} = \frac{\alpha\cdot p_{\text{pred}}}{(1 - p_{\text{pred}}) + \alpha\cdot p_{\text{pred}}}{% endmathjax %}，这个公式就是预估点击率的校准。等式左边的{% mathjax %}p_{\text{pred}}{% endmathjax %}是校准之后的点击率，等式右边是对预估点击率{% mathjax %}p_{\text{pred}}{% endmathjax %}做的变换，公式中用到了采样率{% mathjax %}alpha{% endmathjax %}，在线上排序的时候，首先让模型预估{% mathjax %}p_{\text{pred}}{% endmathjax %}，然后使用{% mathjax %}p_{\text{true}} = \frac{\alpha\cdot p_{\text{pred}}}{(1 - p_{\text{pred}}) + \alpha\cdot p_{\text{pred}}}{% endmathjax %}做校准，最后拿校准之后的点击率作为排序的依据。

#### 排序 - MMoE

`MMoE`(`Multi-gate Mixture-of-Exports`)：模型的输入是一个向量，包含**用户特征**、**物品特征**、**统计特征**、**场景特征**。把向量输入`3`个**神经网络**，每个神经网络结构都相同，都是由很多全连接层组成，但是这`3`个神经网络不共享参数，这`3`个神经网络各输出一个向量，这`3`个向量记作{% mathjax %}x_1,x_2,x_3{% endmathjax %}，这`3`个神经网络代表`3`个”专家“。把下面的特征向量输入到另一个神经网络，这个神经网络也有多个全连层，神经网络的最后加入一个`softmax`激活函数，输出一个`3`维的向量。由于是`softmax`输出，向量的`3`个元素都大于`0`，而且相加等于`1`，向量的`3`个元素记作{% mathjax %}p_1,p_2,p_3{% endmathjax %}，分别对应`3`个专家神经网络，之后用这`3`个元素做权重，对向量{% mathjax %}x_1,x_2,x_3{% endmathjax %}做**加权平均**；同样的方法，把下面的特征向量送入右边的神经网络，在神经网络的最后也是`softmax`激活函数，输出一个`3`个向量，分别记作{% mathjax %}q_1,q_2,q_3{% endmathjax %}，这三个元素也是之后做加权平均的权重。如下图所示：
{% asset_img ml_2.png "MMoE模型" %}

如下图所示，{% mathjax %}p_1,p_2,p_3{% endmathjax %}和{% mathjax %}q_1,q_2,q_3{% endmathjax %}都是权重，用于之后的加权平均，对向量{% mathjax %}x_1,x_2,x_3{% endmathjax %}做加权平均，权重是{% mathjax %}p_1,p_2,p_3{% endmathjax %}，得到左边的向量{% mathjax %}p_1x_1 +p_2x_2 + p_3x_3{% endmathjax %}；用右边的向量{% mathjax %}q_1,q_2,q_3{% endmathjax %}对向量{% mathjax %}x_1,x_2,x_3{% endmathjax %}做加权平均，得到右边的向量{% mathjax %}q_1x_1 +q_2x_2 + q_3x_3{% endmathjax %}。把左边的向量输入一个神经网络，神经网络可以有一个或多个全连接层，神经网络的输出取决于具体的任务，比如神经网络输出是对点击率的预估，是一个介于`0~1`之间的实数，把右边的一个向量输入另一个神经网络，这个神经网络会输出另一个指标的预估，比如对点赞率的预估，也是介于`0~1`之间的实数。这里假设**多目标模型**只有点击率、点赞率这两个目标，所以用了{% mathjax %}p,q{% endmathjax %}这两种权重，假如有`10`个目标，就要用`10`种权重。
{% asset_img ml_3.png "MMoE模型" %}

在实践中`MMoE`模型有一个问题：`softmax`会发生**极化现象**(`polarization`)。上个例子中有`2`个`softmax`函数，各自输出一个3维向量，每个向量都是概率分布，元素大于`0`，相加等于`1`。**极化现象**(`polarization`)是`softmax`输出值`1`个接近`1`，其余接近`0`。举例左边的`softmax`输出值为{% mathjax %}(0,0,1){% endmathjax %}，也就是说左边神经网络点击预估任务只使用了第`3`号专家网络，而没有使用其它的专家网络，这也就是没有使用`MMoE`，没有让`3`个专家网络输出融合，而是简单使用了一个专家；右边的`softmax`输出值为{% mathjax %}(0,1,0){% endmathjax %}，也就是说左边神经网络点击预估任务只使用了第`2`号专家网络，也没有对`3`个专家做融合，而第1号专家网络没有被使用。那么`MMoE`就是一个简单的模型，不会对专家做融合，则失去了`MMoE`的优势。解决**极化现象**的方案：如果有{% mathjax %}n{% endmathjax %}个专家神经网络，那么每个`softmax`的输出都是{% mathjax %}n{% endmathjax %}维向量。不希望输出值中其中一个接近`1`，其余的接近`0`，在训练的过程中，对`softmax`输出使用`dropout`。`softmax`输出的{% mathjax %}n{% endmathjax %}个数值被`mask`的概率都是`10%`，也就是说每个专家被丢弃的概率都是`10%`，这会强迫每个任务根据部分专家做预测，如果用`dropout`，则不太可能发生极化。`MMoE`模型请参考论文：[`Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts`](https://dl.acm.org/doi/pdf/10.1145/3219819.3220007)，极化现象的解决方案请参考：[`Recommending What Video to Watch Next: A Multitask Ranking System`](https://daiwk.github.io/assets/youtube-multitask.pdf)。

#### 排序 - 排序模型的结构

**融合预估分数**：最简单的分数融合方法就是**预估值的加权和**，记作{% mathjax %}p_{\text{click}} + w_1\cdot p_{\text{like}} + w_2\cdot p_{\text{collect}} + \ldots{% endmathjax %}，其中{% mathjax %}p_{\text{click}}{% endmathjax %}就是模型预估的点击率，对应的权重是`1`；{% mathjax %}p_{\text{like}}{% endmathjax %}是模型预估的点赞率，对应的权重的{% mathjax %}w_1{% endmathjax %}；{% mathjax %}p_{\text{collect}}{% endmathjax %}是模型预估的收藏率，对应的权重是{% mathjax %}w_2{% endmathjax %}。另一种融合方式：点击率乘以其它项的加权和，{% mathjax %}p_{\text{click}}(1 + w_1\cdot p_{\text{like}} + w_2\cdot p_{\text{collect}} + \ldots){% endmathjax %}。另一种融合方式：{% mathjax %}(1 + w_1\cdot p_{\text{time}})^{\alpha_1}\cdot (1 + w_2\cdot p_{\text{like}})^{\alpha_2}\;\ldots{% endmathjax %}，其中{% mathjax %}p_{\text{time}}{% endmathjax %}代表预估短视频的观看时长，比如预测用户会观看`10`秒，{% mathjax %}w_1, \alpha_1{% endmathjax %}是超参数，需要自己调整，{% mathjax %}p_{\text{like}}{% endmathjax %}代表预估用户的点赞率。

**视频播放建模**：视频排序的依据还有**播放时长**和**完播**。直接使用回归拟合播放时长效果不好，建议使用`YouTube`的时长建模（论文请参考：[`Deep Neural Networks for YouTube Recommendations`](https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/45530.pdf)）。
- **对播放时长的预估**：这是排序模型使用的特征：**用户特征**、**物品特征**、**统计特征**、**场景特征**。把它输入多层神经网络，这个神经网络被所有任务共享，在这个神经网络之上有多个全连接层，一个全连接层对应`1`个目标，比如点击、点赞、收藏、播放时长等，这里只关注播放时长的预估，全连接层输出的实数，记作{% mathjax %}z{% endmathjax %}，对{% mathjax %}z{% endmathjax %}做`sigmoid`变换得到{% mathjax %}p = \text{sigmoid}(z){% endmathjax %}，记作{% mathjax %}p = \frac{\exp(z)}{1 + \exp(z)}{% endmathjax %}，然后让{% mathjax %}p{% endmathjax %}拟合{% mathjax %}y{% endmathjax %}（{% mathjax %}y{% endmathjax %}是自己定义的，记作{% mathjax %}y = \frac{t}{t + 1}{% endmathjax %}，其中{% mathjax %}t{% endmathjax %}是实际观看时长，{% mathjax %}t{% endmathjax %}越大，则{% mathjax %}y{% endmathjax %}也越大），为了让{% mathjax %}p{% endmathjax %}拟合{% mathjax %}y{% endmathjax %}，我们使用{% mathjax %}p{% endmathjax %}与{% mathjax %}y{% endmathjax %}的交叉熵作为损失函数，记作{% mathjax %}\text{CrossEnptoryLoss}(y,p) = y\cdot\log p + (1 - y)\cdot\log(1 - p){% endmathjax %}。最小化交叉熵损失，记作{% mathjax %}\frac{t}{1 + t}\cdot\log p + \frac{1}{1+t}\cdot\log(1 - p){% endmathjax %}，会让{% mathjax %}p{% endmathjax %}接近于{% mathjax %}y{% endmathjax %}，如果{% mathjax %}p = y{% endmathjax %}，那么{% mathjax %}\exp(z) = t{% endmathjax %}，也就是说，可以用{% mathjax %}\exp(z){% endmathjax %}作为播放时长的预估，对{% mathjax %}z{% endmathjax %}做指数变换，输出的{% mathjax %}\exp(z){% endmathjax %}就是对播放时长的预估。
- **对完播的预估**：一种方法是**回归**，例如视频长度为`10`分钟，实际播放是`4`分钟，则实际播放率是{% mathjax %}y = 0.4{% endmathjax %}。做训练的时候，让预估播放率{% mathjax %}p{% endmathjax %}去拟合{% mathjax %}y{% endmathjax %}，记作{% mathjax %}\text{loss} = y\cdot\log p + (1 - y)\cdot\log(1 - p){% endmathjax %}，其中{% mathjax %}y{% endmathjax %}的大小介于0~1之间，用{% mathjax %}p{% endmathjax %}和{% mathjax %}y{% endmathjax %}的交叉熵作为损失函数，在线上用{% mathjax %}p{% endmathjax %}作为**完播率**的预估，比如说模型输出{% mathjax %}p = 0.73{% endmathjax %}，意思是预计播放73%。视频的完播率会作为融分公式的一项，影响视频的排序。另一种视频完播的建模方法是**二元分类**，需要自己定义完播指标，比如完播`80%`，例如视频的长度是`10`分钟，那么播放超过8分钟就是正样本，否则作为负样本。训练要做**二元分类**，播放 `>=` `80%`属于正样本、播放 `<` `80%`属于负样本。做完训练之后，可以在线上预估完播率，例如模型输出{% mathjax %}p = 0.73{% endmathjax %}，意思是{% mathjax %}\mathbb{P}(\text{播放} > 80\%) = 0.73{% endmathjax %}，预估的播放率会跟点击率一起作为排序的依据。

不能直接把预估的完播率用到融分公式中，视频越长，完播率越低。使用预估的完播率适用于短视频，而不适用于长视频。线上预估完播率之后，然后对其做调整，记作{% mathjax %}p_{\text{finish}} = \frac{\text{预估完播率}}{f(\text{视频长度})}{% endmathjax %}，其中{% mathjax %}f{% endmathjax %}是视频长度的函数，视频越长，{% mathjax %}f{% endmathjax %}值越小。把{% mathjax %}p_{\text{finish}}{% endmathjax %}作为融分公式的一项，与点击率、点赞率一起作为指标决定视频的排序。

#### 排序 - 排序模型的特征

召回和排序的模型中都有用户属性，用户属性都记录在用户画像中，用户`ID`是排序中最重要的特征之一，用户`ID`本身不携带任何有用的信息，但是模型学习到的`Embedding`向量对召回、排序模型有很重要的影响。召回和排序都会对用户做`Embedding`，通常用`32`为或`64`位向量。人口统计学属性包括性别、年龄等，不同年龄、不同性别年龄段的用户兴趣差别很大。用户的账号信息：包括注册时间、活跃度。新用户和老用户、高活和低活用户区别很大。模型需要专门针对新用户、低活用户做优化。再就是用户感兴趣的类目、关键词、品牌。这些信息可以是用户填写的，也可以是算法提取的。这些用户兴趣的信息对排序也是很有用的。与用户画像相对应的是物品画像，物品`ID Embedding`在召回、排序中的重要性非常的高，物品的发布时间和物品的年龄也是很重要的特征，`GeoHash`（经纬度编码）、所在城市对召回、排序都很有用。物品的内容：包括类目、标题、关键词、品牌等信息。通常对离散的内容做`embedding`变成向量。字数、图片数、视频清晰度、标签数这些都是物品自带的属性，反映出物品的质量，物品的点击和交互指标跟这些相关。内容信息量、图片美学是算法打的分数。事先使用人工标注的数据训练`CV`和`NLP`模型，当物品要发布的时候让模型给物品打分，将内容信息量和图片美学写入物品画像中。这些分数可以作为排序模型的特征，除了用户画像和物品画像，还有用户统计特征，比如会统计用户最近`30`天（`7`天、`1`天、`1`小时）的点击率、点赞率、收藏率等等。用各种时间粒度可以反映出用户的实时兴趣、短期兴趣、长期兴趣，除此之外还有分桶统计各种指标，比如图文的点击率和视频的点击率，可以反映出用户对两类的偏好，按照类目分桶；还要物品的统计特征，比如会统计物品最近`30`天（`7`天、`1`天、`1`小时）的点击数、点赞数、收藏数等等。这些统计量反映出物品的受欢迎程度。可按照物品的受众做分桶，按照用户性别分桶、按照用户年龄分桶等。最后一类特征是场景特征，它们随着推荐请求传来的，不用从用户画像、物品画像数据库中取得，当前用户定位的`GeoHash`、定位的城市属于场景特征，当前的时刻对推荐很有用，一个人在同一天不同时刻的兴趣也不相同，比如是否是周末、是否是节假日，再就是设备信息：包括手机品牌、手机型号、操作系统等，设备信息也是有用的特征。

**特征处理**：
- **离散特征**：离散特征处理很简单，做Embedding。离散特征包括：用户`ID`、笔记`ID`、作者`ID`、类目、关键词、城市、手机品牌等。
- **连续特征**：连续特征的第一种处理方式是做分桶转变成离散特征。连续特征包括：年龄、文本字数、视频长度等。连续特征的第二种处理方式是做{% mathjax %}\log(1 + x){% endmathjax %}变换，还可以把点击数、点赞数、收藏数转化为点击率、点赞率、收藏率，并做平滑处理。

两种变换的特征都作为模型的输入，比如{% mathjax %}\log(1 + \text{点击数}){% endmathjax %}、{% mathjax %}\log(1 + \text{点赞数}){% endmathjax %}等。拼花之后点击率、点赞率也会被用到。推荐系统会用到`3`个数据源，包括用户画像、物品画像、统计数据，`3`个数据源都存储在内存数据库之中，在线上服务的时候，排序服务器会从`3`个数据源取回所需的数据，然后把读取的数据做处理，作为特征喂给模型，模型就能预估出点击率、点赞率等指标。系统架构是：用户发起请求到主服务器上，主服务器会把请求发到召回服务器上，做完召回之后，召回服务器会把几十路召回的结果做归并，几千个物品`ID`返回给主服务器，主服务器会把用户`ID`、物品`ID`、场景特征发送到排序服务器上，这里有一个用户`ID`和几千个物品`ID`，物品ID是召回的结果，用户`ID`和场景特征都是从请求中获取的，场景特征包括：时刻、所在的位置、手机的型号和操作系统。接下来，排序服务器会从`3`个数据源中取回排序所需的特征，主要是这`3`个数据源：用户画像、物品画像、统计数据。取回的特征分别是用户特征、物品特征、统计特征。用户画像数据库压力比较小(每次只读取1个用户的特征)，而物品画像数据库压力特别巨大，粗排要给几千个物品做排序，读取几千个物品的特征，同样的道理，存用户统计数据的数据库压力比较小，存物品统计数据的数据库压力比较大。工程实现的时候，用户画像里面存什么都可以，特征可以很多、很大，尽量不要在物品画像中放很大的向量，否则物品画像会承受很大的压力，用户画像较为静态，物品画像可以说是完全静态的，对于用户画像、物品画像主要考虑读取速度，而不用考虑其时效性。统计数据不能在本地缓存，统计数据是动态变化的，时效性很强。在收集到所需的特征之后，排序服务器对特征打包，传递给`TF Serving`，`TF`会给物品打分，并把分数返回给排序服务器，排序服务器会用融合的分数、多样性分数和业务规则对物品做排序，把排名最高的几十个物品返回给主服务器，这些就是最终给用户曝光的物品。如下图所示：
{% asset_img ml_4.png "推荐系统工程架构" %}

#### 排序 - 粗排模型

