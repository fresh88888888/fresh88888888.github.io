---
title: 机器学习(ML)(二十三) — 强化学习探析
date: 2025-01-02 16:00:11
tags:
  - AI
categories:
  - 人工智能
mathjax:
  tex:
    tags: 'ams'
  svg:
    exFactor: 0.03
---

#### 递归内省

**递归内省**(`Recursive Introspection`)是一种新方法，旨在教导**语言模型智能体**（如**大语言模型**，`LLMs`）如何自我改进。该方法的核心在于使模型能够对自身行为进行**内省**、**推理**并**纠正错误**。其主要特点：**自我改进能力**，**递归内省**的目标是使**语言模型**能够在多轮交互中逐步改善其响应。这种方法强调通过反复的**反馈**和**调整**，模型能够识别并纠正先前的错误；`RISE`**方法**，该方法被称为`RISE`(`Recursive IntroSpEction`)，是一种**微调技术**，允许模型在面对复杂问题时，通过观察之前的失败尝试和额外的环境反馈来调整其**策略**；**多轮数据收集与训练**，`RISE`借鉴了**在线模仿学习**和**强化学习**的原则，提出了多轮数据收集和训练策略，以增强`LLM`在后续迭代中**递归检测**和**纠正错误**的能力。
<!-- more -->

`RISE`将单轮提示的**微调**视为解决多轮**马尔可夫决策过程**(`MDP`)，其中初始状态为提示。受**在线模仿学习**和**强化学习**的启发，提出了多轮数据收集和训练策略，以使`LLM`具备在后续迭代中**递归检测**和纠正其先前错误的能力。实验表明，`RISE`使`Llama2、Llama3`和`Mistral`模型能够通过在更多回合在数学推理任务上自我改进，在相同推理时间计算下超越了几种单轮策略。还发现`RISE`具有良好的扩展性，通常在更强大的模型上获得更大的收益。`RISE`对响应做出了改进，使其能够在不干扰单轮能力的情况下找到挑战性提示的正确解决方案。

