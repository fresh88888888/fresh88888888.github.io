---
title: 机器学习(ML)(二十八) — AGI探析
date: 2025-03-23 12:00:11
tags:
  - AI
categories:
  - 人工智能
mathjax:
  tex:
    tags: 'ams'
  svg:
    exFactor: 0.03
---

##### AGI路线图

我们定义了三个`AGI`级别及其主要特征。主要目标是定位当前的`AI`发展，量化现有的局限性，并激励以实现下一级别的能力、评估和对齐。如下图所示：
<!-- more -->
{% asset_img ml_1.png "雷达图展示：评估AGI的方法，涵盖四个核心领域：内部、接口、系统和对齐" %}

**内部领域**：评估基本**认知能力**，如**推理、记忆、感知**和**元认知**；**接口领域**：评估`AGI`的工具使用能力和连接智能的能力；**系统领域**：关注运营方面，包括**效率、规模**和**计算能力**；**对齐领域**：考察**伦理能力**和**安全性**。

- **级别一：萌芽期**`AGI`，这一级别的`AGI`通常在特定基准任务上表现优于或与人类相当。级别一的`AGI`代表了当前最先进的`AI`系统。例如，`GPT-4`和`DeepSeek-R1`在许多自然语言任务中表现出显著的能力，包括语言理解、生成连贯和上下文相关的响应，通常与人类相当或更胜一筹。这些系统在有足够大的人类数据集的情况下通常表现良好，并能在某些领域辅助人类。目前在许多领域处于这一级别的`AGI`。
- **级别二：超人类**`AGI`，从级别一到级别二的关键转折点是`AI`能够在现实世界的任务和应用中完全取代人类。它们在效率（例如，更高的准确性、更好的问题解决能力）、效率（例如，更快的处理速度、更高的吞吐量、处理大量数据的能力）和可靠性（例如，更高的成功率、抗疲劳能力、增强的安全性）方面表现出色。这些系统还可以从有限的数据中学习，跨领域推广知识，在较少的人类干预下适应新环境，并在其方法中表现出**创造力**和**创新**。它们还能进行复杂的决策过程，考虑多种因素，并根据预定义的目标优化结果。值得注意的是，级别二的`AGI`应准备好在现实世界中部署，并在没有任何人类干预的情况下解决当前由人类解决的复杂现实世界任务。在我们看来，除了在高度专业化的领域（例如，围棋游戏）之外，很少有`AI`系统达到了级别二。
- **级别三：终极**`AGI`，虽然级别二的`AGI`能够在解决许多任务时取代人类，但级别二的`AGI`仍然需要人类的努力。我们认为，级别三的`AGI`的本质是，给定某个可能模糊且高层次的目标，这种`AGI`系统能够在没有任何人类干预的情况下完全自我进化。这一级别标志着`AGI`发展的巅峰，代表了一个理想化且可能无法实现的`AI`系统。终极`AGI`将具备远超人类能力的学习、推理和决策能力，并解放人类在这种`AGI`系统发展过程中的参与。因此，在这个阶段，确保这种级别三的`AGI`与人类价值观和目标高度一致变得尤为重要。此外，级别三的`AGI`可能会展示出更深的人类情感，如同理心、社会意识，从而能够与人类和其他`AI`系统无缝协作，甚至具备自我意识的火花。然而，实现终极`AGI`仍然是一个理论概念，其可行性仍在不断研究和辩论中。

**自回归生成是通向AGI的途径吗**？下一个词预测是大模型成功的核心。这引发了一个问题：下一个词预测能否通向`AGI`？本质上，自回归生成利用大量自监督数据的方式代表了一种**大规模多任务学习**。通过预测语料库中给定文本的下一个词，它解决了从传统`NLP`任务（如语法、词汇语义和翻译）到常识推理和知识驱动推理的各种任务。学习**输入-输出关系**，或**上下文学习**，可以被视为下一个词预测。世界上的关系通常以词、视觉标记、时空片段或其他类型的标记编码，使它们可以通过下一个词预测来学习。关键问题仍然是：世界知识的范围，包括直觉、情感、文化和艺术表达等隐性知识，是否能够编码为简化的标记？**自回归方法**能否学习到世界知识中的所有**因果关系**，而不仅仅是**相关性**？此外，**扩散模型**的流行也对自回归生成的未来提出了挑战。这种方法在生成过程中不依赖于先前生成的数据点，而是依赖于逐渐减少噪声来恢复数据的过程。**扩散模型**在生成任务中的效果也导致了其在实际应用中的广泛使用。所有这些都使得**自回归生成**是否是通向`AGI`的途径成为一个持续的争论话题。

**扩展法则是否存在局限**？**扩展法则**表明，增加某些模型的规模和训练数据量可以带来各种任务在性能上的预测改进。这凸显了开发可扩展模型架构和获取更多高质量数据以供这些不断增长的系统使用的重要性。该前提假设表明，通过遵循这一轨迹，我们可以更接近创建具有`AGI`能力的模型。然而，**边际效益递减**现象表明，持续扩展需要指数级增加的资源，以换取微小的改进。此外，某些能力（如创造性思维、现实世界的直觉和伦理推理）可能无法通过单纯的扩展有效学习，因为它们需要更复杂的**推理**和**学习机制**。

**合成数据是未来还是风险**？`AGI`的成功依赖于大量、多样且高质量数据集的获取。尽管现有的高质量数据量将继续增长，但合成数据已成为一种可行且高效的解决方案，能够大规模生成复制现实世界模式的人工数据。然而，这一创新也带来了重大挑战。**合成数据**的滥用可能传播有偏见或误导性的信息，导致与人类期望的偏差。未来的努力应集中在提高合成数据的质量和多样性，并探索适用于其的**扩展法则**。此外，即使人们在模型训练中没有故意使用**合成数据**，`LLM`的广泛使用也可能导致互联网上充斥着**合成数据**。虽然自动区分**合成数据**和**真实数据**具有挑战性，但这可能会对训练数据集造成潜在的污染风险。

**计算优越性是否意味着智力优越性**？许多在游戏中表现出超人类的**智能系统**（如`AlphaGo、AlphaZero、AlphaStar、MuZero`等）不仅能够以大幅度战胜最佳人类世界冠军，还能帮助分析游戏并为高级玩法创建新策略。这些超级游戏`AI`的基础几乎都是一种**搜索计算**，它能够通过算法引导的剪枝巧妙地枚举大量可能性，从而超越人类的思维能力。然而，关于这种计算优越性是否构成真正智能，还是仅仅代表一个强大的程序，仍然存在争议。最近成功的`LLM`系统（例如，`ChatGPT`在国际象棋游戏中表现不佳）并不具备这种**搜索计算能力**，但仍被许多人认为同样的智能。在探索`AGI`的过程中，我们是否应期望未来的系统也具备这些特性，以及如何平衡这些特性与其他改变我们评估`AGI`系统方式的智能特质？

**如何走向完全自主**？当前的`AI`系统被设计用于特定任务和特定场景，展示出专业化的能力。随着我们向`AGI`迈进，期望转向`AI`在没有人类干预的情况下学习新技能和创新工具的自主性。这一进展要求复杂的**自我评估**和**自我改进机制**。此外，`AGI`的愿景包括**完全自主**，消除对人类持续监督的需求。这种自主性强调了先进的**自我调节**、**安全**和**风险预防措施**的重要性，确保未来的`AGI`系统做出的决策能够被信任。

**如何有效地将人类价值观融入**`AGI`？随着`AGI`的发展，将人类价值观和伦理融入这些系统变得至关重要。想象一个`AGI`与人类社会和谐共存的未来，这些系统必须被设计成能够执行任务，并理解和遵守伦理规范和价值观。我们目前依赖于法规和约束，但将“**人类价值观**”真正融入`AGI`将是一个重要的研究领域。`AGI`的发展将伦理原则编码到这种新形式的智能的核心提供了机会。人们期望伦理`AGI`系统能够在复杂的道德环境中指引，并做出反映全球文化多样价值观的决策。

**如何在推进过程中平衡风险和收益**？`AI`发展的初期阶段集中在增强特定能力和解决特定挑战，但`AI`技术的不断进步需要更加注重建立与安全和伦理相关的约束。呼吁停止所有可能导致失控`AI`的研究的呼声越来越高。然而，这一举措需要全球协调和监督，并可能扼杀`AI`的许多潜在好处。相反，主张继续推进`AI`，确保所有强大的`AI`系统都能负责任地构建和部署。这需要：加强对齐研究的关注和投资，创建`AI`必须遵守的普世价值观和目标集，并开发健壮的方法将 `AI`系统与这些原则对齐；确保任何有能力创建先进`AI`的团体都理解并使用这些技术；实施平衡`AI`发展满足最少干预需求与严格监督要求的法规。

