---
title: 机器学习(ML)(十三) — 推荐系统探析
date: 2024-10-29 10:44:11
tags:
  - AI
categories:
  - 人工智能
mathjax:
  tex:
    tags: 'ams'
  svg:
    exFactor: 0.03
---

#### 召回 - 双塔模型

训练双塔模型需要正样本和负样本，选对正、负样本大于改进模型结构。**选择正样本**：如果物品给用户曝光之后，会有点击行为，就说明用户对物品感兴趣。把用户和物品二元组作为作为正样本，但是选取正样本有个问题需要解决，就是少部分物品占据了大部分点击，正样本是有点击的物品，导致正样本属于热门物品。拿过多的热门物品作为正样本，会对冷门物品不公平，这样会使热门物品更热，冷门物品更冷。解决方案是：对冷门物品过采样，或降采样热门物品。**过采样**(`up-sampling`)：一个样本出现多次；降采样(`down-sampling`)：一些样本被抛弃，以一定概率抛弃一些样本。抛弃的概率与样本的点击次数正相关。
<!-- more -->

**选择负样本**：无样本就是用户不感兴趣的物品，没有被召回的物品是负样本；召回了，但是没有被选中和曝光是负样本；曝光了，但是没有被用户点击的也是负样本。负样本分类：
- **简单负样本**：未被召回的物品，大概率是用户不感兴趣的，几亿个物品中只有几千个物品被召回，所以从全体物品中做抽样就可以了，抽到的物品作为负样本。问题在于怎样做抽样？均匀抽样还是非均匀抽样？均匀抽样的坏处是对冷门物品不公平，如果在全体物品中做均匀抽样产生负样本，负样本大多是冷门物品。总拿热门物品做正样本，冷门物品做负样本，这会使热门物品更热，冷门物品更冷。所以负样本采用**非均匀采样**，目的是打压热门物品，负样本抽样的概率与热门物品（点击次数）正相关。热门物品成为负样本的概率大，物品的热门程度可以用点击次数来衡量。可以这样做抽样：每个物品的抽样概率正比于点击次数的`0.75`次方，`0.75`是一个经验值。
- `Batch`**内负样本**：设一个`batch`内有{% mathjax %}n{% endmathjax %}个正样本，那么一个用户可以跟{% mathjax %}n-1{% endmathjax %}个样品组成负样本。那么这个`batch`内有{% mathjax %}n(n-1){% endmathjax %}个负样本，这些都是简单负样本（因为第一个用户不喜欢第二个物品）。对于第一个用户来说第二个物品相当于从全体物品随机抽样的，第一个用户大概率不会喜欢第二个物品，`batch`负样本存在一个问题，(用户, 物品)这个二元组都是通过点击行为选取的，第一个用户和第一个物品之所以成为正样本，原因是用户点击了物品，所以一个物品出现在`batch`内的概率正比于点击次数。也就是它的热门程度，物品成为负样本的概率应该是正比于点击次数的0.75次方，但这里却是正比于点击次数1次方，也就是说热门物品成为负样本的概率过大，这样会造成偏差。修正偏差方案是参考论文：[`Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Recommendations`](https://storage.googleapis.com/gweb-research2023-media/pubtools/5716.pdf)，假设物品{% mathjax %}i{% endmathjax %}被抽样到的概率记作{% mathjax %}p_i{% endmathjax %}，则{% mathjax %}p_i\varpropto \text{点击次数}{% endmathjax %}，反映出物品的热门程度，双塔模型通常用于计算相似度，预估用户对物品{% mathjax %}i{% endmathjax %}的兴趣分数：{% mathjax %}\cos(a,b_i){% endmathjax %}，其中{% mathjax %}a{% endmathjax %}是用户的特征向量，{% mathjax %}b_i{% endmathjax %}是物品的特征向量，训练的时候要尽量鼓励正样本的余弦相似度大，鼓励负样本的余弦相似度小。根据上面论文中的建议：训练双塔模型的时候应该把{% mathjax %}\cos(a,b_i){% endmathjax %}调整为{% mathjax %}\cos(a,b_i) - \log p_i{% endmathjax %}，这样可以纠偏。避免过分打压热门的物品，训练结束之后，在线上做召回时还是使用{% mathjax %}\cos(a,b_i){% endmathjax %}，线上做召回不用做调整。
- **困难负样本**：是被排序淘汰的样本，比如物品被召回，但是被粗排淘汰，例如召回5000个物品进行粗排，粗排按照分数做截断，只保留前500个物品，那么被淘汰的4500个物品都可以被视作负样本，为什么被粗排淘汰的负样本叫做困难负样本呢？这些物品被召回，说明它们跟用户的兴趣多少有些关系，被粗排淘汰，说明用户对物品的兴趣不够强烈，所以被分为了负样本，这些正、负样本做二元分类的话，这些困难负样本容易被分错，容易被错误的判定为正样本，更困难的负样本是通过了粗排，但是精排分数靠后的物品，比方说精排给500个物品打分，排名在后300个物品都是负样本，能够通过粗排进入精排，说明物品已经比较符合用户兴趣了，但未必是用户最感兴趣的，所以在精排中排名靠后的物品视为负样本。训练双塔模型其实是一个二元分类任务，让模型区分正负样本。把全体物品作为简单负样本，则分类准确率会很高。因为它们明显跟用户兴趣不符，被粗排淘汰的物品也是负样本，但它们多少跟用户兴趣有些相关，所以分类比较困难，分类准确率会稍微低一些。精排分类靠后的物品也是负样本，这些物品跟正样本有些相似，所以它们很容易判定为正样本，对它们做分类非常困难，比较常用的做法是把简单负样本和困难负样本混合起来作为训练数据。比如50%（全体物品中随机非均匀抽样）是简单负样本，另外50%（从粗排和精排淘汰的物品中随机抽样）是困难负样本。
{% note warning %}
**常见的错误**：可以把曝光但没有点击的物品作为负样本，这是错误的。用双塔模型去召回训练，效果肯定会变差。训练召回模型不能用这样的负样本，训练排序模型会用这类负样本。
{% endnote %}
**选择负样本的原理**：召回的目的是快速找到用户可能感兴趣的物品。凡是用户感兴趣全部取回来，然后再交给后面的排序模型逐一做甄别，召回模型的任务是区分用感兴趣的物品和不感兴趣的物品，而不是区分比较感兴趣的物品和非常感兴趣的物品。这就是选择负样本的基本思路。
- **全体物品**(`easy`)：可以把全体物品当做负样本，把它们叫做**简单负样本**，这些物品绝大多数都是用户不感兴趣的，双塔模型很容易区分这些负样本；
- **被排序淘汰**(`hard`)：被召回但被粗排或精排淘汰的叫做**困难负样本**，这些物品能被召回说明它们跟用户的兴趣有一定的相关性，被排序模型过滤掉，说明它们跟用户的兴趣不够强烈，他们可以作负样本，这样的负样本跟正样本有点相似，做分类的时候难以区分，所以算是**困难负样本**。
- **有曝光没点击**：看起来可以作为负样本，但其实不能，只要用了这样的负样本，双塔模型的效果肯定会变差，一个物品可以通过精排模型的甄别并曝光给用户，说明物品已经非常匹配用户的兴趣点，每次给用户展示几十个物品，用户不可能每个都点击，没有点击不代表不感兴趣，所以不应该把**有曝光没点击**的物品作为召回的负样本，他只适合训练排序模型，不适合训练召回模型。