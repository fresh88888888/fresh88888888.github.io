---
title: 机器学习(ML)(七) — 探析
date: 2024-09-28 15:24:11
tags:
  - AI
categories:
  - 人工智能
mathjax:
  tex:
    tags: 'ams'
  svg:
    exFactor: 0.03
---

#### 介绍

什么是**决策树**？学习算法输出的模型看起来像一棵树。这里有一个新的测试示例，有一只猫，耳朵形状尖尖的，脸形圆润，有胡须。该模型学习此示例并做出**分类决策**，从树的最顶端节点开始，这称为树的**根节点**，然后查看写在里面的特征，即耳朵形状。根据此示例的耳朵形状的值向左或向右走。耳朵形状的值是尖的，所以将沿着树的左边分支向下走，最后到达椭圆形节点。然后查看脸部形状，脸部是圆形的，所以将沿着这里的箭头向下走。算法会推断这是一只猫。树中最上面的节点称为**根节点**。所有这些节点都称为**决策节点**。它们之所以是**决策节点**，是因为它们会查看特定特征，然后根据特征的值，来决策是沿着树向左走还是向右走。最后，这些底部的节点称为**叶节点**。它们会做出**预测**。
<!-- more -->
{% asset_img ml_1.png %}

给定训练集构建**决策树**有几个步骤。给定一个包含 10 个猫和狗示例的训练集，就像您在上一个视频中看到的那样。**决策树**学习的第一步是决定在**根节点**使用什么特征。这是**决策树**最顶端的第一个节点。假设选择耳朵形状作为根节点的特征。并查看所有训练示例，根据耳朵形状特征的值对它们进行拆分。具体来说，选出五个尖耳朵的例子并将它们移到左边。然后选出五个松软耳朵的例子并将它们移到右边。第二步是只关注**决策树**的左侧部分，根据指定（根据一种算法）的特征进行拆分。假设使用脸型特征。接下来要做的是根据这五个示例的脸型值，将它们拆分成两个子集。然后从这五个示例中取出四个脸型为圆脸的示例并将它们移到左侧。将一个脸型不圆的示例移到右侧。最后，观察到到这四个示例都是猫。这时不再进一步拆分，而是创建一个叶节点，该节点预测猫的分布。在决策树左侧分支的左侧部分完成此操作后，在**决策树**的右侧部分重复类似的过程。关注这五个示例，其中包含一只猫和四只狗。选择某个特征来进一步拆分这五个示例，如果选择了胡须特征，那么根据胡须存在或不存在拆分这五个示例，如下图所示：

左侧的示例只有一个是猫。创建叶节点，在左侧进行猫预测，在右侧进行狗预测。这是一个构建决策树的过程。在此过程中，需要在算法的各个步骤中做出几个关键决策。第一个关键决策是选择在每个节点上使用哪些特征进行拆分？在根节点以及决策树的左分支和右分支上需要确定该节点上是否有一些由猫和狗混合而成的示例。目的是尽可能接近所有猫或所有狗的子集。例如，如果我们有一个特征表示这种动物是否有猫。根节点可以根据这个特征进行拆分，这样左分支中会有五只猫，而右分支中会有五只猫。这些数据的左子集和右子集都是完全纯净的，意味着在左子分支和右子分支中只有一个类别，要么只有猫，要么不是只有猫，那么这个特征将是一个很好的**使用特征**。但是对于实际拥有的特征，如果根据年份形状进行划分，这会导致左侧五个例子中有四个是猫，而右侧五个例子中有一个是猫，或者根据脸部形状进行划分，这会导致左侧七个例子中有四个是猫，而右侧三个例子中有一个是猫，这会导致左侧四个例子中有三个是猫，而右侧六个例子中有两个不是猫。**决策树**学习算法必须在耳朵形状、脸部形状和胡须之间选择。这些特征中的哪一个会导致左侧和右侧子分支上的标签纯度最高？如果可以得到高度纯净的样本子集，那么就可以预测猫或预测不是猫，并且大部分都是正确的。学习决策树时，我们必须做出的第一个决定是如何选择在每个节点上分割哪个特征。构建**决策树**时需要做出的第二个关键决定是何时停止分割。在**决策树**中，节点的深度定义为从表示最顶端的根节点到该特定节点所需的跳数。因此，根节点经过零跳即可到达自身，深度为`0`。它下面的注释深度为`1`，再往下注释深度为`2`。如果决定了**决策树**的最大深度为`2`，那么将不拆分此级别以下的任何节点，以便树永远不会达到深度`3`。其次，通过保持树较小，它不太容易**过度拟合**。决定停止拆分的另一个指标是纯度值是否低于某个阈值。同样，这既是为了保持树较小，也是为了降低过度拟合的风险。最后，如果节点的示例数量低于某个阈值，则会停止拆分。例如，如果我们在根节点上根据脸部形状特征进行拆分，那么右分支将只有三个训练示例，其中一只猫和两只狗，如果不再拆分仅包含三个示例的示例集，而不是将其拆分成更小的子集，并创建一个决策节点，则会预测不是猫。