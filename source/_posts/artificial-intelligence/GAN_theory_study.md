---
title: 生成对抗网络(GAN)（机器学习）
date: 2024-06-24 15:00:11
tags:
  - AI
categories:
  - 人工智能
mathjax:
  tex:
    tags: 'ams'
  svg:
    exFactor: 0.03
---

**生成对抗网络**(`GAN`)由`Goodfellow`等人在[`NeurIPS,2014`](https://arxiv.org/abs/1406.2661)中提出，是机器学习领域一项令人兴奋的最新创新。`GAN`是一种生成模型：它们会创建与您的训练数据相似的新数据实例。例如，即使这些脸不属于任何真实的人，`GAN`也可以创建看起来像人脸照片的图像。
<!-- more -->

#### 基本原理

`GAN`通过将生成器（学习生成目标输出）与鉴别器（学习区分真实数据和生成器输出）配对来实现这种真实性。生成器试图欺骗鉴别器，而鉴别器则试图不被欺骗。

#### 什么是生成模型？

“生成对抗网络”中的`“generative”`是什么意思？“生成”描述了一类与**判别模型形**成对比的统计模型。生成模型可以生成看起来像真实动物的新动物照片，而判别模型可以区分狗和猫。`GAN`只是生成模型的一种。
- 非正式地：生成模型可以生成新的数据实例；判别模型区分不同类型的数据实例。
- 更正式地：给定一组数据实例{% mathjax %}X{% endmathjax %}和一组标签{% mathjax %}Y{% endmathjax %}。生成模型捕捉联合概率为{% mathjax %}P(X,Y){% endmathjax %}，如果没有标签则概率为{% mathjax %}P(X){% endmathjax %}；判别模型捕捉条件概率为{% mathjax %}P(Y|X){% endmathjax %}。

生成模型包括数据本身的分布，并告诉您给定示例的可能性。例如，预测序列中下一个单词的模型通常是生成模型（通常比`GAN`简单得多），因为它们可以为单词序列分配概率。判别模型忽略了给定实例是否可能的问题，而只是告诉您标签应用于该实例的可能性有多大。

#### 概率建模

这两种模型都不必返回代表概率的数字。您可以通过模仿数据分布来对数据分布进行建模。例如，决策树之类的判别分类器可以标记实例而不为该标签分配概率。这样的分类器仍然是一个模型，因为所有预测标签的分布将模拟数据中标签的实际分布。类似地，生成模型可以通过生成看起来像是从该分布中提取的令人信服的“虚假”数据来对分布进行建模。

生成模型比类似的判别模型处理的任务更困难。生成模型必须进行更多建模。图像生成模型可能会捕捉到这样的相关性：“看起来像船的东西可能会出现在看起来像水的东西附近”和“眼睛不太可能出现在额头上”。这些都是非常复杂的分布。相比之下，判别模型可能只需寻找一些明显的模式就能学会“帆船”与“非帆船”之间的区别。它可能会忽略生成模型必须正确处理的许多相关性。判别模型试图在数据空间中划定边界，而生成模型则试图模拟数据在整个空间中的放置方式。例如，下图显示了手写数字的判别模型和生成模型：
{% asset_img g_1.png "判别模型和生成模型的手写示例" %}

判别模型通过在数据空间中画一条线来尝试区分手写的`0`和`1`。如果画对了线，它就可以区分`0`和`1`，而不必对实例在线两侧的数据空间中的位置进行精确建模。相比之下，生成模型则试图通过生成接近数据空间中真实数字的数字来产生令人信服的`1`和`0`。它必须对整个数据空间的分布进行建模。`GAN`提供了一种有效的方法来训练这些丰富的模型以类似于真实分布。

#### GAN结构概述

生成对抗网络(`GAN`)由两部分组成：
- 生成器学习生成可信的数据。生成的实例将成为鉴别器的反面训练示例。
- 鉴别器学会区分生成器的虚假数据和真实数据。鉴别器会惩罚产生不合理结果的生成器。

当训练开始时，生成器会生成明显是假的数据，而鉴别器很快就能分辨出这是假的：
{% asset_img g_2.png %}

随着训练的进行，生成器越来越接近产生可以欺骗鉴别器的输出：
{% asset_img g_3.png %}

在上图中，生成的数据现在有一个绿色矩形，左上角有数字10，还有一张简单的脸部图像。最后，如果生成器训练进展顺利，鉴别器分辨真假的能力就会变差。它开始将假数据归类为真数据，其准确率也会下降。
{% asset_img g_4.png %}

这是整个系统的图片：
{% asset_img g_5.png %}

生成器和鉴别器都是神经网络。生成器的输出直接连接到鉴别器的输入。通过反向传播，鉴别器的分类提供给生成器用来更新其权重的信号。
##### 生成器

`GAN`的生成器部分通过结合来自鉴别器的反馈来学习创建虚假数据。它学会让鉴别器将其输出分类为真实数据。与鉴别器训练相比，生成器训练需要生成器和鉴别器之间更紧密的集成。`GAN`中训练生成器的部分包括：
- 随机输入。
- 生成器网络，将随机输入转换为数据实例。
- 鉴别器网络，对生成的数据进行分类。
- 鉴别器输出
- 生成器损失，对未能欺骗鉴别器的生成器进行惩罚。

该图展示了生成器训练中的反向传播：
{% asset_img g_6.png %}

###### 随机输入

神经网络需要某种形式的输入。通常，我们输入想要处理的数据，例如我们想要分类或预测的实例。但是，对于输出全新数据实例的网络，我们使用什么作为输入呢？最基本的`GAN`形式是将随机噪声作为输入。然后，生成器将这种噪声转换为有意义的输出。通过引入噪声，我们可以让`GAN`生成各种各样的数据，从目标分布的不同位置进行采样。实验表明噪声的分布并不重要，因此我们可以选择易于采样的分布，例如均匀分布。为方便起见，噪声采样空间的维度通常小于输出空间的维度。请注意，有些`GAN`使用非随机输入来塑造输出。请参阅`GAN`变体。使用鉴别器训练生成器。为了训练神经网络，我们会改变网络的权重以减少其输出的错误或损失。然而，在我们的`GAN`中，生成器与我们试图影响的损失没有直接联系。生成器将数据输入到鉴别器网络中，鉴别器产生我们试图影响的输出。生成器损失会惩罚生成器，因为它生成了鉴别器网络认为是假的样本。网络的这个额外部分必须包含在反向传播中。反向传播通过计算权重对输出的影响（即如果改变权重，输出将如何变化）来将每个权重调整到正确的方向。但生成器权重的影响取决于它输入的鉴别器权重的影响。因此反向传播从输出开始，并通过鉴别器流回到生成器。同时，我们不希望判别器在生成器训练期间发生变化。试图击中移动目标会让生成器的难题变得更加困难。因此我们按照以下步骤训练生成器：
- 采样随机噪声。
- 从采样的随机噪声中产生生成器输出。
- 获取生成器输出的鉴别器“真实”或“假”分类。
- 计算鉴别器分类的损失。
- 通过鉴别器和生成器进行反向传播以获得梯度。
- 使用梯度改变生成器权重。

##### 鉴别器

`GAN`中的鉴别器只是一个分类器。它试图区分真实数据和生成器创建的数据。它可以使用任何适合其分类数据类型的网络架构。该图展示了鉴别器训练中的反向传播：
{% asset_img g_7.png %}

鉴别器的训练数据有两个来源：
- 真实数据实例，例如真实的人物图片。判别器在训练期间使用这些实例作为正例。
- 生成器创建的虚假数据实例。鉴别器在训练期间使用这些实例作为反面示例。

在上图中，两个“样本”框代表输入判别器的两个数据源。在判别器训练期间，生成器不会进行训练。生成器的权重保持不变，同时为判别器生成训练样本。
