---
title: 机器学习(ML)(四) — 探析
date: 2024-09-11 10:42:11
tags:
  - AI
categories:
  - 人工智能
mathjax:
  tex:
    tags: 'ams'
  svg:
    exFactor: 0.03
---

#### 介绍

几十年前，**神经网络**刚被发明时，最初的动机是编写能够模仿人类大脑或生物大脑学习和思考方式的软件。尽管如今，**神经网络**（有时也称为**人工神经网络**）已经变得与我们对大脑实际看法大不相同。一些生物学动机仍然保留在我们今天对**人工神经网络**或**计算机神经网络**的看法中。让我们先来看看大脑是如何工作的，以及它与**神经网络**的关系。人类大脑，或者更广泛地说，生物大脑表现出更高水平或更强大的**智能**，**神经网络**的初衷是试图构建软件来模仿大脑。
<!-- more -->

**神经网络**的研究始于`20`世纪`50`年代，后来一度失宠。然后在`20`世纪`80`年代和`90`年代初期，它们再次受到欢迎，并在一些应用领域表现出巨大的吸引力，例如手写数字识别，当时甚至用于读取写邮件的邮政编码和手写支票上的美元数字。但随后在`20`世纪`90`年代末，它再次失宠。大约从`2005`年开始，它再次复苏，并随着深度学习而重新焕发活力。当时惊讶的一件事是**深度学习**和**神经网络**的含义非常相似。但当时可能没有得到充分重视，**深度学习**这个术语听起来好多了，因为它是深度的学习。所以，在过去的十年或十五年里，**深度学习**成为了一个迅速发展的品牌。从那时起，**神经网络**就彻底改变了一个又一个应用领域。现代**神经网络**或**深度学习**产生巨大影响的第一个应用领域可能是**语音识别**，我们开始看到现代深度学习带来的更好的语音识别系统，`[inaudible]`和`Geoff Hinton`等人对此起到了重要作用，然后它开始进入**计算机视觉**领域。人们仍然会谈论`2012`年的`ImageNet`时刻，那也许是一个更大的轰动，当时`[inaudible]`发挥了他们的想象力，对**计算机视觉**产生了巨大的影响。然后在接下来的几年里，它让我们进入了文本或自然语言处理领域等等。现在，**神经网络**被应用于从气候变化到医学成像到在线广告到产品推荐等各个领域，现在**机器学习**的许多应用领域都使用**神经网络**。尽管今天的**神经网络**与大脑的学习方式几乎没有任何关系，但早期的动机是尝试构建软件来模仿大脑。那么大脑是如何工作的呢？这是一张说明大脑中神经元的图表。
{% asset_img ml_1.png %}

人类的所有思维都来自大脑中的**神经元**，它们发出**电脉冲**，有时还会与其他神经元形成新的连接。给定一个像这样的**神经元**，它有许多输入，从其他**神经元**接收电脉冲，然后圈出的这个神经元进行一些计算，然后通过电脉冲将这些输出发送给其他神经元，这个**上层神经元**的输出反过来又成为**下层神经元**的输入，这个神经元再次聚合来自多个其他神经元的输入，然后可能将其自己的输出发送给其他**神经元**，这就是人类思维的组成部分。这是**生物神经元**的简化图。**神经元**由左侧显示的**细胞体**组成，如果你上过生物学课，你可能会认出这是**神经元**的核心。神经元有不同的输入。在**生物神经元**中，输入线称为**树突**，然后它偶尔会通过输出线（称为**轴突**）向其他神经元发送电脉冲。这些电脉冲会成为另一个神经元的输入。因此，**人工神经网络**使用一个非常简化的**数学模型**来描述**生物神经元**的功能。**神经元**的作用是接受一些输入，一个或多个输入，这些输入只是数字。它进行一些计算并输出其他数字，然后这些数字可以作为第二个神经元的输入，如右图所示。当你构建**人工神经网络**或**深度学习算法**时，你通常希望同时模拟许多这样的神经元，而不是一次构建一个神经元。在这个图中，画了三个神经元。这些神经元共同的作用是输入一些数字，进行一些计算，然后输出一些其他数字。尽管对**生物神经元**和**人工神经元**进行了松散的类比，但我今天几乎不知道人类大脑是如何工作的。事实上，每隔几年，神经科学家就会在大脑的工作原理上取得一些根本性的突破。大脑的实际工作原理还有许多突破尚未发现，因此，试图盲目模仿今天对人类大脑的了解（坦率地说，了解的很少），可能不会让我们在构建**原始智能**方面走得那么远。以目前在神经科学方面的知识水平，肯定不行。话虽如此，即使有了这些极其简化的**神经元模型**，也能够构建真正强大的**深度学习算法**。因此，当你深入研究**神经网络**和**深度学习**时，即使其起源是受生物驱动的，也不要太在意生物驱动。事实上，这些从事深度学习研究的人已经不再过多地关注生物驱动。相反，他们只是使用**工程原理**来弄清楚如何构建更有效的算法。但我认为，不时推测和思考生物神经元的工作原理仍然很有趣。**神经网络**的概念已经存在了几十年。为什么**神经网络**直到最近几年才真正流行起来？在横轴上画出你拥有的用于问题的**数据量**，在纵轴上画出应用于该问题的学习算法的**性能**或**准确性**。
{% asset_img dl_2.png %}

在过去的几十年里，随着互联网的兴起、手机的兴起、社会的数字化，我们为许多应用所拥有的数据量稳步向右发展。许多使用电子替代了纸质记录，例如，如果您订购了某样东西，而不是写在纸上，那么更有可能是数字记录。如果您去看医生，您的健康记录现在更有可能是数字的，而不是纸质的。因此，在许多应用领域，**数据量**呈爆炸式增长。我们看到，使用传统的**机器学习算法**，例如**逻辑回归**和**线性回归**，即使您为这些算法输入更多数据，也很难使其性能持续提高。因此，就像**线性回归**和**逻辑回归**等传统学习算法一样，它们无法随着我们现在可以输入的数据量而扩展，也无法有效地利用不同应用所拥有的这些数据。如果你在这个数据集上训练一个**小型神经网络**，那么它的性能可能看起来是这样的。如果你训练一个**中型神经网络**，也就是一个包含更多神经元的网络，它的性能可能看起来是那样的。如果你训练一个**大型神经网络**，也就是一个包含大量人工神经元的网络，那么对于某些应用来说，性能会不断提高。这意味着两件事，对于某些拥有大量数据的应用，有时你会听到大数据这个词，如果你能够训练一个非常大的神经网络来利用你拥有的大量数据，那么你就可以在**语音识别**、**图像识别**、**自然语言处理**应用等许多领域获得更好的性能，而这些是早期学习算法无法实现的。这导致**深度学习算法**的腾飞，这也是更快的计算机处理器（包括`GPU`）兴起的原因。这种硬件最初设计用于生成美观的计算机图形，但后来发现它对**深度学习**也非常有用。这也是**深度学习算法**成为今天的样子的主要力量。这就是**神经网络**的起源，也是它们在过去几年中如此迅速发展的原因。

