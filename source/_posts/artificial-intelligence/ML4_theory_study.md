---
title: 机器学习(ML)(四) — 探析
date: 2024-09-11 10:42:11
tags:
  - AI
categories:
  - 人工智能
mathjax:
  tex:
    tags: 'ams'
  svg:
    exFactor: 0.03
---

#### 介绍

几十年前，**神经网络**刚被发明时，最初的动机是编写能够模仿人类大脑或生物大脑学习和思考方式的软件。尽管如今，**神经网络**（有时也称为**人工神经网络**）已经变得与我们对大脑实际看法大不相同。一些生物学动机仍然保留在我们今天对**人工神经网络**或**计算机神经网络**的看法中。让我们先来看看大脑是如何工作的，以及它与**神经网络**的关系。人类大脑，或者更广泛地说，生物大脑表现出更高水平或更强大的**智能**，**神经网络**的初衷是试图构建软件来模仿大脑。
<!-- more -->

**神经网络**的研究始于`20`世纪`50`年代，后来一度失宠。然后在`20`世纪`80`年代和`90`年代初期，它们再次受到欢迎，并在一些应用领域表现出巨大的吸引力，例如手写数字识别，当时甚至用于读取写邮件的邮政编码和手写支票上的美元数字。但随后在`20`世纪`90`年代末，它再次失宠。大约从`2005`年开始，它再次复苏，并随着深度学习而重新焕发活力。当时惊讶的一件事是**深度学习**和**神经网络**的含义非常相似。但当时可能没有得到充分重视，**深度学习**这个术语听起来好多了，因为它是深度的学习。所以，在过去的十年或十五年里，**深度学习**成为了一个迅速发展的品牌。从那时起，**神经网络**就彻底改变了一个又一个应用领域。现代**神经网络**或**深度学习**产生巨大影响的第一个应用领域可能是**语音识别**，我们开始看到现代深度学习带来的更好的语音识别系统，`[inaudible]`和`Geoff Hinton`等人对此起到了重要作用，然后它开始进入**计算机视觉**领域。人们仍然会谈论`2012`年的`ImageNet`时刻，那也许是一个更大的轰动，当时`[inaudible]`发挥了他们的想象力，对**计算机视觉**产生了巨大的影响。然后在接下来的几年里，它让我们进入了文本或自然语言处理领域等等。现在，**神经网络**被应用于从气候变化到医学成像到在线广告到产品推荐等各个领域，现在**机器学习**的许多应用领域都使用**神经网络**。尽管今天的**神经网络**与大脑的学习方式几乎没有任何关系，但早期的动机是尝试构建软件来模仿大脑。那么大脑是如何工作的呢？这是一张说明大脑中神经元的图表。
{% asset_img ml_1.png %}

人类的所有思维都来自大脑中的**神经元**，它们发出**电脉冲**，有时还会与其他神经元形成新的连接。给定一个像这样的**神经元**，它有许多输入，从其他**神经元**接收电脉冲，然后圈出的这个神经元进行一些计算，然后通过电脉冲将这些输出发送给其他神经元，这个**上层神经元**的输出反过来又成为**下层神经元**的输入，这个神经元再次聚合来自多个其他神经元的输入，然后可能将其自己的输出发送给其他**神经元**，这就是人类思维的组成部分。这是**生物神经元**的简化图。**神经元**由左侧显示的**细胞体**组成，如果你上过生物学课，你可能会认出这是**神经元**的核心。神经元有不同的输入。在**生物神经元**中，输入线称为**树突**，然后它偶尔会通过输出线（称为**轴突**）向其他神经元发送电脉冲。这些电脉冲会成为另一个神经元的输入。因此，**人工神经网络**使用一个非常简化的**数学模型**来描述**生物神经元**的功能。**神经元**的作用是接受一些输入，一个或多个输入，这些输入只是数字。它进行一些计算并输出其他数字，然后这些数字可以作为第二个神经元的输入，如右图所示。当你构建**人工神经网络**或**深度学习算法**时，你通常希望同时模拟许多这样的神经元，而不是一次构建一个神经元。在这个图中，画了三个神经元。这些神经元共同的作用是输入一些数字，进行一些计算，然后输出一些其他数字。尽管对**生物神经元**和**人工神经元**进行了松散的类比，但我今天几乎不知道人类大脑是如何工作的。事实上，每隔几年，神经科学家就会在大脑的工作原理上取得一些根本性的突破。大脑的实际工作原理还有许多突破尚未发现，因此，试图盲目模仿今天对人类大脑的了解（坦率地说，了解的很少），可能不会让我们在构建**原始智能**方面走得那么远。以目前在神经科学方面的知识水平，肯定不行。话虽如此，即使有了这些极其简化的**神经元模型**，也能够构建真正强大的**深度学习算法**。因此，当你深入研究**神经网络**和**深度学习**时，即使其起源是受生物驱动的，也不要太在意生物驱动。事实上，这些从事深度学习研究的人已经不再过多地关注生物驱动。相反，他们只是使用**工程原理**来弄清楚如何构建更有效的算法。但我认为，不时推测和思考生物神经元的工作原理仍然很有趣。**神经网络**的概念已经存在了几十年。为什么**神经网络**直到最近几年才真正流行起来？在横轴上画出你拥有的用于问题的**数据量**，在纵轴上画出应用于该问题的学习算法的**性能**或**准确性**。
{% asset_img ml_2.png %}

在过去的几十年里，随着互联网的兴起、手机的兴起、社会的数字化，我们为许多应用所拥有的数据量稳步向右发展。许多使用电子替代了纸质记录，例如，如果您订购了某样东西，而不是写在纸上，那么更有可能是数字记录。如果您去看医生，您的健康记录现在更有可能是数字的，而不是纸质的。因此，在许多应用领域，**数据量**呈爆炸式增长。我们看到，使用传统的**机器学习算法**，例如**逻辑回归**和**线性回归**，即使您为这些算法输入更多数据，也很难使其性能持续提高。因此，就像**线性回归**和**逻辑回归**等传统学习算法一样，它们无法随着我们现在可以输入的数据量而扩展，也无法有效地利用不同应用所拥有的这些数据。如果你在这个数据集上训练一个**小型神经网络**，那么它的性能可能看起来是这样的。如果你训练一个**中型神经网络**，也就是一个包含更多神经元的网络，它的性能可能看起来是那样的。如果你训练一个**大型神经网络**，也就是一个包含大量人工神经元的网络，那么对于某些应用来说，性能会不断提高。这意味着两件事，对于某些拥有大量数据的应用，有时你会听到大数据这个词，如果你能够训练一个非常大的神经网络来利用你拥有的大量数据，那么你就可以在**语音识别**、**图像识别**、**自然语言处理**应用等许多领域获得更好的性能，而这些是早期学习算法无法实现的。这导致**深度学习算法**的腾飞，这也是更快的计算机处理器（包括`GPU`）兴起的原因。这种硬件最初设计用于生成美观的计算机图形，但后来发现它对**深度学习**也非常有用。这也是**深度学习算法**成为今天的样子的主要力量。这就是**神经网络**的起源，也是它们在过去几年中如此迅速发展的原因。

为了说明**神经网络**的工作原理，让我们从一个例子开始。使用一个需求预测的例子，在这个例子中，查看产品并尝试预测该产品是否会成为畅销产品？你正在销售`T`恤，你想知道某件`T`恤是否会成为畅销产品，并且收集了以不同价格出售的不同`T`恤的数据，以及哪些`T`恤成为畅销产品。如今，零售商使用这种类型的应用程序来规划更好的库存水平以及营销活动。如果你知道什么可能成为畅销产品，你会计划提前购买更多库存。在这个例子中，输入特征{% mathjax %}x{% endmathjax %}是`T`恤的价格，这是学习算法的输入。如果使用**逻辑回归**来将`S`型函数拟合到这样的数据，那么预测输出看起来像这样{% mathjax %}f_{\vec{w},b}(\vec{x}) = \frac{1}{1+e^{-wx + b}}{% endmathjax %}，作为学习算法的输出。为了构建**神经网络**，使用字母{% mathjax %}a{% endmathjax %}来表示该**逻辑回归算法**的输出。{% mathjax %}a{% endmathjax %}代表激活，指的是**神经元**向下游其他**神经元**发送输出的程度。这个**逻辑回归单元**被认为是大脑中单个**神经元**的非常简化的模型。**神经元**的作用是输入价格{% mathjax %}x{% endmathjax %}，然后计算这个公式{% mathjax %}a = f_{\vec{w},b}(\vec{x}) = \frac{1}{1+e^{-(wx + b)}}{% endmathjax %}，输出由这个公式计算的{% mathjax %}a{% endmathjax %}，输出这件`T`恤成为畅销品的概率。
{% asset_img ml_3.png %}

另一种理解**神经元**的方式是将其视为一台小型计算机，其唯一工作是输入一个或几个数字，例如价格，然后输出一个或几个其他数字，在本例中是`T`恤成为畅销品的**概率**。**逻辑回归算法**比大脑中的任何**生物神经元**都简单得多。这就是为什么**人工神经网络**是人类大脑的一个极其简化的模型。尽管在实践中，**深度学习算法**确实非常有效。鉴于对单个神经元的这种描述，现在构建**神经网络**只需要取出一堆这些**神经元**并将它们连接在一起或将它们放在一起。举一个例子，我们将使用四个特征来预测`T`恤是否是畅销品。这些特征包括`T`恤的价格、运费、特定`T`恤的营销量以及材料质量，这是高品质的厚棉布还是低质量的材料？现在，可能会怀疑`T`恤是否成为畅销品实际上取决于几个因素。首先，这件`T`恤的价格是否合理。其次，潜在买家对这件`T`恤的认知程度如何？第三是感知质量偏见或潜在偏见，认为这是一件高品质的`T`恤。创建一个**人工神经元**，估计这件`T`恤被认为非常实惠的概率。价格实惠主要取决于价格和运费，因为总付款金额是价格加上运费的一部分。在这里使用一个小神经元，一个逻辑回归单元来输入价格和运费，并预测人们是否认为这是实惠的？其次，我将在这里创建另一个人工神经元来估​​计，人们对这件 T 恤的认知程度是否很高？在这种情况下，认知度主要取决于 T 恤的营销。最后，我们将创建另一个神经元来估​​计人们是否认为这是高质量的，这可能主要取决于`T`恤的价格和材料质量。价格是一个因素，如果有一件价格非常高的`T`恤，人们会认为它是高质量的，因为它非常昂贵，也许人们认为它会是高质量的。根据这些对可负担性、认知度和感知质量的估计，将这三个**神经元**的输出连接到右边的另一个**神经元**，然后是另一个**逻辑回归单元**。它最终输入这三个数字并输出这件`T`恤成为畅销品的**概率**。在神经网络的术语中，把这三个**神经元**组合成一个**层**。**层是一组神经元**，它将相同或相似的特征作为输入，然后输出几个数字。左侧的三个神经元形成一层，这就是我将它们画在彼此之上的原因，而右侧的单个**神经元**也是一个层。左侧的层有三个神经元，因此一个层可以有多个神经元，也可以只有一个神经元，就像右侧这一层的情况一样。右侧这一层也称为**输出层**，因为这个最终神经元的输出是**神经网络**预测的**输出概率**。在神经网络术语中，把可负担性意识和感知质量称为**激活**。**激活**这个术语来自**生物神经元**，它指的是**生物神经元**向下游的其他**神经元**发送的输出值或电脉冲的程度。这些关于可负担性、意识和感知质量的数字是这一层中这三个**神经元**的**激活**，而且这个输出概率是右侧显示的这个神经元的**激活**。这个神经网络执行以下计算。它输入四个数字，然后**神经网络**的这一层使用这四个数字来计算新的数字，也称为**激活值**。然后最后一层，即**神经网络**的**输出层**使用这三个数字来计算一个数字。在**神经网络**中，这四个数字的列表也称为**输入层**，它只是一个四个数字的列表。现在，对这个**神经网络**做一个简化。按照目前为止必须一次检查一个**神经元**，并决定它要从前一层获取什么输入。例如，我们说可负担性只是价格和运费的函数，而知名度只是营销的函数，等等，但是如果你正在构建一个大型**神经网络**，那么手动决定哪些**神经元**应该将哪些特征作为输入将是一项艰巨的工作。**神经网络**在实践中的实现方式是某一层中的每个神经元；假设中间这一层可以访问前一层的每个**特征**和每个值，也就是**输入层**，如果试图预测可负担性，并且它知道价格、运费、营销和材料成本是多少，那么你可能会学会忽略营销和材料，只需通过适当设置参数来找出答案，只关注与可负担性最相关的特征子集。为了进一步简化这个**神经网络**的符号和描述，把这四个输入**特征**写成一个向量{% mathjax %}\vec{x}{% endmathjax %}，把**神经网络**视为具有四个特征，这些**特征**构成了这个**特征向量**{% mathjax %}\vec{x}{% endmathjax %}。这个**特征向量**被输入到中间这一层，然后计算三个激活值。这三个激活值又变成另一个向量，被输入到这个最终的**输出层**，最终输出这件`T`恤成为畅销品的概率。这就是神经网络的全部。

它有几个层，每个层输入一个向量并输出另一个向量。例如，中间的这个层输入四个数字{% mathjax %}\vec{x}{% endmathjax %}并输出三个数字，分别对应可负担性、知名度和感知质量。这`2`个层称为输出层，输入层。为了给中间的层起个名字，中间的这个层称为**隐藏层**。在训练集中，可以观察{% mathjax %}x{% endmathjax %}和{% mathjax %}y{% endmathjax %}。数据集告诉您{% mathjax %}x{% endmathjax %}是什么，{% mathjax %}y{% endmathjax %}是什么，但**数据集**不会告诉您可负担性、知名度和感知质量的正确值是什么。这些值的正确值是隐藏的。在训练集中看不到它们，这就是为什么中间的这个层被称为**隐藏层**。让我先把这个图的左半部分遮住，然后看看剩下的部分。你在这里看到的是，有一个**逻辑回归算法**或**逻辑回归单元**，它将`T`恤的可负担性、知名度和感知质量作为输入，并使用这三个特征来估计`T`恤成为畅销品的概率。这只是**逻辑回归**。但很酷的是，它不是使用原始特征，如价格、运费、营销等，而是使用可能更好的**特征集**，即可负担性、知名度和感知质量质量，希望这些特征能够更好地预测这件`T`恤是否会成为畅销品。理解这种神经网络的一种方式就是**逻辑回归**。但作为**逻辑回归**的一个版本，它们可以学习自己的特征，从而更容易做出准确的预测。如果你想预测房子的价格，你可以取地块的正面或宽度，然后将其乘以地块的深度，以构建一个更复杂的特征，{% mathjax %}x^{<1>}\times x^{<2>}{% endmathjax %}即草坪的大小。我们在那里进行手动特征工程，我们必须查看特征{% mathjax %}x^{<1>}x_2\times x^{<2>}{% endmathjax %}，并手动决定如何将它们组合在一起。**神经网络**所做的是不需要手动设计特征，它可以学习自己的特征。这就是*神经网络*成为当今世界上最强大的学习算法之一的原因。总而言之，输入层有一个**特征向量**，在这个例子中是四个数字，它被输入到**隐藏层**，**隐藏层**输出三个数字。我将使用一个向量来表示这个**隐藏层**输出的**激活向量**。然后**输出层**将其输入为三个数字并输出一个数字，这将是最终的**激活**，或者神经网络的最终预测。

{% note warning %}
请注意，尽管之前将这个神经网络描述为计算可负担性、意识和感知质量，但**神经网络**的一个非常好的特性是，当你从数据中训练它时，你不需要明确地决定**神经网络**应该计算哪些特征，比如可负担性等等，或者自己弄清楚它想要在这个**隐藏层**中使用哪些特征。这就是它成为如此强大的学习算法的原因。这个神经网络有一个单层，即**隐藏层**。让我们看一些其他神经网络的例子。这个**神经网络**有一个**输入特征向量**{% mathjax %}\vec{x}{% endmathjax %}，它被馈送到一个**隐藏层**。将其称为第一个隐藏层。如果这个隐藏层有三个神经元，它将输出一个包含三个**激活值**的向量。这三个数字可以输入到第二个**隐藏层**。如果第二个**隐藏层**有两个**神经元**到**逻辑单元**，那么第二个**隐藏层**将输出另一个包含两个**激活值**的向量，向量接着进入**输出层**，然后输出**神经网络**的最终预测。在一些文献中，您会看到这种具有多个层的**神经网络**，称为**多层感知器**。
{% endnote %}