---
title: 机器学习(ML)(二十六) — 强化学习探析
date: 2025-02-23 09:00:11
tags:
  - AI
categories:
  - 人工智能
mathjax:
  tex:
    tags: 'ams'
  svg:
    exFactor: 0.03
---

#### 论文解读

这篇文章[SFT记忆，RL泛化：基础模型后训练的比较研究](https://arxiv.org/pdf/2501.17161)，从标题中也可以看出比较的的对象主要是**监督微调**(`SFT`)和**强化学习**(`RL`)，主要探讨了**监督微调**(`SFT`)和**强化学习**(`RL`)在基础模型**后训练**(`post training`)中的不同作用。特别是在模型的**泛化能力**和**记忆力**方面的比较。
<!-- more -->

**监督微调**(`Supervised Fine-Tuning，SFT`)是一种在**机器学习**领域广泛应用的技术，特别是在**迁移学习**的背景下。它主要用于将**预训练模型**调整到特定的下游任务上，以提高模型在该任务上的表现。`SFT`通常分为以下几个步骤：
- **预训练**：首先，**基础模型**在大规模数据集上进行预训练，学习语言模式、语法和上下文。这一阶段使模型具备广泛的语言理解能力。
- **数据标注**：为**微调**准备一个特定任务的数据集，每个数据点都带有正确的输出或答案。这些标注数据对于监督学习至关重要，因为它们指导模型在微调过程中的参数调整。
- **微调**：将**预训练模型**在标注数据集上进一步训练，调整其参数以提高在特定任务上的性能。例如，如果模型需要处理法律文件，则可以使用标注的法律文本进行微调，使其更好地理解法律术语和结构。

**监督微调**(`SFT`)和**强化学习**(`RL`)常用于**基础模型**的两种**后训练**技术。研究表明，**监督微调**(`SFT`)倾向于记忆训练数据，而**强化学习**(`RL`)则更关注于适应新场景和任务。论文引入了两个评估任务：`GeneralPoints`：一个算术推理卡牌游戏，要求模型使用四个数字创建等于目标数字（默认是24）的方程。`V-IRL`：一个真实世界的导航环境，模型需要根据视觉标志导航到目标位置。这两个任务都包含规则变体和视觉变体，用于评估模型在未见数据上的泛化能力。

虽然**监督微调**(`SFT`)和**强化学习**(`RL`)在基础模型训练中被广泛使用，但它们对泛化的不同影响仍然不清楚，这使得构建可靠和稳健的人工智能系统变得具有挑战性。分析基础模型的**泛化能力**中的一个关键挑战是**区分数据记忆**与**可转移原则的获取**。因此，作者研究了一个关键问题：**监督微调**(`SFT`)或**强化学习**(`RL`)是否**主要记忆训练数据**，或者它们是否学习了可以适应新任务变体的**可泛化原则**。为了解决这个问题，需关注**泛化**的两个方面：基于**文本的规则泛化**和**视觉泛化**。对于文本规则，研究模型应用学习到的规则（给定文本指令）到这些规则变体的能力。对于**视觉-语言模型**(`VLMs`)，**视觉泛化**衡量在给定任务中对视觉输入变化（如颜色和空间布局）的表现一致性。为了研究基于**文本**和**视觉的泛化**，使用了两个不同的任务，这些任务体现了基于规则和视觉变体。第一个任务是`GeneralPoints`，这是一个算术推理卡牌游戏任务，旨在评估模型的**算术推理能力**。在`GeneralPoints`中，模型接收四张卡片，并需要使用每张卡片的数值计算目标数字（默认是`24`），每张卡片只能使用一次。第二个任务是`V-IRL`，这是一个关注**模型空间推理能力**的真实世界导航任务。采用了类似于多步`RL`框架，在对主干模型进行`SFT`后实例化`RL`，使用序列修订公式。在`GeneralPoints`和`V-IRL`中，观察到`RL`学习到了**可泛化的规则**（以文本形式表达），其分布内性能提升也能转移到未见规则上。相反，`SFT`似乎只是**记忆了训练规则**，并未能实现**泛化**。除了基于文本的规则泛化外，还进一步探索了**视觉领域的泛化**，观察到`RL`也能对视觉分布外任务进行**泛化**，而`SFT`仍然无法做到泛化。作为视觉分布外泛化能力的副产品，通过多轮`RL`方法在`V-IRL`小型基准测试中**泛化能力**提升了`33.8%`（`44.0% → 77.8%`），突显了`RL`的泛化能力。为了理解`RL`如何影响模型的**视觉能力**，对`GeneralPoints`进行了额外分析，揭示使用**基于结果**的**奖励函数**训练`RL`能够改善视觉识别能力。与`SFT`相比，`RL`表现出更好的**泛化能力**，但`SFT`仍然有助于稳定模型输出格式，从而使`RL`能够实现其**泛化能力**的提升。同样增加**最大步骤数**来扩大推理计算时间也可以提高**泛化能力**。
{% asset_img ml_1.png "RL与SFT在OOD泛化下的比较研究" %}

实验结果表明：
- `RL`**的泛化能力**：研究发现，经过`RL`训练的模型，特别是在使用**基于结果**的奖励进行训练时，能够在文本和视觉变体之间有效泛化。与此相比，`SFT`则更倾向于**记忆训练数据**，并且在面对分布外场景时表现不佳。
- `SFT`**的记忆偏向**：`SFT`训练的模型往往会对特定的输入模式进行匹配，而不是理解其背后的逻辑。例如，在`GeneralPoints`任务中，如果模型仅仅记住了特定卡片颜色与数字的关联，当规则变化时，其表现会显著下降。
- `RL`**对视觉识别能力的提升**：研究还发现，`RL`不仅提高了模型在文本任务中的表现，也增强了其在视觉任务中的基础视觉识别能力。
- `SFT`**与**`RL`**的互补性**：尽管`RL`在**泛化能力**上表现更好，但研究表明，`SFT`仍然对有效的`RL`训练至关重要。`SFT`能够稳定模型输出格式，从而为后续的`RL`提供良好的基础。

#### AGI 探析

通往**人工通用智能**的道路不仅是一场技术征程，更是一次哲学层面的探索——它要求我们重新诠释数字时代**智能**与**伦理**的深层内涵。———— `Alex Kim`，未来洞察研究院人工智能伦理部主任。

要开始探讨我们距离`AGI`（**人工通用智能**）还有多远这一命题，首先需要以人工智能发展史为锚点，理解人类对更先进系统的深层诉求。通过本文，我们希望以大型语言模型(`LLMs`)等现代`AI`系统为观测视角，为当前`AGI`发展进程提供证据与洞见。核心目标在于审慎叩问：`LLMs`是否就是终极答案？只有秉持这种持续探索的科研自觉，我们才有可能真正触碰`AGI`的疆界。

**人工智能简史**，**人工智能**(`AI`)的发展通过其在**视觉感知**、**语言理解**、**推理优化**等领域的强大能力深刻改变了人类社会。典型案例是`DeepMind`于`2021`年推出的`AlphaFold`，彻底革新了蛋白质结构预测领域，推动了生物科学研究的前沿突破。值得注意的是，`AI`发展历程并非一帆风顺：
- **奠基阶段**(`1950s-1970s`)：早期研究聚焦**符号主义**与**连接主义**，为智能计算的**范式**奠定理论基础。受限于算力与数据规模，研究多停留在概念验证层面。
- **寒冬与复苏**(`1980s-1990s`)：因技术预期过高与现实落差，`AI`经历发展低谷。**机器学习**与**神经网络理论**突破为技术复苏注入动力。
- **深度学习革命**(`2010s`至今)：**图像识别**与**语音识别**取得跨越式发展，`ChatGPT`的横空出世标志着大语言模型(`LLMs`)开启`AI`研究的新纪元。**统一知识表征体系，多任务协同求解能力突破**。

尽管**人工智能**(`AI`)为人类社会带来了巨大的改善，但社会的物质和精神需求日益增长，使得人们对`AI`仅提供的便利性感到不满足。因此，实现能够高效、有效地执行更广泛任务的**人工通用智能**(`AGI`)已成为一个迫切关注的问题。`AGI`被描述为一种至少在大多数任务上与人类一样能力的`AI`系统(`Wang et al., 2018; Voss and Jovanovic, 2023`)。我们到底距离`AGI`还有多远，以及如何实现`AGI`？为了探讨这些问题，现有研究主要分为三个类别：**定义与概念**、**技术方法与应用**、以及**伦理与社会影响**。
- **定义与概念**：`Wang`等人(`2018`)从与人类的比较角度定义了`AGI`的概念，并提出了不同层次的`AGI`。`Voss`和`Jovanovic`(`2023`)为实现`AGI`提供了方向，设定了与`AGI`相关的人类化要求。
- **技术方法与应用**：`Yan`(`2022`)和`Wang`等人(`2019`)提出，`AGI`可以通过将**逻辑**与**深度学习**相结合来实现。`Das`等人(`2023`)认为，`AGI`技术的发展存在许多风险，如安全和隐私问题。
- **伦理与社会影响**：`Rayhan`(`2023`)认为，人们应该考虑创建`AGI`的**伦理影响**，包括对**人类社会、隐私和权力动态**的影响。`Bugaj`和`Goertzel`(`2007`)提出了**五项伦理原则**及其对`AGI`交互的影响。这些研究从不同角度刻画了`AGI`，但仍缺乏对`AGI`发展过程的系统性评估和对`AGI`目标的明确定义，这使得衡量当前`AI`发展与`AGI`未来的差距变得困难，并且难以提出实现`AGI`的可能路径。
{% asset_img ml_2.png  %}

由上图所示，从`AGI`(**人工通用智能**)所需的主要能力概述开始，分为**内部能力**、与**外部世界的接口连接**以及支持这些功能的**基础设施系统**。在部署方面，需要更为复杂的对齐程序，以在约束和人类期望下释放`AGI`系统的潜力。此外，我们描绘了一个路线图。`AGI`的三个层次：**胚胎**`AGI`、**超人类**`AGI`和**终极**`AGI`，帮助我们定位当前状态、相关评估框架以及对一些可能阻碍我们向`AGI`前进的关键问题的见解。

