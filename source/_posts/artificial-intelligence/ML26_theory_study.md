---
title: 机器学习(ML)(二十六) — 强化学习探析
date: 2025-02-23 09:00:11
tags:
  - AI
categories:
  - 人工智能
mathjax:
  tex:
    tags: 'ams'
  svg:
    exFactor: 0.03
---

#### 论文解读

这篇文章[SFT记忆，RL泛化：基础模型后训练的比较研究](https://arxiv.org/pdf/2501.17161)，从标题中也可以看出比较的的对象主要是**监督微调**(`SFT`)和**强化学习**(`RL`)，主要探讨了**监督微调**(`SFT`)和**强化学习**(`RL`)在基础模型**后训练**(`post training`)中的不同作用。特别是在模型的**泛化能力**和**记忆力**方面的比较。
<!-- more -->

**监督微调**(`Supervised Fine-Tuning，SFT`)是一种在**机器学习**领域广泛应用的技术，特别是在**迁移学习**的背景下。它主要用于将**预训练模型**调整到特定的下游任务上，以提高模型在该任务上的表现。`SFT`通常分为以下几个步骤：
- **预训练**：首先，**基础模型**在大规模数据集上进行预训练，学习语言模式、语法和上下文。这一阶段使模型具备广泛的语言理解能力。
- **数据标注**：为**微调**准备一个特定任务的数据集，每个数据点都带有正确的输出或答案。这些标注数据对于监督学习至关重要，因为它们指导模型在微调过程中的参数调整。
- **微调**：将**预训练模型**在标注数据集上进一步训练，调整其参数以提高在特定任务上的性能。例如，如果模型需要处理法律文件，则可以使用标注的法律文本进行微调，使其更好地理解法律术语和结构。

**监督微调**(`SFT`)和**强化学习**(`RL`)常用于**基础模型**的两种**后训练**技术。研究表明，**监督微调**(`SFT`)倾向于记忆训练数据，而**强化学习**(`RL`)则更关注于适应新场景和任务。论文引入了两个评估任务：`GeneralPoints`：一个算术推理卡牌游戏，要求模型使用四个数字创建等于目标数字（默认是24）的方程。`V-IRL`：一个真实世界的导航环境，模型需要根据视觉标志导航到目标位置。这两个任务都包含规则变体和视觉变体，用于评估模型在未见数据上的泛化能力。

虽然**监督微调**(`SFT`)和**强化学习**(`RL`)在基础模型训练中被广泛使用，但它们对泛化的不同影响仍然不清楚，这使得构建可靠和稳健的人工智能系统变得具有挑战性。分析基础模型的**泛化能力**中的一个关键挑战是**区分数据记忆**与**可转移原则的获取**。因此，作者研究了一个关键问题：**监督微调**(`SFT`)或**强化学习**(`RL`)是否**主要记忆训练数据**，或者它们是否学习了可以适应新任务变体的**可泛化原则**。为了解决这个问题，需关注**泛化**的两个方面：基于**文本的规则泛化**和**视觉泛化**。对于文本规则，研究模型应用学习到的规则（给定文本指令）到这些规则变体的能力。对于**视觉-语言模型**(`VLMs`)，**视觉泛化**衡量在给定任务中对视觉输入变化（如颜色和空间布局）的表现一致性。为了研究基于**文本**和**视觉的泛化**，使用了两个不同的任务，这些任务体现了基于规则和视觉变体。第一个任务是`GeneralPoints`，这是一个算术推理卡牌游戏任务，旨在评估模型的**算术推理能力**。在`GeneralPoints`中，模型接收四张卡片，并需要使用每张卡片的数值计算目标数字（默认是`24`），每张卡片只能使用一次。第二个任务是`V-IRL`，这是一个关注**模型空间推理能力**的真实世界导航任务。采用了类似于多步`RL`框架，在对主干模型进行`SFT`后实例化`RL`，使用序列修订公式。在`GeneralPoints`和`V-IRL`中，观察到`RL`学习到了**可泛化的规则**（以文本形式表达），其分布内性能提升也能转移到未见规则上。相反，`SFT`似乎只是**记忆了训练规则**，并未能实现**泛化**。除了基于文本的规则泛化外，还进一步探索了**视觉领域的泛化**，观察到`RL`也能对视觉分布外任务进行**泛化**，而`SFT`仍然无法做到泛化。作为视觉分布外泛化能力的副产品，通过多轮`RL`方法在`V-IRL`小型基准测试中**泛化能力**提升了`33.8%`（`44.0% → 77.8%`），突显了`RL`的泛化能力。为了理解`RL`如何影响模型的**视觉能力**，对`GeneralPoints`进行了额外分析，揭示使用**基于结果**的**奖励函数**训练`RL`能够改善视觉识别能力。与`SFT`相比，`RL`表现出更好的**泛化能力**，但`SFT`仍然有助于稳定模型输出格式，从而使`RL`能够实现其**泛化能力**的提升。同样增加**最大步骤数**来扩大推理计算时间也可以提高**泛化能力**。
{% asset_img ml_1.png "RL与SFT在OOD泛化下的比较研究" %}

实验结果表明：
- `RL`**的泛化能力**：研究发现，经过`RL`训练的模型，特别是在使用**基于结果**的奖励进行训练时，能够在文本和视觉变体之间有效泛化。与此相比，`SFT`则更倾向于**记忆训练数据**，并且在面对分布外场景时表现不佳。
- `SFT`**的记忆偏向**：`SFT`训练的模型往往会对特定的输入模式进行匹配，而不是理解其背后的逻辑。例如，在`GeneralPoints`任务中，如果模型仅仅记住了特定卡片颜色与数字的关联，当规则变化时，其表现会显著下降。
- `RL`**对视觉识别能力的提升**：研究还发现，`RL`不仅提高了模型在文本任务中的表现，也增强了其在视觉任务中的基础视觉识别能力。
- `SFT`**与**`RL`**的互补性**：尽管`RL`在**泛化能力**上表现更好，但研究表明，`SFT`仍然对有效的`RL`训练至关重要。`SFT`能够稳定模型输出格式，从而为后续的`RL`提供良好的基础。

#### AGI 探析

通往**人工通用智能**的道路不仅是一场技术征程，更是一次哲学层面的探索——它要求我们重新诠释数字时代**智能**与**伦理**的深层内涵。———— `Alex Kim`，未来洞察研究院人工智能伦理部主任。

要开始探讨我们距离`AGI`（**人工通用智能**）还有多远这一命题，首先需要以人工智能发展史为锚点，理解人类对更先进系统的深层诉求。通过本文，我们希望以大型语言模型(`LLMs`)等现代`AI`系统为观测视角，为当前`AGI`发展进程提供证据与洞见。核心目标在于审慎叩问：`LLMs`是否就是终极答案？只有秉持这种持续探索的科研自觉，我们才有可能真正触碰`AGI`的疆界。

**人工智能简史**，**人工智能**(`AI`)的发展通过其在**视觉感知**、**语言理解**、**推理优化**等领域的强大能力深刻改变了人类社会。典型案例是`DeepMind`于`2021`年推出的`AlphaFold`，彻底革新了蛋白质结构预测领域，推动了生物科学研究的前沿突破。值得注意的是，`AI`发展历程并非一帆风顺：
- **奠基阶段**(`1950s-1970s`)：早期研究聚焦**符号主义**与**连接主义**，为智能计算的**范式**奠定理论基础。受限于算力与数据规模，研究多停留在概念验证层面。
- **寒冬与复苏**(`1980s-1990s`)：因技术预期过高与现实落差，`AI`经历发展低谷。**机器学习**与**神经网络理论**突破为技术复苏注入动力。
- **深度学习革命**(`2010s`至今)：**图像识别**与**语音识别**取得跨越式发展，`ChatGPT`的横空出世标志着大语言模型(`LLMs`)开启`AI`研究的新纪元。**统一知识表征体系，多任务协同求解能力突破**。

尽管**人工智能**(`AI`)为人类社会带来了巨大的改善，但社会的物质和精神需求日益增长，使得人们对`AI`仅提供的便利性感到不满足。因此，实现能够高效、有效地执行更广泛任务的**人工通用智能**(`AGI`)已成为一个迫切关注的问题。`AGI`被描述为一种至少在大多数任务上与人类一样能力的`AI`系统(`Wang et al., 2018; Voss and Jovanovic, 2023`)。我们到底距离`AGI`还有多远，以及如何实现`AGI`？为了探讨这些问题，现有研究主要分为三个类别：**定义与概念**、**技术方法与应用**、以及**伦理与社会影响**。
- **定义与概念**：`Wang`等人(`2018`)从与人类的比较角度定义了`AGI`的概念，并提出了不同层次的`AGI`。`Voss`和`Jovanovic`(`2023`)为实现`AGI`提供了方向，设定了与`AGI`相关的人类化要求。
- **技术方法与应用**：`Yan`(`2022`)和`Wang`等人(`2019`)提出，`AGI`可以通过将**逻辑**与**深度学习**相结合来实现。`Das`等人(`2023`)认为，`AGI`技术的发展存在许多风险，如安全和隐私问题。
- **伦理与社会影响**：`Rayhan`(`2023`)认为，人们应该考虑创建`AGI`的**伦理影响**，包括对**人类社会、隐私和权力动态**的影响。`Bugaj`和`Goertzel`(`2007`)提出了**五项伦理原则**及其对`AGI`交互的影响。这些研究从不同角度刻画了`AGI`，但仍缺乏对`AGI`发展过程的系统性评估和对`AGI`目标的明确定义，这使得衡量当前`AI`发展与`AGI`未来的差距变得困难，并且难以提出实现`AGI`的可能路径。
{% asset_img ml_2.png  %}

由上图所示，从`AGI`(**人工通用智能**)所需的主要能力概述开始，分为**内部能力**、与**外部世界的接口连接**以及支持这些功能的**基础设施系统**。在部署方面，需要更为复杂的对齐程序，以在约束和人类期望下释放`AGI`系统的潜力。此外，我们描绘了一个路线图。`AGI`的三个层次：**胚胎**`AGI`、**超人类**`AGI`和**终极**`AGI`，帮助我们定位当前状态、相关评估框架以及对一些可能阻碍我们向`AGI`前进的关键问题的见解。
{% asset_img ml_3.png  %}

由上图所示，`AGI`内部，即`AGI`的“**大脑**”，由四个主要组成部分：**感知**、**推理**、**记忆**和**元认知**。人类大脑的复杂性，以及其特定功能区域分别负责**认知**和**行为**的不同方面，为`AGI`系统的架构提供了一个引人入胜的类比。类似于人类大脑分为感官处理、情感、认知和执行功能等区域，`AGI`系统的“**大脑**”也可以基本上分为四个主要组成部分：**感知**、**记忆**、**推理能力**和**元认知**。这些组成部分反映了人类**认知**的基本方面，并在创建一个真正智能的系统中扮演着不同的关键角色。**感知**是指在`AGI`与其环境交互过程中对感官信息的组织和解释，被视为`AGI`的基本能力，包括**视觉、听觉、触觉、嗅觉**等。`AGI`的**推理**是基于对环境的感知，并对环境执行行动。`AGI`与环境的互动，包括**感知**的获取和行动的执行，将被保存为`AGI`的**记忆**。这些**记忆**将被用于`AGI`的**元认知**。

**感知**是指系统解释和理解周围世界的能力。这涉及对感官数据的处理和分析，以构建对环境的动态和上下文理解。**自然语言**作为人类交流的主要方式，已经从早期人类互动的起源发展到复杂的系统，如**大语言模型**(`LLMs`)。这些模型扩展了理解和参与对话以及执行创意任务的能力。然而，文本本身可能无法完全捕捉到现实世界经验的深度，这凸显了**多模态智能**的重要性，即结合图像、视频和音频以实现更丰富的**人机交互**。从传统`LLMs`到**多模态模型**的转变代表了一次重大的技术飞跃，促进了跨多种输入的更加逼真的互动。这一转变由近期**多模态**`LLMs`的发展所突显，解决了仅依赖语言理解的局限性，并为涉及多种数据形式的复杂挑战打开了大门。整合各种模型应遵循两个原则：1）理解“如何”将外部模态信息纳入，并确保不同模块的无缝整合；2）确定“使用什么”信息以保持原始模型的完整性并增强整体能力。利用现成的`LLMs`和**多模态编码器**的主要目标是在它们之间建立无缝连接。这种连接可以是外部的，即在不改变现有模型结构的情况下对齐多模态知识，也可以是内部的，允许`LLMs`与其他模态编码器进行更为复杂的交互。这些方法通常需要大量训练，例如创建一个可学习的接口，将`LLM`与非语言模态（特别是视觉）联系起来。类似于`LLM`的**预训练**和**微调**，**多模态**`LLMs`(`MLLMs`)遵循一个基于**预训练**`LLM`的两阶段训练范式，并将其适应**多模态领域**。第一阶段，称为**视觉-语言对齐阶段**，旨在使**语言模型**能够理解视觉标记。第二阶段涉及**多模态指令调整**，以使模型与人类感知相一致。这些阶段根据`LLM`与**多模态编码器**之间的组合架构有明确的分类。

**模态的外部连接**，外部方法基于通过额外结构和现有模型将视觉分支与`LLMs`（**大语言模型**）连接起来的理念。
- **投影式**：**模态连接器**存在于`LLMs`和多**模态编码器**之外，可以通过简单的**线性投影**或相对复杂的选择方法来实现。这种类型的`MLLM`（**多模态大语言模型**）通常在两个对齐训练阶段激活投影层或`LLMs`。
- **查询式**：这些`MLLMs`使用设计更为复杂的连接器，但仍然独立于`LLMs`和**多模态编码器**之外。这种模型本质上利用了类似**注意力**的交互，即在可学习变量与视觉标记之间进行交互。由于其连接器能够学习到比简单投影式更复杂的数据模式，因此仅**激活连接器**也能获得更优的多模态性能。
- **语言式**：语言作为接口是将所有现成模型整合为一个整体的流行方向。这些方法利用各种预构建模块进行生成和其他任务，`LLMs`主要负责模块的协调。利用工具的一个主要优势是这些系统可以更灵活地进行规划，以便做出决策或创作多媒体内容，语言作为桥梁。一个突出的最新方法是`GPT-4V`**模型**，它可以通过连接最先进的生成器生成生动的图像。虽然这些方法为各种任务提供了更广泛的技术解决方案，但它们在实现与接口式方法相当的性能深度方面通常不如后者。

