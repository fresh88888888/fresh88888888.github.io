---
title: 机器学习(ML)(十一) — 推荐系统探析
date: 2024-10-16 15:50:11
tags:
  - AI
categories:
  - 人工智能
mathjax:
  tex:
    tags: 'ams'
  svg:
    exFactor: 0.03
---

#### 介绍

**推荐系统**(`Recommendation system`)的商业影响和实际使用案例数量甚至远远超过学术界的关注程度。每次你访问京东`app`、淘宝`app`、美团`app`等或腾讯视频等电影流媒体网站，或者访问提供短视频(抖音、快手)应用时，这类应用都会向你推荐他们认为你可能想买的东西、他们认为你可能想看的电影或他们认为你可能想尝试的餐馆。对于许多公司来说，很大一部分销售额是由他们的**推荐系统**(`Recommendation system`)推动的。因此，对于许多公司来说，**推荐系统**(`Recommendation system`)带来的经济效益或价值非常大。因此，我们很有必要深入了解一下什么是**推荐系统**(`Recommendation system`)。
<!-- more -->

我将使用预测电影评分的应用作为示例。假设您经营一家大型电影流媒体网站，您的用户使用一到五颗星对电影进行评分。因此，在典型的**推荐系统**(`Recommendation system`)中，您有一组用户，这里有四个用户`Alice、Bob Carol`和`Dave`。用户编号为`1、2、3、4`。以及一组电影《爱在最后》、《浪漫永恒》、《可爱的小狗》、《不停歇的汽车追逐》和《剑与空手道》。用户所做的就是将这些电影评为一到五颗星。假设`Alice`给《爱在最后》评了五颗星，给《浪漫永恒》评了五颗星。也许她还没有看过《可爱的小狗》，所以没有对这部电影进行评分。则通过问号来表示，她认为《不停歇的汽车追逐》和《剑与空手道》应该得零颗星等。在**推荐系统**(`Recommendation system`)中，你有一定数量的用户和一定数量的项目。在这种情况下，**项目**是您想要推荐给用户的电影。尽管在这个例子中使用的是电影，但同样的逻辑或同样的东西也适用于任何东西，从产品或网站到餐馆，甚至推荐哪些媒体的文章、要展示的社交媒体文章，对用户感到更有趣的东西。这里使用的符号是{% mathjax %}n_u{% endmathjax %}来表示用户数量。所以在这个例子中，{% mathjax %}n_u = 4{% endmathjax %}，因为你有四个用户{% mathjax %}n_m{% endmathjax %}表示电影数量或实际上是项目数量。所以在这个例子中，{% mathjax %}n_m = 5{% endmathjax %}，因为我们有五部电影。如果用户{% mathjax %}j{% endmathjax %}对电影{% mathjax %}i{% endmathjax %}进行了评分，将设置{% mathjax %}r(i,j) = 1{% endmathjax %}。假设`Dallas Alice`对电影`1`进行了评分，但尚未对电影`3`进行评分，因此{% mathjax %}r(1,1) = 1{% endmathjax %}，因为她对电影`1`进行了评分，但{% mathjax %}r(3,1) = 0{% endmathjax %}，因为她尚未对电影`3`进行评分。最后使用{% mathjax %}y^{(i,j)}{% endmathjax %}表示用户{% mathjax %}j{% endmathjax %}对电影{% mathjax %}i{% endmathjax %}给出的评分。例如，此处的评分将是用户`2`对电影`3`的评分等于{% mathjax %}y^{(3,2)} = 4{% endmathjax %}。请注意，并非每个用户都会对每部电影进行评分，因此系统需要知道哪些用户对哪些电影进行了评分。这就是为什么用户{% mathjax %}j{% endmathjax %}对电影{% mathjax %}i{% endmathjax %}进行了评分，将定义为{% mathjax %}r(i,j) = 1{% endmathjax %}，如果用户{% mathjax %}j{% endmathjax %}尚未对电影{% mathjax %}i{% endmathjax %}进行评分，则{% mathjax %}r(i,j) = 0{% endmathjax %}。使用此**推荐系统**(`Recommendation system`)框架，解决问题的一种方法是查看用户尚未评分的电影。并尝试预测用户对这些电影的评分，因为这样我们就可以尝试向用户推荐他们更有可能评为五星的电影。

如果我们有每件商品的特征或每部电影的特征，我们该如何开发一个推荐系统？这里四个用户对五部电影中的部分电影进行了评分。在这里添加了两个特征{% mathjax %}x_1{% endmathjax %}和{% mathjax %}x_2{% endmathjax %}，它们分别表示每一部电影在多大程度上是爱情电影或动作电影。例如，《爱在最后》是一部非常浪漫的电影，所以这个特征取`0.9`，并且它不是一部动作电影。所以这个特征取`0`。《不停歇的汽车追逐》中只有一点点浪漫。所以它的值为`0.1`，但它有大量的动作。所以这个特征取值为`1.0`。这时的用户数量表示为：{% mathjax %}n_u = 4{% endmathjax %}，电影数量表示为{% mathjax %}n_m = 5{% endmathjax %}。最后引入{% mathjax %}n{% endmathjax %}来表示特征数量。因此{% mathjax %}n = 2{% endmathjax %}。有了这些特征，则第一部电影（即电影《爱在最后》）的特征为{% mathjax %}x^{(1)} = \begin{bmatrix}0.9 \\0 \end{bmatrix}{% endmathjax %}。第三部电影《可爱的小狗》的特征为{% mathjax %}x^{(3)} =  \begin{bmatrix}0.99 \\0 \end{bmatrix}{% endmathjax %}。如何预测`Alice`的电影评分。假设预测电影{% mathjax %}i{% endmathjax %}的评分为{% mathjax %}w\cdot x^{(i)} + b{% endmathjax %}。这个很像线性回归。例如，如果最终选择参数{% mathjax %}w^{(1)} =  \begin{bmatrix}5 \\0 \end{bmatrix}{% endmathjax %}并假设{% mathjax %}b^{(1)} = 0{% endmathjax %}，那么对于电影三的预测，其特征为{% mathjax %}x^{(3)} = \begin{bmatrix}0.99 \\0 \end{bmatrix}{% endmathjax %}，第一个特征为`0.99`，第二个特征为`0`。我们的预测将是{% mathjax %}w^{(1)}\cdot x^{(3)} + b^{(1)} = 4.95{% endmathjax %}。这个评分似乎很合理。看起来`Alice`对《爱在最后》和《永远的浪漫》这两部非常浪漫的电影给出了高评分，但对动作片《不停歇的汽车追逐》和《剑与空手道》给出了低评分。所以对于《可爱的小狗的爱》预测给出`4.95`分似乎很合理。因此，参数{% mathjax %}w{% endmathjax %}和{% mathjax %}b{% endmathjax %}对于`Alice`来说似乎是很合理的模型。对于多个用户来说，只需添加一些符号。在这里添加上标`1`，表示用户`1`的参数{% mathjax %}w^{(1)},\;b^{(1)}{% endmathjax %}，这样为数据集上的`4`个用户中的每一个设置不同的参数。将用户{% mathjax %}j{% endmathjax %}对电影{% mathjax %}i{% endmathjax %}的评分预测为{% mathjax %}w^{(j)}\cdot x^{(i)} + b^{(j)}{% endmathjax %}。这里的参数{% mathjax %}w^{(j)}{% endmathjax %}和{% mathjax %}b^{(j)}{% endmathjax %}是用于预测用户{% mathjax %}j{% endmathjax %}对电影{% mathjax %}i{% endmathjax %}评分的参数，{% mathjax %}x^{(i)}{% endmathjax %}是电影{% mathjax %}i{% endmathjax %}的特征。这很像**线性回归**，只是为数据集中的`4`个用户中的每一个拟合不同的线性回归模型。让我们看看如何为该算法制定成本函数。这里注意，如果用户{% mathjax %}j{% endmathjax %}对电影{% mathjax %}i{% endmathjax %}进行了评分，则{% mathjax %}r^{(i,j)} = 1/0{% endmathjax %}。{% mathjax %}y^{(i,j)}{% endmathjax %}用户{% mathjax %}j{% endmathjax %}对电影{% mathjax %}i{% endmathjax %}的评分。这里引入一种新的符号，使用{% mathjax %}m^{(j)}{% endmathjax %}表示用户{% mathjax %}j{% endmathjax %}评分的电影数量。如果用户评分了`4`部电影，则{% mathjax %}m^{(j)} = 4{% endmathjax %}。如果用户评分了`3`部电影，则{% mathjax %}m^{(j)} = 3{% endmathjax %}。预测的**成本函数**为{% mathjax %}\frac{1}{2m^{(j)}}\sum\limits_{i:r(i,j) = 1}(w^{(j)}\cdot x^{(i)} + b^{(j)} - y^{(i,j)})^2{% endmathjax %}。选择参数{% mathjax %}w{% endmathjax %}和{% mathjax %}b{% endmathjax %}来最小化预测评分和观察实际评分之间的**平方误差**。但是用户还没有对所有电影进行评分，如果要对此求和，我们将仅对{% mathjax %}r^{(i,j)} = 1{% endmathjax %}的{% mathjax %}i{% endmathjax %}值求和。意味着用户{% mathjax %}j{% endmathjax %}对该电影{% mathjax %}i{% endmathjax %}进行了评分。最后，对{% mathjax %}m^{(j)}{% endmathjax %}进行归一化为`1`。这类似于用于**线性回归**的**成本函数**。这就是{% mathjax %}w^{(j)},b^{(j)}{% endmathjax %}的成本函数{% mathjax %}\mathbf{J}{% endmathjax %}。如果我们将其最小化，会得到一组相当不错的参数{% mathjax %}w^{(j)}{% endmathjax %}和{% mathjax %}b^{(j)}{% endmathjax %}用于预测用户{% mathjax %}j{% endmathjax %}的评分。再给这个成本函数添加一个项，即防止**过度拟合**的正则化项。即{% mathjax %}\frac{\lambda}{2m^{(j)}}{% endmathjax %}。对于**推荐系统**(`Recommendation system`)来说，{% mathjax %}m^{(j)}{% endmathjax %}只是一个常数。因此，即使把它取出来，也应该得到相同的{% mathjax %}w{% endmathjax %}和{% mathjax %}b{% endmathjax %}值。我们将**最小化成本函数**作为{% mathjax %}w^{(j)}{% endmathjax %}和{% mathjax %}b^{(j)}{% endmathjax %}的函数{% mathjax %}\underset{w^{(j)},b^{(j)}}{\min}\mathbf{J}(w^{(j)},b^{(j)}) = \frac{1}{2m^{(j)}}\sum\limits_{i:r(i,j) = 1}(w^{(j)}\cdot x^{(i)} + b^{(j)} - y^{(i,j)})^2 + \frac{\lambda}{2m^{(j)}}\sum\limits_{k = 1}^n (w_k^{(j)})^2{% endmathjax %}。为了学习所有用户的参数{% mathjax %}w^{(1)}、b^{(1)}、w^{(2)}、b^{(2)}、\ldots、w^{(n_u)}、b^{(n_u)}{% endmathjax %}，则成本函数的计算公式为{% mathjax %}\mathbf{J}\left(\begin{array}{ccc} w^{(1)} ,& \ldots &, w^{(n_u)}\\ b^{(1)} ,& \ldots &, b^{(n_u)}\end{array}\right) = \frac{1}{2m^{(j)}}\sum\limits_{j=1}^{n_u}\sum\limits_{i:r(i,j) = 1}(w^{(j)}\cdot x^{(i)} + b^{(j)} - y^{(i,j)})^2 + \frac{\lambda}{2m^{(j)}}\sum\limits_{j=1}^{n_u}\sum\limits_{k = 1}^n (w_k^{(j)})^2{% endmathjax %}。这成为学习所有用户的所有参数的成本。如果我们使用**梯度下降法**或其他优化算法将其最小化{% mathjax %}w^{(1)}、b^{(1)}、w^{(2)}、b^{(2)}、\ldots、w^{(n_u)}、b^{(n_u)}{% endmathjax %}的**成本函数**为{% mathjax %}\underset{w^{(1)},b^{(1)},w^{(2)},b^{(2)},\ldots,w^{(n_u)},b^{(n_u)}}{\min}\;\frac{1}{2m^{(j)}}\sum\limits_{j=1}^{n_u}\sum\limits_{i:r(i,j) = 1}(w^{(j)}\cdot x^{(i)} + b^{(j)} - y^{(i,j)})^2 + \frac{\lambda}{2m^{(j)}}\sum\limits_{j=1}^{n_u}\sum\limits_{k = 1}^n (w_k^{(j)})^2{% endmathjax %}，那么你将拥有一组非常好的参数来预测所有用户的电影评分。请注意，这个算法很像**线性回归**，它的作用类似于**线性回归**的输出{% mathjax %}f(x){% endmathjax %}。只是现在需要为每个用户训练一个不同的**线性回归模型**。将这些特征{% mathjax %}x_1,x_2{% endmathjax %}输入模型，就可以学习参数并预测电影评分。

#### 协同过滤

如果每部电影都有特征，例如特征{% mathjax %}x_1{% endmathjax %}和{% mathjax %}x_2{% endmathjax %}可以表明这是一部爱情片还是一部动作片。那么可以使用**线性回归**来预测电影评级。但是，如果没有这些特征该怎么办？如何从数据找到这些特征{% mathjax %}x_1{% endmathjax %}和{% mathjax %}x_2{% endmathjax %}。如下图所示，假设我们学习了用户`1`的参数{% mathjax %}w^{(1)}= \begin{bmatrix}5 \\0 \end{bmatrix}{% endmathjax %}，{% mathjax %}b^{(1)} = 0{% endmathjax %}。{% mathjax %}w^{(2)}= \begin{bmatrix}5 \\0 \end{bmatrix}{% endmathjax %}，{% mathjax %}b^{(2)} = 0{% endmathjax %}。{% mathjax %}w^{(3)}= \begin{bmatrix}0 \\5 \end{bmatrix}{% endmathjax %}，{% mathjax %}b^{(3)} = 0{% endmathjax %}，对于用户`4`，{% mathjax %}w^{(4)}= \begin{bmatrix}0 \\5 \end{bmatrix}{% endmathjax %}，{% mathjax %}b^{(4)} = 0{% endmathjax %}。要预测用户{% mathjax %}j{% endmathjax %}对电影{% mathjax %}i{% endmathjax %}的评分，则{% mathjax %}w^{(j)}\cdot x^{(i)} + b^{(j)}{% endmathjax %}。
{% asset_img ml_1.png %}

为了简化这个例子，我们将设置{% mathjax %}b = 0{% endmathjax %}，{% mathjax %}b{% endmathjax %}的值忽略。考虑到`Alice`给第一部电影的评分是`5`，则{% mathjax %}w^{(1)}\cdot x^{(1)} = 5{% endmathjax %}，因为`Bob`给它评分也是`5`，所以{% mathjax %}w^{(2)}\cdot x^{(2)} = 5{% endmathjax %}。{% mathjax %}w^{(3)}\cdot x^{(1)} \approx 0{% endmathjax %}，{% mathjax %}w^{(4)}\cdot x^{(1)} \approx 0{% endmathjax %}。如果第一部电影的特征是`1、0`，在这种情况下，{% mathjax %}w^{(1)}\cdot x^{(1)} = 5{% endmathjax %}，{% mathjax %}w^{(2)}\cdot x^{(1)} = 5{% endmathjax %}，类似地，{% mathjax %}w^{(3)}\cdot x^{(1)} = 0{% endmathjax %}，{% mathjax %}w^{(4)}\cdot x^{(1)} = 0{% endmathjax %}。如果你有这些参数向量，你也可以尝试为第二部电影提出特征向量{% mathjax %}x^{(2)}{% endmathjax %}，为第三部电影提出特征向量{% mathjax %}x^{(3)}{% endmathjax %}，依此类推，让算法对这些电影的预测接近用户给出的实际评分。让我们设计出一个**成本函数**来学习{% mathjax %}x^{(1)}{% endmathjax %}和{% mathjax %}x^{(2)}{% endmathjax %}的值。但在协同过滤中，这是因为您有来自同一部电影的同一项目的多个用户的评分。这使我们能够尝试猜测这些特征的可能值。给定{% mathjax %}w^{(1)}、b^{(1)}、w^{(2)}、b^{(2)}、\ldots、w^{(n_u)}、b^{(n_u)}{% endmathjax %}等。如果您想了解特定电影的特征{% mathjax %}x^{(i)}{% endmathjax %}，使用的成本函数为{% mathjax %}\mathbf{J}(x^{(i)}) = \frac{1}{2}\sum\limits_{j:r(i,j) = 1} (w^{(j)}\cdot x^{(i)} + b^{(j)} -y^{(i,j)})^2 + \frac{\lambda}{2}\sum\limits_{k=1}^n (x_k^{(i)})^2{% endmathjax %}。最后，为了学习所有特征{% mathjax %}x^{(1)},\ldots,x^{(n_m)}{% endmathjax %}（有{% mathjax %}n_m{% endmathjax %}部电影），在则成本函数调整为：{% mathjax %}\mathbf{J}(x^{(1)},x^{(2)},\ldots,x^{(n_m)}) = \frac{1}{2}\sum\limits_{i=1}^{n_m}\sum\limits_{j:r(i,j) = 1} (w^{(j)}\cdot x^{(i)} + b^{(j)} -y^{(i,j)})^2 + \frac{\lambda}{2}\sum\limits_{i=1}^{n_m}\sum\limits_{k=1}^n (x_k^{(i)})^2{% endmathjax %}，这就是学习数据集中所有电影特征的**成本函数**。如果您有参数{% mathjax %}w{% endmathjax %}和{% mathjax %}b{% endmathjax %}，那么使用**梯度最小化**，将其作为{% mathjax %}x^{(1)},x^{(2)},\ldots,x^{(n_m)}{% endmathjax %}的**成本函数**{% mathjax %}\underset{x^{(1)},x^{(2)},\ldots,x^{(n_m)}}{\min}\;\frac{1}{2}\sum\limits_{i=1}^{n_m}\sum\limits_{j:r(i,j) = 1} (w^{(j)}\cdot x^{(i)} + b^{(j)} -y^{(i,j)})^2 + \frac{\lambda}{2}\sum\limits_{i=1}^{n_m}\sum\limits_{k=1}^n (x_k^{(i)})^2{% endmathjax %}，对于**协同过滤**，通过学习参数{% mathjax %}w^{(1)}、b^{(1)}、w^{(2)}、b^{(2)}、\ldots、w^{(n_u)}、b^{(n_u)}{% endmathjax %}最小化**成本函数**为{% mathjax %}\underset{w^{(1)},b^{(1)},w^{(2)},b^{(2)},\ldots,w^{(n_u)},b^{(n_u)}}{\min}\;\frac{1}{2}\sum\limits_{j=1}^{n_u}\sum\limits_{i:r(i,j) = 1}(w^{(j)}\cdot x^{(i)} + b^{(j)} - y^{(i,j)})^2 + \frac{\lambda}{2}\sum\limits_{j=1}^{n_u}\sum\limits_{k = 1}^n (w_k^{(j)})^2{% endmathjax %}，将上下两个成本函数合并为：{% mathjax %}\mathbf{J}(w,b,x) =  \frac{1}{2}\sum\limits_{(i,j):r(i,j) = 1} (w^{(j)}\cdot x^{(i)} + b^{(j)} -y^{(i,j)})^2 + \frac{\lambda}{2}\sum\limits_{j=1}^{n_u}\sum\limits_{k = 1}^n (w_k^{(j)})^2 + \frac{\lambda}{2}\sum\limits_{i=1}^{n_m}\sum\limits_{k=1}^n (x_k^{(i)})^2{% endmathjax %}。最后计算参数梯度下降的值为{% mathjax %}w_{i}^{(j)} = w_i^{(j)} - \alpha\frac{\partial}{\partial w_i^{(j)}}\mathbf{J}(w,b,x),\; b^{(j)} = b^{(j)} - \alpha\frac{\partial}{\partial b^{(j)}}\mathbf{J}(w,b,x),\; x_{k}^{(i)} = x_k^{(i)} - \alpha\frac{\partial}{\partial x_k^{(i)}}\mathbf{J}(w,b,x){% endmathjax %}。这里的算法称为**协同过滤算法**，**协同过滤**指的是多个用户协同评价了同一部电影，让你对这部电影有所了解，让你可以猜测这部电影的特征是什么，反过来可以预测其他尚未评价一部电影的用户如何评价它。这种**协同过滤**是从多个用户收集数据。用户之间的这种**协作**可以帮助您预测未来其他用户的评分。

**推荐系统**(`Recommendation system`)或**协同过滤**算法都涉及到了**二元标签**，如何从**线性回归**到**逻辑回归**，再到预测数字，再到预测**二元标签**，这是一个带有**元标签**的**协同过滤**数据集的示例。标签`1`指出用户喜欢某部电影。意味着`Alice`从头到尾看完了电影《爱在最后》和《浪漫永恒》。问号通常表示用户尚未看该商品，因此无法决定是否对该特定商品点赞或收藏。如何将**协同过滤算法**应用于此数据集。在具有**二元标签**的协同过滤中，有很多方法可以定义标签`1`和标签`0`。在一个在线购物网站中，标签可以表示用户{% mathjax %}j{% endmathjax %}在看到商品后是否选择购买商品。标签`1`表示购买了商品，标签`0`表示没有购买商品。问号表示没有看到商品。或者在社交媒体环境中，标签`1`或`0`可以表示用户在看到某项商品后是否喜欢或不喜欢该商品。问号表示用户尚未看到该商品，或者许多网站不要求用户明确评分，而是使用用户行为来猜测用户是否喜欢该商品。例如，您可以测量用户是否在某项商品上花费了至少`30`秒。如果是，则将其标记为`1`；如果用户看到了某项商品但没有花费至少`30`秒，则将其标记为`0`。如果用户尚未看到该商品，则将其标记为问号。另一种根据用户行为隐式生成评分的方法是查看用户是否点击了某项商品。这通常在在线广告中完成，如果用户看到了广告，如果他们点击了该广告，则将其标记为`1`，如果他们没有点击，则将其标记为`0`；如果用户甚至没有看到该广告，则标记为问号。这些**二元标签**通常具有以下粗略含义。`1`表示用户在看到某件商品后参与其中，而参与可能意味着他们点击或花费`30`秒或明确喜欢或想购买该商品。`0`表示用户在看到该商品后没有参与，问号表示该商品尚未显示给用户。给定这些**二元标签**，该算法与**线性回归**非常相似，可以预测这些二元输出。之前，我们预测标签{% mathjax %}y^{(i,j)} = w^{(j)}\cdot x^{(i)} + b^{(j)}{% endmathjax %}。这很像**线性回归模型**。对于**二元标签**，预测{% mathjax %}y^{(i,j)}{% endmathjax %}的概率{% mathjax %}w^{(j)}\cdot x^{(i)} + b^{(j)}{% endmathjax %}。但它由公式{% mathjax %}g(w^{(j)}\cdot x^{(i)} + b^{(j)}){% endmathjax %}表示，其中{% mathjax %}g(z) = \frac{1}{1 + e^{-z}}{% endmathjax %}。这就是逻辑函数，就像在逻辑回归中看到的一样。我们要做的是将与**线性回归模型**转变为与**逻辑回归模型**，该模型将预测{% mathjax %}y^{(i,j)} = 1{% endmathjax %}的概率。为了构建此算法，我们还必须将成本函数从**平方误差成本函数**修改为更适合**二元标签**的成本函数，以用于**逻辑回归**模型。二元标签损失为{% mathjax %}y^{(i,j)}:\;f_{(w,b,x)}(x) = g(w^{(j)}\cdot x^{(i)} + b^{(j)}),\; L(f_{(w,b,x)}(x),y^{(i,j)}) = -y^{(i,j)}\log(f_{(w,b,x)}(x)) - (1-y^{(i,j)})\log(1- f_{(w,b,x)}(x)){% endmathjax %}，则二元标签协同过滤的成本函数为{% mathjax %}\mathbf{J}(w,b,x) = \sum\limits_{(i,j):r(i,j) = 1} L(f_{(w,b,x)}(x), y^{(i,j)}){% endmathjax %}。这也称为**二元交叉熵成本函数**。这就是采用**线性回归**（如**协同过滤算法**）并将其推广到**二元标签**的方法。

在构建**推荐系统**(`Recommendation system`)时。如果先进行**均值归一化**，则性能会更好一些。也就是说，如果将电影评分**归一化**为具有一致的平均值，又有什么结果？为了解释**均值归一化**，需要添加第五个用户`Eve`，她还没有对任何电影进行评分。添加**均值归一化**将有助于算法对用户`Eve`做出更好的预测。如果要在这个数据集上训练**协同过滤算法**，会得到第五个用户的参数{% mathjax %}w{% endmathjax %}，对于用户`Eve`，{% mathjax %}w^{(5)}= \begin{bmatrix}0 \\0 \end{bmatrix}{% endmathjax %}，{% mathjax %}b^{(5)}= 0{% endmathjax %}。因为`Eve`还没有对任何电影进行评分，所以参数{% mathjax %}w{% endmathjax %}和{% mathjax %}b{% endmathjax %}不会影响成本函数中的第一个项，`Eve`的电影评分在这个**平方误差成本函**数中不起作用。`Eve`对所有电影的评分将是{% mathjax %}w^{(5)}\cdot x^{(i)} + b^{(5)} = 0{% endmathjax %}。**均值归一化**将帮助该算法更好地预测尚未对任何电影进行评分的新用户的电影评分。为了描述**均值归一化**，可以将所有值（包括`Eve`的所有问号）放入二维矩阵中。只是为了以更持久、更紧凑的方式写出所有评分（包括问号）。要进行均值归一化，我们要做的就是获取所有这些评分，并计算每部电影的平均评分。因此，电影一有两个 5 分和两个 0 分，因此平均评分为 2.5。电影二有一个 5 分和一个 0 分，因此平均评分为 2.5。第三部电影的评分为`4`和`0`，平均得分为`2`。第四部电影的平均评分为`2.25`。第五部电影不太受欢迎，平均评分为`1.25`。将这五个数字全部收集到一个向量中，我将这个向量称为{% mathjax %}\mu{% endmathjax %}，因为这是每部电影的平均评分向量。对看过该特定电影的用户进行平均。从每个评分中减去给出的平均评分。例如，这部电影的评分是`5`。减去平均评分`2.5`，得到`2.5`。这部电影的评分是`0`星。减去`2.25`，得到`-2.25`的评分，依此类推，现在包括新用户 `Eve`在内的五个用户以及所有五部电影都是如此。然后，右边的这些新值将成为{% mathjax %}y^{(i,j)}{% endmathjax %}的新值。假设用户`1`对电影一给出了`2.5`分，对电影四给出了`-2.25`分。然后利用此方法，您可以像之前一样为电影{% mathjax %}i{% endmathjax %}上的用户{% mathjax %}j{% endmathjax %}学习{% mathjax %}w^{(j)}、b^{(j)}、x^{(i)}{% endmathjax %}，预测{% mathjax %}w^{(j)}\cdot x^{(i)} + b^{(j)} + \mu_i{% endmathjax %}。由于我们在此**均值归一化**步骤中减去了电影{% mathjax %}i{% endmathjax %}的{% mathjax %}\mu_i{% endmathjax %}，为了预测不是负星级评分。必须将这个{% mathjax %}\mu_i{% endmathjax %}加回来。举一个具体的例子，新用户`Eve`还没有给任何电影打过分，那么可能会学习参数{% mathjax %}w^{(5)} = \begin{bmatrix}0 \\0 \end{bmatrix}{% endmathjax %}，并且{% mathjax %}b^{(5)} = 0{% endmathjax %}。如果查看电影`1`的预测评分，将预测`Eve`的评分{% mathjax %}w^{(5)}\cdot x^{(1)} + b^{(5)} + \mu_1 = 2.5{% endmathjax %}。`Eve`可能会给这部电影打`2.5`分似乎更合理，而不是认为`Eve`会给所有电影打零分，因为她还没有给任何电影打分。事实上，这种算法的效果是，它将导致新用户`Eve`的初始猜测恰好等于其他用户对这五部电影的评分的平均值。取电影的平均评分似乎比猜测`Eve`的所有评分都是零更合理。事实证明，将不同电影评分**的平均值归一化**为`0`，**推荐系统**(`Recommendation system`)也会运行得更快一些。但这确实使算法对没有评分过任何电影或评分过很少电影的用户表现更好。预测也会变得更加合理。这就是**均值归一化**。它使算法运行得更快。当有用户对很少的电影甚至根本没有电影进行过评分时，算法能够给出更好、更合理的预测。**均值归一化**将使**推荐系统**(`Recommendation system`)工作得更好。

我们接下来了解如何使用`TensorFlow`实现**协同过滤算法**。`TensorFlow`对于构建其他类型的机器学习算法也非常有用。例如**协同过滤算法**。为了实现**梯度下降**，您需要找到**成本函数**的导数，但`TensorFlow`可以自动找出**成本函数**的导数。需要做的就是实现**成本函数**，无需了解任何微积分，无需自己求导，您只需几行代码即可获得`TensorFlow`来计算该导数项，该导数可用于优化**成本函数**。接下来看看这一切是如何工作的。在第一个线性回归示例中。设置了{% mathjax %}b = 0{% endmathjax %}。因此模型预测为{% mathjax %}f(x) = w\cdot x{% endmathjax %}。找到使成本函数{% mathjax %}\mathbf{J}{% endmathjax %}最小化的{% mathjax %}w{% endmathjax %}值。通过**梯度下降**更新，则{% mathjax %}w = w - \alpha\frac{\partial}{\partial w}\mathbf{J}(w,b),\;b = b - \alpha\frac{\partial}{\partial b}\mathbf{J}(w,b){% endmathjax %}，继续执行梯度下降更新直到收敛。有时计算这个导数或偏导数项可能很困难。`TensorFlow`可以解决这个问题。使用一个非常简单的**成本函数**为：{% mathjax %}\mathbf{J} = (wx - 1)^2{% endmathjax %}。如果{% mathjax %}f(x) = wx,\;y = 1{% endmathjax %}，并且这里的{% mathjax %}b{% endmathjax %}不进行优化，那么最终的成本函数为：{% mathjax %}w = w - \alpha\frac{\partial}{\partial w}\mathbf{J}(w,b){% endmathjax %}。**梯度下降算法**将重复此更新，直到收敛。`TensorFlow`可以自动计算此**导数项**。下面的代码实现：
```python
w = tf.Varibale(3.0)
x, y = 1.0
alpha = 0.01
iterations = 30

for iter in range(iterations):
    with tf.GradientTape() as tape:
        costJ = (w*x - y)**2
    
    [djdw] = tape.gradient(costJ, [w])
    w.assign_add(-alpha * djdw)
```
`w=tf.variable(3.0)`，参数{% mathjax %}w{% endmathjax %}初始化为`3.0`。设置`x=1.0、y=1.0`并将**学习率**(`alpha`)设置为`0.01`。运行**梯度下降**`30`次，即`30`次迭代。这是让`TensorFlow`自动为您计算导数的语法。`TensorFlow`有一个被称为梯度带(`Gradient Tape`)的工具。计算{% mathjax %}f(x) = wx{% endmathjax %}f(x)和{% mathjax %}\mathbf{J} = (f(x) - y)^2{% endmathjax %}。`TensorFlow`将自动记录步骤序列。这是启用**自动微分**所必需的。接下来，`TensorFlow`将在**梯度带**中保存操作序列。`TensorFlow`自动计算此导数项，将其称为`dJdw`。这是`TensorFlow`的一个非常强大的功能，称为`Auto Diff`。其他一些机器学习包，如`Pytorch`，也支持`Auto Diff`。如何使用`Auto Diff`实现**协同过滤算法**。一旦可以自动计算导数，不仅限于**梯度下降**。还可以用于`adam`优化算法。

如果您访问在线购物网站(如淘宝或京东)，正在查看特定商品（例如某本书），网站可能会向您显示“这里有一些与本书类似的其他书籍”之类的信息。网站是如何做到这一点的？当您查看某件商品时，它会向您显示其他类似或相关的商品供您考虑。**协同过滤算法**提供了一种查找相关商品的好方法。学习了每个商品的特征{% mathjax %}x^{(i)}{% endmathjax %}。当使用该算法自动学习特征{% mathjax %}x^{(i)}{% endmathjax %}时，查看单个特征{% mathjax %}x_1、x_2、x_3{% endmathjax %}，你会发现它们很难解释。很难学习特征{% mathjax %}x_1{% endmathjax %}是一部动作片，{% mathjax %}x_2{% endmathjax %}是一部外国电影等等。将这些特征集合起来，确实传递了这部电影的一些信息。给定项目{% mathjax %}i{% endmathjax %}的特征{% mathjax %}x^{(i)}{% endmathjax %}，如果你想找到其他项目，比如与电影{% mathjax %}i{% endmathjax %}相关的其他电影，那么你可以尝试找到具有与{% mathjax %}x^{(i)}{% endmathjax %}相似的特征{% mathjax %}x^{(k)}{% endmathjax %}的项目{% mathjax %}k{% endmathjax %}。具体来说，给定一个特征向量{% mathjax %}x^{(k)}{% endmathjax %}，确定与特征{% mathjax %}x^{(i)}{% endmathjax %}相似的项目的方法如下：{% mathjax %}\sum\limits_{l=1}^n (x_l^{(k)} - x_l^{(i)})^2{% endmathjax %}。在数学中，这两个向量{% mathjax %}x^{(k)}{% endmathjax %}和{% mathjax %}x^{(i)}{% endmathjax %}之间的平方距离可以写成如下形式：{% mathjax %}\|x^{(k)} - x^{(i)}\|^2{% endmathjax %}。如果找到了{% mathjax %}x^{(k)}{% endmathjax %}，确定与特征{% mathjax %}x^{(i)}{% endmathjax %}相似的项目的方法如下：{% mathjax %}\sum\limits_{l=1}^n (x_l^{(k)} - x_l^{(i)})^2{% endmathjax %}。在数学中，这两个向量{% mathjax %}x^{(k)}{% endmathjax %}和{% mathjax %}x^{(i)}{% endmathjax %}之间距离最小的一部电影，而且还找到了特征向量最相似的`5`个或`10`个电影，那么您最终会找到与项目{% mathjax %}x^{(i)}{% endmathjax %}相关的`5`个或`10`个项目。

如果你正在构建一个网站，希望帮助用户找到与他们正在查看的特定产品相关的产品，那么这将是一个不错的方法，因为特征{% mathjax %}x^{(i)}{% endmathjax %}可以了解项目{% mathjax %}i{% endmathjax %}的含义，具有类似特征的其他项目{% mathjax %}x^{(k)}{% endmathjax %}将与项目{% mathjax %}i{% endmathjax %}相似。**协同过滤**的一些局限性。在**协同过滤**中，有一组项目，用户对一些项目子集进行了评分。其中一个缺点是它在冷启动问题上表现不佳。例如，如果你的目录中有一个新项目，比如说某人刚刚发布了一部新电影，几乎没有人对该电影进行过评分，如果之前很少有用户对其进行过评分，如何对新项目进行排名？同样，对于只对几个项目进行过评分的新用户，我们如何确保向他们展示一些合理的内容？对很少进行项目评分的用户展示他们可能感兴趣的东西。这被称为**冷启动问题**，因为当有一个新项目时，很少有用户进行评分，或者有一个很少对项目进行评分的新用户，那么该项目或该用户的**协同过滤**结果可能不是很准确。**协同过滤**的第二个限制是它没有提供一种很自然的方式来使用有关项目或用户的辅助信息或附加信息。例如，对于目录中的某部电影，您可能知道该电影的类型、主演、制片厂、预算是多少等等。您可能拥有关于某部电影的大量特征。对于单个用户，您可能了解他们的人口统计信息，例如年龄、性别、位置。他们会表达偏好，例如，如果他们告诉你他们喜欢某些类型的电影，但不喜欢其他类型的电影，或者如果您知道用户的`IP`地址，这可以告诉您很多有关用户位置的信息，了解用户的位置也可能有助于您猜测用户可能对什么感兴趣，或者是否知道用户是通过移动设备还是桌面设备访问您的网站，或者是否知道他们正在使用哪种`Web`浏览器。所有这些都是可以获得的线索。它们可以与用户的偏好惊人地相关。尽管**协同过滤**（多个用户对多个项目进行评分）是一组非常强大的算法，但它也有一些局限性。

#### 内容过滤

接下来讲解第二种**推荐系统**(`Recommendation system`)，即基于**内容**的过滤算法。首先，将**协同过滤方法**与**基于内容的过滤方法**进行对比。对于**协同过滤**，一般会根据给出相似评分的用户的评分推荐商品。一些用户对某些商品给出了评分，算法会利用这些评分推荐新商品。相比之下，基于内容的过滤方法将根据用户的特征和商品的特征来推荐商品。换句话说，它需要每个用户的一些特征以及每个商品的一些特征，并使用这些特征来尝试确定哪些商品和用户可能彼此匹配。使用**基于内容的过滤算法**。**基于内容的过滤**将继续使用{% mathjax %}r^{(i,j)}{% endmathjax %}来表示用户{% mathjax %}j{% endmathjax %}是否对项目{% mathjax %}i{% endmathjax %}进行了评分，并继续使用{% mathjax %}y^{(i,j)}{% endmathjax %}来表示用户{% mathjax %}j{% endmathjax %}对项目{% mathjax %}i{% endmathjax %}的评分。但基于内容的过滤的关键在于，能够充分利用用户和项目的特征来找到比**协同过滤方法**更好的匹配。让我们看看它是如何工作的？以下是电影推荐的示例。你知道用户的年龄，用户的性别，用户的国家/地区。如果世界上大约有`200`个国家/地区，那么也可以有一个具有大约`200`个可能值的**独热特征**。你还可以查看用户过去的行为来构建此特征向量。例如，如果查看目录中的前`1000`部电影，您可能会构建`1000`个特征。如果有一组电影，并且知道每部电影属于哪种类型，那么用户给出的每个类型的平均评分是多少。在用户评分的所有爱情电影中，平均评分是多少？在用户评分的所有动作电影中，平均评分是多少？所有其他类型也是如此。这个特征的一个有趣之处在于它实际上取决于用户给出的评分。但这并没有错。构建一个取决于用户评分的特征向量是一种完全可以开发特征向量来描述该用户的方法。有了这些特征，你就可以得到一个特征向量{% mathjax %}x_u^{(j)}{% endmathjax %}。同样，你也可以为每个项目的每个电影想出一组特征，例如电影的年份是多少？已知电影的类型是什么？如果电影有评论家的评论，你可以构建一个或多个特征来捕捉评论家对电影的评价。或者，你实际上可以采用电影的用户评分来构建一个特征，比如这部电影的平均评分。这个特征取决于用户给出的评分。你可以为给定的电影构建一个特征，该特征取决于电影收到的评分，你也可以拥有每个国家/地区的平均评分或每个用户的平均评分。对于每部电影，构建一个特征向量，{% mathjax %}x_m^{(i)}{% endmathjax %}，上标{% mathjax %}i{% endmathjax %}代表电影。给定这样的特征，任务就是给定的电影{% mathjax %}i{% endmathjax %}是否与用户{% mathjax %}j{% endmathjax %}匹配。请注意，用户特征和电影特征的大小可能有很大差异。例如，用户特征可能是`1500`个，而电影特征可能只有`50`个。在**基于内容的过滤**中，我们将开发一种匹配用户和电影的学习算法。之前，将用户{% mathjax %}j{% endmathjax %}对电影{% mathjax %}i{% endmathjax %}的评分预测为：{% mathjax %}w^{(j)}\cdot x^{(i)} + b^{(j)}{% endmathjax %}。为了开发**基于内容的过滤**，这里将去掉{% mathjax %}b^{(j)}{% endmathjax %}。这里不会用{% mathjax %}w^{(j)}{% endmathjax %}表示用户{% mathjax %}j{% endmathjax %}，用{% mathjax %}v^{(j)}_u{% endmathjax %}来代替{% mathjax %}w^{(j)}{% endmathjax %}。这里的{% mathjax %}v{% endmathjax %}代表一个向量。这里的{% mathjax %}u{% endmathjax %}下标代表用户。用{% mathjax %}v_m^{(i)}{% endmathjax %}代替{% mathjax %}x^{(i)}{% endmathjax %}，这里的下标{% mathjax %}m{% endmathjax %}来代表用户，上标{% mathjax %}i{% endmathjax %}代表电影。{% mathjax %}v_u^{(j)}{% endmathjax %}是一个向量，是根据用户{% mathjax %}j{% endmathjax %}的特征计算出的列表，{% mathjax %}v_m^{(i)}{% endmathjax %}是根据电影{% mathjax %}i{% endmathjax %}特征计算出的列表。如果能够选择出合适的向量{% mathjax %}v_m^{(i)}, v_u^{(j)}{% endmathjax %}，那么这两个向量之间的点积能够很好地预测用户{% mathjax %}j{% endmathjax %}对电影{% mathjax %}i{% endmathjax %}的评分。如果{% mathjax %}v_u = \begin{bmatrix}4.9 \\0.1 \\ \vdots \\3.0 \end{bmatrix}{% endmathjax %}能够捕捉用户的偏好。第一个数字捕捉他们有多喜欢爱情电影。第二个数字捕捉他们有多喜欢动作电影等等。然后 ，电影向量是{% mathjax %}v_m = \begin{bmatrix}4.5 \\0.2 \\ \vdots \\3.5 \end{bmatrix}{% endmathjax %}等等，这些数字捕捉这部电影的爱情程度、动作程度等等。然后点积为{% mathjax %}v_u^{(j)} \cdot v_m^{(i)}{% endmathjax %}，即逐元素相乘这些列表然后求和，能够知道这个特定用户对这部电影的喜欢程度。如何计算这个向量{% mathjax %}v^{(j)}_u{% endmathjax %}来简洁地表示用户的偏好？同样，给定电影的特征，如何计算{% mathjax %}v^{(i)}_m{% endmathjax %}？请注意，这里的{% mathjax %}v{% endmathjax %}必须具有相同的大小。如果你想对{% mathjax %}v_u{% endmathjax %}和{% mathjax %}v_m{% endmathjax %}进行点积，那么它们两个必须具有相同的维度，例如两者都是`32`。总结一下，在**协同过滤**中，需要让大量用户对不同的项目进行评分。相比之下，在**基于内容的过滤**中，有用户的特征和项目的特征，希望用一种方法来找到用户和项目之间的良好匹配。我们需要计算这些向量，{% mathjax %}v_u{% endmathjax %}代表用户，{% mathjax %}v_m{% endmathjax %}代表电影中的项目，然后对它们计算点积来找到良好的匹配。

使用**深度学习**实现**基于内容的过滤算法**是一个好方法。给定一个描述用户的特征向量，例如年龄、性别、国家等，必须计算向量{% mathjax %}v_u{% endmathjax %}，同样，给定一个描述电影的向量，例如上映年份、电影中的明星等，必须计算向量{% mathjax %}v_m{% endmathjax %}。为了计算向量{% mathjax %}v_u{% endmathjax %}，我们将使用**神经网络**。第一个**神经网络**就是**用户网络**。如下图所示：
{% asset_img ml_2.png %}

它将用户的特征列表{% mathjax %}x_u{% endmathjax %}作为输入，即用户的年龄、性别、国家等。然后使用几个层，比如**密集层**，然后输出描述用户的向量{% mathjax %}v_u{% endmathjax %}。请注意，在这个神经网络中，输出层有`32`个单元，因此{% mathjax %}v_u{% endmathjax %}是`32`个值列表。与之前使用的大多数**神经网络**不同，最后一层不是只有一个单元的层，而是`32`个单元的层。同样，计算电影的向量{% mathjax %}v_m{% endmathjax %}，我们可以建立一个**电影网络**，如下图所示：
{% asset_img ml_3.png %}

该网络以电影的特征作为输入，并通过**神经网络**的几层输出{% mathjax %}v_m{% endmathjax %}，即描述电影的向量。最后，我们将预测该用户对该电影的评分，即点积{% mathjax %}v_u\cdot v_m{% endmathjax %}，**用户网络**和**电影网络**可以有不同数量的**隐藏层**和每个**隐藏层**都具有不同数量的单元。所有**输出层**都具有相同的尺寸和维度。如果我们有**二元标签**，用{% mathjax %}y{% endmathjax %}表示用户喜欢或偏爱某个项目，也可以修改此算法的输出。除了{% mathjax %}v_u\cdot v_m{% endmathjax %}，还可以使用`S`型函数，并用它来预测{% mathjax %}y^{(i,j)} = 1{% endmathjax %}的概率。如果我们想强调这是用户{% mathjax %}j{% endmathjax %}对电影{% mathjax %}i{% endmathjax %}的预测，可以在这里添加上标{% mathjax %}i{% endmathjax %}和{% mathjax %}j{% endmathjax %}。将**用户网络**和**电影网络**绘制为两个独立的神经网络。还可以将它们绘制在一个图中，就像它是一个**神经网络**一样。如下图所示：
{% asset_img ml_4.png %}

在上图中的上半部分，我们有**用户网络**，它的输入是{% mathjax %}x_u{% endmathjax %}并最终计算{% mathjax %}v_u{% endmathjax %}。在上图中的下半部分，我们有**电影网络**，它的输入是{% mathjax %}x_m{% endmathjax %}并最终计算{% mathjax %}v_m{% endmathjax %}，然后将这两个向量点积{% mathjax %}v_u\cdot v_m{% endmathjax %}。这里的点代表**点积**。现在，这个模型有很多参数。**神经网络**的每一层都有一组常见的神经网络参数。如何训练**用户网络**和**电影网络**的参数？我们要做的就是构建一个成本函数{% mathjax %}\mathbf{J}{% endmathjax %}，它与**协同过滤**中看到的**成本函数**非常相似，假设有一些用户对某些电影进行了评分的数据集，其成本函数为：{% mathjax %}\mathbf{J} = \sum\limits_{(i,j):r(i,j) = 1}(v^{(j)}_u\cdot v^{(i)}_m - y^{(i,j)})^2 + \text{NN regularization term}{% endmathjax %}。我们的目标是训练**神经网络**的参数，根据{% mathjax %}v_u{% endmathjax %}和 {% mathjax %}v_m{% endmathjax %}对{% mathjax %}y^{(i,j)}{% endmathjax %}的预测效果来判断这两个网络，并且利用成本函数，通过梯度下降来调整**神经网络**的参数，使成本函数{% mathjax %}\mathbf{J}{% endmathjax %}尽可能小。如果你想要正则化这个模型，我们也可以添加**神经网络正则化项**，以激励**神经网络**保持其参数值较小。在训练完这个模型后，可以用它来寻找相似的商品。这类似于我们在**协同过滤**特征中看到的，它也能帮助你找到相似的商品。{% mathjax %}v^{(j)}_u{% endmathjax %}是一个长度为`32`的向量，它描述了具有这些特征{% mathjax %}x^{(j)}_u{% endmathjax %}的用户。{% mathjax %}v^{(i)}_m{% endmathjax %}是一个长度为`32`的向量，它描述了一部具有这些特征{% mathjax %}x^{(i)}_m{% endmathjax %}的电影。给定一部电影，如果想找到与之相似的其他电影怎么办？这个向量{% mathjax %}v^{(i)}_m{% endmathjax %}描述了电影{% mathjax %}i{% endmathjax %}。如果你想找到与之相似的其他电影，那么可以寻找其他电影 {% mathjax %}k{% endmathjax %}，使得描述电影{% mathjax %}k{% endmathjax %}的向量与描述电影{% mathjax %}i{% endmathjax %}的向量之间的距离{% mathjax %}\min \|v^{(k)}_m - v^{(i)}_m\|^2{% endmathjax %}，即最小的平方距离。这个表达式的作用类似于在**协同过滤**中的作用，使用这种方法，还可以找到与给定项目相似的项目。你可以提前计算与给定电影相似的电影，这一点非常重要。这就是如何使用**深度学习**来构建**基于内容的过滤算法**。神经网络的一个好处是，更容易将多个**神经网络**组合在一起，使它们协同工作以构建更大的系统。我们可以将**用户网络**和**电影网络**组合在一起，然后输出的内积。这种将两个神经网络组合在一起的能力是提出更复杂的架构的方式，这种架构非常强大。

