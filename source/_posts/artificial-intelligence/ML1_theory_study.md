---
title: 机器学习(ML)(一) — 探析
date: 2024-08-22 18:00:11
tags:
  - AI
categories:
  - 人工智能
mathjax:
  tex:
    tags: 'ams'
  svg:
    exFactor: 0.03
---

#### 介绍

**机器学习**如今正在创造巨大的经济价值。我认为，当今机器学习创造的经济价值的`99%`是通过一种机器学习实现的，这种机器学习被称为**监督学习**。
<!-- more -->

#### 监督学习

**监督机器学习**是指学习`x`到`y`或输入到输出映射的算法。让我们看一些例子。如果你想制造一辆自动驾驶汽车，学习算法会将图像和来自其他传感器（如雷达或其他东西）的一些信息作为输入，然后尝试输出其他汽车的位置，以便你的自动驾驶汽车可以安全地绕过其他汽车。或者以制造业为例。你可以让学习算法将制造的产品图片作为输入，比如刚从生产线上下来的手机，然后让学习算法输出产品中是否有划痕、凹痕或其他缺陷。这称为**视觉检查**，它可以帮助制造商减少或防止产品出现缺陷。在所有这些应用中，你首先会使用输入`x`和正确答案的示例（即标签`y`）来训练你的模型。模型从这些输入、输出或`x`和`y`对中学习之后，它们就可以采用全新的输入`x`（它从未见过的东西），并尝试生成相应的输出`y`。让我们更深入地研究一个具体的例子。假设你想根据房子的大小来预测房价。你收集了一些数据，假设你绘制了数据，它看起来像这样。这里的横轴是房子的面积（以平方英尺为单位）。纵轴上是房价，以千美元为单位。有了这些数据，假设一个朋友想知道`750`平方英尺的房子的价格。学习算法可以如何帮助你？学习算法可以做的一件事就是，对于数据的直线，读取直线，看起来你朋友的房子可以卖到大约`15`万美元。但**拟合直线**并不是唯一可以使用的学习算法。还有其他算法可以更好地适用于此应用。例如，路由和拟合直线后，你可能会决定最好**拟合曲线**，即比直线稍微复杂一些的函数。如果你这样做并在这里做出预测，那么看起来，你朋友的房子可以卖到接近`20`万美元。因为我们给算法提供了一个数据集，其中给出了所谓的正确答案，即地块上每栋房子的标签或正确价格`y`。学习算法的任务是产生更多这样的正确答案，具体来说，预测房屋的价格。这就是为什么这是监督学习。这种房价预测是一种特殊的监督学习，称为**回归**，意思是指从无限多个可能的数字中预测一个数字。还有第二种监督学习问题，那就是**分类**问题。
{% asset_img ml_1.png %}

**监督学习算法**可以学习预测输入、输出或`X`到`Y`的映射。**回归算法**，它是一种**监督学习算法**，可以学习从无限多个可能的数字中预测数字。**监督学习算法**的第二种类型称为**分类算法**。以乳腺癌检测为例，这是一个**分类**问题。假设您正在构建一个机器学习系统，以便医生可以使用诊断工具来检测乳腺癌。因为早期检测可能会挽救患者的生命。使用患者的医疗记录，您的机器学习系统会尝试确定肿块是恶性的（即癌性）还是危险的。或者，如果该肿瘤或肿块是良性的，意味着它只是一个肿块，不是癌性的，这不是很危险吗？这些肿瘤被标记为良性（在本例中我会用`0`表示）或恶性（在本例中我会用`1`表示）。然后你可以在这样的图表上绘制你的数据，其中横轴代表肿瘤的大小，纵轴只取两个值`0`或`1`，具体取决于肿瘤是良性的还是恶性的。这与回归不同的一个原因是我们只预测少数可能的输出。在这种情况下，两个可能的输出是`0`或`1`，即良性或恶性。这不同于回归，回归预测任何数字，即无限多个可能的数字中的数字。因此，只有两种可能的输出就是分类。因为在这个例子中只有两种可能的输出，所以你也可以将该数据集绘制在一条线上。现在，我将使用两个不同的符号来表示类别，使用圆圈表示良性示例，使用十字表示恶性示例。如果新患者前来接受诊断，并且他们有这种大小的肿块，那么问题是，您的系统会将此肿瘤归类为良性还是恶性？事实证明，在分类问题中，您还可以拥有两个以上的可能输出类别。也许您的学习算法可以在被诊断为恶性时输出多种类型的癌症诊断。因此，我们将两种不同类型的癌症称为`1`型和`2`型。在这种情况下，平均值将有三种可能的输出类别可以预测。顺便说一下，在分类中，术语输出类别和输出类别经常互换使用。因此，当我提到输出时，我说的类别是同一个意思。总结一下，分类算法预测类别。类别不一定是数字。它可以是非数字的，例如，它可以预测图片是猫还是狗。它可以预测肿瘤是良性还是恶性。类别也可以是数字，如`0、1`或`0、1、2`。但在解释数字时，分类与回归的不同之处在于，**分类预测的是一小组有限的可能输出类别**，如`0、1`和`2`，而不是所有可能的数字，如`0.5`或`1.7`。在我们研究的监督学习示例中，我们只有一个输入值，即肿瘤的大小。但您也可以使用多个输入值来预测输出。这里有一个例子，您不仅知道肿瘤的大小，还知道每个患者的年龄。您的新数据集现在有两个输入，年龄和肿瘤大小。在这个新数据集中，我们将使用圆圈表示肿瘤为良性的患者，使用十字表示肿瘤为恶性的患者。因此，当新患者入院时，医生可以测量患者的肿瘤大小并记录患者的年龄。那么，我们如何预测这个病人的肿瘤是良性的还是恶性的呢？学习算法可能会做的是找到一些边界，将恶性肿瘤与良性肿瘤区分开来。因此，学习算法必须决定如何通过这些数据拟合一条边界线。学习算法找到的边界线将有助于医生进行诊断。在这种情况下，肿瘤更可能是良性的。从这个例子中，我们已经看到了如何使用患者的年龄和肿瘤大小。在其他机器学习问题中，通常需要更多的输入值。比如肿瘤团块的厚度、细胞大小的均匀性、细胞形状的均匀性等等。**监督学习**的两种主要类型是**回归**和**分类**。在回归应用中，如预测房价，学习算法必须从无限多个可能的输出数字中预测数字。而在分类中，学习算法必须对一个类别进行预测，所有类别都是一小组可能的输出。所以你现在知道什么是**监督学习**，包括**回归**和**分类**。

#### 无监督学习

继监督学习之后，机器学习最广泛的形式是**无监督学习**。在分类问题中，每个示例都与一个输出标签`y`相关联，例如良性或恶性，在无监督学习中由极点和十字表示。给定与任何输出标签`y`都不相关的数据，假设您获得了有关患者及其肿瘤大小和患者年龄的数据。但不是肿瘤是良性还是恶性的，因此数据集看起来像右边的这样。我们不需要诊断肿瘤是良性还是恶性，因为我们没有给出任何标签。相反，我们的工作是在数据集中寻找某种结构或模式，或者只是在数据中找到一些有趣的东西。我们称之为**无监督学习**，因为我们不是去监督算法。为了给每个输入提供正确的答案，我们要求我们自己找出什么是有趣的。或者在这个特定的数据集中可能存在什么模式或结构。**无监督学习算法**可能会决定将数据分配给两个不同的组或两个不同的集群。因此，它可能会决定，这里有一个集群，那里有另一个集群或组。这是一种特殊类型的**无监督学习**，称为**聚类算法**。因为它将未标记的数据放入不同的集群中，这被用在许多应用程序中。例如，谷歌新闻中使用了**聚类**，谷歌新闻所做的就是每天查看互联网上数十万篇新闻文章，并将相关故事分组在一起。当天互联网上成千上万的新闻文章，找到提到类似单词的文章并将它们分组到聚类中。这个**聚类算法**可以自己找出哪些词表明某些文章属于同一组。新闻故事太多了，每天对所有使用封面的主题进行这样的操作是不现实的。相反，算法必须在没有监督的情况下自行找出今天的新闻文章集群是什么。这就是为什么这种**聚类算法**是一种无监督学习算法。让我们看看无监督学习应用于聚类遗传或`DNA`数据的例子。这张图片显示了`DNA`微阵列数据的图片，它们看起来像电子表格的微小网格。每个小列代表一个人的遗传或`DNA`活动，例如，这里的整个列来自一个人的`DNA`。另一列是另一个人的，每一行代表一个特定的基因。举个例子，也许这个角色代表影响眼睛颜色的基因，或者这个角色代表影响身高的基因。研究人员甚至发现，一个人是否不喜欢某些蔬菜，如西兰花、球芽甘蓝或芦笋，与遗传有关。所以下次有人问你为什么没吃完沙拉，你可以告诉他们，这可能是`DNA`微种族的遗传。这个想法是测量某些基因在每个人身上的表达程度。所以这些颜色，红色、绿色、灰色等等，显示了不同个体有或没有特定基因活跃的程度。然后你可以运行一个**聚类算法**，将个体分成不同的类别。或者不同类型的人，比如这些个体可能聚在一起，我们就叫这种类型一。这些人被分为第二类，这些人被分为第三类。这是**无监督学习**，因为我们没有提前告诉算法，有第一种人具有某些特征。或者第二种人具有某些特征。相反，我们说的是这里有一堆数据。我不知道不同类型的人是什么，但你能自动在数据中找到结构吗？并且自动找出主要类型的个体，因为我们没有提前给算法正确的答案。这是**无监督学习**，这是第二个例子，许多公司都有庞大的客户信息数据库，有了这些数据。你能自动将客户分组到不同的细分市场中吗，这样你就可以更有效地为客户服务。总结一下**聚类算法**，这是一种**无监督学习算法**，它获取没有标签的数据并尝试自动将它们分组到群集中。

让我们对**无监督学习**进行更正式的定义，并快速了解一下除**聚类**之外的其他一些**无监督学习类型**。在监督学习中，数据同时带有输入`x`和输出标签`y`，而在**无监督学习**中，数据仅带有输入`x`，而没有输出标签`y`，并且算法必须在数据中找到某种结构或某种模式。**无监督学习-聚类算法**，它将相似的数据点分组在一起。还有他两种类型的**无监督学习**。一种称为**异常检测**，用于检测异常事件。这对于金融系统中的**欺诈检测**非常重要，其中异常事件、异常交易可能是欺诈的迹象，并且对于许多其他应用也非常重要。您还将了解**降维**。您可以将大数据集压缩为很小的数据集，同时尽可能少地丢失信息。您还记得垃圾邮件过滤问题。如果您有标记数据，现在将其标记为垃圾邮件或非垃圾邮件，则可以将其视为监督学习问题。第二个例子是新闻报道的例子。您可以使用聚类算法将新闻文章分组在一起。我们将使用**无监督学习**。

#### 回归模型

##### 线性回归模型

**线性回归模型**，将直线拟合到您的数据中。它可能是当今世界上使用最广泛的学习算法。让我们从一个可以使用线性回归的问题开始。假设您想根据房屋大小预测房屋价格。我们将使用美国波特兰市的房屋大小和价格数据集。这里有一个图表，其中横轴是房屋的面积（以平方英尺为单位），纵轴是房屋的价格（以千美元为单位）。让我们继续绘制数据集中各种房屋的数据点。这里的每个数据点，每个小`十`字都是一栋房屋，其大小和最近售出的价格。现在，假设您是波特兰的房地产经纪人，正在帮助客户出售房子。客户问您，您认为这套房子能卖多少钱？这个数据集可能有助于您估算她能卖出的价格。您首先测量房子的大小，结果是房子面积为`1250`平方英尺。您认为这套房子能卖多少钱？您可以这样做，您可以从这个数据集构建一个**线性回归模型**。您的模型将与数据拟合一条直线，可能看起来像这样。如下图所示，根据与数据拟合的直线，您可以看到房子面积为`1250`平方英尺，它将与此处的最佳拟合线相交，如果您将其追踪到左侧的垂直轴，可以看到价格可能在这里，大约`220,000`美元。这就是所谓的监督学习模型的一个例子。
{% asset_img ml_2.png %}

首先通过提供具有正确答案的数据来训练模型，因为你获得了房屋的模型示例，包括房屋大小以及模型应该为每栋房屋预测的价格。也就是说，数据集中给出了每栋房屋的正确答案。这种**线性回归模型**是一种特殊类型的**监督学习模型**。它被称为**回归模型**，因为它将数字预测为输出。任何预测诸如`220,000`或`1.5`或`-33.2`之类的数字的**监督学习模型**都在解决所谓的回归问题。**线性回归**是回归模型的一个例子。但是还有其他模型可以解决回归问题。与**回归模型**相比，另一种最常见的监督学习模型称为**分类模型**。**分类模型**预测类别或离散类别，例如预测一张图片是猫还是狗，或者如果给定医疗记录，它必须预测患者是否患有特定疾病。分类和回归之间的区别，在分类中，只有少数可能的输出。如果您的模型识别猫和狗，则有两个可能的输出。或者，也许您试图识别患者的`10`种可能的医疗疾病中的任何一种，因此存在一组离散的、有限的可能输出。我们称之为**分类问题**，而在回归中，模型可以输出无限多的可能数字。除了将这些数据可视化为左侧的图表之外，还有另一种有用的数据查看方式，即右侧的数据表。数据包含一组输入。这将是房子的大小，即此处的这一列。它也有输出。您要预测价格，也就是这里的这一列。请注意，横轴和纵轴分别对应这两列，即面积和价格。如果此数据表中有 47 行，则左侧的图表上有 47 个小十字，每个十字对应表格的一行。例如，表格的第一行是一栋房子，面积为`2,104`平方英尺，这栋房子的售价为`400,000`美元，大约是这个数字。表格的第一行被绘制为此处的。请注意，您客户的房子不在此数据集中，因为它尚未出售，所以没人知道价格是多少。要预测客户房屋的价格，您首先要训练模型从训练集中学习，然后该模型可以预测客户房屋的价格。在机器学习中，表示此处输入的标准符号是小写`x`，我们称之为输入变量，也称为**特征**或**输入特征**。例如，对于训练集中的第一栋房子，`x`是房子的大小，因此`x`等于`2,104`。表示您要预测的输出变量（有时也称为**目标变量**）的标准符号是小写`y`。这里，`y`是房价，对于第一个训练样本，它等于`400`，所以`y`等于`400`。数据集中每栋房子占一行，在这个训练集中，有`47`行，每行代表一个不同的训练样本。我们将使用小写`m`来表示训练样本的总数，因此这里`m`等于`47`。对于第一个训练样本`(x, y)`，这对数字是`(2104, 400)`。现在我们有很多不同的训练样本。为了引用特定的训练样本，这将对应于左侧表格中的特定行，我将使用{% mathjax %}(x^{(i)},y^{(i)}){% endmathjax %}来表示。上标告诉我们这是第`i`个训练示例，例如第一个、第二个或第三个直到第`47`个训练示例。这里的`i`指的是表中的特定行。例如，这是第一个示例，当训练集中的{% mathjax %}i=1{% endmathjax %} 时，{% mathjax %}x^{(1)} = 2104,y^{(1)} = 400{% endmathjax %}。请注意，括号中的上标`i`不是指数。这个`i`只是训练集的索引，指的是表中的第`i`行。
{% asset_img ml_3.png %}

**监督学习算法**将输入一个数据集，然后它到底在做什么，输出什么？监督学习中的训练集既包括**输入特征**，例如房屋大小，也包括**输出目标**，例如房屋价格。输出目标是从中学习的模型的正确答案。要训练模型，您需要将训练集（**输入特征**和**输出目标**）输入到您的学习算法中。然后**监督学习算法**将产生一些函数。我们将这个函数写成小写的{% mathjax %}f{% endmathjax %}，其中{% mathjax %}f{% endmathjax %}代表函数。从历史上看，这个函数曾经被称为**假设**。{% mathjax %}f{% endmathjax %}的工作是获取新的输入`x`和输出，我将其称为{% mathjax %}\hat{y}{% endmathjax %}，它的写法就像变量`y`顶部有一个小帽子符号。在机器学习中，{% mathjax %}\hat{y}{% endmathjax %}是`y`的估计值或预测值。函数{% mathjax %}f{% endmathjax %}称为模型。{% mathjax %}x{% endmathjax %}`称为输入或输入特征，模型的输出是预测值{% mathjax %}\hat{y}{% endmathjax %}。模型的预测是{% mathjax %}y{% endmathjax %}的估计值。当符号只是字母{% mathjax %}y{% endmathjax %}时，它指的是**目标**，即训练集中的实际真实值。相反，{% mathjax %}\hat{y}{% endmathjax %}是一个估计值。如果你正在帮助你的客户出售房子，那么，房子的真实价格在他们卖掉之前是未知的。你的模型{% mathjax %}f{% endmathjax %}，给定大小，输出价格，即估计量，即对真实价格的预测。现在，当我们设计学习算法时，一个关键问题是，我们将如何表示函数{% mathjax %}f{% endmathjax %}？或者换句话说，我们将使用什么数学公式来计算{% mathjax %}f{% endmathjax %}？假设，让我们坚持认为{% mathjax %}f{% endmathjax %}是一条直线。您的函数可以写成{% mathjax %}f(x) = wx + b{% endmathjax %}。但现在，只知道{% mathjax %}w{% endmathjax %}和{% mathjax %}b{% endmathjax %}是数字，而{% mathjax %}w{% endmathjax %}和{% mathjax %}b{% endmathjax %}选择的值将根据输入特征{% mathjax %}x{% endmathjax %}预测{% mathjax %}\hat{y}{% endmathjax %}。意味着{% mathjax %}f{% endmathjax %}是一个以{% mathjax %}x{% endmathjax %}为输入的函数，并且根据{% mathjax %}w{% endmathjax %}和{% mathjax %}b{% endmathjax %}的值，{% mathjax %}f{% endmathjax %}将输出预测{% mathjax %}\hat{y}{% endmathjax %}的某个值。

让我们在图表上绘制训练集，其中输入特征 {% mathjax %}x{% endmathjax %}在横轴上，输出目标{% mathjax %}y{% endmathjax %}在纵轴上。请记住，算法会从这些数据中学习并生成最佳拟合线，例如这里的这条线。这条直线是线性函数{% mathjax %}f(x) = wx + b{% endmathjax %}。这个函数的作用是，它使用{% mathjax %}x{% endmathjax %}的线性函数预测{% mathjax %}y{% endmathjax %}的值。你可能会问，为什么我们要选择线性函数，线性函数只是直线的另一种叫法，而不是一些非线性函数，比如曲线或抛物线？有时候你也想拟合更复杂的非线性函数。但由于这个线性函数相对简单易用，让我们以直线为基础，最终帮助你得到更复杂的非线性模型。这个特定的模型有一个名字，叫做**线性回归**。更具体地说，这是一个变量的**线性回归**，其中短语“一个变量”表示只有一个输入变量或特征{% mathjax %}x{% endmathjax %}，即房子的大小。一个输入变量的线性模型的另一个名称是**单变量线性回归**。单变量只是表示一个变量的另一种叫法。

##### 成本函数

为了实现**线性回归**，第一个关键步骤是先定义一个称为**成本函数**的东西。**成本函数**将告诉我们模型的表现如何，以便我们可以尝试让它做得更好。回想一下，你有一个包含输入特征{% mathjax %}x{% endmathjax %}和输出目标{% mathjax %}y{% endmathjax %}的训练集。**线性函数**{% mathjax %}f(x) = wx + b{% endmathjax %}将用来拟合这个训练集的模型。{% mathjax %}w{% endmathjax %}和{% mathjax %}b{% endmathjax %}被称为**模型的参数**。在机器学习中，模型的参数是可以在训练期间调整以改进模型的变量。有时你也会听到参数{% mathjax %}w{% endmathjax %}和{% mathjax %}b{% endmathjax %}被称为**系数**或**权重**。现在让我们看看这些参数{% mathjax %}w{% endmathjax %}和{% mathjax %}b{% endmathjax %}的作用。你为{% mathjax %}w{% endmathjax %}和{% mathjax %}b{% endmathjax %}选择的值，你会得到不同的函数{% mathjax %}f(x){% endmathjax %}，这会在图表上生成不同的线。当{% mathjax %}w=0{% endmathjax %}且{% mathjax %}b=1.5{% endmathjax %}时，{% mathjax %}f{% endmathjax %}看起来就像这条水平线。在这种情况下，{% mathjax %}f(x) = 0x + 1.5{% endmathjax %}，因此{% mathjax %}f{% endmathjax %}始终是一个常数值。它始终预测{% mathjax %}y{% endmathjax %}的估计值为`1.5`。{% mathjax %}y{% endmathjax %}始终等于{% mathjax %}b{% endmathjax %}，此处{% mathjax %}b{% endmathjax %}也称为{% mathjax %}y{% endmathjax %}**截距**，因为这是它与该图上的垂直轴或{% mathjax %}y{% endmathjax %}轴的交点。作为第二个示例，如果{% mathjax %}w=0.5{% endmathjax %}且{% mathjax %}b=0{% endmathjax %}，则{% mathjax %}f(x) = 0.5x{% endmathjax %}。当{% mathjax %}x{% endmathjax %}为`0`时，预测值也为`0`；当{% mathjax %}x{% endmathjax %}为`2`时，预测值是`1`。您会得到一条如下图所示的直线，请注意斜率为`1/2`。{% mathjax %}w{% endmathjax %}的值给出直线的斜率为`1/2`。最后，如果{% mathjax %}w=0.5{% endmathjax %}且{% mathjax %}b=1{% endmathjax %}，则{% mathjax %}f(x) = 0.5x + 1{% endmathjax %}；当{% mathjax %}x=0{% endmathjax %}时，{% mathjax %}f(0) = 1{% endmathjax %}，因此直线与纵轴相交于{% mathjax %}b{% endmathjax %}，即{% mathjax %}y{% endmathjax %}**截距**。同样，当{% mathjax %}x = 2{% endmathjax %}时，{% mathjax %}f(x) = 2{% endmathjax %}，因此直线如下所示。
{% asset_img ml_4.png %}

同样，此斜率为`1/2`，因此{% mathjax %}w{% endmathjax %}的值给出斜率为`1/2`。您有一个如下所示的训练集。对于**线性回归**，您要做的就是选择参数{% mathjax %}w{% endmathjax %}和 {% mathjax %}b{% endmathjax %}的值，以便您从函数{% mathjax %}f{% endmathjax %}获得的直线能够很好地拟合数据。例如，可能像这里显示的这条线。当我看到该线在视觉上与数据拟合时，这意味着与其他不太接近这些点的线相比，由{% mathjax %}f{% endmathjax %}定义的线大致穿过或接近训练示例。像此处的这个点的训练示例由{% mathjax %}x^{(i)}、y^{(i)}{% endmathjax %}定义，其中{% mathjax %}y{% endmathjax %}是目标。对于给定的输入{% mathjax %}x^{(i)}{% endmathjax %}，函数{% mathjax %}f{% endmathjax %}会对{% mathjax %}y{% endmathjax %}做出预测值，它预测{% mathjax %}y{% endmathjax %}的值是此处显示的{% mathjax %}\hat{y}{% endmathjax %}。对于我们选择的模型，{% mathjax %}f(x^i) = wx^{(i)} +b{% endmathjax %}。现在的问题是如何找到{% mathjax %}w{% endmathjax %}和{% mathjax %}b{% endmathjax %}的值，使得对于许多或所有训练示例{% mathjax %}x^{(i)}、y^{(i)}{% endmathjax %}，预测{% mathjax %}\hat{y}^{(i)}{% endmathjax %}接近真实目标{% mathjax %}y^{(i)}{% endmathjax %}。要回答这个问题，让我们首先看一下如何衡量一条线与训练数据的**拟合程度**。要做到这一点，我们将构建一个**成本函数**。**成本函数**取预测{% mathjax %}\hat{y}{% endmathjax %}，并通过{% mathjax %}\hat{y} - y{% endmathjax %}将其与目标 {% mathjax %}y{% endmathjax %}进行比较。这个差异称为**误差**，我们**测量预测与目标的差距**。

接下来，让我们计算这个**误差**的平方。此外，我们将要为训练集中的不同训练示例{% mathjax %}i{% endmathjax %}计算这个项。在测量误差时，例如{% mathjax %}i{% endmathjax %}，我们将计算这个平方误差项。最后，我们要测量整个训练集的误差。具体来说，将平方误差加起来。我们从{% mathjax %}i{% endmathjax %}相加，等于{% mathjax %}1,2,3,\ldots,n{% endmathjax %}，记住{% mathjax %}m{% endmathjax %}是训练示例的数量，对于这个数据集是`47`。如果我们有更多的训练示例，{% mathjax %}m{% endmathjax %}就会更大，你的**成本函数**就会计算出更大的数字。这是对更多示例求和。为了建立一个不会随着训练集大小的增加而自动变大的**成本函数**，按照惯例，我们将计算**平均平方误差**而不是**总平方误差**，我们通过像这样除以{% mathjax %}m{% endmathjax %}来实现。机器学习人员使用的**成本函数**实际上是除以`2`乘以{% mathjax %}m{% endmathjax %}。额外的除以`2`只是为了让我们后面的一些计算看起来更简洁，但**成本函数**无论你是否包括这个除以`2`的值，{% mathjax %}n{% endmathjax %}仍然有效。这里的表达式就是**成本函数**，我们将用{% mathjax %}\mathbf{J}(w,b) = \frac{1}{2m}\sum_{i=1}^m(\hat{y}^{(i)} - y^{(i)})^2{% endmathjax %}来表示**成本函数**。这也被称为**平方误差成本函数**，之所以这样称呼，是因为你要对这些误差项取平方。在机器学习中，不同的人会针对不同的应用使用不同的**成本函数**，但**平方误差成本函数**是迄今为止线性回归最常用的**成本函数**，就此而言，对于所有**回归**问题，它似乎在许多应用中都能给出良好的结果。预测{% mathjax %}\hat{y} = f(x){% endmathjax %}。我们可以将成本函数{% mathjax %}\mathbf{J}{% endmathjax %}重写为{% mathjax %}\mathbf{J}(w,b) = \frac{1}{2m}\sum_{i=1}^m(f_{w,b}(x^{(i)}) - y^{(i)})^2{% endmathjax %}。最终，我们将要找到使**成本函数**变小的{% mathjax %}w{% endmathjax %}和{% mathjax %}b{% endmathjax %}的值。
{% asset_img ml_5.png %}
