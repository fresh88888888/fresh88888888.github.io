---
title: 机器学习(ML)(三) — 探析
date: 2024-08-28 12:15:11
tags:
  - AI
categories:
  - 人工智能
mathjax:
  tex:
    tags: 'ams'
  svg:
    exFactor: 0.03
---

#### 逻辑回归

**线性回归**不是解决分类问题的算法。另一种称为**逻辑回归**的算法。它是当今最流行和使用最广泛的学习算法之一。确定电子邮件是否为垃圾邮件的示例。您要输出的答案要么是“否”，要么是“是”。能否判断这笔交易是否是欺诈性的、试图将肿瘤分类为恶性还是非恶性。在每个问题中，你想要预测的变量只能是两个可能值中的一个。否或是。这种只有两个可能输出的分类问题称为**二元分类**。**二元**这个词指的是只有两个可能的类或两个可能的类别。它们基本上是同一个意思。
<!-- more -->

按照惯例，我们可以用几种常见的方式来指代这两个类或类别。我们经常将其指定为否或是，或者有时等同于假或真，或者非常普遍地使用`0`或`1`。按照计算机科学中的常见惯例，`0`表示假，`1`表示真。常用的方式是将假或`0`类称为**负示例**，将真或`1`类称为**正示例**。例如，对于垃圾邮件分类，非垃圾邮件的电子邮件可能被称为负类。因为问题的输出是垃圾邮件。输出为否或`0`。相反，包含垃圾邮件的电子邮件可能被称为正类。为了明确起见，负和正不一定意味着坏与好或邪恶与好。只是使用负示例和正示例来传达或零或假与存在或真或`1`可能正在寻找的某物的概念。在非垃圾邮件和垃圾邮件之间。您将哪个称为假或`0`，将哪个称为真或`1`有点随意。通常两种选择都可以。那么你如何构建分类算法呢？

这是一个用于对肿瘤是否为恶性进行分类的训练集示例。`1`类，阳性类别，`0`类，阴性类别。在横轴上绘制了肿瘤大小，在纵轴上绘制了标签`y`。**线性回归**并尝试将直线拟合到数据中。线性回归不仅预测`0`和`1`的值。而是`0`和`1`之间的所有数字，甚至小于`0`或大于`1`。但在这里我们想要预测类别。你可以尝试选择一个阈值，比如`0.5`。如果模型输出的值低于`0.5`，那么你就可以预测{% mathjax %}y=0{% endmathjax %}。如果模型输出{% mathjax %}y\geq 0.6 {% endmathjax %}，那么预测{% mathjax %}y=1{% endmathjax %}。请注意，这个阈值{% mathjax %}0.5{% endmathjax %}与最佳拟合直线相交。所以如果你在这里画一条垂直线，左边的所有内容最终都会预测{% mathjax %}y=0{% endmathjax %}。而右边的所有内容最终都会预测{% mathjax %}y=1{% endmathjax %}。对于这个特定的数据集，**线性回归**可以做一些合理的工作。但现在让我们看看如果你的数据集有一个更多的训练示例会发生什么。让我们也延伸一下横轴。请注意，这个训练示例不应该真正改变你对数据点分类的方式。我们刚才画的这条垂直分界线仍然有意义，因为它是小于这个的肿瘤应该被归类为`0`的临界值。大于这个的肿瘤应该被归类为`1`。但是一旦你在右边添加了这个额外的训练示例。**线性回归**的最佳拟合线将像这样移动。如果你继续使用`0.5`的阈值，你现在会注意到这个点左边的所有内容都被预测为`0`（非恶性）。而这个点右边的所有内容都被预测为`1`。这不是我们想要的，因为向右添加这个示例不会改变我们关于如何对恶性肿瘤和良性肿瘤进行分类的任何结论。但是如果你尝试使用**线性回归**来做到这一点，添加不应该改变任何东西的示例。最终，我们学习到的这个分类问题函数。显然，当肿瘤很大时，我们希望算法将其归类为恶性。所以我们刚才看到的是**线性回归**导致最佳拟合线。当我们在右侧添加一个示例时，它会移动。分界线（也称为**决策边界**）会向右移动。

##### 介绍

**逻辑回归**，它可能是世界上使用最广泛的分类算法。让我们继续以分类肿瘤是/否为恶性为例。而之前我们将使用标签`1`或“是”表示正类，以表示恶性肿瘤，使用`0`或“否”和负类表示良性肿瘤。下面数据集的图表，其中横轴是肿瘤大小，纵轴仅取`0`和`1`的值，因为这是一个分类问题。**逻辑回归**是将一条曲线拟合成这样的曲线，即此数据集的`S`形曲线。对于此示例，如果患者患有此大小的肿瘤，则算法将输出`0.7`，表明更接近是恶性和良性的。输出标签{% mathjax %}y{% endmathjax %}绝不会是`0.7`，而只能是`0`或`1`。为了构建**逻辑回归算法**，可以描述这样一个数学函数，称为`S`型函数，有时也称为**逻辑函数**。`S`型函数如下所示。左右两边图表的{% mathjax %}x{% endmathjax %}轴不同。左侧图表的{% mathjax %}x{% endmathjax %}轴表示肿瘤大小。而在右侧图表中，这里有`0`，横轴同时取负值和正值，并将横轴标记为`Z`。在这里显示的只是从`[-3,+3]`的范围。因此，`S`型函数的输出值介于`0`和`1`之间。如果我用{% mathjax %}g(z){% endmathjax %}来表示这个函数，那么{% mathjax %}g(z) = \frac{1}{1 + e^{-z}}{% endmathjax %}。这里的`e`是一个数学常数，其值约为`2.7`。注意，如果{% mathjax %}z=100{% endmathjax %}，那么{% mathjax %}e^{-z} = e^{-100}{% endmathjax %}，这是一个很小的数。因此最终结果是`1`加上一个很小的数，分母基本上非常接近`1`。这就是为什么当{% mathjax %}z{% endmathjax %}很大时，{% mathjax %}g(z) \approx 1{% endmathjax %}。这就是为什么`S`型函数具有这种形状，它从非常接近`0`开始，然后缓慢增加或增长到`1`的值。另外，在`Sigmoid`函数中，当{% mathjax %}z=0{% endmathjax %}时，因此 {% mathjax %}\frac{g}{z} = \frac{1}{1+1} = 0.5{% endmathjax %}，这就是它在`0.5`处通过纵轴的原因。
{% asset_img ml_1.png %}

现在，让我们用它来构建**逻辑回归算法**。我们将分两步进行。在第一步中，直线函数（如线性回归函数）可以定义为{% mathjax %}f_{\vec{w},b}(\vec{x}) = \vec{w}\cdot \vec{x} +b{% endmathjax %}。我们将此值存储在一个变量中，称之为{% mathjax %}z{% endmathjax %}。下一步是获取此{% mathjax %}z{% endmathjax %}值并将其传递给`Sigmoid`函数（也称为**逻辑函数**）{% mathjax %}g{% endmathjax %}。现在，{% mathjax %}g(z) = \frac{1}{1 + e^{-z}}{% endmathjax %}。介于`0`和`1`之间。将这两个方程放在一起，它们会给出`x`的逻辑回归模型`f`，{% mathjax %}z = \vec{w}\cdot\vec{x} + b,\;\; f_{\vec{w},b}(\vec{x}) = g(\vec{w}\cdot\vec{x} + b) = \frac{1}{1+e^{-(\vec{w}\cdot\vec{x} + b)}}{% endmathjax %}。这是**逻辑回归模型**，它的作用是输入特征或特征集{% mathjax %}x{% endmathjax %}，并输出一个介于`0`和`1`之间的数字。
{% asset_img ml_2.png %}

接下来，让我们看看如何解释**逻辑回归**的输出。我们回到肿瘤分类的例子。给定某个输入{% mathjax %}x{% endmathjax %}，输出类别或标签{% mathjax %}y=1{% endmathjax %}的概率。例如，在这个应用中，{% mathjax %}x{% endmathjax %}是肿瘤大小，{% mathjax %}y{% endmathjax %}是`0`或`1`，如果一个病人来就诊，她的肿瘤大小为{% mathjax %}x{% endmathjax %}，如果基于这个输入{% mathjax %}x{% endmathjax %}，模型会加上`0.7`，那么这意味着模型预测认为这个病人的真实标签{% mathjax %}y=1{% endmathjax %}的可能性是`70%`。换句话说，模型告诉我们，它认为病人的肿瘤有`70%`的可能性是恶性的。我们知道 {% mathjax %}y{% endmathjax %}必须是`0`或`1`，所以如果{% mathjax %}y{% endmathjax %}有`70%`的机会是`1`，那么它为`0`的可能性是多少？因此这两个数字相加的概率必须等于`1`或`100%`。这就是为什么如果{% mathjax %}y=1{% endmathjax %}的概率为`0.7`或`70%`，那么它为`0`的概率就必须是`0.3`或`30%`，则{% mathjax %}\mathbf{P}(y=1) + \mathbf{P}(y=0) = 1{% endmathjax %}。有时你会看到这种符号，即给定输入特征{% mathjax %}x{% endmathjax %}和参数{% mathjax %}w{% endmathjax %}和{% mathjax %}b{% endmathjax %}，{% mathjax %}f_{\vec{w},b}(\vec{x}) = \mathbf{P}(y = 1|\vec{x};\vec{w},b){% endmathjax %}。这里的分号只是用来表示{% mathjax %}w{% endmathjax %}和{% mathjax %}b{% endmathjax %}是影响计算的参数，即给定输入特征{% mathjax %}x{% endmathjax %}，{% mathjax %}y=1{% endmathjax %}的概率是多少？

##### 决策边界

