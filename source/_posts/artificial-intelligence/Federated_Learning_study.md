---
title: 联邦学习(Federated Learning)-探析(分布式机器学习)
date: 2024-07-31 11:15:11
tags:
  - AI
categories:
  - 人工智能
mathjax:
  tex:
    tags: 'ams'
  svg:
    exFactor: 0.03
---


#### 介绍

**联邦学习**(`Federated Learning，FL`)是一种**分布式机器学习**技术，旨在保护**数据隐私**的同时，利用分散在多个边缘设备或服务器上的本地数据进行模型训练。该方法由谷歌在`2016`年首次提出，主要用于解决**数据孤岛**和**隐私保护**问题。它本质上是一种保护隐私的多方协作机器学习框架，它允许参与方建立一个联合训练模型，但参与方均在本地维护其底层数据而不将原始数据进行共享。**联邦学习**的核心思想是将模型训练过程分布在多个本地设备上，而不是将所有数据集中到一个中央服务器。每个设备在本地使用其数据进行模型训练，然后将模型参数（而非原始数据）发送到中央服务器进行聚合。通过这种方式，联邦学习能够有效保护**数据隐私**，减少数据传输的风险和成本。
<!-- more -->

**联邦学习**的典型工作流程如下：
- **初始化模型**：中央服务器初始化一个全局模型，并将其发送到各个客户端设备。
- **本地训练**：每个客户端设备在本地数据上训练模型，并更新模型参数。
- **参数上传**：各个客户端将更新后的模型参数发送回中央服务器。
- **参数聚合**：中央服务器对接收到的模型参数进行聚合，更新全局模型。
- **重复迭代**：重复上述步骤，直到模型收敛或达到预期的性能指标。

根据数据**样本空间和特征空间**的分布模式不同，**联邦学习**可以分为以下三类：
- **水平联邦学习**(`Horizontal Federated Learning`)：适用于数据特征重叠较多，但用户重叠较少的情况。数据集按用户维度水平分割，各个参与者的数据特征是对齐的。
- **垂直联邦学习**(`Vertical Federated Learning`)：适用于用户重叠较多，但数据特征重叠较少的情况。数据集按特征维度垂直分割，各个参与者的数据样本是对齐的。
- **联邦迁移学习**(`Federated Transfer Learning`)：适用于数据样本和数据特征重叠都很少的情况，通过迁移学习的方法进行模型训练。

**联邦学习**的优势：
- **数据隐私保护**：数据不离开本地设备，仅传输模型参数，减少了数据泄露的风险。
- **降低数据传输成本**：避免了将大量数据上传到中央服务器的需求，降低了带宽和存储成本。
- **适应性强**：能够处理异构数据，适用于各种分布式数据环境。

**联邦学习**通过在分布式环境中进行模型训练，解决了传统集中式机器学习在**数据隐私**和**数据孤岛**方面的挑战。随着技术的不断发展，**联邦学习**在各种应用场景中的潜力将不断被挖掘和实现。

#### 联邦学习

多个数据拥有方{% mathjax %}\mathbf{F}_i(i = 1,2,\ldots,N){% endmathjax %}的目的是将各自的数据{% mathjax %}\mathbf{D}_i{% endmathjax %}联合，共同训练机器学习模型。传统做法是把数据整合到一起，形成全局数据集{% mathjax %}\mathbf{D} = \{\mathbf{D}_i, i=1,2,\ldots,N\}{% endmathjax %}，并利用{% mathjax %}\mathbf{D}{% endmathjax %}训练生成模型{% mathjax %}\mathbf{M}_{\text{sum}}{% endmathjax %}。然而，该方案因违背数据隐私保护而难以实施。为了解决这一问题**联邦学习**定义如下：联邦学习是指使得这些数据拥有方{% mathjax %}\mathbf{F}_i{% endmathjax %}在不用给出己方数据{% mathjax %}\mathbf{D}_i{% endmathjax %}的情况下可以进行模型训练并得到全局模型{% mathjax %}\mathbf{M}_{\text{fed}}{% endmathjax %}的计算过程，并能够保证模型{% mathjax %}\mathbf{M}_{\text{fed}}{% endmathjax %}的效果{% mathjax %}\mathbf{V}_{\text{fed}}{% endmathjax %}与传统模型{% mathjax %}\mathbf{M}_{\text{sum}}{% endmathjax %}的效果{% mathjax %}\mathbf{V}_{\text{sum}}{% endmathjax %}间的差距足够小，即：
{% mathjax '{"conversion":{"em":14}}' %}
|\mathbf{V}_{\text{fed}} - \mathbf{V}_{\text{sum}}| < \delta
{% endmathjax %}
其中，{% mathjax %}\delta{% endmathjax %}为设定的非负实数。

**水平联邦学习**(`HFL`)适用于联邦学习的参与方的数据有重叠的数据特征，即数据特征在参与方之间是对齐的，但是参与方拥有的数据样本是不同的。
{% asset_img fl_2.png  %}

**垂直联邦学习**(`VFL`)适用于联邦学习参与方的训练数据有重叠的数据样本，即参与方之间的数据样本是对齐的，但是在数据特征上有所不同。
{% asset_img fl_1.png  %}

**联邦迁移学习**(`FTL`)适用于当两个数据集不仅在样本大小上不同，而且在特征空间上也不同时。将中国的一家银行和美国的一家电子商务公司视为两个独立的实体。由于地理限制，两家机构的用户群体重叠很小。然而，由于企业不同，两家公司的特征空间只有一小部分重叠。具体而言，通过应用受限的一般样本集来学习两个特征空间的典型描述，然后将其用于为仅具有单侧特征的样本生成预测结果。`FTL`解决了当前联合学习方法无法解决的困难，这就是为什么它是该领域的一个重要补充。
{% asset_img fl_3.png  %}

#### 联邦学习保护隐私

{% asset_img fl_4.png "十二个人定期合并他们的模型，以协作训练共享模型——无需共享他们的数据" %}

大型数据集使机器学习取得了惊人的突破。但数据往往是个人或专有的，并不适合共享，这使得隐私成为集中式数据收集和模型训练的关键问题和障碍。借助**联邦学习**，可以使用来自多个用户的数据协作训练模型，而无需任何原始数据离开他们的设备。通过联邦学习，这些设备（如手机、手表、汽车、相机、恒温器、太阳能电池板、望远镜等等）还可以实现新技术。想想我们的汽车如何在不泄露我们行踪的情况下为自动驾驶汽车的大规模训练做出贡献。而且这种机器学习方法也可以应用于不同的组织。医院可以利用来自世界各地护理提供者的各种干预措施带来的患者结果来设计更好的治疗计划，而无需共享高度敏感的健康数据。拥有专有药物开发数据的制药公司可以合作建立关于人体如何代谢不同化合物的知识。该框架有潜力实现对复杂系统和流程的大规模聚合和建模，例如城市交通、经济市场、能源使用和发电模式、气候变化和公共卫生问题。最终，**联邦学习**的目标是让人们、公司、管辖区和机构能够协作提出并回答/决策重大问题，同时保持对个人数据的所有权。

##### 联邦学习系统-设计

