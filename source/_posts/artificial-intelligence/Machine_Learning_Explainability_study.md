---
title: 机器学习可解释性
date: 2024-03-05 20:20:32
tags:
  - AI
categories:
  - 人工智能
---

#### 模型见解的用例

许多人说机器学习模型是“黑匣子”，从某种意义上说，它们可以做出很好的预测，但你无法理解这些预测背后的逻辑。这种说法是正确的，因为大多数数据科学家还不知道如何从模型中提取见解。
- 模型认为数据中哪些特征最重要？
- 对于模型的任何单个预测，数据中的每个特征如何影响该特定预测？
- 每个特征如何从大的角度影响模型的预测（考虑大量可能的预测时，其典型效果是什么）？
<!-- more -->

##### 为什么这些见解很有价值？

这些见解有很多用途，包括：
- 调试
- 特征工程
- 指导未来的数据收集
- 为人类决策提供信息
- 建立信任

##### 调试

世界上有大量不可靠、无组织且通常是脏的数据。当您编写预处理代码时，您会添加潜在的错误源。再加上目标泄漏的可能性，在真实的数据科学项目中，在某个时刻出现错误是常态，而不是例外。考虑到错误的频率和潜在的灾难性后果，调试是数据科学中最有价值的技能之一。了解模型发现的模式将帮助您识别这些模式何时与您对现实世界的了解不一致，这通常是追踪错误的第一步。

##### 特征工程

特征工程通常是提高模型精度的最有效方法。特征工程通常涉及使用原始数据或之前创建的特征的转换来重复创建新特征。有时，您可以仅凭对基础主题的直觉来完成此过程。但是，当您拥有数百个原始功能或缺乏有关您正在研究的主题的背景知识时，您将需要更多指导。预测贷款违约的`Kaggle`竞赛给出了一个极端的例子。本次竞赛有数百个原始功能。出于隐私原因，这些功能的名称为 f1、f2、f3，而不是常见的英文名称。这模拟了您对原始数据缺乏直觉的场景。一位竞争对手发现其中两个功能（特别是`f527 - f528`）之间的差异创建了一个非常强大的新功能。包含这种差异作为特征的模型比不包含这种差异的模型要好得多。但是，当您从数百个变量开始时，您会如何考虑创建这个变量呢？`f527`和`f528`是重要的功能，并且它们的作用是紧密相连的。这将引导您考虑这两个变量的转换，并可能找到`f527 - f528`的“黄金特征”。随着越来越多的数据集从数百或数千个原始特征开始，这种方法变得越来越重要。

##### 指导未来的数据收集

您无法控制在线下载的数据集。但许多使用数据科学的企业和组织都有机会扩展他们收集的数据类型。收集新类型的数据可能会很昂贵或不方便，因此他们只有在知道值得时才愿意这样做。基于模型的见解可以让您很好地了解当前拥有的功能的价值，这将帮助您推断哪些新值可能最有帮助。

##### 为人类决策提供信息

有些决策是由模型自动做出的。亚马逊不会让人类（或精灵）匆忙决定每当您访问他们的网站时向您展示什么。但许多重要的决定是由人类做出的。对于这些决策，见解可能比预测更有价值。

##### 建立信任

在没有验证一些基本事实的情况下，许多人不会认为他们可以相信您的模型做出重要决策。考虑到数据错误的频率，这是一项明智的预防措施。在实践中，展示符合他们对问题的一般理解的见解将有助于建立信任，即使是在对数据科学了解甚少的人之间也是如此。

#### 排列重要性

我们可能会问模型的最基本问题之一是：哪些特征对预测影响最大？这个概念称为“特征重要性”。有多种方法可以衡量特征重要性。有些方法回答了上述问题的略有不同的版本。其他方法也有缺陷。与大多数其他方法相比，排列重要性为：
- 计算速度快
- 广泛使用和理解
- 与我们希望特征重要性度量具有的属性一致

##### 他是如何工作的？

排列重要性使用的模型与您迄今为止看到的任何模型都不同，许多人一开始会觉得它令人困惑。因此，我们将从一个示例开始，使其更加具体。考虑具有以下格式的数据：
{% asset_img mlk_1.png %}

我们希望使用`10`岁时的数据来预测一个人`20`岁时的身高。我们的数据包括有用的特征（`10`岁时的身高）、几乎没有预测能力的特征（拥有的袜子）以及我们在本说明中不会重点关注的一些其他特征。排列重要性是在模型拟合后计算的。因此，我们不会更改模型或更改对于给定的身高、袜子数量等值的预测。相反，我们会问以下问题：如果我随机打乱验证数据的单列，而将目标和所有其他列留在原处，这将如何影响现在打乱的数据中的预测准确性？
{% asset_img mlk_2.png %}

随机重新排序单个列会导致预测不太准确，因为结果数据不再对应于现实世界中观察到的任何内容。如果我们对模型严重依赖于预测的列进行洗牌，模型的准确性尤其会受到影响。在这种情况下，调整`10`岁时的身高会导致糟糕的预测。如果我们对拥有的袜子进行洗牌，那么最终的预测就不会受到那么大的影响。

有了这种认识，流程如下：
- 获得经过训练的模型。
- 将值打乱在单列中，使用生成的数据集进行预测。使用这些预测和真实目标值来计算损失函数遭受洗牌的程度。性能下降衡量了您刚刚洗牌的变量的重要性。
- 将数据恢复到原始顺序（撤消步骤`2`中的随机播放）。现在，对数据集中的下一列重复步骤`2`，直到计算出每列的重要性。

##### 代码例子

我们的示例将使用一个模型，根据球队的统计数据来预测足球队是否会获得“最佳球员”获胜者。“游戏最佳球员”奖颁发给游戏中的最佳球员。模型构建不是我们当前的重点，因此下面的单元格加载数据并构建基本模型。
```python
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier

data = pd.read_csv('../input/fifa-2018-match-statistics/FIFA 2018 Statistics.csv')
y = (data['Man of the Match'] == "Yes")  # Convert from string "Yes"/"No" to binary
feature_names = [i for i in data.columns if data[i].dtype in [np.int64]]
X = data[feature_names]
train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)
my_model = RandomForestClassifier(n_estimators=100, random_state=0).fit(train_X, train_y)
```
以下是如何使用 eli5 库计算和显示重要性:
```python
import eli5
from eli5.sklearn import PermutationImportance

perm = PermutationImportance(my_model, random_state=1).fit(val_X, val_y)
eli5.show_weights(perm, feature_names = val_X.columns.tolist())
```
输出结果为：
```bash
Weight	Feature
0.1750 ± 0.0848	Goal Scored(进球数)
0.0500 ± 0.0637	Distance Covered (Kms)
0.0437 ± 0.0637	Yellow Card
0.0187 ± 0.0500	Off-Target
0.0187 ± 0.0637	Free Kicks
0.0187 ± 0.0637	Fouls Committed
0.0125 ± 0.0637	Pass Accuracy %
0.0125 ± 0.0306	Blocked
0.0063 ± 0.0612	Saves
0.0063 ± 0.0250	Ball Possession %
0 ± 0.0000	Red
0 ± 0.0000	Yellow & Red
0.0000 ± 0.0559	On-Target
-0.0063 ± 0.0729	Offsides
-0.0063 ± 0.0919	Corners
-0.0063 ± 0.0250	Goals in PSO
-0.0187 ± 0.0306	Attempts
-0.0500 ± 0.0637	Passes
```

##### 解释排列重要性

顶部的值是最重要的特征，而底部的值最不重要。每行的第一个数字显示随机改组后模型性能下降的程度（在本例中，使用“准确性”作为性能指标）。与数据科学中的大多数事情一样，洗牌列带来的确切性能变化存在一定的随机性。我们通过多次洗牌重复该过程来测量排列重要性计算中的随机性。`±`后面的数字衡量从一次重组到下一次重组的性能变化情况。您偶尔会看到排列重要性的负值。在这些情况下，对混洗（或噪声）数据的预测恰好比真实数据更准确。当特征无关紧要（重要性应该接近`0`）但随机导致对混洗数据的预测更加准确时，就会发生这种情况。这种情况在小数据集（如本例中的数据集）中更为常见，因为运气/机会的空间更大。在我们的示例中，最重要的特征是进球数。这似乎是明智的。足球迷可能对其他变量的排序是否令人惊讶有一些直觉。
