---
title: 特征工程（Python）
date: 2024-03-13 15:20:32
tags:
  - AI
categories:
  - 人工智能
---

#### 介绍

##### 特征工程的目标

特征工程的目标很简单，**就是让您的数据更适合当前的问题**。考虑“表观温度”测量，例如炎热指数和风寒。这些量试图根据我们可以直接测量的气温、湿度和风速来测量人类感知的温度。您可以将表观温度视为一种特征工程的结果，试图使观察到的数据与我们真正关心的内容更相关。你可以使用特征工程来实现：
- 提高模型的预测性能。
- 减少计算或数据需求。
- 提高结果的可解释性。

##### 特征工程的指导原则

为了使某个功能有用，它必须与模型能够学习的目标有关系。例如，线性模型只能学习线性关系。因此，当使用线性模型时，您的目标是转换特征以使它们与目标的关系呈线性。这里的关键思想是，应用于特征的转换本质上成为模型本身的一部分。假设您试图根据一侧的长度来预测方形地块的价格。将线性模型直接拟合到长度会产生较差的结果：关系不是线性的。
{% asset_img fe_1.png %}

然而，如果我们对长度特征进行平方以获得“面积”，我们就会创建线性关系。将`Area`添加到特征集中意味着该线性模型现在可以拟合抛物线。换句话说，对特征进行平方使线性模型能够拟合平方特征。
{% asset_img fe_2.png %}

这应该向您展示为什么在特征工程上投入的时间可以获得如此高的回报。无论您的模型无法学习什么关系，您都可以通过转换来提供。在开发功能集时，请考虑您的模型可以使用哪些信息来实现其最佳性能。
##### 举例 - 混凝土配方

为了说明这些想法，我们将了解如何向数据集添加一些合成特征来提高随机森林模型的预测性能。混凝土数据集包含各种混凝土配方和最终产品的抗压强度，这是衡量该种混凝土可以承受多少载荷的指标。该数据集的任务是预测给定配方的混凝土的抗压强度。
```python
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import cross_val_score

df = pd.read_csv("../input/fe-course-data/concrete.csv")
df.head()
```
结果输出为：
{% asset_img fe_3.png %}

您可以在这里看到各种混凝土的各种成分。稍后我们将看到添加从这些特征派生的一些额外的综合特征如何帮助模型学习它们之间的重要关系。我们首先通过在未增强的数据集上训练模型来建立基线。这将帮助我们确定我们的新功能是否真正有用。在特征工程过程开始时建立这样的基线是一个很好的做法。基线分数可以帮助您决定您的新功能是否值得保留，或者您是否应该放弃它们并可能尝试其他功能。
```python
X = df.copy()
y = X.pop("CompressiveStrength")

# Train and score baseline model
baseline = RandomForestRegressor(criterion="absolute_error", random_state=0)
baseline_score = cross_val_score(
    baseline, X, y, cv=5, scoring="neg_mean_absolute_error"
)
baseline_score = -1 * baseline_score.mean()

print(f"MAE Baseline Score: {baseline_score:.4}")
```
结果输出为：
```bash
MAE Baseline Score: 8.232
```
如果您曾经在家做饭，您可能知道食谱中成分的比例通常比其绝对数量更能预测食谱的结果。我们可能会推断，上述特征的比率将是压缩强度的良好预测指标。下面的单元格向数据集添加了三个新的比率特征。
```python
X = df.copy()
y = X.pop("CompressiveStrength")

# Create synthetic features
X["FCRatio"] = X["FineAggregate"] / X["CoarseAggregate"]
X["AggCmtRatio"] = (X["CoarseAggregate"] + X["FineAggregate"]) / X["Cement"]
X["WtrCmtRatio"] = X["Water"] / X["Cement"]

# Train and score model on dataset with additional ratio features
model = RandomForestRegressor(criterion="absolute_error", random_state=0)
score = cross_val_score(
    model, X, y, cv=5, scoring="neg_mean_absolute_error"
)
score = -1 * score.mean()

print(f"MAE Score with Ratio Features: {score:.4}")
```
结果输出为：
```bash
MAE Score with Ratio Features: 7.948
```
果然，性能提高了！这证明这些新的比率特征向模型暴露了之前未检测到的重要信息。

#### 互信息(Mutual Information)

##### 介绍

第一次遇到新的数据集有时会让人感到不知所措。您可能会看到成百上千个特征，甚至没有任何说明。你从哪里开始呢？重要的第一步是使用特征效用指标构建排名，该指标是衡量特征与目标之间关联性的函数。然后，您可以选择一小部分最有用的特征进行最初开发。我们将使用的指标称为“互信息”。互信息很像相关性，因为它衡量两个量之间的关系。互信息的优点是可以检测任何类型的关系，而相关性只能检测线性关系。互信息是一个很好的通用指标，在功能开发开始时（当您可能还不知道要使用什么模型时）特别有用。 

互信息：
- 易于使用和解释。
- 计算效率高。
- 理论上是有根据的。
- 抵抗过度拟合。
- 能够检测任何类型的关系。

##### 互信息及其衡量的内容

互信息用不确定性来描述关系。两个量之间的互信息(`MI`)衡量一个量的知识减少另一个量的不确定性的程度。如果您知道某个特征的价值，您对目标的信心会有多大？这是艾姆斯住房数据的一个示例。该图显示了房屋的外部质量与其售价之间的关系。每个点代表一座房子。
{% asset_img fe_4.png %}

从图中我们可以看出，知道了`ExterQual`的值应该可以让你更加确定对应的`SalePrice——ExterQual`的每个类别都倾向于将`SalePrice`集中在一定的范围内。`ExterQual`与`SalePrice`的相互信息是`SalePrice`的不确定性对`ExterQual`的四个值的平均减少量。例如，由于“公平”出现的频率低于“典型”，因此“公平”在`MI`分数中的权重较小。（技术说明：我们所说的不确定性是使用信息论中称为“熵”的量来测量的。变量的熵大致意味着：“您需要多少是或否问题来描述该情况的发生。”您要问的问题越多，您对变量的不确定性就越大。互信息是您期望该功能回答有关目标的多少问题。）

##### 解释互信息分数

数量之间的最小可能互信息为`0.0`。当`MI`为零时，这些量是独立的：两者都无法告诉您有关对方的任何信息。相反，理论上`MI`没有上限。但实际上，高于`2.0`左右的值并不常见。（互信息是一对数量，因此增长非常缓慢。）下图将让您了解`MI`值如何对应于特征与目标的关联类型和程度。
{% asset_img fe_5.png %}

应用互信息时需要记住以下几点：
- `MI`可以帮助您了解某个特征作为目标预测因子（单独考虑）的相对潜力。
- 一个特征在与其他特征交互时可能会提供非常丰富的信息，但单独使用时可能不会提供如此丰富的信息。`MI`无法检测特征之间的交互。它是一个单变量度量。
- 某个特征的实际用途取决于您使用该特征的型号。一项特征仅在其与目标的关系是您的模型可以学习的范围内才有用。仅仅因为某个特征具有高`MI`分数并不意味着您的模型能够利用该信息执行任何操作。您可能需要首先转换特征才能公开关联。

##### 举例 - 1985 年汽车

汽车数据集包含`1985`年车型的`193`辆汽车。该数据集的目标是根据汽车的`23`个特征（例如品牌、车身样式和马力）来预测汽车的价格（目标）。在此示例中，我们将利用互信息对特征进行排序，并通过数据可视化研究结果。