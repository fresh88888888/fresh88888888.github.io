<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.2">
<link rel="preconnect" href="https://fonts.googleapis.com" crossorigin>
<link rel="preconnect" href="https://cdnjs.cloudflare.com" crossorigin>
  <link rel="apple-touch-icon" sizes="180x180" href="/favicon.ico">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon.ico">
  <link rel="mask-icon" href="/favicon.ico" color="#222">
  <meta name="google-site-verification" content="lk2gSYFP_NyLNFob-fFnt7fm-I_n1ZYws-WZll7mshg">
  <meta name="msvalidate.01" content="6Jdc01DjYOLguhS5">
  <meta name="baidu-site-verification" content="code-NR10G09zww">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic%7Ccursive:300,300italic,400,400italic,700,700italic%7CSource+Code+Pro:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/yellow/pace-theme-minimal.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"fresh88888888.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.17.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"flat"},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":true,"nav":null},"stickytabs":true,"motion":{"enable":true,"async":true,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/local-search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":10,"unescape":false,"preload":true}}</script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/config.min.js"></script>

    <meta name="description" content="论文解读这篇文章SFT记忆，RL泛化：基础模型后训练的比较研究，从标题中也可以看出比较的的对象主要是监督微调(SFT)和强化学习(RL)，主要探讨了监督微调(SFT)和强化学习(RL)在基础模型后训练(post training)中的不同作用。特别是在模型的泛化能力和记忆力方面的比较。">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习(ML)(二十六) — 强化学习探析">
<meta property="og:url" content="https://fresh88888888.github.io/2025/02/23/artificial-intelligence/ML26_theory_study/index.html">
<meta property="og:site_name" content="UMBRELLA">
<meta property="og:description" content="论文解读这篇文章SFT记忆，RL泛化：基础模型后训练的比较研究，从标题中也可以看出比较的的对象主要是监督微调(SFT)和强化学习(RL)，主要探讨了监督微调(SFT)和强化学习(RL)在基础模型后训练(post training)中的不同作用。特别是在模型的泛化能力和记忆力方面的比较。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://fresh88888888.github.io/2025/02/23/artificial-intelligence/ML26_theory_study/ml_1.png">
<meta property="og:image" content="https://fresh88888888.github.io/2025/02/23/artificial-intelligence/ML26_theory_study/ml_2.png">
<meta property="og:image" content="https://fresh88888888.github.io/2025/02/23/artificial-intelligence/ML26_theory_study/ml_3.png">
<meta property="og:image" content="https://fresh88888888.github.io/2025/02/23/artificial-intelligence/ML26_theory_study/ml_4.png">
<meta property="og:image" content="https://fresh88888888.github.io/2025/02/23/artificial-intelligence/ML26_theory_study/ml_5.png">
<meta property="article:published_time" content="2025-02-23T01:00:11.000Z">
<meta property="article:modified_time" content="2025-02-23T01:00:11.000Z">
<meta property="article:author" content="umbrella">
<meta property="article:tag" content="AI">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://fresh88888888.github.io/2025/02/23/artificial-intelligence/ML26_theory_study/ml_1.png">


<link rel="canonical" href="https://fresh88888888.github.io/2025/02/23/artificial-intelligence/ML26_theory_study/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://fresh88888888.github.io/2025/02/23/artificial-intelligence/ML26_theory_study/","path":"2025/02/23/artificial-intelligence/ML26_theory_study/","title":"机器学习(ML)(二十六) — 强化学习探析"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>机器学习(ML)(二十六) — 强化学习探析 | UMBRELLA</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">UMBRELLA</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">未雨绸缪，举重若轻</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-算法"><a href="/Algorithm/" rel="section"><i class="fa fa-calendar fa-fw"></i>算法</a></li><li class="menu-item menu-item-c++-&nbsp;编程"><a href="/Programming-C++/" rel="section"><i class="fa fa-heartbeat fa-fw"></i>C++ &nbsp;编程</a></li><li class="menu-item menu-item-rust-编程"><a href="/Programming-Rust/" rel="section"><i class="fa fa-cat fa-fw"></i>Rust 编程</a></li><li class="menu-item menu-item-go-&nbsp;&nbsp;&nbsp;编程"><a href="/Programming-Go/" rel="section"><i class="fa fa-hippo fa-fw"></i>Go &nbsp;&nbsp;&nbsp;编程</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB"><span class="nav-number">1.</span> <span class="nav-text">论文解读</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#AGI-%E6%8E%A2%E6%9E%90"><span class="nav-number">2.</span> <span class="nav-text">AGI 探析</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#AI%E6%84%9F%E7%9F%A5"><span class="nav-number">2.1.</span> <span class="nav-text">AI感知</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#AI%E6%8E%A8%E7%90%86"><span class="nav-number">2.2.</span> <span class="nav-text">AI推理</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#AI%E8%AE%B0%E5%BF%86"><span class="nav-number">2.3.</span> <span class="nav-text">AI记忆</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#AI%E5%85%83%E8%AE%A4%E7%9F%A5"><span class="nav-number">2.4.</span> <span class="nav-text">AI元认知</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#AGI%E6%8E%A5%E5%8F%A3%EF%BC%9A%E8%BF%9E%E6%8E%A5%E4%B8%96%E7%95%8C%E4%B8%8EAGI"><span class="nav-number">2.5.</span> <span class="nav-text">AGI接口：连接世界与AGI</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#AGI%E7%B3%BB%E7%BB%9F%EF%BC%9A%E5%AE%9E%E7%8E%B0AGI%E6%9C%BA%E5%88%B6"><span class="nav-number">2.6.</span> <span class="nav-text">AGI系统：实现AGI机制</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="umbrella"
      src="/avatar.jpeg">
  <p class="site-author-name" itemprop="name">umbrella</p>
  <div class="site-description" itemprop="description">没事就多看看书</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">255</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">21</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">65</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/fresh88888888" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;fresh88888888" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:fresh888888@foxmail.com" title="E-Mail → mailto:fresh888888@foxmail.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
    </div>

    
    <div class="sidebar-inner sidebar-blogroll">
      <div class="links-of-blogroll animated">
        <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
          链接
        </div>
        <ul class="links-of-blogroll-list">
            <li class="links-of-blogroll-item">
              <a href="https://www.rust-lang.org/zh-CN/" title="https:&#x2F;&#x2F;www.rust-lang.org&#x2F;zh-CN&#x2F;" rel="noopener" target="_blank">Rust</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://go.dev/" title="https:&#x2F;&#x2F;go.dev&#x2F;" rel="noopener" target="_blank">Golang</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://isocpp.org/" title="https:&#x2F;&#x2F;isocpp.org&#x2F;" rel="noopener" target="_blank">C++</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://www.python.org/" title="https:&#x2F;&#x2F;www.python.org&#x2F;" rel="noopener" target="_blank">Python</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://doc.rust-lang.org/cargo/index.html" title="https:&#x2F;&#x2F;doc.rust-lang.org&#x2F;cargo&#x2F;index.html" rel="noopener" target="_blank">Cargo</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://gist.github.com/rxaviers/7360908" title="https:&#x2F;&#x2F;gist.github.com&#x2F;rxaviers&#x2F;7360908" rel="noopener" target="_blank">Emoji</a>
            </li>
        </ul>
      </div>
    </div>
        <div class="pjax">
        </div>
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://fresh88888888.github.io/2025/02/23/artificial-intelligence/ML26_theory_study/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/avatar.jpeg">
      <meta itemprop="name" content="umbrella">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="UMBRELLA">
      <meta itemprop="description" content="没事就多看看书">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="机器学习(ML)(二十六) — 强化学习探析 | UMBRELLA">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          机器学习(ML)(二十六) — 强化学习探析
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-02-23 09:00:11" itemprop="dateCreated datePublished" datetime="2025-02-23T09:00:11+08:00">2025-02-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" itemprop="url" rel="index"><span itemprop="name">人工智能</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>15k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>49 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h4 id="论文解读"><a href="#论文解读" class="headerlink" title="论文解读"></a>论文解读</h4><p>这篇文章<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2501.17161">SFT记忆，RL泛化：基础模型后训练的比较研究</a>，从标题中也可以看出比较的的对象主要是<strong>监督微调</strong>(<code>SFT</code>)和<strong>强化学习</strong>(<code>RL</code>)，主要探讨了<strong>监督微调</strong>(<code>SFT</code>)和<strong>强化学习</strong>(<code>RL</code>)在基础模型<strong>后训练</strong>(<code>post training</code>)中的不同作用。特别是在模型的<strong>泛化能力</strong>和<strong>记忆力</strong>方面的比较。</p>
<span id="more"></span>

<p><strong>监督微调</strong>(<code>Supervised Fine-Tuning，SFT</code>)是一种在<strong>机器学习</strong>领域广泛应用的技术，特别是在<strong>迁移学习</strong>的背景下。它主要用于将<strong>预训练模型</strong>调整到特定的下游任务上，以提高模型在该任务上的表现。<code>SFT</code>通常分为以下几个步骤：</p>
<ul>
<li><strong>预训练</strong>：首先，<strong>基础模型</strong>在大规模数据集上进行预训练，学习语言模式、语法和上下文。这一阶段使模型具备广泛的语言理解能力。</li>
<li><strong>数据标注</strong>：为<strong>微调</strong>准备一个特定任务的数据集，每个数据点都带有正确的输出或答案。这些标注数据对于监督学习至关重要，因为它们指导模型在微调过程中的参数调整。</li>
<li><strong>微调</strong>：将<strong>预训练模型</strong>在标注数据集上进一步训练，调整其参数以提高在特定任务上的性能。例如，如果模型需要处理法律文件，则可以使用标注的法律文本进行微调，使其更好地理解法律术语和结构。</li>
</ul>
<p><strong>监督微调</strong>(<code>SFT</code>)和<strong>强化学习</strong>(<code>RL</code>)常用于<strong>基础模型</strong>的两种<strong>后训练</strong>技术。研究表明，<strong>监督微调</strong>(<code>SFT</code>)倾向于记忆训练数据，而<strong>强化学习</strong>(<code>RL</code>)则更关注于适应新场景和任务。论文引入了两个评估任务：<code>GeneralPoints</code>：一个算术推理卡牌游戏，要求模型使用四个数字创建等于目标数字（默认是24）的方程。<code>V-IRL</code>：一个真实世界的导航环境，模型需要根据视觉标志导航到目标位置。这两个任务都包含规则变体和视觉变体，用于评估模型在未见数据上的泛化能力。</p>
<p>虽然<strong>监督微调</strong>(<code>SFT</code>)和<strong>强化学习</strong>(<code>RL</code>)在基础模型训练中被广泛使用，但它们对泛化的不同影响仍然不清楚，这使得构建可靠和稳健的人工智能系统变得具有挑战性。分析基础模型的<strong>泛化能力</strong>中的一个关键挑战是<strong>区分数据记忆</strong>与<strong>可转移原则的获取</strong>。因此，作者研究了一个关键问题：<strong>监督微调</strong>(<code>SFT</code>)或<strong>强化学习</strong>(<code>RL</code>)是否<strong>主要记忆训练数据</strong>，或者它们是否学习了可以适应新任务变体的<strong>可泛化原则</strong>。为了解决这个问题，需关注<strong>泛化</strong>的两个方面：基于<strong>文本的规则泛化</strong>和<strong>视觉泛化</strong>。对于文本规则，研究模型应用学习到的规则（给定文本指令）到这些规则变体的能力。对于<strong>视觉-语言模型</strong>(<code>VLMs</code>)，<strong>视觉泛化</strong>衡量在给定任务中对视觉输入变化（如颜色和空间布局）的表现一致性。为了研究基于<strong>文本</strong>和<strong>视觉的泛化</strong>，使用了两个不同的任务，这些任务体现了基于规则和视觉变体。第一个任务是<code>GeneralPoints</code>，这是一个算术推理卡牌游戏任务，旨在评估模型的<strong>算术推理能力</strong>。在<code>GeneralPoints</code>中，模型接收四张卡片，并需要使用每张卡片的数值计算目标数字（默认是<code>24</code>），每张卡片只能使用一次。第二个任务是<code>V-IRL</code>，这是一个关注<strong>模型空间推理能力</strong>的真实世界导航任务。采用了类似于多步<code>RL</code>框架，在对主干模型进行<code>SFT</code>后实例化<code>RL</code>，使用序列修订公式。在<code>GeneralPoints</code>和<code>V-IRL</code>中，观察到<code>RL</code>学习到了<strong>可泛化的规则</strong>（以文本形式表达），其分布内性能提升也能转移到未见规则上。相反，<code>SFT</code>似乎只是<strong>记忆了训练规则</strong>，并未能实现<strong>泛化</strong>。除了基于文本的规则泛化外，还进一步探索了<strong>视觉领域的泛化</strong>，观察到<code>RL</code>也能对视觉分布外任务进行<strong>泛化</strong>，而<code>SFT</code>仍然无法做到泛化。作为视觉分布外泛化能力的副产品，通过多轮<code>RL</code>方法在<code>V-IRL</code>小型基准测试中<strong>泛化能力</strong>提升了<code>33.8%</code>（<code>44.0% → 77.8%</code>），突显了<code>RL</code>的泛化能力。为了理解<code>RL</code>如何影响模型的<strong>视觉能力</strong>，对<code>GeneralPoints</code>进行了额外分析，揭示使用<strong>基于结果</strong>的<strong>奖励函数</strong>训练<code>RL</code>能够改善视觉识别能力。与<code>SFT</code>相比，<code>RL</code>表现出更好的<strong>泛化能力</strong>，但<code>SFT</code>仍然有助于稳定模型输出格式，从而使<code>RL</code>能够实现其<strong>泛化能力</strong>的提升。同样增加<strong>最大步骤数</strong>来扩大推理计算时间也可以提高<strong>泛化能力</strong>。</p>
<img data-src="/2025/02/23/artificial-intelligence/ML26_theory_study/ml_1.png" class="" title="RL与SFT在OOD泛化下的比较研究">

<p>实验结果表明：</p>
<ul>
<li><code>RL</code><strong>的泛化能力</strong>：研究发现，经过<code>RL</code>训练的模型，特别是在使用<strong>基于结果</strong>的奖励进行训练时，能够在文本和视觉变体之间有效泛化。与此相比，<code>SFT</code>则更倾向于<strong>记忆训练数据</strong>，并且在面对分布外场景时表现不佳。</li>
<li><code>SFT</code><strong>的记忆偏向</strong>：<code>SFT</code>训练的模型往往会对特定的输入模式进行匹配，而不是理解其背后的逻辑。例如，在<code>GeneralPoints</code>任务中，如果模型仅仅记住了特定卡片颜色与数字的关联，当规则变化时，其表现会显著下降。</li>
<li><code>RL</code><strong>对视觉识别能力的提升</strong>：研究还发现，<code>RL</code>不仅提高了模型在文本任务中的表现，也增强了其在视觉任务中的基础视觉识别能力。</li>
<li><code>SFT</code><strong>与</strong><code>RL</code><strong>的互补性</strong>：尽管<code>RL</code>在<strong>泛化能力</strong>上表现更好，但研究表明，<code>SFT</code>仍然对有效的<code>RL</code>训练至关重要。<code>SFT</code>能够稳定模型输出格式，从而为后续的<code>RL</code>提供良好的基础。</li>
</ul>
<h4 id="AGI-探析"><a href="#AGI-探析" class="headerlink" title="AGI 探析"></a>AGI 探析</h4><p>通往<strong>人工通用智能</strong>的道路不仅是一场技术征程，更是一次哲学层面的探索——它要求我们重新诠释数字时代<strong>智能</strong>与<strong>伦理</strong>的深层内涵。———— <code>Alex Kim</code>，未来洞察研究院人工智能伦理部主任。</p>
<p>要开始探讨我们距离<code>AGI</code>（<strong>人工通用智能</strong>）还有多远这一命题，首先需要以人工智能发展史为锚点，理解人类对更先进系统的深层诉求。通过本文，我们希望以大型语言模型(<code>LLMs</code>)等现代<code>AI</code>系统为观测视角，为当前<code>AGI</code>发展进程提供证据与洞见。核心目标在于审慎叩问：<code>LLMs</code>是否就是终极答案？只有秉持这种持续探索的科研自觉，我们才有可能真正触碰<code>AGI</code>的疆界。</p>
<p><strong>人工智能简史</strong>，<strong>人工智能</strong>(<code>AI</code>)的发展通过其在<strong>视觉感知</strong>、<strong>语言理解</strong>、<strong>推理优化</strong>等领域的强大能力深刻改变了人类社会。典型案例是<code>DeepMind</code>于<code>2021</code>年推出的<code>AlphaFold</code>，彻底革新了蛋白质结构预测领域，推动了生物科学研究的前沿突破。值得注意的是，<code>AI</code>发展历程并非一帆风顺：</p>
<ul>
<li><strong>奠基阶段</strong>(<code>1950s-1970s</code>)：早期研究聚焦<strong>符号主义</strong>与<strong>连接主义</strong>，为智能计算的<strong>范式</strong>奠定理论基础。受限于算力与数据规模，研究多停留在概念验证层面。</li>
<li><strong>寒冬与复苏</strong>(<code>1980s-1990s</code>)：因技术预期过高与现实落差，<code>AI</code>经历发展低谷。<strong>机器学习</strong>与<strong>神经网络理论</strong>突破为技术复苏注入动力。</li>
<li><strong>深度学习革命</strong>(<code>2010s</code>至今)：<strong>图像识别</strong>与<strong>语音识别</strong>取得跨越式发展，<code>ChatGPT</code>的横空出世标志着大语言模型(<code>LLMs</code>)开启<code>AI</code>研究的新纪元。<strong>统一知识表征体系，多任务协同求解能力突破</strong>。</li>
</ul>
<p>尽管<strong>人工智能</strong>(<code>AI</code>)为人类社会带来了巨大的改善，但社会的物质和精神需求日益增长，使得人们对<code>AI</code>仅提供的便利性感到不满足。因此，实现能够高效、有效地执行更广泛任务的<strong>人工通用智能</strong>(<code>AGI</code>)已成为一个迫切关注的问题。<code>AGI</code>被描述为一种至少在大多数任务上与人类一样能力的<code>AI</code>系统(<code>Wang et al., 2018; Voss and Jovanovic, 2023</code>)。我们到底距离<code>AGI</code>还有多远，以及如何实现<code>AGI</code>？为了探讨这些问题，现有研究主要分为三个类别：<strong>定义与概念</strong>、<strong>技术方法与应用</strong>、以及<strong>伦理与社会影响</strong>。</p>
<ul>
<li><strong>定义与概念</strong>：<code>Wang</code>等人(<code>2018</code>)从与人类的比较角度定义了<code>AGI</code>的概念，并提出了不同层次的<code>AGI</code>。<code>Voss</code>和<code>Jovanovic</code>(<code>2023</code>)为实现<code>AGI</code>提供了方向，设定了与<code>AGI</code>相关的人类化要求。</li>
<li><strong>技术方法与应用</strong>：<code>Yan</code>(<code>2022</code>)和<code>Wang</code>等人(<code>2019</code>)提出，<code>AGI</code>可以通过将<strong>逻辑</strong>与<strong>深度学习</strong>相结合来实现。<code>Das</code>等人(<code>2023</code>)认为，<code>AGI</code>技术的发展存在许多风险，如安全和隐私问题。</li>
<li><strong>伦理与社会影响</strong>：<code>Rayhan</code>(<code>2023</code>)认为，人们应该考虑创建<code>AGI</code>的<strong>伦理影响</strong>，包括对<strong>人类社会、隐私和权力动态</strong>的影响。<code>Bugaj</code>和<code>Goertzel</code>(<code>2007</code>)提出了<strong>五项伦理原则</strong>及其对<code>AGI</code>交互的影响。这些研究从不同角度刻画了<code>AGI</code>，但仍缺乏对<code>AGI</code>发展过程的系统性评估和对<code>AGI</code>目标的明确定义，这使得衡量当前<code>AI</code>发展与<code>AGI</code>未来的差距变得困难，并且难以提出实现<code>AGI</code>的可能路径。<img data-src="/2025/02/23/artificial-intelligence/ML26_theory_study/ml_2.png" class=""></li>
</ul>
<p>由上图所示，从<code>AGI</code>(<strong>人工通用智能</strong>)所需的主要能力概述开始，分为<strong>内部能力</strong>、与<strong>外部世界的接口连接</strong>以及支持这些功能的<strong>基础设施系统</strong>。在部署方面，需要更为复杂的对齐程序，以在约束和人类期望下释放<code>AGI</code>系统的潜力。此外，我们描绘了一个路线图。<code>AGI</code>的三个层次：<strong>胚胎</strong><code>AGI</code>、<strong>超人类</strong><code>AGI</code>和<strong>终极</strong><code>AGI</code>，帮助我们定位当前状态、相关评估框架以及对一些可能阻碍我们向<code>AGI</code>前进的关键问题的见解。</p>
<img data-src="/2025/02/23/artificial-intelligence/ML26_theory_study/ml_3.png" class="">

<p>由上图所示，<code>AGI</code>内部，即<code>AGI</code>的“<strong>大脑</strong>”，由四个主要组成部分：<strong>感知</strong>、<strong>推理</strong>、<strong>记忆</strong>和<strong>元认知</strong>。人类大脑的复杂性，以及其特定功能区域分别负责<strong>认知</strong>和<strong>行为</strong>的不同方面，为<code>AGI</code>系统的架构提供了一个引人入胜的类比。类似于人类大脑分为感官处理、情感、认知和执行功能等区域，<code>AGI</code>系统的“<strong>大脑</strong>”也可以基本上分为四个主要组成部分：<strong>感知</strong>、<strong>记忆</strong>、<strong>推理能力</strong>和<strong>元认知</strong>。这些组成部分反映了人类<strong>认知</strong>的基本方面，并在创建一个真正智能的系统中扮演着不同的关键角色。<strong>感知</strong>是指在<code>AGI</code>与其环境交互过程中对感官信息的组织和解释，被视为<code>AGI</code>的基本能力，包括<strong>视觉、听觉、触觉、嗅觉</strong>等。<code>AGI</code>的<strong>推理</strong>是基于对环境的感知，并对环境执行行动。<code>AGI</code>与环境的互动，包括<strong>感知</strong>的获取和行动的执行，将被保存为<code>AGI</code>的<strong>记忆</strong>。这些<strong>记忆</strong>将被用于<code>AGI</code>的<strong>元认知</strong>。</p>
<h5 id="AI感知"><a href="#AI感知" class="headerlink" title="AI感知"></a>AI感知</h5><p><strong>感知</strong>是指系统解释和理解周围世界的能力。这涉及对感官数据的处理和分析，以构建对环境的动态和上下文理解。<strong>自然语言</strong>作为人类交流的主要方式，已经从早期人类互动的起源发展到复杂的系统，如<strong>大语言模型</strong>(<code>LLMs</code>)。这些模型扩展了理解和参与对话以及执行创意任务的能力。然而，文本本身可能无法完全捕捉到现实世界经验的深度，这凸显了<strong>多模态智能</strong>的重要性，即结合图像、视频和音频以实现更丰富的<strong>人机交互</strong>。从传统<code>LLMs</code>到<strong>多模态模型</strong>的转变代表了一次重大的技术飞跃，促进了跨多种输入的更加逼真的互动。这一转变由近期<strong>多模态</strong><code>LLMs</code>的发展所突显，解决了仅依赖语言理解的局限性，并为涉及多种数据形式的复杂挑战打开了大门。整合各种模型应遵循两个原则：1）理解“如何”将外部模态信息纳入，并确保不同模块的无缝整合；2）确定“使用什么”信息以保持原始模型的完整性并增强整体能力。利用现成的<code>LLMs</code>和<strong>多模态编码器</strong>的主要目标是在它们之间建立无缝连接。这种连接可以是外部的，即在不改变现有模型结构的情况下对齐多模态知识，也可以是内部的，允许<code>LLMs</code>与其他模态编码器进行更为复杂的交互。这些方法通常需要大量训练，例如创建一个可学习的接口，将<code>LLM</code>与非语言模态（特别是视觉）联系起来。类似于<code>LLM</code>的<strong>预训练</strong>和<strong>微调</strong>，<strong>多模态</strong><code>LLMs</code>(<code>MLLMs</code>)遵循一个基于<strong>预训练</strong><code>LLM</code>的两阶段训练范式，并将其适应<strong>多模态领域</strong>。第一阶段，称为<strong>视觉-语言对齐阶段</strong>，旨在使<strong>语言模型</strong>能够理解视觉标记。第二阶段涉及<strong>多模态指令调整</strong>，以使模型与人类感知相一致。这些阶段根据<code>LLM</code>与<strong>多模态编码器</strong>之间的组合架构有明确的分类。</p>
<p><strong>模态的外部连接</strong>，外部方法基于通过额外结构和现有模型将视觉分支与<code>LLMs</code>（<strong>大语言模型</strong>）连接起来的理念。</p>
<ul>
<li><strong>投影式</strong>：<strong>模态连接器</strong>存在于<code>LLMs</code>和多<strong>模态编码器</strong>之外，可以通过简单的<strong>线性投影</strong>或相对复杂的选择方法来实现。这种类型的<code>MLLM</code>（<strong>多模态大语言模型</strong>）通常在两个对齐训练阶段激活投影层或<code>LLMs</code>。</li>
<li><strong>查询式</strong>：这些<code>MLLMs</code>使用设计更为复杂的连接器，但仍然独立于<code>LLMs</code>和<strong>多模态编码器</strong>之外。这种模型本质上利用了类似<strong>注意力</strong>的交互，即在可学习变量与视觉标记之间进行交互。由于其连接器能够学习到比简单投影式更复杂的数据模式，因此仅<strong>激活连接器</strong>也能获得更优的多模态性能。</li>
<li><strong>语言式</strong>：语言作为接口是将所有现成模型整合为一个整体的流行方向。这些方法利用各种预构建模块进行生成和其他任务，<code>LLMs</code>主要负责模块的协调。利用工具的一个主要优势是这些系统可以更灵活地进行规划，以便做出决策或创作多媒体内容，语言作为桥梁。一个突出的最新方法是<code>GPT-4V</code><strong>模型</strong>，它可以通过连接最先进的生成器生成生动的图像。虽然这些方法为各种任务提供了更广泛的技术解决方案，但它们在实现与接口式方法相当的性能深度方面通常不如后者。</li>
</ul>
<p><strong>模态的内部连接</strong>，将<strong>多模态编码器</strong>与<code>LLM</code>（<strong>大语言模型</strong>）连接的另一种方法是调整<code>LLM</code>的内部模块。</p>
<ul>
<li><strong>基于交叉注意力</strong>：<code>Flamingo(Alayrac et al., 2022)</code>提出了一种<strong>感知器</strong>，在<code>LLMs</code>的<strong>注意力模块</strong>内增加了额外的<strong>交叉注意力机制</strong>。<code>Flamingo</code>的几种变体也使用相同或类似的框架来调整<code>MLLMs</code>（<code>多模态大语言模型</code>）。</li>
<li><strong>自回归式</strong>：像<code>Fuyu(Bavishi et al., 2023)</code>及其变体这样的<code>MLLMs</code>将视觉标记视为<strong>语言标记</strong>，并从预训练阶段开始使用相同的自回归训练损失来更新整个模型参数。</li>
</ul>
<p><strong>多模态大语言模型</strong>(<code>MLLMs</code>)的额外模态：尽管早期模型主要集中在视觉输入和文本输出上，但近期的发展已扩展到包括多种模态的输入和输出形式。在输入方面，通过适当的<strong>模态编码器</strong>和训练数据，<code>LLMs</code>（<strong>大语言模型</strong>）现在可以理解视频、音频以及多种非语言模态，使这种方法具有<strong>可扩展性</strong>和<strong>可访问性</strong>。在输出方面，最近的研究转向了创建超越单纯文本生成的混合内容。<code>LLMs</code>已经从最初的检索图像和生成文本发展到同时生成视觉和文本内容。生成图像和文本的详细技术路径包括对具有统一表示的图像-文本数据进行<strong>自回归调整</strong>，以及将文本特征转换为<strong>图像生成模型</strong>(<code>Stable Diffusion</code>)的符号调整。此外，视觉领域的最新进展为在没有文本的情况下生成内容提供了可扩展的方法，增强了将视觉模型扩展到生成任务的潜力。这为在语言之外的其他模态中扩展和发现类似的“<code>AGI</code><strong>现象</strong>”提供了可能性。</p>
<p>当前<code>AGI</code>级别的<strong>感知模型</strong>仍然受到模态有限和<strong>鲁棒性</strong>不足的限制。为解决这些问题，所以提出了几个潜在的未来研究方向：</p>
<ul>
<li><strong>模态多样化</strong>：整合多种数据类型以提升模型能力是至关重要的。需要探索不常见的模态（如图形），并同时整合多种模态（如图像、音频和视频）。这需要精心设计的模块、高质量的数据以及平衡管理不同模态之间的相互作用及其与语言的关系。例如，虽然<code>GPT-4V</code>只能处理语言和视觉信息，但最新的<code>Gemini</code><strong>模型</strong>已将其能力扩展到更广泛的音频和视频范围。潜在的方法包括使用统一模态表示工具（如<code>ImageBind</code>和<code>LanguageBind</code>）来弥合模态差距，减轻从其他模态学习的负担。</li>
<li><strong>提高多模态系统的鲁棒性和可靠性</strong>：随着越来越多的综合基准测试出现，这些测试不仅涵盖一般情况，还包括挑战性输入（如数学问题、反事实指令和攻击字符串），显然<strong>多模态系统</strong>（特别是较小的系统）在面对对抗性示例时表现不佳，并且严重依赖语言，缺乏在分布异常情况下的<strong>推理能力</strong>（如多面板图像、草图和长序列图像）。这些观察结果在实际应用中可能带来潜在风险。为应对这些挑战并构建更具<strong>鲁棒性</strong>的多模态<code>AGI</code>模型，可以考虑将对抗性示例纳入训练或增加训练数据指令格式的多样性。</li>
<li><strong>可解释的多模态模型</strong>：与传统模型不同，<strong>多模态模型</strong>涉及不同模态之间的复杂交互，因此揭示其内部工作机制以理解和创建更强大的<strong>多模态模型</strong>至关重要。为此，研究努力提供了训练或生成过程中的解释，揭示了模型性能和推理的洞见。方法如用多样化的训练数据探测模型性能已被探索。此外，<code>Gemini</code>团队通过提供生成解释来增强用户对<code>AI</code>推理过程的信任和理解。提高<strong>多模态模型</strong>的另一个方面是增加透明度，这包括识别特定的模型组件或配置，这些组件或配置有助于系统的能力（如<strong>视觉编码器</strong>、<strong>连接器</strong>或<strong>训练范式</strong>）。研究还特别调查了不同模态处理器对整体模型性能的影响。随着<strong>多模态模型</strong>的发展，未来的研究必须优先考虑<strong>可解释性</strong>和<strong>透明度</strong>，以便充分发挥这些强大<code>AI</code>系统的潜力，同时确保其负责任和道德。例如，未来的研究方向可以探索严格控制的实验来训练<code>AI</code>模型，以分解每个部分，或探测模型组件以找到最有效的模块。</li>
</ul>
<h5 id="AI推理"><a href="#AI推理" class="headerlink" title="AI推理"></a>AI推理</h5><p><strong>推理</strong>是基于<strong>可用信息</strong>、<strong>逻辑</strong>和<strong>先验知识</strong>得出<strong>结论</strong>或做出决策的<strong>认知过程</strong>。它包括<strong>评估证据</strong>、<strong>识别关系</strong>以及<strong>应用规则</strong>或<strong>原则</strong>来解决问题。<code>AI</code><strong>推理</strong>指的是<code>AI</code><strong>系统</strong>模拟这一过程的能力，使机器能够<strong>理解情境</strong>、<strong>推断结论</strong>并以类似人类推理的方式<strong>做出决策</strong>。</p>
<p>当前<code>AI</code><strong>推理</strong>的状况，大量研究表明，<strong>推理能力</strong>已经在<strong>大型机器学习模型</strong>中显现。<strong>大语言模型</strong>(<code>LLMs</code>)，包括<code>GPT-3</code>、<code>LLaMA 2</code>和<code>PALM 2</code>，已经在各种<code>NLP</code>任务中实现了灵活的零样本和少样本推理能力。<strong>大视觉语言模型</strong>(<code>LVLMs</code>)，如<code>GPT-4</code><strong>视觉版</strong>和<code>Gemini</code>，通过有效地整合视觉和语言推理，进一步推动了这一进展。已经开发出多种策略，以在不更新模型的情况下激发有效和高效的推理。这些方法在包括算术、常识、符号推理以及模拟和现实世界挑战在内的广泛任务中显著提高了模型性能。</p>
<p>思维导航：</p>
<ul>
<li><strong>思维链</strong>(<code>CoT</code>)：<strong>思维链</strong>生成一系列中间推理步骤，称为“<strong>思维</strong>”，以使模型能够分解多步骤问题，并为更复杂的任务分配额外的计算。这为模型的推理过程提供了<strong>可解释</strong>的洞见，帮助理解答案的推导过程，并识别推理中可能出现的错误。</li>
<li><strong>思维树</strong>(<code>ToT</code>)：<strong>思维树</strong>使用基于树的<strong>搜索算法</strong>来导航“<strong>思维</strong>”，以进行深思熟虑的问题解决。这使得<strong>大语言模型</strong>(<code>LLMs</code>)能够探索多种推理路径，并在必要时进行<strong>前瞻</strong>或<strong>回溯</strong>。</li>
<li><strong>思维图</strong>(<code>GoT</code>)：<strong>思维图</strong>将信息组织成图结构，其中“<strong>思维</strong>”是顶点，边对应于这些顶点之间的依赖关系。这种基于图的组织方式促进了更复杂的思维整合和操作，允许创建更复杂的<strong>推理路径</strong>和<strong>反馈机制</strong>。</li>
<li><strong>程序思维</strong>(<code>PoT</code>)：<strong>程序思维</strong>利用语言模型将推理过程表达为程序，将计算委托给外部计算机执行生成的程序以获得答案。这种计算与推理的分离提高了对高度符号化推理问题的性能。</li>
<li><strong>自洽推理</strong>：自洽性通过采样多样化的推理路径并选择最一致的答案，克服了<strong>贪婪解码</strong>的<strong>局限性</strong>，实现了更可靠的结果。</li>
<li><strong>其他提示策略</strong>：许多其他提示方法已被开发出来，以提高<code>LLMs</code>的推理能力。例如，复杂性提示、自动思维链、最简至最复杂提示、分解提示、工具<code>LLM</code>和<code>ToRA</code>等方法，通过不同的方式增强了模型的推理能力。</li>
<li><strong>动态推理与规划</strong>：<code>ReAct</code>通过交替生成<code>推理轨迹</code>和<code>行动计划</code>，实现<code>动态推理</code>。<code>DEPS</code>通过<code>动态反馈循环</code>提高计划的可靠性。<code>Inner Monologue</code>和<code>ProgPrompt</code>等方法通过实时反馈调整计划，提高任务完成率和适应性。</li>
<li><strong>反思与改进</strong>：自我改进和反思等方法通过迭代生成和反馈，使模型能够根据反馈进行调整。<code>CRITIC</code>利用外部工具验证<code>LLMs</code>的行动，并进行自我校正。</li>
<li><strong>整合语言模型、世界模型和代理模型</strong>：<code>LAW</code>框架结合<code>语言模型</code>、<code>世界模型</code>和<code>代理模型</code>，促进更强大的推理能力。<code>RAP</code>和<code>BIP-ALM</code>等方法通过语言模型实现更复杂的<code>推理</code>和<code>规划</code>。</li>
<li><strong>具身智能体的推理与规划</strong>：<code>Voyager</code>和<code>Generative Agents</code>等方法通过<code>动态推理</code>和<code>反馈循环</code>，提高了<strong>具身智能体</strong>在执行任务和与环境互动方面的能力。</li>
</ul>
<p>尽管当前系统在各种任务中展示了令人印象深刻的推理技能，但它们仍存在一些重大缺陷和挑战：</p>
<ul>
<li><strong>因果学习</strong>：基础模型需要学习<strong>因果关系</strong>，以实现更好的<strong>理解</strong>和<strong>泛化</strong>。这些模型主要依赖训练数据中的模式，但这些模式并不总是能捕捉到人类知识和经验的深度和广度。此外，这些模型通常基于数据中提取的模式运行，而不是真正理解底层的<strong>因果关系</strong>。<code>Zečević</code>等人（<code>2023</code>）描述了<code>LLMs</code>如何表面上复制<strong>因果关系</strong>，但缺乏底层的<strong>因果机制</strong>，使它们更像是“因果鹦鹉”而非真正的因果模型。<code>Jin</code>等人（<code>2023</code>）提出了一个具有挑战性的因果推理数据集，并建议LLMs在可靠推理因果关系方面仍有很长的路要走。未来<code>AGI</code>的进步应专注于<strong>学习因果关系</strong>而非<strong>相关性</strong>，从而实现更好的<strong>泛化</strong>和更深入的理解。</li>
<li><strong>复杂和长上下文推理</strong>：<code>AGI</code>必须解决复杂的<strong>多步推理任务</strong>的挑战。尽管已经开发了许多策略来缓解这一问题，但这些策略通常需要明确的指导或问题的仔细构建，这在未来可能变得不必要。即使采用这些方法，模型在处理长上下文信息并在整个推理任务中保持连贯和逻辑推理方面仍然面临挑战。</li>
<li><strong>幻觉、不确定性评估和模糊处理</strong>：<code>AGI</code>应解决<strong>幻觉问题</strong>，即生成与提供的来源内容不符或无意义的内容。这种倾向影响性能，并在实际应用中引发重大安全问题。此外，这些模型通常难以准确评估其不确定性，并在输出中有效传达这种不确定性，这可能导致误导性的结果。它们还难以处理<strong>模糊性</strong>，这可能使其在复杂情境中的<strong>可用性</strong>复杂化。</li>
<li><strong>社交推理</strong>：<code>AGI</code>应提高<strong>社交推理能力</strong>，以增强与人类和其他<strong>智能体</strong>的互动。当前的<code>AI</code>模型缺乏健全的<strong>心智理论</strong>，即理解他人心理状态的能力。提高这一能力对于<code>AGI</code>系统在开放环境中与人类和其他<strong>智能体</strong>安全有效地互动至关重要。理解社交线索和规范是这一发展的核心，因为它使<code>AGI</code>能够在不同情境中解释和回应隐含的沟通和行为期望。</li>
<li><strong>可解释性和透明度</strong>：<code>AGI</code>应解决可<strong>解释性</strong>和<strong>透明度</strong>的挑战，从而提高其决策的<strong>可靠性</strong>。大多数<code>AI</code>系统缺乏这些特性，使得难以理解它们如何得出特定结论或答案。旨在用<strong>自然语言</strong>引出推理的技术并不总是与模型实际使用的推理过程一致，生成的解释可能具有系统性误导。这一局限性阻碍了它们的推理能力，并在需要<strong>决策审计</strong>或<strong>证明</strong>的领域（如医疗和法律）带来重大挑战。</li>
<li><strong>动态推理和跨领域规划</strong>：未来的<code>AGI</code>系统旨在实现跨领域的<strong>动态推理</strong>、<strong>道德</strong>和<strong>高效的规划</strong>，以及前所未有的规模和速度的<strong>类人智能</strong>。我们仍然远未实现<code>AGI</code>级别的能力，即在没有重新训练或人类监督的情况下，在各种领域进行<strong>推理</strong>和<strong>规划</strong>。这一旅程包括增强<code>AI</code>系统在不同领域之间转移知识和技能的能力，使它们能够高效地应对未知情况。关键的发展重点是创建能够在广泛的战略目标和详细行动之间进行规划的算法。此外，<code>AI</code>系统在规划阶段需要更有效地管理资源（如时间、能源和成本），并确保这些规划过程符合道德标准和安全法规，特别是在敏感领域，以避免滥用或意外后果。</li>
<li><strong>创新解决方案</strong>：未来的<code>AGI</code>系统将能够<strong>理解上下文</strong>、<strong>推断因果关系</strong>，并在各种领域中<strong>动态应用高级逻辑规划</strong>。通过综合大量信息并进行深思熟虑的规划，它们可以为<strong>创造性假设的构建</strong>、<strong>复杂道德判断的做出</strong>、<strong>新场景结果的预测</strong>以及<strong>持续学习</strong>和完善对世界的理解提供创新解决方案。这些未来的<code>AGI</code>系统不仅将在处理和生成信息方面表现出色，还将能够以深度类似于<strong>人类智能</strong>的方式理解和与世界互动，但规模和速度将远超人类能力。</li>
</ul>
<h5 id="AI记忆"><a href="#AI记忆" class="headerlink" title="AI记忆"></a>AI记忆</h5><p><strong>语言和视觉模型的无状态特性</strong>，语言和视觉模型本质上是无状态的，它们在交互之间不保留信息。然而，<strong>高级智能体</strong>不同，它们能够管理内部或外部记忆，从而能够进行复杂的多步交互。这种记忆存储了中间信息、领域特定或广泛的知识以及<strong>智能体</strong>之前<strong>观察、思考和行动的序列</strong>等。它帮助<strong>智能体</strong>利用以前的知识或经验进行<strong>推理、规划</strong>和<strong>自我提升</strong>。</p>
<p>当前<code>AI</code><strong>记忆</strong>的状态从三个关键方面审视当前<code>AI</code><strong>记忆</strong>的现状：</p>
<ul>
<li><strong>记忆管理</strong>：决定存储什么信息以及何时存储。</li>
<li><strong>记忆表示</strong>：定义信息的结构形式。</li>
<li><strong>记忆利用</strong>：解决如何高效有效地应用和使用<strong>记忆</strong>。</li>
</ul>
<p><strong>记忆管理</strong>，记忆根据持续时间分为<strong>短期记忆</strong>和<strong>长期记忆</strong>。<strong>短期记忆</strong>：短期记忆在维持当前决策过程所需的信息方面起着至关重要的作用。一个显著的例子是<strong>上下文提示</strong>，它利用基础模型自身的上下文作为一种<strong>短期记忆</strong>。这种方法可以提供额外的信息或示例，或用于生成<strong>中间推理</strong>。更广泛地说，<strong>短期记忆</strong>包括所有决策所需的即时数据，包括：1、感知模块收集或处理的实时数据；2、推理、规划和自我进化模块的即时输出；3、从长期记忆中主动检索的信息。这些元素共同合成，指导并告知后续行动。<strong>长期记忆</strong>：长期记忆可以广泛分为两类：<strong>经验</strong>和<strong>知识</strong>。经验包括过去的<strong>观察、思考、行动</strong>等。这些丰富的经验在决策过程中起着关键作用。通过检索相关经验，<strong>智能体</strong>可以获得必要的信息，理解过去行动的反馈，并在理解和推理中实现一定程度的<strong>泛化</strong>。例如，<code>Reflexion</code>反思任务反馈信号，并将其作为文本摘要保存，直接纳入后续情境的上下文中，以提高性能。<code>Generative Agents</code>以自然语言记录经验，并使用<strong>相关性</strong>（基于<strong>嵌入</strong>）、<strong>最近性</strong>（基于<strong>规则</strong>）和<strong>重要性</strong>（基于<strong>推理</strong>）标准检索记忆。<strong>知识</strong>代表了<strong>智能体</strong>对世界和自身的理解，增强了其推理和决策能力。<strong>知识</strong>可以来自两个来源：<strong>从经验中收集</strong>和<strong>同化的知识</strong>，或者利用<strong>外部知识库</strong>。例如，<code>Voyager</code>维护一个不断扩展的可执行代码技能库，用于初步行动以完成任务。<code>ReAct</code>使用<code>Wikipedia API</code>在<strong>智能体</strong>缺乏信息时获取外部知识。</p>
<p><strong>记忆表示</strong>，记忆表示分为<strong>文本记忆</strong>和<strong>参数记忆</strong>。<strong>文本记忆</strong>是当前表示记忆内容的主要方法，包括<strong>自然语言</strong>的原始形式和结构化形式（如元组、数据库等）。<strong>参数记忆</strong>可以通过<strong>监督微调</strong>、<strong>知识编辑</strong>和<strong>模型合并</strong>等技术将领域特定知识整合到模型参数中。<strong>文本记忆</strong>在每次推理时都需要将记忆纳入<strong>上下文提示</strong>，导致成本更高且处理时间更长。相比之下，<strong>参数记忆</strong>在写入阶段成本更高，因为微调模型比简单的文本存储更具挑战性。在<strong>可解释性</strong>方面，<strong>文本记忆</strong>通常比<strong>参数记忆</strong>更透明，因为<strong>自然语言</strong>是人类理解的最直接方式。</p>
<p><strong>记忆利用</strong>，利用记忆的两种常见技术是<strong>记忆检索</strong>和<strong>长上下文</strong><code>LLMs</code>。<strong>记忆检索</strong>：<strong>记忆检索</strong>涉及从<strong>长期记忆</strong>中读取信息到<strong>短期记忆</strong>中以供即时使用。这可以通过<strong>基于规则的检索</strong>或<strong>检索增强方法</strong>实现。<strong>基于规则的检索</strong>可以使用<strong>关键词</strong>、<strong>时间步长</strong>或<strong>特定模式搜索记忆</strong>。<strong>检索增强方法</strong>如<code>Dense Passage Retriever</code>(<code>DPR</code>)创建文档的<strong>稠密表示</strong>，并基于其<strong>先验概率检索</strong>最相关的文档。<strong>长上下文</strong><code>LLMs</code>：<strong>长上下文</strong><code>LLMs</code>通过扩展<strong>上下文窗口</strong>，为模型访问<strong>长期记忆</strong>开辟了新的途径。<code>Ring Attention</code>和<code>LongRoPE</code>等技术通过改进<strong>注意机制</strong>和<strong>存储方法</strong>，大大降低了<strong>长上下文推理</strong>的时间和成本。随着<code>GPU</code>性能的提升和注意机制的突破，<code>LLMs</code>的<strong>上下文窗口</strong>已从<code>GPT-2</code>的<code>1024</code>个<code>token</code>扩展到<code>GPT-4</code>的<code>8192</code>个<code>token</code>，甚至超过<code>16K</code>个<code>token</code>。这些扩展的<strong>上下文窗口</strong>使得<code>AI</code>系统能够更有效地存储和回忆上下文中的<strong>知识</strong>和<strong>经验</strong>，从而实现更快速和全面的<strong>基于上下文的推理</strong>。</p>
<p><code>AGI</code><strong>级别的记忆</strong>，实现<code>AGI</code>级别的记忆需要管理庞大且动态组织的信息，改进记忆在推理和规划中的利用，并具备自主更新和丰富记忆库的能力。这涉及类似人类的有意记忆使用，但超越人类的能力，允许更全面和复杂的回忆。</p>
<ul>
<li><strong>未来的</strong><code>AGI</code><strong>将高效管理多样且分层的记忆，确保隐私、协作和可扩展性</strong>。当前的<code>AI</code><strong>智能体</strong>在构建分层记忆和无缝整合各种格式的信息方面面临挑战。未来的<code>AGI</code><strong>系统</strong>预计将在处理嵌入、视频、文档和数据库等多种形式的记忆方面表现出色，既高效又有效。它们还需要处理不同级别的记忆权限：本地记忆对于保护隐私至关重要，而共享记忆（在集中或分散结构中，视需要）则是协作和分布式流程所必需的。用于记忆管理的架构预计将高度组织化和可扩展。这些系统可能具备先进的算法，用于分类和索引信息，使<strong>智能体</strong>能够高效地检索和记录各种经验和知识。此外，它们可以动态更新和重组记忆结构，确保信息的最佳存储和检索。</li>
<li><strong>未来的</strong><code>AGI</code><strong>将通过整合检索和高级推理来增强记忆利用，实现更类似人类的智能和适应性</strong>。超越简单的<strong>记忆检索</strong>，未来的<code>AGI</code><strong>系统</strong>可以通过将<strong>检索过程</strong>与<strong>高级推理</strong>相结合，精细地合成和应用信息，从而提高<strong>记忆利用率</strong>。这些检索过程可以被学习或更新，以适应不断变化的环境。能够实时访问和应用相关信息将是实现更类似人类智能的重要一步，使这些系统能够以高度理解和适应性应对新情况。</li>
<li><strong>未来的</strong><code>AGI</code><strong>将自主更新知识，实现持续学习和适应，同时确保安全</strong>。与主要依赖预先存在的人类生成内容的现有<strong>检索增强模型</strong>不同，未来的<code>AGI</code><strong>系统</strong>可以<strong>自主生成</strong>、<strong>评估</strong>和将新内容纳入其记忆库。这些更新应包括提高性能所需的知识和系统可以借鉴的经验。这一概念与<strong>自我进化</strong>密切相关。它将使<code>AGI</code>能够从自身的经验和洞察中学习，不断丰富和更新其知识库。在不断变化的世界中，这种能力还将使系统能够根据新信息迅速适应，并摒弃过时的知识。确保记忆更新的安全性至关重要，必须确保不会写入有害信息，以防止污染。为自主<code>AGI</code>设计安全约束涉及创建强大的<strong>验证协议</strong>，在整合之前评估新信息的<strong>真实性</strong>、<strong>相关性</strong>和影响。可以实施<strong>专家系统</strong>定期审查更新，使用<strong>异常检测标记异常</strong>和潜在有害数据，并采用其他方法来强化这些安全约束。</li>
</ul>
<h5 id="AI元认知"><a href="#AI元认知" class="headerlink" title="AI元认知"></a>AI元认知</h5><p><strong>元认知</strong>(<code>Choudrie和Selamat，2006</code>)是人类的<strong>关键认知</strong>和<strong>情感技能</strong>，包括<strong>理解复杂情境、自我意识</strong>和<strong>创新动机</strong>。这些能力有助于分享<strong>隐性知识</strong>并推动个人成长。开发具有如此先进<strong>元认知</strong>的<code>AGI</code>引发了一个根本性的疑问：在追求<strong>人工智能</strong>的过程中，我们是否正处于创造一种新生命形式的边缘？其影响深远，因为引入具有<strong>自我意识</strong>和<strong>自主决策能力</strong>的实体可能重新定义<strong>生命和智能</strong>的边界。这一诱人的前景需要严格的伦理考量和监管审查，以确保<code>AGI</code>的演化对人类社会产生积极影响，而不会无意中引发具有意想不到后果的<strong>范式转变</strong>。</p>
<p><strong>当前</strong><code>AI</code><strong>元认知的现状</strong>，关于<strong>元认知</strong>的讨论延伸到<code>AGI</code>领域，这些能力被认为同样重要。对于<code>AGI</code>系统，<strong>元认知</strong>能力如<strong>自我意识</strong>、<strong>意识</strong>、<strong>自我进化能力</strong>和<strong>心智理论</strong>被认为是实现<code>AGI</code>的基础。这些内在能力可以使<code>AI</code><strong>系统</strong>自主学习、高效完成任务，并更紧密地与人类意图保持一致。</p>
<ul>
<li><code>AGI</code><strong>中的自我意识</strong>：在<code>AI</code>中发展<strong>自我意识</strong>，特别是在机器人领域，依赖于复杂的概念，如<strong>自我反思</strong>、<strong>元认知</strong>和<strong>自我疏离</strong>。这些概念对于构建具有支持自我描述、使用个人代词和响应自我聚焦线索能力的<strong>认知架构</strong>的社交机器人至关重要，这些能力是促进有效人类互动和环境导航的基础。随着<code>AI</code>系统的演进，赋予它们类似人类的审慎特质的哲学和实际考量正变得越来越重要，预示着一个新兴的研究领域。为了全面理解这一领域，结合<strong>心理学</strong>、<strong>人工智能</strong>和<strong>伦理学</strong>的跨学科方法至关重要。为了无缝融入以人类为中心的世界，<code>AGI</code>必须具备对自身和他人<strong>信念、意图</strong>和<strong>欲望</strong>的<strong>敏锐意识</strong>。这种“<strong>心智理论</strong>”(<code>Premack and Woodruff, 1978</code>)是一种<strong>元能力</strong>，使<code>AGI</code>能够理解和预测行为，从而促进更顺畅的人类互动。这种理解将使<code>AGI</code>在复杂的社会情境中做出更细致和明智的决策。</li>
<li><code>AGI</code><strong>的人格特质</strong>：最近的研究表明，<code>LLMs</code>可以展示一致的<strong>人格特质</strong>，如大五人格或<code>MBTI</code>框架中的类型，<code>ChatGPT</code>通常表现出与<code>ENFJ</code>类型相符的特质。这些模型还倾向于表现出特定的<strong>认知思维风格</strong>，例如<code>ChatGPT</code>的回答中显示出整体思维的倾向。研究越来越多地致力于有意地赋予<code>LLMs</code>特定的人格，使它们能够展示出多样且可验证的行为。</li>
<li><code>AGI</code><strong>元认知在自我进化中的能力</strong>：尽管前述研究将<code>AGI</code>定义为推理等易于衡量的能力，但可能忽视了<strong>元认知能力</strong>如<strong>自我进化</strong>或<strong>自我意识</strong>的潜在重要性。研究主要通过<strong>智能体</strong>的迭代适应来展示这一点，例如任务执行、代码执行或<strong>物理模拟反馈</strong>。其他自我进化策略包括<strong>提示适应</strong>和<strong>优化</strong>、<strong>通过错误识别</strong>和<strong>自我反思持续改进</strong>，以及作为<strong>短期</strong>或<strong>长期学习机制的记忆检索</strong>。这些方法主要强调基于<code>LLMs</code>的循环框架中任务的迭代精炼。相比之下，最新的进展提出了解决<strong>智能体跨任务自我进化的方法</strong>，强调利用过去的经验来有效进化<code>AI</code><strong>系统</strong>。</li>
</ul>
<p>这些特质之所以重要，首先是因为<strong>自我意识</strong>可以通过准确评估自身的优势和局限性，增强<code>AGI</code>的适应性问题解决能力，从而在面对新挑战时实时调整策略。其次，随着<code>AGI</code>与社会功能的联系越来越紧密，伦理和道德决策能力变得越来越重要，需要<strong>自我意识</strong>来导航复杂的道德困境，并确保与人类价值观的一致。此外，<code>AGI</code>自主进化和适应的潜力在没有人类指导的情况下，可能带来更高的长期效率和能力，甚至可能导致其能力的指数级增长——这是真正<code>AGI</code>的关键特征。最后，在<code>AGI</code>中融入<strong>自主意识</strong>可能带来更自然和有效的<strong>人机互动</strong>，增强协作，并在需要与人类团队或社会结构深度融合的场景中开发更直观的用户界面。</p>
<p><code>AGI</code><strong>级别的元认知</strong>，<code>AGI</code><strong>元认知</strong>的未来是一个令人兴奋的可能性领域，可以显著扩展<strong>人工智能</strong>的边界。<code>AGI</code>在增强<strong>心智理论</strong>和<strong>社会推理</strong>方面具有重大潜力。当前的<code>AI</code>在理解他人心理状态方面存在困难，而这对于细致的社交互动至关重要。未来的<code>AGI</code>可以通过<strong>多模态输入</strong>和<strong>先进推理</strong>，更好地模拟他人的<strong>信念、意图</strong>和<strong>行动</strong>。例如，具有<strong>增强社会推理能力</strong>的<code>AGI</code><strong>导师</strong>可以深入理解每个学生的知识、学习风格和动机，提供超个性化的指导。</p>
<ul>
<li><code>AGI</code><strong>潜在的真正自我意识和意识</strong>：未来的<code>AGI</code>可能具备深度的自我意识，能够进行内省、反思，并探讨存在的问题。这将<strong>模糊人工智能</strong>与<strong>生物智能</strong>之间的界限，引发哲学和伦理问题。然而，<code>AI</code>是否能够实现类似人类的意识仍然存在不确定性；这可能需要整合<strong>元认知</strong>、<strong>内省</strong>和<strong>自我感知能力</strong>。想象一个<code>AGI</code><strong>伙伴</strong>，它不仅能够交流，还能在情感上深度共鸣，分享人类的状态。</li>
<li><code>AGI</code><strong>自主自我进化和开放式学习的潜力</strong>：研究应集中在<code>AGI</code><strong>自主自我进化</strong>和<strong>开放式学习</strong>的潜力上。由好奇心和内在动机驱动的<code>AGI</code>可以迅速<strong>自我提升，设定目标，创新策略，并突破界限</strong>。它们可能在某些领域超越人类智能，产生推动领域前进的新见解和突破。想象一个<code>AGI</code><strong>科学家</strong>，它不知疲倦地进行实验，形成和测试假设，并以前所未有的速度做出发现。</li>
</ul>
<p>在思考具有先进<strong>元认知</strong>的<code>AGI</code>的含义和考量时，我们面临关于<strong>意识、智能、伦理</strong>以及我们在世界中位置的深刻问题。将<code>AGI</code>作为富有同情心的伙伴、洞察力的顾问和不知疲倦的创新者融入社会的令人兴奋的潜力，与需要应对创造潜在优越存在和重新定义人类与人工智能边界的挑战相平衡。实现这一<code>AGI</code><strong>元认知</strong>愿景需要大量研究和开发，以弥合当前的能力差距。尽管如此，这一未来的令人敬畏的潜力和哲学挑战使其成为一个极其重要的<code>AI</code>进步领域，值得深思熟虑和努力实现。当我们站在这个新时代的门槛上，以热情、谨慎和深刻的反思来面对<code>AGI</code><strong>元认知</strong>的发展至关重要，因为这将对我们的世界和我们对智能的理解产生深远的影响。</p>
<h5 id="AGI接口：连接世界与AGI"><a href="#AGI接口：连接世界与AGI" class="headerlink" title="AGI接口：连接世界与AGI"></a>AGI接口：连接世界与AGI</h5><p>在开发<code>AGI</code>的过程中，一个至关重要的方面是其与外部世界互动的能力。这种<strong>互动</strong>通过各种接口实现，使<code>AGI</code>系统能够感知、理解并在其<strong>数字</strong>、<strong>物理</strong>或<strong>智力</strong>环境中采取行动。<code>AGI</code>与数字世界的接口概念扩展了其范围，使<strong>智能体</strong>能够与<strong>互联网</strong>、<strong>数据库</strong>、<strong>代码</strong>和<code>API</code>等数字环境互动，并展示出类似人类行为的<strong>智能行为</strong>。这一接口作为桥梁，将<code>AGI</code>与复杂的现实世界场景联系起来，为模拟和互动人类知识和经验的多面性提供了一个不可或缺的平台。通过促进<code>AGI</code>与现实世界信息结构和问题解决情境的互动，这一<strong>数字世界接口</strong>(<code>Interface</code>)加速了更为多才多艺和强大的<strong>人工通用智能</strong>的发展，使其能够在各种领域中有效运作。</p>
<img data-src="/2025/02/23/artificial-intelligence/ML26_theory_study/ml_4.png" class="" title="AGI接口的互联领域：数字接口、物理接口、智能接口">

<ul>
<li><code>AI</code><strong>与物理世界的接口</strong>：将<code>AI</code>集成到物理实体中是追求<code>AGI</code>（通用人工智能）的重要方向。物理世界中的<code>AGI</code>强调通过直接与环境互动来学习，并对现实产生影响，例如创造或修改物质。展望未来，具身智能的<code>AGI</code>之路涵盖了几个关键的研究和发展领域。一个至关重要的领域是增强<code>AI</code>系统的上下文和环境理解能力。<code>AGI</code>需要发展出解释和适应动态现实世界环境的能力，其复杂程度至少要与人类认知相当。这种高级的环境分析和感知能力对于<code>AGI</code>有效地在复杂多变的物理环境中导航和互动至关重要，类似于人类在各种情境中所展现的适应性和直觉。</li>
<li><code>AI</code><strong>与智能的接口</strong>：将<code>AI</code>与其他智能实体（无论是人工智能还是人类）集成是实现<code>AGI</code>的重要方面。与智能接口进行知识交换、协作，并增强整体系统的能力。通常有两种方式来改进将<code>AGI</code>系统与其他系统集成。第一种侧重于通过不同模型之间的顺序交互来实现与<code>AGI</code>模型之间的学习。第二种强调这些模型之间的同步协作，将不同的<strong>智能体</strong>连接起来，形成一个全面而强大的<code>AGI</code>系统。</li>
<li><code>AI</code><strong>与人类的接口</strong>：人类智能一直是<code>AI</code>的最终目标，人类也是<code>AI</code>的主要受益者。在向<code>AGI</code>迈进的过程中，我们应赋予<code>AI</code>与人类互动的能力，以确保<code>AI</code>能够真正造福人类。未来研究需要找出<code>AGI</code>如何在人们想要做的事情上受益的策略。<code>AGI</code>将具备与智能人类相当的能力，带来许多可能性，可以为人类带来好处。然而，如果使用<code>AGI</code>的成本超过其带来的好处，人们可能无法从中获益。展望未来，有许多机会在不同模态和各种环境中设计<code>AGI</code>级别的接口，例如可穿戴计算、智能环境和混合现实。</li>
</ul>
<h5 id="AGI系统：实现AGI机制"><a href="#AGI系统：实现AGI机制" class="headerlink" title="AGI系统：实现AGI机制"></a>AGI系统：实现AGI机制</h5><p>许多大模型（如<code>Llama 2、GPT-4、Gemini、Claude 3、Mistral</code>和<code>DeepSeek</code>）展现出的涌现行为，通常在模型参数数量达到一定规模时出现。使这种扩展在保持<strong>大语言模型</strong>(<code>LLMs</code>)足够效率的同时成为基础：</p>
<ul>
<li>可扩展的模型架构在计算和建模方面进行了基础和算法上的定义；</li>
<li>大规模训练技术优化了更多硬件加速器，这些加速器可能分布在不同的位置；</li>
<li>推理基础设施确保多个模型稳定性和高吞吐量；</li>
<li>成本和效率使数据、模型组合和自动化过程更加高效；</li>
<li>硬件计算平台尝试打破软物理约束，从而为未来的算法创新提供下一代计算能力和硬件基础。</li>
</ul>
<p>这些进步对促进可扩展性至关重要，这一趋势预计将迈向<strong>人工通用智能</strong>(<code>AGI</code>)的过程中继续发挥关键作用。随着<code>AI</code>系统研究和工程的不断改进，我们可以想象模型将在云端的数千个<strong>异构加速器</strong>上进行训练，这不仅将多个智能体连接成一个多功能的整体，还能为人们的日常生活提供即时和个性化的帮助。</p>
<img data-src="/2025/02/23/artificial-intelligence/ML26_theory_study/ml_5.png" class="" title="当前AGI系统的分类">

<p>包括可扩展的模型架构、大规模训练、优化的推理技术、降低成本和提高效率的方法，以及用于<code>AI</code>研究和工程化的下一代计算平台。通过研究和工程化的不断改进，我们可以想象模型将在云端的数千个<strong>异构加速器</strong>上进行训练，这不仅将多个<strong>智能体</strong>连接成一个整体，还能为人们的日常生活提供即时和个性化的帮助。</p>
<p>系统挑战：</p>
<ul>
<li><strong>大量训练数据的需求</strong>，挑战描述：大模型需要大量的训练数据才能达到最优。随着互联网上可用数据量的迅速增长，数据的平均质量和真实性可能不会同样快速提高。这部分是由于生成模型和用户内容创作所致。解决方案：需要更复杂的自动化数据处理流程，以便从不同来源选择、结构化、清理和混合数据，从而实现高效的训练。</li>
<li><strong>迭代速度和成本</strong>，挑战描述：每次大模型训练迭代都需要巨大的资源和时间，尤其是在原型设计和实验阶段。此外，人为错误和系统错误等因素可能导致训练中断。解决方案：自动化的超参数和架构搜索流程，以及合理设计的训练基础设施，可以显著降低迭代成本并提高模型开发速度。</li>
<li><strong>隐私敏感和资源受限环境</strong>，挑战描述：尽管当前的大模型在数据中心部署，集中处理用户请求，但在边缘设备上部署模型以满足隐私或延迟敏感场景的需求日益增长。然而，边缘设备通常在计算和内存能力上有限，这促使开发在资源受限条件下优化技术，同时不损害模型性能。</li>
<li><strong>高效的微调和适应方法</strong>，挑战描述：在特定任务数据上微调预训练模型是最流行的范式。尽管如此，对整个模型权重进行更新所需的计算资源和时间仍然对于许多用户来说是不可接受的。高效的微调方法有助于降低领域适应、智能体训练和特定任务优化的障碍。</li>
<li><strong>服务延迟和吞吐量</strong>，挑战描述：<code>AGI</code>系统需要支持低延迟和高吞吐量，以提供无缝的用户体验和参与度。然而，当前系统通常在批处理优化、首个令牌的时间或单个查询完成时间之间进行权衡。在所有这些指标之间找到平衡是一个具有挑战性的问题。</li>
<li><strong>内存占用</strong>，挑战描述：部署大模型的一个突出挑战是内存占用，尤其是对于<strong>长上下文</strong>和<strong>多模态输入</strong>，由于<strong>自注意力机制</strong>的二次性质。<code>KV</code>缓存是常见的技术，用于以内存换取更快的推理，如果处理不当，也会带来显著的内存负担。</li>
<li><strong>硬件兼容性和加速</strong>，挑战描述：模型服务的性能严重依赖于工程师如何利用硬件的能力。为不同加速器架构设计的专用内核和算法可以显著提高推理速度。与异构设备兼容并创建统一的软件抽象可以帮助充分发挥大模型的潜力。</li>
</ul>
<p><strong>自注意力模式</strong>：<strong>自注意力机制</strong>是<code>Transformer</code>架构的核心，但它随着输入序列长度的增加而增长，这严重限制了其在当前硬件内存容量下处理长上下文任务的潜力。然而，<strong>自注意力</strong>中使用的<strong>全因果掩码</strong>可能并不是最优的，浪费了计算资源和时间。基于“幸运票”假设和结构稀疏性观察，许多研究探索了不同的<strong>注意力掩码模式</strong>，以减少计算和内存需求。</p>
<ul>
<li><strong>滑动窗口模式</strong>：<strong>滑动窗口模式</strong>限制了局部注意力范围，虽然提高了效率，但可能会导致性能略微下降。</li>
<li><strong>膨胀模式</strong>：<strong>膨胀模式</strong>通过降低注意力分辨率来减少计算量。</li>
<li><strong>全局令牌</strong>：一些研究观察到句子中的某些令牌在语义上更重要，因此引入了不同类型的<strong>全局令牌</strong>，以实现高效的注意力机制。</li>
</ul>
<p>值得注意的是，对于不同规模的模型，计算瓶颈可能在<strong>自注意力</strong>和<strong>全连接层</strong>之间切换，而盲目使用基于<strong>启发式的稀疏模式</strong>可能不仅带来微小的加速，还可能导致性能损失。从而激发了对更复杂和适应性高效模式的研究。</p>
<p><strong>模型压缩</strong>：<strong>模型压缩</strong>的目标是减少大型模型的内存占用、计算复杂度和部署成本。常见的方法包括<strong>知识蒸馏</strong>(<code>KD</code>)和<strong>剪枝</strong>等。<strong>知识蒸馏</strong>是一种从大教师模型中提取知识并传递给小学生模型的过程，使得学生模型可以更高效地部署。这种方法可以分为<strong>黑盒</strong>和<strong>白盒</strong>两种：</p>
<ul>
<li><strong>黑盒知识蒸馏</strong>：只需要通过<code>API</code>调用查询教师模型并收集输入输出对来训练学生模型。例如，<code>Alpaca</code>通过从<code>ChatGPT</code>蒸馏，仅需约<code>100</code>美元即可在效率和性能之间取得平衡。</li>
<li><strong>白盒知识蒸馏</strong>：可以访问更多信息，如教师模型的权重和损失值，这可能会促进更好的知识传递。提出了使用<strong>反向</strong><code>KL</code><strong>散度</strong>来防止学生模型过度预测教师分布中的低概率区域。</li>
</ul>
<p><strong>剪枝</strong>：<strong>剪枝</strong>是通过移除模型中不重要的权重、神经元或层来减少模型大小和计算复杂度的方法。常见的剪枝类型包括：</p>
<ul>
<li><strong>无结构剪枝</strong>：移除个别权重以实现<strong>网络稀疏化</strong>。</li>
<li><strong>有结构剪枝</strong>：移除整个通道或层，简化模型架构。例如，<code>ZipLM</code>通过迭代识别和移除损失-运行时间权衡最差的组件来结构化剪枝模型。</li>
</ul>
<p><strong>内核优化</strong>：内核是为了加速大型网络中的基本计算（如矩阵乘法）而开发的。<strong>内核融合</strong>是一种将两个或多个内核合并为一个的技术，可以减少内核启动的开销和冗余的内存访问。这种技术在许多推理引擎中得到了广泛应用，例如<code>LightSeq、FasterTransformer</code>和<code>ByteTransformer</code>，这些实现主要包括分组的<code>GEMM</code>（通用矩阵乘法）、层归一化、激活计算和自注意力。内核优化的关键技术：</p>
<ul>
<li><strong>内核融合</strong>：通过合并多个内核，减少内核启动的开销和内存访问次数，从而提高计算效率。</li>
<li><strong>利用</strong><code>GPU</code><strong>内存层次</strong>：通过优化内存访问模式，隐藏内存延迟并最大化线程占用率，以提高计算效率。</li>
</ul>
<p><strong>自动编译技术</strong>：随着对高度优化的内核实现的需求增加，<strong>自动编译技术</strong>已经成为一个非常活跃的研究领域。这种方法比源代码库（如<code>CUTLASS</code>、<code>cuBLAS</code>和<code>cuDNN</code>）提供了更大的灵活性。自动编译工具包括：</p>
<ul>
<li><code>TVM</code>（<code>Tensor Virtual Machine</code>）：<code>TVM</code>可以将代码编译为高度优化的低级代码，同时提供<code>Python</code>接口以便于快速原型开发。</li>
<li><code>Triton</code>：<code>Triton</code>提供了一个<code>Python</code>接口，允许用户编写自定义内核，并适应不同计算平台和后端的异构设备。</li>
<li><code>JAX</code>：<code>JAX</code>提供了一个<code>Python</code>接口，用于编写自定义内核，并支持多种硬件加速器。</li>
</ul>
<p>这些工具不仅降低了编写自定义内核的学习曲线，还提供了适应不同计算平台的抽象层。</p>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>umbrella
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://fresh88888888.github.io/2025/02/23/artificial-intelligence/ML26_theory_study/" title="机器学习(ML)(二十六) — 强化学习探析">https://fresh88888888.github.io/2025/02/23/artificial-intelligence/ML26_theory_study/</a>
  </li>
  <li class="post-copyright-license">
      <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/AI/" rel="tag"># AI</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2025/01/17/artificial-intelligence/ML25_theory_study/" rel="prev" title="机器学习(ML)(二十五) — 强化学习探析">
                  <i class="fa fa-chevron-left"></i> 机器学习(ML)(二十五) — 强化学习探析
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2025/03/15/artificial-intelligence/ML27_theory_study/" rel="next" title="机器学习(ML)(二十七) — 强化学习探析">
                  机器学习(ML)(二十七) — 强化学习探析 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments utterances-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">辽ICP备15012817号-2 </a>
  </div>
  <div class="copyright">
    &copy; 2022 – 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">umbrella</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">1.4m</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">77:32</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/fresh88888888" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script size="300" alpha="0.6" zIndex="-1" src="https://cdnjs.cloudflare.com/ajax/libs/ribbon.js/1.0.2/ribbon.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.0/jquery.min.js" integrity="sha256-2Pmvv0kuTBOenSvLm6bvfBSSHrUJ+3A7x6P5Ebd07/g=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.8/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/comments.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/utils.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/motion.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/next-boot.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/pjax.min.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/search/local-search.min.js"></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdnjs.cloudflare.com/ajax/libs/pdfobject/2.2.12/pdfobject.min.js","integrity":"sha256-g2xji1rlE3KsGVClvuxTbcR0Kn2+wtQADSff2Tbb4zA="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/tags/pdf.min.js"></script>



  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/fancybox.min.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/pace.min.js"></script>


  
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  <script src="https://cdnjs.cloudflare.com/ajax/libs/quicklink/2.3.0/quicklink.umd.js" integrity="sha256-yvJQOINiH9fWemHn0vCA5lsHWJaHs6/ZmO+1Ft04SvM=" crossorigin="anonymous"></script>
  <script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":true,"archive":true,"delay":true,"timeout":5000,"priority":true,"url":"https://fresh88888888.github.io/2025/02/23/artificial-intelligence/ML26_theory_study/"}</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/quicklink.min.js"></script>
<script class="next-config" data-name="utterances" type="application/json">{"enable":true,"repo":"fresh88888888.github.io","issue_term":"title","theme":"github-light"}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/comments/utterances.min.js"></script>

</body>
</html>
