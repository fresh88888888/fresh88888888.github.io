<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.2">
<link rel="preconnect" href="https://fonts.googleapis.com" crossorigin>
<link rel="preconnect" href="https://cdnjs.cloudflare.com" crossorigin>
  <link rel="apple-touch-icon" sizes="180x180" href="/favicon.ico">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon.ico">
  <link rel="mask-icon" href="/favicon.ico" color="#222">
  <meta name="google-site-verification" content="lk2gSYFP_NyLNFob-fFnt7fm-I_n1ZYws-WZll7mshg">
  <meta name="msvalidate.01" content="6Jdc01DjYOLguhS5">
  <meta name="baidu-site-verification" content="code-NR10G09zww">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic%7Ccursive:300,300italic,400,400italic,700,700italic%7CSource+Code+Pro:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/yellow/pace-theme-minimal.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"fresh88888888.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.17.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"flat"},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":true,"nav":null},"stickytabs":true,"motion":{"enable":true,"async":true,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/local-search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":10,"unescape":false,"preload":true}}</script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/config.min.js"></script>

    <meta name="description" content="TensorFlow Recommenders(TFRS)是一个用于构建推荐（Recommender）系统模型的库，在推荐（Recommender）系统的整个构建流程 - 无论是数据准备、模型构建、训练、评估还是部署都可以起到很大的作用。TFRS融合了多任务学习、特征交互建模和TPU训练的研究成果。推荐系统通常有多个组件来进行检索、排名和后期排名。 推荐系统通常由两个阶段组成：  检索阶段：负责从">
<meta property="og:type" content="article">
<meta property="og:title" content="检索模型（TensorFlow 构建推荐系统）">
<meta property="og:url" content="https://fresh88888888.github.io/2024/04/17/artificial-intelligence/TFRS_study/index.html">
<meta property="og:site_name" content="UMBRELLA">
<meta property="og:description" content="TensorFlow Recommenders(TFRS)是一个用于构建推荐（Recommender）系统模型的库，在推荐（Recommender）系统的整个构建流程 - 无论是数据准备、模型构建、训练、评估还是部署都可以起到很大的作用。TFRS融合了多任务学习、特征交互建模和TPU训练的研究成果。推荐系统通常有多个组件来进行检索、排名和后期排名。 推荐系统通常由两个阶段组成：  检索阶段：负责从">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://fresh88888888.github.io/2024/04/17/artificial-intelligence/TFRS_study/tfrs_1.png">
<meta property="article:published_time" content="2024-04-17T02:50:11.000Z">
<meta property="article:modified_time" content="2024-04-17T02:50:11.000Z">
<meta property="article:author" content="umbrella">
<meta property="article:tag" content="AI">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://fresh88888888.github.io/2024/04/17/artificial-intelligence/TFRS_study/tfrs_1.png">


<link rel="canonical" href="https://fresh88888888.github.io/2024/04/17/artificial-intelligence/TFRS_study/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://fresh88888888.github.io/2024/04/17/artificial-intelligence/TFRS_study/","path":"2024/04/17/artificial-intelligence/TFRS_study/","title":"检索模型（TensorFlow 构建推荐系统）"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>检索模型（TensorFlow 构建推荐系统） | UMBRELLA</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">UMBRELLA</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">未雨绸缪，举重若轻</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-算法"><a href="/Algorithm/" rel="section"><i class="fa fa-calendar fa-fw"></i>算法</a></li><li class="menu-item menu-item-c++-&nbsp;编程"><a href="/Programming-C++/" rel="section"><i class="fa fa-heartbeat fa-fw"></i>C++ &nbsp;编程</a></li><li class="menu-item menu-item-rust-编程"><a href="/Programming-Rust/" rel="section"><i class="fa fa-cat fa-fw"></i>Rust 编程</a></li><li class="menu-item menu-item-go-&nbsp;&nbsp;&nbsp;编程"><a href="/Programming-Go/" rel="section"><i class="fa fa-hippo fa-fw"></i>Go &nbsp;&nbsp;&nbsp;编程</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A3%80%E7%B4%A2%E6%A8%A1%E5%9E%8B%EF%BC%88Retrieval-Model%EF%BC%89"><span class="nav-number">1.</span> <span class="nav-text">检索模型（Retrieval Model）</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">1.1.</span> <span class="nav-text">数据集</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">1.2.</span> <span class="nav-text">准备数据集</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0%E6%A3%80%E7%B4%A2%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.3.</span> <span class="nav-text">实现检索模型</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%8B%9F%E5%90%88%E5%92%8C%E8%AF%84%E4%BC%B0"><span class="nav-number">1.4.</span> <span class="nav-text">拟合和评估</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%9C%8D%E5%8A%A1"><span class="nav-number">1.5.</span> <span class="nav-text">服务</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%80%90%E9%A1%B9%E6%8E%A8%E8%8D%90"><span class="nav-number">1.6.</span> <span class="nav-text">逐项推荐</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="umbrella"
      src="/avatar.jpeg">
  <p class="site-author-name" itemprop="name">umbrella</p>
  <div class="site-description" itemprop="description">没事就多看看书</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">188</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">21</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">65</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/fresh88888888" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;fresh88888888" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:fresh888888@foxmail.com" title="E-Mail → mailto:fresh888888@foxmail.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
    </div>

    
    <div class="sidebar-inner sidebar-blogroll">
      <div class="links-of-blogroll animated">
        <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
          链接
        </div>
        <ul class="links-of-blogroll-list">
            <li class="links-of-blogroll-item">
              <a href="https://www.rust-lang.org/zh-CN/" title="https:&#x2F;&#x2F;www.rust-lang.org&#x2F;zh-CN&#x2F;" rel="noopener" target="_blank">Rust</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://go.dev/" title="https:&#x2F;&#x2F;go.dev&#x2F;" rel="noopener" target="_blank">Golang</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://isocpp.org/" title="https:&#x2F;&#x2F;isocpp.org&#x2F;" rel="noopener" target="_blank">C++</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://www.python.org/" title="https:&#x2F;&#x2F;www.python.org&#x2F;" rel="noopener" target="_blank">Python</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://doc.rust-lang.org/cargo/index.html" title="https:&#x2F;&#x2F;doc.rust-lang.org&#x2F;cargo&#x2F;index.html" rel="noopener" target="_blank">Cargo</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://gist.github.com/rxaviers/7360908" title="https:&#x2F;&#x2F;gist.github.com&#x2F;rxaviers&#x2F;7360908" rel="noopener" target="_blank">Emoji</a>
            </li>
        </ul>
      </div>
    </div>
        <div class="pjax">
        </div>
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://fresh88888888.github.io/2024/04/17/artificial-intelligence/TFRS_study/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/avatar.jpeg">
      <meta itemprop="name" content="umbrella">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="UMBRELLA">
      <meta itemprop="description" content="没事就多看看书">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="检索模型（TensorFlow 构建推荐系统） | UMBRELLA">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          检索模型（TensorFlow 构建推荐系统）
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-04-17 10:50:11" itemprop="dateCreated datePublished" datetime="2024-04-17T10:50:11+08:00">2024-04-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" itemprop="url" rel="index"><span itemprop="name">人工智能</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3.2k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>11 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p><code>TensorFlow Recommenders(TFRS)</code>是一个用于构建推荐（<code>Recommender</code>）系统模型的库，在推荐（<code>Recommender</code>）系统的整个构建流程 - 无论是数据准备、模型构建、训练、评估还是部署都可以起到很大的作用。<code>TFRS</code>融合了多任务学习、特征交互建模和<code>TPU</code>训练的研究成果。推荐系统通常有多个组件来进行检索、排名和后期排名。</p>
<p>推荐系统通常由两个阶段组成：</p>
<ul>
<li><strong>检索阶段</strong>：负责从所有可能的候选者中选择数百个候选者的初始集合。检索模型的主要目标是有效地剔除用户不感兴趣的所有候选者。由于检索模型可能要处理数百万个候选者，因此它必须具有很高的计算效率。</li>
<li><strong>排名阶段</strong>：获取检索模型的输出，并对它们进行微调以选择尽可能好的推荐。它的任务是将用户感兴趣的项目集缩小到可能的候选者的候选名单。<span id="more"></span></li>
</ul>
<p>以下是一个简单的示例：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装&amp;导入TFRS</span></span><br><span class="line">!pip install -q tensorflow-recommenders</span><br><span class="line">!pip install -q --upgrade tensorflow-datasets</span><br></pre></td></tr></table></figure>
<p>读取数据、定义、训练模型和预测：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> tensorflow_datasets <span class="keyword">as</span> tfds</span><br><span class="line"><span class="keyword">import</span> tensorflow_recommenders <span class="keyword">as</span> tfrs</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Dict</span>, Text</span><br><span class="line"></span><br><span class="line"><span class="comment"># 评分数据</span></span><br><span class="line"><span class="comment"># Ratings data.</span></span><br><span class="line">ratings = tfds.load(<span class="string">&#x27;movielens/100k-ratings&#x27;</span>, split=<span class="string">&quot;train&quot;</span>)</span><br><span class="line"><span class="comment"># Features of all the available movies.</span></span><br><span class="line">movies = tfds.load(<span class="string">&#x27;movielens/100k-movies&#x27;</span>, split=<span class="string">&quot;train&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Select the basic features.</span></span><br><span class="line">ratings = ratings.<span class="built_in">map</span>(<span class="keyword">lambda</span> x: &#123;<span class="string">&quot;movie_title&quot;</span>: x[<span class="string">&quot;movie_title&quot;</span>],<span class="string">&quot;user_id&quot;</span>: x[<span class="string">&quot;user_id&quot;</span>]&#125;)</span><br><span class="line">movies = movies.<span class="built_in">map</span>(<span class="keyword">lambda</span> x: x[<span class="string">&quot;movie_title&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建词汇表以将用户ID和电影标题转换为嵌入层的整数索引：</span></span><br><span class="line">user_ids_vocabulary = tf.keras.layers.StringLookup(mask_token=<span class="literal">None</span>)</span><br><span class="line">user_ids_vocabulary.adapt(ratings.<span class="built_in">map</span>(<span class="keyword">lambda</span> x: x[<span class="string">&quot;user_id&quot;</span>]))</span><br><span class="line"></span><br><span class="line">movie_titles_vocabulary = tf.keras.layers.StringLookup(mask_token=<span class="literal">None</span>)</span><br><span class="line">movie_titles_vocabulary.adapt(movies)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义两个模型和检索任务。</span></span><br><span class="line"><span class="comment"># Define user and movie models.</span></span><br><span class="line">user_model = tf.keras.Sequential([</span><br><span class="line">    user_ids_vocabulary,</span><br><span class="line">    tf.keras.layers.Embedding(user_ids_vocabulary.vocab_size(), <span class="number">64</span>)</span><br><span class="line">])</span><br><span class="line">movie_model = tf.keras.Sequential([</span><br><span class="line">    movie_titles_vocabulary,</span><br><span class="line">    tf.keras.layers.Embedding(movie_titles_vocabulary.vocab_size(), <span class="number">64</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define your objectives.</span></span><br><span class="line">task = tfrs.tasks.Retrieval(metrics=tfrs.metrics.FactorizedTopK(</span><br><span class="line">    movies.batch(<span class="number">128</span>).<span class="built_in">map</span>(movie_model)</span><br><span class="line">  )</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建模型、训练模型并生成预测：</span></span><br><span class="line"><span class="comment"># Create a retrieval model.</span></span><br><span class="line">model = MovieLensModel(user_model, movie_model, task)</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=tf.keras.optimizers.Adagrad(<span class="number">0.5</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train for 3 epochs.</span></span><br><span class="line">model.fit(ratings.batch(<span class="number">4096</span>), epochs=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use brute-force search to set up retrieval using the trained representations.</span></span><br><span class="line">index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)</span><br><span class="line">index.index_from_dataset(movies.batch(<span class="number">100</span>).<span class="built_in">map</span>(<span class="keyword">lambda</span> title: (title, model.movie_model(title))))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get some recommendations.</span></span><br><span class="line">_, titles = index(np.array([<span class="string">&quot;42&quot;</span>]))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Top 3 recommendations for user 42: <span class="subst">&#123;titles[<span class="number">0</span>, :<span class="number">3</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MovieLensModel</span>(tfrs.Model):</span><br><span class="line">  <span class="comment"># We derive from a custom base class to help reduce boilerplate. Under the hood,</span></span><br><span class="line">  <span class="comment"># these are still plain Keras Models.</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,user_model: tf.keras.Model,movie_model: tf.keras.Model,task: tfrs.tasks.Retrieval</span>):</span><br><span class="line">    <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Set up user and movie representations.</span></span><br><span class="line">    self.user_model = user_model</span><br><span class="line">    self.movie_model = movie_model</span><br><span class="line">    <span class="comment"># Set up a retrieval task.</span></span><br><span class="line">    self.task = task</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">compute_loss</span>(<span class="params">self, features: <span class="type">Dict</span>[Text, tf.Tensor], training=<span class="literal">False</span></span>) -&gt; tf.Tensor:</span><br><span class="line">    <span class="comment"># Define how the loss is computed.</span></span><br><span class="line">    user_embeddings = self.user_model(features[<span class="string">&quot;user_id&quot;</span>])</span><br><span class="line">    movie_embeddings = self.movie_model(features[<span class="string">&quot;movie_title&quot;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> self.task(user_embeddings, movie_embeddings)</span><br></pre></td></tr></table></figure>
<p>结果输出为：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Epoch 1/3</span><br><span class="line">25/25 [==============================] - 34s 1s/step - factorized_top_k/top_1_categorical_accuracy: 7.0000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0016 - factorized_top_k/top_10_categorical_accuracy: 0.0050 - factorized_top_k/top_50_categorical_accuracy: 0.0457 - factorized_top_k/top_100_categorical_accuracy: 0.1034 - loss: 33069.6692 - regularization_loss: 0.0000e+00 - total_loss: 33069.6692</span><br><span class="line">Epoch 2/3</span><br><span class="line">25/25 [==============================] - 31s 1s/step - factorized_top_k/top_1_categorical_accuracy: 2.8000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0052 - factorized_top_k/top_10_categorical_accuracy: 0.0150 - factorized_top_k/top_50_categorical_accuracy: 0.1054 - factorized_top_k/top_100_categorical_accuracy: 0.2118 - loss: 31012.9641 - regularization_loss: 0.0000e+00 - total_loss: 31012.9641</span><br><span class="line">Epoch 3/3</span><br><span class="line">25/25 [==============================] - 30s 1s/step - factorized_top_k/top_1_categorical_accuracy: 5.3000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0088 - factorized_top_k/top_10_categorical_accuracy: 0.0228 - factorized_top_k/top_50_categorical_accuracy: 0.1445 - factorized_top_k/top_100_categorical_accuracy: 0.2675 - loss: 30421.9365 - regularization_loss: 0.0000e+00 - total_loss: 30421.9365</span><br><span class="line"></span><br><span class="line">Top 3 recommendations <span class="keyword">for</span> user 42: [b<span class="string">&#x27;Just Cause (1995)&#x27;</span> b<span class="string">&#x27;Rent-a-Kid (1995)&#x27;</span> b<span class="string">&#x27;Cobb (1994)&#x27;</span>]</span><br></pre></td></tr></table></figure>
<h4 id="检索模型（Retrieval-Model）"><a href="#检索模型（Retrieval-Model）" class="headerlink" title="检索模型（Retrieval Model）"></a>检索模型（Retrieval Model）</h4><p>检索模型通常由两个子模型组成：</p>
<ul>
<li>使用查询特征计算查询表示（<code>normally a fixed-dimensionality embedding vector</code>）的<strong>查询模型</strong>。</li>
<li>使用候选特征计算候选表示（<code>an equally-sized vector</code>）的<strong>候选模型</strong>。</li>
</ul>
<p>然后将两个模型的输出相乘以给出查询-候选者亲和力分数，分数越高表示候选者和查询之间的匹配越好。我们接下来的步骤：</p>
<ul>
<li>获取数据并将其分成训练集和测试集。</li>
<li>实现检索模型。</li>
<li>模型拟合并评估。</li>
<li>通过构建近似最近邻(<code>ANN</code>)索引将其导出以实现高效检索。</li>
</ul>
<h5 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h5><p>在本示例中，我们将使用<code>Movielens</code>数据集构建和训练这样的两塔模型。<code>Movielens</code>数据集是明尼苏达大学<code>GroupLens</code>研究小组的经典数据集。它包含一组用户对电影的评分，是推荐系统研究的主要数据集。我们可以通过两种方式处理数据：</p>
<ul>
<li>它可以解释为：用户观看和评价了哪些电影，以及没有观看和评价哪些电影。这是一种<strong>隐式反馈</strong>，用户的<code>watches</code>会告诉我们他们喜欢看到哪些内容以及不想看到哪些内容。</li>
<li>它也可以被视为用户对他们观看的电影的喜爱程度。这是一种<strong>显示反馈</strong>：假设用户观看了一部电影，我们可以通过查看他们给出的评分来了解他们的喜欢程度。</li>
</ul>
<p>在本示例中，我们重点关注<strong>检索系统</strong>：从目录中预测用户可能观看的一组电影的模型。通常，隐式数据在这里更有用，因此我们将<code>Movielens</code>视为<strong>隐式系统</strong>。这意味着用户观看的每一部电影都是一个正例，而他们没有看过的每一部电影都是一个隐含的反例。</p>
<h5 id="准备数据集"><a href="#准备数据集" class="headerlink" title="准备数据集"></a>准备数据集</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pprint</span><br><span class="line"><span class="keyword">import</span> tempfile</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> tensorflow_datasets <span class="keyword">as</span> tfds</span><br><span class="line"><span class="keyword">import</span> tensorflow_recommenders <span class="keyword">as</span> tfrs</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Dict</span>, Text</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请注意，由于MovieLens数据集没有预定义的分割，因此所有数据都在训练分割下。</span></span><br><span class="line"><span class="comment"># Ratings data.</span></span><br><span class="line">ratings = tfds.load(<span class="string">&quot;movielens/100k-ratings&quot;</span>, split=<span class="string">&quot;train&quot;</span>)</span><br><span class="line"><span class="comment"># Features of all the available movies.</span></span><br><span class="line">movies = tfds.load(<span class="string">&quot;movielens/100k-movies&quot;</span>, split=<span class="string">&quot;train&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在此示例中，我们将重点关注收视率数据。我们只在数据集中保留user_id和movie_title字段。</span></span><br><span class="line">ratings = ratings.<span class="built_in">map</span>(<span class="keyword">lambda</span> x: &#123;<span class="string">&quot;movie_title&quot;</span>: x[<span class="string">&quot;movie_title&quot;</span>],<span class="string">&quot;user_id&quot;</span>: x[<span class="string">&quot;user_id&quot;</span>],&#125;)</span><br><span class="line">movies = movies.<span class="built_in">map</span>(<span class="keyword">lambda</span> x: x[<span class="string">&quot;movie_title&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 我们使用随机分割，将80%的评级放入训练集中，将20%的评级放入测试集中。</span></span><br><span class="line">tf.random.set_seed(<span class="number">42</span>)</span><br><span class="line">shuffled = ratings.shuffle(<span class="number">100_000</span>, seed=<span class="number">42</span>, reshuffle_each_iteration=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">train = shuffled.take(<span class="number">80_000</span>)</span><br><span class="line">test = shuffled.skip(<span class="number">80_000</span>).take(<span class="number">20_000</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 我们还可以找出数据中存在的唯一用户ID和电影标题。</span></span><br><span class="line"><span class="comment"># 我们需要能够将分类特征的原始值映射到模型中的嵌入向量。</span></span><br><span class="line"><span class="comment"># 为此，我们需要一个将原始特征值映射到连续范围内的整数的词汇表：这使我们能够在嵌入表中查找相应的嵌入。</span></span><br><span class="line">movie_titles = movies.batch(<span class="number">1_000</span>)</span><br><span class="line">user_ids = ratings.batch(<span class="number">1_000_000</span>).<span class="built_in">map</span>(<span class="keyword">lambda</span> x: x[<span class="string">&quot;user_id&quot;</span>])</span><br><span class="line">unique_movie_titles = np.unique(np.concatenate(<span class="built_in">list</span>(movie_titles)))</span><br><span class="line">unique_user_ids = np.unique(np.concatenate(<span class="built_in">list</span>(user_ids)))</span><br><span class="line"></span><br><span class="line">unique_movie_titles[:<span class="number">10</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># array([b&quot;&#x27;Til There Was You (1997)&quot;, b&#x27;1-900 (1994)&#x27;,</span></span><br><span class="line"><span class="comment">#        b&#x27;101 Dalmatians (1996)&#x27;, b&#x27;12 Angry Men (1957)&#x27;, b&#x27;187 (1997)&#x27;,</span></span><br><span class="line"><span class="comment">#        b&#x27;2 Days in the Valley (1996)&#x27;,</span></span><br><span class="line"><span class="comment">#        b&#x27;20,000 Leagues Under the Sea (1954)&#x27;,</span></span><br><span class="line"><span class="comment">#        b&#x27;2001: A Space Odyssey (1968)&#x27;,</span></span><br><span class="line"><span class="comment">#        b&#x27;3 Ninjas: High Noon At Mega Mountain (1998)&#x27;,</span></span><br><span class="line"><span class="comment">#        b&#x27;39 Steps, The (1935)&#x27;], dtype=object)</span></span><br></pre></td></tr></table></figure>
<h5 id="实现检索模型"><a href="#实现检索模型" class="headerlink" title="实现检索模型"></a>实现检索模型</h5><p>选择模型的架构是建模的关键部分。因为我们正在构建一个两塔检索模型，所以我们可以单独构建每个塔，然后将它们组合到最终模型中。</p>
<img data-src="/2024/04/17/artificial-intelligence/TFRS_study/tfrs_1.png" class="">

<p>“塔”这个词的意思是输入层之上的全连接层遵循塔模式，即这些层的宽度逐渐减小，这使得它们看起来像一个堆叠的塔。正如你在上图所看到的，左侧有一座塔将用户特征映射到用户嵌入，我们称之为查询塔。右侧的另一个塔将项目特征映射到项目嵌入，我们称之为候选塔。模型的输出定义为用户嵌入和项目嵌入的点积。这个简单的模型实际上对应于<strong>矩阵分解模型</strong>，我们首先定义查询塔：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第一步是确定查询和候选表示的维度：较高的值对应的模型可能更准确，但拟合速度也会较慢并且更容易过度拟合。</span></span><br><span class="line">embedding_dimension = <span class="number">32</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二步是定义模型本身。在这里，我们将使用Keras预处理层首先将用户ID转换为整数，然后通过嵌入层将其转换为用户嵌入。 </span></span><br><span class="line"><span class="comment"># 请注意，我们使用之前计算的唯一用户ID列表作为词汇表：</span></span><br><span class="line">user_model = tf.keras.Sequential([</span><br><span class="line">  tf.keras.layers.StringLookup(vocabulary=unique_user_ids, mask_token=<span class="literal">None</span>),</span><br><span class="line">  <span class="comment"># We add an additional embedding to account for unknown tokens.</span></span><br><span class="line">  tf.keras.layers.Embedding(<span class="built_in">len</span>(unique_user_ids) + <span class="number">1</span>, embedding_dimension)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 候选塔</span></span><br><span class="line">movie_model = tf.keras.Sequential([</span><br><span class="line">  tf.keras.layers.StringLookup(vocabulary=unique_movie_titles, mask_token=<span class="literal">None</span>),</span><br><span class="line">  tf.keras.layers.Embedding(<span class="built_in">len</span>(unique_movie_titles) + <span class="number">1</span>, embedding_dimension)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在我们的训练数据中，我们有正对（user, movie）。 </span></span><br><span class="line"><span class="comment"># 为了弄清楚我们的模型有多好，我们需要将模型为该对计算的亲和力分数与所有其他可能候选者的分数进行比较：</span></span><br><span class="line"><span class="comment"># 如果正对的分数高于所有其他候选者，该模型很准确。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 为此，我们可以使用tfrs.metrics.FactorizedTopK指标。该指标有一个必需的参数：用作评估隐式否定的候选数据集。</span></span><br><span class="line">metrics = tfrs.metrics.FactorizedTopK(candidates=movies.batch(<span class="number">128</span>).<span class="built_in">map</span>(movie_model))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下一个组成部分是用于训练模型的损失。在本例中，我们将利用检索任务对象：一个将损失函数和度量计算捆绑在一起的便捷包装器：</span></span><br><span class="line">task = tfrs.tasks.Retrieval(</span><br><span class="line">  metrics=metrics</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>我们现在可以将它们全部整合到一个模型中。<code>TFRS</code>公开了一个基本模型类(<code>tfrs.models.Model</code>)，它简化了构建模型的过程：我们需要做的就是在<code>__init__</code>方法中设置组件，并实现<code>compute_loss</code>方法，获取原始特征并返回损失值。然后，基础模型将负责创建适当的训练循环以适应我们的模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MovielensModel</span>(tfrs.Model):</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, user_model, movie_model</span>):</span><br><span class="line">    <span class="built_in">super</span>().__init__()</span><br><span class="line">    self.movie_model: tf.keras.Model = movie_model</span><br><span class="line">    self.user_model: tf.keras.Model = user_model</span><br><span class="line">    self.task: tf.keras.layers.Layer = task</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">compute_loss</span>(<span class="params">self, features: <span class="type">Dict</span>[Text, tf.Tensor], training=<span class="literal">False</span></span>) -&gt; tf.Tensor:</span><br><span class="line">    <span class="comment"># We pick out the user features and pass them into the user model.</span></span><br><span class="line">    user_embeddings = self.user_model(features[<span class="string">&quot;user_id&quot;</span>])</span><br><span class="line">    <span class="comment"># And pick out the movie features and pass them into the movie model,</span></span><br><span class="line">    <span class="comment"># getting embeddings back.</span></span><br><span class="line">    positive_movie_embeddings = self.movie_model(features[<span class="string">&quot;movie_title&quot;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># The task computes the loss and the metrics.</span></span><br><span class="line">    <span class="keyword">return</span> self.task(user_embeddings, positive_movie_embeddings)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NoBaseClassMovielensModel</span>(tf.keras.Model):</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, user_model, movie_model</span>):</span><br><span class="line">    <span class="built_in">super</span>().__init__()</span><br><span class="line">    self.movie_model: tf.keras.Model = movie_model</span><br><span class="line">    self.user_model: tf.keras.Model = user_model</span><br><span class="line">    self.task: tf.keras.layers.Layer = task</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">train_step</span>(<span class="params">self, features: <span class="type">Dict</span>[Text, tf.Tensor]</span>) -&gt; tf.Tensor:</span><br><span class="line">    <span class="comment"># Set up a gradient tape to record gradients.</span></span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line"></span><br><span class="line">      <span class="comment"># Loss computation.</span></span><br><span class="line">      user_embeddings = self.user_model(features[<span class="string">&quot;user_id&quot;</span>])</span><br><span class="line">      positive_movie_embeddings = self.movie_model(features[<span class="string">&quot;movie_title&quot;</span>])</span><br><span class="line">      loss = self.task(user_embeddings, positive_movie_embeddings)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># Handle regularization losses as well.</span></span><br><span class="line">      regularization_loss = <span class="built_in">sum</span>(self.losses)</span><br><span class="line"></span><br><span class="line">      total_loss = loss + regularization_loss</span><br><span class="line"></span><br><span class="line">    gradients = tape.gradient(total_loss, self.trainable_variables)</span><br><span class="line">    self.optimizer.apply_gradients(<span class="built_in">zip</span>(gradients, self.trainable_variables))</span><br><span class="line"></span><br><span class="line">    metrics = &#123;metric.name: metric.result() <span class="keyword">for</span> metric <span class="keyword">in</span> self.metrics&#125;</span><br><span class="line">    metrics[<span class="string">&quot;loss&quot;</span>] = loss</span><br><span class="line">    metrics[<span class="string">&quot;regularization_loss&quot;</span>] = regularization_loss</span><br><span class="line">    metrics[<span class="string">&quot;total_loss&quot;</span>] = total_loss</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> metrics</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">test_step</span>(<span class="params">self, features: <span class="type">Dict</span>[Text, tf.Tensor]</span>) -&gt; tf.Tensor:</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Loss computation.</span></span><br><span class="line">    user_embeddings = self.user_model(features[<span class="string">&quot;user_id&quot;</span>])</span><br><span class="line">    positive_movie_embeddings = self.movie_model(features[<span class="string">&quot;movie_title&quot;</span>])</span><br><span class="line">    loss = self.task(user_embeddings, positive_movie_embeddings)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Handle regularization losses as well.</span></span><br><span class="line">    regularization_loss = <span class="built_in">sum</span>(self.losses)</span><br><span class="line"></span><br><span class="line">    total_loss = loss + regularization_loss</span><br><span class="line"></span><br><span class="line">    metrics = &#123;metric.name: metric.result() <span class="keyword">for</span> metric <span class="keyword">in</span> self.metrics&#125;</span><br><span class="line">    metrics[<span class="string">&quot;loss&quot;</span>] = loss</span><br><span class="line">    metrics[<span class="string">&quot;regularization_loss&quot;</span>] = regularization_loss</span><br><span class="line">    metrics[<span class="string">&quot;total_loss&quot;</span>] = total_loss</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> metrics</span><br></pre></td></tr></table></figure>
<h5 id="拟合和评估"><a href="#拟合和评估" class="headerlink" title="拟合和评估"></a>拟合和评估</h5><p>定义模型后，我们可以使用标准的<code>Keras</code>拟合和评估例程来拟合和评估模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 我们首先实例化模型。</span></span><br><span class="line">model = MovielensModel(user_model, movie_model)</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=tf.keras.optimizers.Adagrad(learning_rate=<span class="number">0.1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 然后对训练和评估数据进行混洗、批处理和缓存。</span></span><br><span class="line">cached_train = train.shuffle(<span class="number">100_000</span>).batch(<span class="number">8192</span>).cache()</span><br><span class="line">cached_test = test.batch(<span class="number">4096</span>).cache()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型：</span></span><br><span class="line">model.fit(cached_train, epochs=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Epoch 1/3</span></span><br><span class="line"><span class="comment"># 10/10 [==============================] - 6s 309ms/step - factorized_top_k/top_1_categorical_accuracy: 7.2500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0063 - factorized_top_k/top_10_categorical_accuracy: 0.0140 - factorized_top_k/top_50_categorical_accuracy: 0.0753 - factorized_top_k/top_100_categorical_accuracy: 0.1471 - loss: 69820.5881 - regularization_loss: 0.0000e+00 - total_loss: 69820.5881</span></span><br><span class="line"><span class="comment"># Epoch 2/3</span></span><br><span class="line"><span class="comment"># 10/10 [==============================] - 3s 302ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0011 - factorized_top_k/top_5_categorical_accuracy: 0.0119 - factorized_top_k/top_10_categorical_accuracy: 0.0260 - factorized_top_k/top_50_categorical_accuracy: 0.1403 - factorized_top_k/top_100_categorical_accuracy: 0.2616 - loss: 67457.6612 - regularization_loss: 0.0000e+00 - total_loss: 67457.6612</span></span><br><span class="line"><span class="comment"># Epoch 3/3</span></span><br><span class="line"><span class="comment"># 10/10 [==============================] - 3s 301ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0014 - factorized_top_k/top_5_categorical_accuracy: 0.0189 - factorized_top_k/top_10_categorical_accuracy: 0.0400 - factorized_top_k/top_50_categorical_accuracy: 0.1782 - factorized_top_k/top_100_categorical_accuracy: 0.3056 - loss: 66284.5682 - regularization_loss: 0.0000e+00 - total_loss: 66284.5682</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 最后，我们可以在测试集上评估我们的模型：</span></span><br><span class="line">model.evaluate(cached_test, return_dict=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># &#123;&#x27;factorized_top_k/top_1_categorical_accuracy&#x27;: 0.0010000000474974513,</span></span><br><span class="line"><span class="comment">#  &#x27;factorized_top_k/top_5_categorical_accuracy&#x27;: 0.008700000122189522,</span></span><br><span class="line"><span class="comment">#  &#x27;factorized_top_k/top_10_categorical_accuracy&#x27;: 0.021150000393390656,</span></span><br><span class="line"><span class="comment">#  &#x27;factorized_top_k/top_50_categorical_accuracy&#x27;: 0.121799997985363,</span></span><br><span class="line"><span class="comment">#  &#x27;factorized_top_k/top_100_categorical_accuracy&#x27;: 0.23340000212192535,</span></span><br><span class="line"><span class="comment">#  &#x27;loss&#x27;: 28256.8984375,</span></span><br><span class="line"><span class="comment">#  &#x27;regularization_loss&#x27;: 0,</span></span><br><span class="line"><span class="comment">#  &#x27;total_loss&#x27;: 28256.8984375&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型预测：我们可以使用tfrs.layers.factorized_top_k.BruteForce层来做到这一点。</span></span><br><span class="line"><span class="comment"># Create a model that takes in raw query features, and</span></span><br><span class="line">index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)</span><br><span class="line"><span class="comment"># recommends movies out of the entire movies dataset.</span></span><br><span class="line">index.index_from_dataset(</span><br><span class="line">  tf.data.Dataset.<span class="built_in">zip</span>((movies.batch(<span class="number">100</span>), movies.batch(<span class="number">100</span>).<span class="built_in">map</span>(model.movie_model)))</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get recommendations.</span></span><br><span class="line">_, titles = index(tf.constant([<span class="string">&quot;42&quot;</span>]))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Recommendations for user 42: <span class="subst">&#123;titles[<span class="number">0</span>, :<span class="number">3</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Recommendations for user 42: [b&#x27;Christmas Carol, A (1938)&#x27; b&#x27;Rudy (1993)&#x27; b&#x27;Bridges of Madison County, The (1995)&#x27;]</span></span><br></pre></td></tr></table></figure>
<h5 id="服务"><a href="#服务" class="headerlink" title="服务"></a>服务</h5><p>模型训练完成后，我们需要一种部署它的方法。在双塔检索模型中，服务有两个组成部分：</p>
<ul>
<li>服务查询模型，接收查询的特征并将其转换为查询嵌入。</li>
<li>服务候选人模型。这通常采用近似最近邻(<code>ANN</code>)索引的形式，该索引允许响应查询模型生成的查询近似候选对象。</li>
</ul>
<p>在<code>TFRS</code>中，这两个组件都可以打包到单个可导出模型中，该模型采用原始用户<code>ID</code>并返回该用户的热门电影的标题。这是通过将模型导出为<code>SavedModel</code>格式来完成的，这使得可以使用<code>TensorFlow Serving</code>发布服务。要部署这样的模型，我们只需导出上面创建的<code>BruteForce</code>层：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Export the query model.</span></span><br><span class="line"><span class="keyword">with</span> tempfile.TemporaryDirectory() <span class="keyword">as</span> tmp:</span><br><span class="line">  path = os.path.join(tmp, <span class="string">&quot;model&quot;</span>)</span><br><span class="line">  <span class="comment"># Save the index.</span></span><br><span class="line">  tf.saved_model.save(index, path)</span><br><span class="line">  <span class="comment"># Load it back; can also be done in TensorFlow Serving.</span></span><br><span class="line">  loaded = tf.saved_model.load(path)</span><br><span class="line">  <span class="comment"># Pass a user id in, get top predicted movie titles back.</span></span><br><span class="line">  scores, titles = loaded([<span class="string">&quot;42&quot;</span>])</span><br><span class="line"></span><br><span class="line">  <span class="built_in">print</span>(<span class="string">f&quot;Recommendations: <span class="subst">&#123;titles[<span class="number">0</span>][:<span class="number">3</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Recommendations: [b&#x27;Christmas Carol, A (1938)&#x27; b&#x27;Rudy (1993)&#x27; b&#x27;Bridges of Madison County, The (1995)&#x27;]</span></span><br></pre></td></tr></table></figure>
<h5 id="逐项推荐"><a href="#逐项推荐" class="headerlink" title="逐项推荐"></a>逐项推荐</h5><p>在这个模型中，我们创建了一个用户电影模型。但是，对于某些应用（例如，产品详细信息页面），通常会执行逐项（例如，电影到电影）的推荐。像这样的训练模型将遵循本示例中所示的相同模式，但使用不同的训练数据。在这里，我们有一个用户和一个电影塔，并使用（用户，电影）对来训练它们。在项目到项目模型中，我们将有两个项目塔（查询和候选项目），并使用（查询项目、候选项目）对训练模型。</p>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>umbrella
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://fresh88888888.github.io/2024/04/17/artificial-intelligence/TFRS_study/" title="检索模型（TensorFlow 构建推荐系统）">https://fresh88888888.github.io/2024/04/17/artificial-intelligence/TFRS_study/</a>
  </li>
  <li class="post-copyright-license">
      <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/AI/" rel="tag"># AI</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2024/04/16/artificial-intelligence/recommendation_system_study/" rel="prev" title="内容过滤 & 协同过滤（TensorFlow 构建推荐系统）">
                  <i class="fa fa-chevron-left"></i> 内容过滤 & 协同过滤（TensorFlow 构建推荐系统）
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2024/04/17/artificial-intelligence/ranking_model_study/" rel="next" title="排名模型（TensorFlow 构建推荐系统）">
                  排名模型（TensorFlow 构建推荐系统） <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments utterances-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">辽ICP备15012817号-2 </a>
  </div>
  <div class="copyright">
    &copy; 2022 – 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">umbrella</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">830k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">46:08</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/fresh88888888" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script size="300" alpha="0.6" zIndex="-1" src="https://cdnjs.cloudflare.com/ajax/libs/ribbon.js/1.0.2/ribbon.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.0/jquery.min.js" integrity="sha256-2Pmvv0kuTBOenSvLm6bvfBSSHrUJ+3A7x6P5Ebd07/g=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.8/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/comments.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/utils.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/motion.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/next-boot.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/pjax.min.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/search/local-search.min.js"></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdnjs.cloudflare.com/ajax/libs/pdfobject/2.2.12/pdfobject.min.js","integrity":"sha256-g2xji1rlE3KsGVClvuxTbcR0Kn2+wtQADSff2Tbb4zA="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/tags/pdf.min.js"></script>



  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/fancybox.min.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/pace.min.js"></script>


  
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  <script src="https://cdnjs.cloudflare.com/ajax/libs/quicklink/2.3.0/quicklink.umd.js" integrity="sha256-yvJQOINiH9fWemHn0vCA5lsHWJaHs6/ZmO+1Ft04SvM=" crossorigin="anonymous"></script>
  <script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":true,"archive":true,"delay":true,"timeout":5000,"priority":true,"url":"https://fresh88888888.github.io/2024/04/17/artificial-intelligence/TFRS_study/"}</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/quicklink.min.js"></script>
<script class="next-config" data-name="utterances" type="application/json">{"enable":true,"repo":"fresh88888888.github.io","issue_term":"title","theme":"github-light"}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/comments/utterances.min.js"></script>

</body>
</html>
