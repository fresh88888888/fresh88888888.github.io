<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.2">
<link rel="preconnect" href="https://fonts.googleapis.com" crossorigin>
<link rel="preconnect" href="https://cdnjs.cloudflare.com" crossorigin>
  <link rel="apple-touch-icon" sizes="180x180" href="/favicon.ico">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon.ico">
  <link rel="mask-icon" href="/favicon.ico" color="#222">
  <meta name="google-site-verification" content="lk2gSYFP_NyLNFob-fFnt7fm-I_n1ZYws-WZll7mshg">
  <meta name="msvalidate.01" content="6Jdc01DjYOLguhS5">
  <meta name="baidu-site-verification" content="code-NR10G09zww">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic%7Ccursive:300,300italic,400,400italic,700,700italic%7CSource+Code+Pro:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/yellow/pace-theme-minimal.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"fresh88888888.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.17.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"flat"},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":true,"nav":null},"stickytabs":true,"motion":{"enable":true,"async":true,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/local-search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":10,"unescape":false,"preload":true}}</script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/config.min.js"></script>

    <meta name="description" content="密度估计密度估计(Density Estimation)是一种用于估计随机变量的概率密度函数(PDF)的非参数统计方法。它通过对样本数据进行分析，提供一个平滑的函数，以表示数据在不同值上的分布情况。密度估计(Density Estimation)在数据分析、机器学习、信号处理等多个领域中具有广泛应用。">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习(ML)(九) — 探析">
<meta property="og:url" content="https://fresh88888888.github.io/2024/10/09/artificial-intelligence/ML9_theory_study/index.html">
<meta property="og:site_name" content="UMBRELLA">
<meta property="og:description" content="密度估计密度估计(Density Estimation)是一种用于估计随机变量的概率密度函数(PDF)的非参数统计方法。它通过对样本数据进行分析，提供一个平滑的函数，以表示数据在不同值上的分布情况。密度估计(Density Estimation)在数据分析、机器学习、信号处理等多个领域中具有广泛应用。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://fresh88888888.github.io/2024/10/09/artificial-intelligence/ML9_theory_study/ml_1.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/10/09/artificial-intelligence/ML9_theory_study/ml_2.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/10/09/artificial-intelligence/ML9_theory_study/ml_3.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/10/09/artificial-intelligence/ML9_theory_study/ml_4.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/10/09/artificial-intelligence/ML9_theory_study/ml_5.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/10/09/artificial-intelligence/ML9_theory_study/ml_6.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/10/09/artificial-intelligence/ML9_theory_study/ml_7.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/10/09/artificial-intelligence/ML9_theory_study/ml_8.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/10/09/artificial-intelligence/ML9_theory_study/ml_9.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/10/09/artificial-intelligence/ML9_theory_study/ml_10.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/10/09/artificial-intelligence/ML9_theory_study/ml_11.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/10/09/artificial-intelligence/ML9_theory_study/ml_12.png">
<meta property="article:published_time" content="2024-10-09T08:24:11.000Z">
<meta property="article:modified_time" content="2024-10-09T08:24:11.000Z">
<meta property="article:author" content="umbrella">
<meta property="article:tag" content="AI">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://fresh88888888.github.io/2024/10/09/artificial-intelligence/ML9_theory_study/ml_1.png">


<link rel="canonical" href="https://fresh88888888.github.io/2024/10/09/artificial-intelligence/ML9_theory_study/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://fresh88888888.github.io/2024/10/09/artificial-intelligence/ML9_theory_study/","path":"2024/10/09/artificial-intelligence/ML9_theory_study/","title":"机器学习(ML)(九) — 探析"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>机器学习(ML)(九) — 探析 | UMBRELLA</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">UMBRELLA</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">未雨绸缪，举重若轻</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-算法"><a href="/Algorithm/" rel="section"><i class="fa fa-calendar fa-fw"></i>算法</a></li><li class="menu-item menu-item-c++-&nbsp;编程"><a href="/Programming-C++/" rel="section"><i class="fa fa-heartbeat fa-fw"></i>C++ &nbsp;编程</a></li><li class="menu-item menu-item-rust-编程"><a href="/Programming-Rust/" rel="section"><i class="fa fa-cat fa-fw"></i>Rust 编程</a></li><li class="menu-item menu-item-go-&nbsp;&nbsp;&nbsp;编程"><a href="/Programming-Go/" rel="section"><i class="fa fa-hippo fa-fw"></i>Go &nbsp;&nbsp;&nbsp;编程</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AF%86%E5%BA%A6%E4%BC%B0%E8%AE%A1"><span class="nav-number">1.</span> <span class="nav-text">密度估计</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B-Gaussian-Mixture-Model"><span class="nav-number">2.</span> <span class="nav-text">高斯混合模型(Gaussian Mixture Model)</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%8F%98%E5%88%86%E8%B4%9D%E5%8F%B6%E6%96%AF%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B-VB-GMM"><span class="nav-number">2.1.</span> <span class="nav-text">变分贝叶斯高斯混合模型(VB-GMM)</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B5%81%E5%BD%A2%E5%AD%A6%E4%B9%A0-Manifold-Learning"><span class="nav-number">3.</span> <span class="nav-text">流形学习(Manifold Learning)</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90-PCA"><span class="nav-number">3.1.</span> <span class="nav-text">主成分分析(PCA)</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%A2%9E%E9%87%8F%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90-IPCA"><span class="nav-number">3.1.1.</span> <span class="nav-text">增量主成分分析(IPCA)</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E9%9A%8F%E6%9C%BA%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3%E7%9A%84%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90-PCA-using-Randomized-SVD"><span class="nav-number">3.1.2.</span> <span class="nav-text">随机奇异值分解的主成分分析(PCA using Randomized SVD)</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%A8%80%E7%96%8F%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90-SPCA"><span class="nav-number">3.1.3.</span> <span class="nav-text">稀疏主成分分析(SPCA)</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%A0%B8%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90-KPCA"><span class="nav-number">3.2.</span> <span class="nav-text">核主成分分析(KPCA)</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%88%AA%E6%96%AD%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3-TSVD-%E5%92%8C%E6%BD%9C%E5%9C%A8%E8%AF%AD%E4%B9%89%E5%88%86%E6%9E%90-LSA"><span class="nav-number">3.3.</span> <span class="nav-text">截断奇异值分解(TSVD)和潜在语义分析(LSA)</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%AD%97%E5%85%B8%E5%AD%A6%E4%B9%A0-Dictionary-Learning"><span class="nav-number">3.4.</span> <span class="nav-text">字典学习(Dictionary Learning)</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="umbrella"
      src="/avatar.jpeg">
  <p class="site-author-name" itemprop="name">umbrella</p>
  <div class="site-description" itemprop="description">没事就多看看书</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">244</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">21</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">65</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/fresh88888888" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;fresh88888888" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:fresh888888@foxmail.com" title="E-Mail → mailto:fresh888888@foxmail.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
    </div>

    
    <div class="sidebar-inner sidebar-blogroll">
      <div class="links-of-blogroll animated">
        <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
          链接
        </div>
        <ul class="links-of-blogroll-list">
            <li class="links-of-blogroll-item">
              <a href="https://www.rust-lang.org/zh-CN/" title="https:&#x2F;&#x2F;www.rust-lang.org&#x2F;zh-CN&#x2F;" rel="noopener" target="_blank">Rust</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://go.dev/" title="https:&#x2F;&#x2F;go.dev&#x2F;" rel="noopener" target="_blank">Golang</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://isocpp.org/" title="https:&#x2F;&#x2F;isocpp.org&#x2F;" rel="noopener" target="_blank">C++</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://www.python.org/" title="https:&#x2F;&#x2F;www.python.org&#x2F;" rel="noopener" target="_blank">Python</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://doc.rust-lang.org/cargo/index.html" title="https:&#x2F;&#x2F;doc.rust-lang.org&#x2F;cargo&#x2F;index.html" rel="noopener" target="_blank">Cargo</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://gist.github.com/rxaviers/7360908" title="https:&#x2F;&#x2F;gist.github.com&#x2F;rxaviers&#x2F;7360908" rel="noopener" target="_blank">Emoji</a>
            </li>
        </ul>
      </div>
    </div>
        <div class="pjax">
        </div>
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://fresh88888888.github.io/2024/10/09/artificial-intelligence/ML9_theory_study/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/avatar.jpeg">
      <meta itemprop="name" content="umbrella">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="UMBRELLA">
      <meta itemprop="description" content="没事就多看看书">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="机器学习(ML)(九) — 探析 | UMBRELLA">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          机器学习(ML)(九) — 探析
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-10-09 16:24:11" itemprop="dateCreated datePublished" datetime="2024-10-09T16:24:11+08:00">2024-10-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" itemprop="url" rel="index"><span itemprop="name">人工智能</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>11k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>35 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h4 id="密度估计"><a href="#密度估计" class="headerlink" title="密度估计"></a>密度估计</h4><p><strong>密度估计</strong>(<code>Density Estimation</code>)是一种用于估计随机变量的<strong>概率密度函数</strong>(<code>PDF</code>)的非参数统计方法。它通过对样本数据进行分析，提供一个平滑的函数，以表示数据在不同值上的分布情况。<strong>密度估计</strong>(<code>Density Estimation</code>)在<strong>数据分析</strong>、<strong>机器学习</strong>、<strong>信号处理</strong>等多个领域中具有广泛应用。</p>
<span id="more"></span>
<p><strong>密度估计</strong>(<code>Density Estimation</code>)的主要方法包括：<strong>直方图</strong>(<code>Histogram</code>)、<strong>核密度估计</strong>(<code>Kernel Density Estimation, KDE</code>)、<strong>参数密度估计</strong>：</p>
<ul>
<li><strong>直方图</strong>(<code>Histogram</code>)：<strong>直方图</strong>是最基本的<strong>密度估计</strong>方法之一。通过将数据范围划分为若干个区间（称为“<strong>箱</strong>”），并计算每个区间内的数据点数量，<strong>直方图</strong>可以直观地展示数据分布。优点：简单易懂，易于实现；缺点：对箱宽和起始位置敏感，可能导致信息损失。不够平滑，无法很好地捕捉数据的细微结构。</li>
<li><strong>核密度估计</strong>(<code>Kernel Density Estimation, KDE</code>)：<strong>核密度估计</strong>是一种更为灵活和光滑的<strong>密度估计</strong>方法。它通过在每个数据点周围放置一个<strong>核函数</strong>（如高斯核）来构建平滑的<strong>密度曲线</strong>。<code>KDE</code>的公式为：<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -2.366ex;" xmlns="http://www.w3.org/2000/svg" width="20.987ex" height="5.449ex" role="img" focusable="false" viewBox="0 -1362.5 9276 2408.5" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-37-TEX-I-1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path><path id="MJX-37-TEX-N-5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path><path id="MJX-37-TEX-N-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path id="MJX-37-TEX-I-1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path id="MJX-37-TEX-N-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path><path id="MJX-37-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-37-TEX-N-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path id="MJX-37-TEX-I-1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-37-TEX-SO-2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path><path id="MJX-37-TEX-I-1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path id="MJX-37-TEX-I-1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path><path id="MJX-37-TEX-N-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path id="MJX-37-TEX-I-210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><use data-c="1D453" xlink:href="#MJX-37-TEX-I-1D453"></use></g><g data-mml-node="mo" transform="translate(457,279) translate(-250 0)"><use data-c="5E" xlink:href="#MJX-37-TEX-N-5E"></use></g></g></g><g data-mml-node="mo" transform="translate(550,0)"><use data-c="28" xlink:href="#MJX-37-TEX-N-28"></use></g><g data-mml-node="mi" transform="translate(939,0)"><use data-c="1D465" xlink:href="#MJX-37-TEX-I-1D465"></use></g><g data-mml-node="mo" transform="translate(1511,0)"><use data-c="29" xlink:href="#MJX-37-TEX-N-29"></use></g><g data-mml-node="mo" transform="translate(2177.8,0)"><use data-c="3D" xlink:href="#MJX-37-TEX-N-3D"></use></g><g data-mml-node="mfrac" transform="translate(3233.6,0)"><g data-mml-node="mn" transform="translate(255.4,394) scale(0.707)"><use data-c="31" xlink:href="#MJX-37-TEX-N-31"></use></g><g data-mml-node="mi" transform="translate(220,-345) scale(0.707)"><use data-c="1D45B" xlink:href="#MJX-37-TEX-I-1D45B"></use></g><rect width="624.3" height="60" x="120" y="220"></rect></g><g data-mml-node="munderover" transform="translate(4264.5,0)"><g data-mml-node="mo" transform="translate(45.8,0)"><use data-c="2211" xlink:href="#MJX-37-TEX-SO-2211"></use></g><g data-mml-node="TeXAtom" transform="translate(0,-887.9) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D456" xlink:href="#MJX-37-TEX-I-1D456"></use></g><g data-mml-node="mo" transform="translate(345,0)"><use data-c="3D" xlink:href="#MJX-37-TEX-N-3D"></use></g><g data-mml-node="mn" transform="translate(1123,0)"><use data-c="31" xlink:href="#MJX-37-TEX-N-31"></use></g></g><g data-mml-node="mi" transform="translate(361.7,950) scale(0.707)"><use data-c="1D45B" xlink:href="#MJX-37-TEX-I-1D45B"></use></g></g><g data-mml-node="mi" transform="translate(5578.8,0)"><use data-c="1D43E" xlink:href="#MJX-37-TEX-I-1D43E"></use></g><g data-mml-node="mo" transform="translate(6467.8,0)"><use data-c="28" xlink:href="#MJX-37-TEX-N-28"></use></g><g data-mml-node="mfrac" transform="translate(6856.8,0)"><g data-mml-node="mrow" transform="translate(220,451.6) scale(0.707)"><g data-mml-node="mi"><use data-c="1D465" xlink:href="#MJX-37-TEX-I-1D465"></use></g><g data-mml-node="mo" transform="translate(572,0)"><use data-c="2212" xlink:href="#MJX-37-TEX-N-2212"></use></g><g data-mml-node="msub" transform="translate(1350,0)"><g data-mml-node="mi"><use data-c="1D465" xlink:href="#MJX-37-TEX-I-1D465"></use></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><use data-c="1D456" xlink:href="#MJX-37-TEX-I-1D456"></use></g></g></g><g data-mml-node="mi" transform="translate(811.5,-345) scale(0.707)"><use data-c="210E" xlink:href="#MJX-37-TEX-I-210E"></use></g><rect width="1790.2" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(8887,0)"><use data-c="29" xlink:href="#MJX-37-TEX-N-29"></use></g></g></g></svg></mjx-container>。其中<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="4.299ex" height="2.993ex" role="img" focusable="false" viewBox="0 -1073 1900 1323" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-36-TEX-I-1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path><path id="MJX-36-TEX-N-5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path><path id="MJX-36-TEX-N-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path id="MJX-36-TEX-I-1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path id="MJX-36-TEX-N-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><use data-c="1D453" xlink:href="#MJX-36-TEX-I-1D453"></use></g><g data-mml-node="mo" transform="translate(457,279) translate(-250 0)"><use data-c="5E" xlink:href="#MJX-36-TEX-N-5E"></use></g></g></g><g data-mml-node="mo" transform="translate(550,0)"><use data-c="28" xlink:href="#MJX-36-TEX-N-28"></use></g><g data-mml-node="mi" transform="translate(939,0)"><use data-c="1D465" xlink:href="#MJX-36-TEX-I-1D465"></use></g><g data-mml-node="mo" transform="translate(1511,0)"><use data-c="29" xlink:href="#MJX-36-TEX-N-29"></use></g></g></g></svg></mjx-container>是数据点<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.294ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 572 453" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-36-TEX-I-1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D465" xlink:href="#MJX-36-TEX-I-1D465"></use></g></g></g></svg></mjx-container>的估计密度，<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.357ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 600 453" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-36-TEX-I-1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D45B" xlink:href="#MJX-36-TEX-I-1D45B"></use></g></g></g></svg></mjx-container>是样本数量，<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="2.011ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 889 683" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-35-TEX-I-1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D43E" xlink:href="#MJX-35-TEX-I-1D43E"></use></g></g></g></svg></mjx-container>是核函数，<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.303ex" height="1.595ex" role="img" focusable="false" viewBox="0 -694 576 705" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-35-TEX-I-210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="210E" xlink:href="#MJX-35-TEX-I-210E"></use></g></g></g></svg></mjx-container>是带宽参数，决定了核的宽度。优点：提供平滑的密度估计，能够更好地捕捉数据的分布特征，可以选择不同类型的核函数，以适应不同的数据分布。缺点：带宽选择对结果影响较大，选择不当可能导致<strong>过拟合</strong>或<strong>欠拟合</strong>，在高维空间中计算复杂度较高，可能导致“维度诅咒”。</li>
<li><strong>参数密度估计</strong>：<strong>参数密度估计</strong>假设数据遵循某种已知的分布（如<strong>正态分布</strong>、<strong>指数分布</strong>等），通过<strong>最大似然估计</strong>或<strong>贝叶斯方法</strong>来估计参数。这种方法通常适用于数据量较少且对分布有<strong>先验知识</strong>的情况。优点：计算效率高，模型简单。缺点：对模型假设敏感，如果真实分布与假设不符，可能导致偏差。</li>
</ul>
<p><strong>密度估计</strong>(<code>Density Estimation</code>)是一种重要的统计工具，通过不同的方法可以有效地描述和理解数据的分布特征。无论是使用简单的直方图还是更复杂的核密度估计，选择合适的方法和参数对于获取准确和有意义的结果至关重要。这里举一个例子，使用<strong>核密度估计</strong>(<code>KDE</code>)学习手写数字数据的生成模型并从该模型中提取新样本。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_digits</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KernelDensity</span><br><span class="line"></span><br><span class="line"><span class="comment"># load the data</span></span><br><span class="line">digits = load_digits()</span><br><span class="line"><span class="comment"># project the 64-dimensional data to a lower dimension</span></span><br><span class="line">pca = PCA(n_components=<span class="number">15</span>, whiten=<span class="literal">False</span>)</span><br><span class="line">data = pca.fit_transform(digits.data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># use grid search cross-validation to optimize the bandwidth</span></span><br><span class="line">params = &#123;<span class="string">&quot;bandwidth&quot;</span>: np.logspace(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">20</span>)&#125;</span><br><span class="line">grid = GridSearchCV(KernelDensity(), params)</span><br><span class="line">grid.fit(data)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;best bandwidth: &#123;0&#125;&quot;</span>.<span class="built_in">format</span>(grid.best_estimator_.bandwidth))</span><br><span class="line"></span><br><span class="line"><span class="comment"># use the best estimator to compute the kernel density estimate</span></span><br><span class="line">kde = grid.best_estimator_</span><br><span class="line"></span><br><span class="line"><span class="comment"># sample 44 new points from the data</span></span><br><span class="line">new_data = kde.sample(<span class="number">44</span>, random_state=<span class="number">0</span>)</span><br><span class="line">new_data = pca.inverse_transform(new_data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># turn data into a 4 x 11 grid</span></span><br><span class="line">new_data = new_data.reshape(<span class="number">4</span>, <span class="number">11</span>, -<span class="number">1</span>)</span><br><span class="line">real_data = digits.data[:<span class="number">44</span>].reshape(<span class="number">4</span>, <span class="number">11</span>, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># plot real digits and resample digits</span></span><br><span class="line">fig, ax = plt.subplots(<span class="number">9</span>, <span class="number">11</span>, subplot_kw=<span class="built_in">dict</span>(xticks=[], yticks=[]))</span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">11</span>):</span><br><span class="line">    ax[<span class="number">4</span>, j].set_visible(<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">        im = ax[i, j].imshow(real_data[i, j].reshape((<span class="number">8</span>, <span class="number">8</span>)), cmap=plt.cm.binary, interpolation=<span class="string">&quot;nearest&quot;</span>)</span><br><span class="line">        im.set_clim(<span class="number">0</span>, <span class="number">16</span>)</span><br><span class="line">        im = ax[i + <span class="number">5</span>, j].imshow(real_data[i, j].reshape((<span class="number">8</span>, <span class="number">8</span>)), cmap=plt.cm.binary, interpolation=<span class="string">&quot;nearest&quot;</span>)</span><br><span class="line">        im.set_clim(<span class="number">0</span>, <span class="number">16</span>)</span><br><span class="line"></span><br><span class="line">ax[<span class="number">0</span>, <span class="number">5</span>].set_title(<span class="string">&quot;Selection from the input data&quot;</span>)</span><br><span class="line">ax[<span class="number">5</span>, <span class="number">5</span>].set_title(<span class="string">&#x27;&quot;New&quot; digits drawn from the kernel density model&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<img data-src="/2024/10/09/artificial-intelligence/ML9_theory_study/ml_1.png" class="">

<h4 id="高斯混合模型-Gaussian-Mixture-Model"><a href="#高斯混合模型-Gaussian-Mixture-Model" class="headerlink" title="高斯混合模型(Gaussian Mixture Model)"></a>高斯混合模型(Gaussian Mixture Model)</h4><p><strong>高斯混合模型</strong>(<code>GMM</code>)是一种基于概率的统计模型，假设所有数据点是由多个<strong>高斯分布</strong>的混合生成的。它广泛应用于<strong>聚类</strong>、<strong>密度估计</strong>和<strong>分类</strong>等任务。<strong>高斯混合模型</strong>(<code>GMM</code>)的核心思想是将复杂的<strong>数据分布</strong>视为多个简单的<strong>高斯分布</strong>的组合，从而更好地捕捉数据的多样性和复杂性。</p>
<ul>
<li><strong>高斯分布</strong>：<strong>高斯分布</strong>，也称为<strong>正态分布</strong>，是一种在自然界中常见的概率分布，其<strong>概率密度函数</strong>呈现出钟形曲线。<strong>多维高斯分布</strong>则通过<strong>均值向量</strong>和<strong>协方差矩阵</strong>来描述。</li>
<li><strong>混合模型</strong>：<strong>高斯混合模型</strong>(<code>GMM</code>)将数据视为多个<strong>高斯分布</strong>的加权组合。每个<strong>高斯分布</strong>对应一个“<strong>成分</strong>”，其权重表示该成分在整体模型中的重要性。</li>
<li><strong>数学表示</strong>：<strong>高斯混合模型</strong>(<code>GMM</code>)的<strong>概率密度函数</strong>可以表示为：<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -2.411ex;" xmlns="http://www.w3.org/2000/svg" width="26.204ex" height="5.879ex" role="img" focusable="false" viewBox="0 -1533 11582.2 2598.7" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-33-TEX-I-1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path><path id="MJX-33-TEX-N-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path id="MJX-33-TEX-I-1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path id="MJX-33-TEX-N-7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path><path id="MJX-33-TEX-I-1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path><path id="MJX-33-TEX-N-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path><path id="MJX-33-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-33-TEX-SO-2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path><path id="MJX-33-TEX-I-1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path><path id="MJX-33-TEX-N-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path id="MJX-33-TEX-I-1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path><path id="MJX-33-TEX-I-1D70B" d="M132 -11Q98 -11 98 22V33L111 61Q186 219 220 334L228 358H196Q158 358 142 355T103 336Q92 329 81 318T62 297T53 285Q51 284 38 284Q19 284 19 294Q19 300 38 329T93 391T164 429Q171 431 389 431Q549 431 553 430Q573 423 573 402Q573 371 541 360Q535 358 472 358H408L405 341Q393 269 393 222Q393 170 402 129T421 65T431 37Q431 20 417 5T381 -10Q370 -10 363 -7T347 17T331 77Q330 86 330 121Q330 170 339 226T357 318T367 358H269L268 354Q268 351 249 275T206 114T175 17Q164 -11 132 -11Z"></path><path id="MJX-33-TEX-I-1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path><path id="MJX-33-TEX-I-1D707" d="M58 -216Q44 -216 34 -208T23 -186Q23 -176 96 116T173 414Q186 442 219 442Q231 441 239 435T249 423T251 413Q251 401 220 279T187 142Q185 131 185 107V99Q185 26 252 26Q261 26 270 27T287 31T302 38T315 45T327 55T338 65T348 77T356 88T365 100L372 110L408 253Q444 395 448 404Q461 431 491 431Q504 431 512 424T523 412T525 402L449 84Q448 79 448 68Q448 43 455 35T476 26Q485 27 496 35Q517 55 537 131Q543 151 547 152Q549 153 557 153H561Q580 153 580 144Q580 138 575 117T555 63T523 13Q510 0 491 -8Q483 -10 467 -10Q446 -10 429 -4T402 11T385 29T376 44T374 51L368 45Q362 39 350 30T324 12T288 -4T246 -11Q199 -11 153 12L129 -85Q108 -167 104 -180T92 -202Q76 -216 58 -216Z"></path><path id="MJX-33-TEX-N-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path><path id="MJX-33-TEX-N-3A3" d="M666 247Q664 244 652 126T638 4V0H351Q131 0 95 0T57 5V6Q54 12 57 17L73 36Q89 54 121 90T182 159L305 299L56 644L55 658Q55 677 60 681Q63 683 351 683H638V679Q640 674 652 564T666 447V443H626V447Q618 505 604 543T559 605Q529 626 478 631T333 637H294H189L293 494Q314 465 345 422Q400 346 400 340Q400 338 399 337L154 57Q407 57 428 58Q476 60 508 68T551 83T575 103Q595 125 608 162T624 225L626 251H666V247Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D45D" xlink:href="#MJX-33-TEX-I-1D45D"></use></g><g data-mml-node="mo" transform="translate(503,0)"><use data-c="28" xlink:href="#MJX-33-TEX-N-28"></use></g><g data-mml-node="mi" transform="translate(892,0)"><use data-c="1D465" xlink:href="#MJX-33-TEX-I-1D465"></use></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(1464,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><use data-c="7C" xlink:href="#MJX-33-TEX-N-7C"></use></g></g><g data-mml-node="mi" transform="translate(1742,0)"><use data-c="1D703" xlink:href="#MJX-33-TEX-I-1D703"></use></g><g data-mml-node="mo" transform="translate(2211,0)"><use data-c="29" xlink:href="#MJX-33-TEX-N-29"></use></g><g data-mml-node="mo" transform="translate(2877.8,0)"><use data-c="3D" xlink:href="#MJX-33-TEX-N-3D"></use></g><g data-mml-node="munderover" transform="translate(3933.6,0)"><g data-mml-node="mo" transform="translate(108,0)"><use data-c="2211" xlink:href="#MJX-33-TEX-SO-2211"></use></g><g data-mml-node="TeXAtom" transform="translate(0,-907.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D458" xlink:href="#MJX-33-TEX-I-1D458"></use></g><g data-mml-node="mo" transform="translate(521,0)"><use data-c="3D" xlink:href="#MJX-33-TEX-N-3D"></use></g><g data-mml-node="mn" transform="translate(1299,0)"><use data-c="31" xlink:href="#MJX-33-TEX-N-31"></use></g></g><g data-mml-node="mi" transform="translate(321.7,950) scale(0.707)"><use data-c="1D43E" xlink:href="#MJX-33-TEX-I-1D43E"></use></g></g><g data-mml-node="msub" transform="translate(5372.3,0)"><g data-mml-node="mi"><use data-c="1D70B" xlink:href="#MJX-33-TEX-I-1D70B"></use></g><g data-mml-node="mi" transform="translate(603,-150) scale(0.707)"><use data-c="1D458" xlink:href="#MJX-33-TEX-I-1D458"></use></g></g><g data-mml-node="mi" transform="translate(6393.7,0)"><use data-c="1D441" xlink:href="#MJX-33-TEX-I-1D441"></use></g><g data-mml-node="mo" transform="translate(7281.7,0)"><use data-c="28" xlink:href="#MJX-33-TEX-N-28"></use></g><g data-mml-node="mi" transform="translate(7670.7,0)"><use data-c="1D465" xlink:href="#MJX-33-TEX-I-1D465"></use></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(8242.7,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><use data-c="7C" xlink:href="#MJX-33-TEX-N-7C"></use></g></g><g data-mml-node="msub" transform="translate(8520.7,0)"><g data-mml-node="mi"><use data-c="1D707" xlink:href="#MJX-33-TEX-I-1D707"></use></g><g data-mml-node="mi" transform="translate(636,-150) scale(0.707)"><use data-c="1D458" xlink:href="#MJX-33-TEX-I-1D458"></use></g></g><g data-mml-node="mo" transform="translate(9575.1,0)"><use data-c="2C" xlink:href="#MJX-33-TEX-N-2C"></use></g><g data-mml-node="msub" transform="translate(10019.8,0)"><g data-mml-node="mi"><use data-c="3A3" xlink:href="#MJX-33-TEX-N-3A3"></use></g><g data-mml-node="mi" transform="translate(755,-150) scale(0.707)"><use data-c="1D458" xlink:href="#MJX-33-TEX-I-1D458"></use></g></g><g data-mml-node="mo" transform="translate(11193.2,0)"><use data-c="29" xlink:href="#MJX-33-TEX-N-29"></use></g></g></g></svg></mjx-container>，其中<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="2.011ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 889 683" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-33-TEX-I-1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D43E" xlink:href="#MJX-33-TEX-I-1D43E"></use></g></g></g></svg></mjx-container>是成分数量，<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="2.311ex" height="1.332ex" role="img" focusable="false" viewBox="0 -431 1021.4 588.8" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-31-TEX-I-1D70B" d="M132 -11Q98 -11 98 22V33L111 61Q186 219 220 334L228 358H196Q158 358 142 355T103 336Q92 329 81 318T62 297T53 285Q51 284 38 284Q19 284 19 294Q19 300 38 329T93 391T164 429Q171 431 389 431Q549 431 553 430Q573 423 573 402Q573 371 541 360Q535 358 472 358H408L405 341Q393 269 393 222Q393 170 402 129T421 65T431 37Q431 20 417 5T381 -10Q370 -10 363 -7T347 17T331 77Q330 86 330 121Q330 170 339 226T357 318T367 358H269L268 354Q268 351 249 275T206 114T175 17Q164 -11 132 -11Z"></path><path id="MJX-31-TEX-I-1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="1D70B" xlink:href="#MJX-31-TEX-I-1D70B"></use></g><g data-mml-node="mi" transform="translate(603,-150) scale(0.707)"><use data-c="1D458" xlink:href="#MJX-31-TEX-I-1D458"></use></g></g></g></g></svg></mjx-container>是第<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.179ex" height="1.595ex" role="img" focusable="false" viewBox="0 -694 521 705" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-31-TEX-I-1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D458" xlink:href="#MJX-31-TEX-I-1D458"></use></g></g></g></svg></mjx-container>个成分的权重，<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="11.739ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 5188.5 1000" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-31-TEX-I-1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path><path id="MJX-31-TEX-N-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path id="MJX-31-TEX-I-1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path id="MJX-31-TEX-N-7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path><path id="MJX-31-TEX-I-1D707" d="M58 -216Q44 -216 34 -208T23 -186Q23 -176 96 116T173 414Q186 442 219 442Q231 441 239 435T249 423T251 413Q251 401 220 279T187 142Q185 131 185 107V99Q185 26 252 26Q261 26 270 27T287 31T302 38T315 45T327 55T338 65T348 77T356 88T365 100L372 110L408 253Q444 395 448 404Q461 431 491 431Q504 431 512 424T523 412T525 402L449 84Q448 79 448 68Q448 43 455 35T476 26Q485 27 496 35Q517 55 537 131Q543 151 547 152Q549 153 557 153H561Q580 153 580 144Q580 138 575 117T555 63T523 13Q510 0 491 -8Q483 -10 467 -10Q446 -10 429 -4T402 11T385 29T376 44T374 51L368 45Q362 39 350 30T324 12T288 -4T246 -11Q199 -11 153 12L129 -85Q108 -167 104 -180T92 -202Q76 -216 58 -216Z"></path><path id="MJX-31-TEX-I-1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path><path id="MJX-31-TEX-N-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path><path id="MJX-31-TEX-N-3A3" d="M666 247Q664 244 652 126T638 4V0H351Q131 0 95 0T57 5V6Q54 12 57 17L73 36Q89 54 121 90T182 159L305 299L56 644L55 658Q55 677 60 681Q63 683 351 683H638V679Q640 674 652 564T666 447V443H626V447Q618 505 604 543T559 605Q529 626 478 631T333 637H294H189L293 494Q314 465 345 422Q400 346 400 340Q400 338 399 337L154 57Q407 57 428 58Q476 60 508 68T551 83T575 103Q595 125 608 162T624 225L626 251H666V247Z"></path><path id="MJX-31-TEX-N-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D441" xlink:href="#MJX-31-TEX-I-1D441"></use></g><g data-mml-node="mo" transform="translate(888,0)"><use data-c="28" xlink:href="#MJX-31-TEX-N-28"></use></g><g data-mml-node="mi" transform="translate(1277,0)"><use data-c="1D465" xlink:href="#MJX-31-TEX-I-1D465"></use></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(1849,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><use data-c="7C" xlink:href="#MJX-31-TEX-N-7C"></use></g></g><g data-mml-node="msub" transform="translate(2127,0)"><g data-mml-node="mi"><use data-c="1D707" xlink:href="#MJX-31-TEX-I-1D707"></use></g><g data-mml-node="mi" transform="translate(636,-150) scale(0.707)"><use data-c="1D458" xlink:href="#MJX-31-TEX-I-1D458"></use></g></g><g data-mml-node="mo" transform="translate(3181.4,0)"><use data-c="2C" xlink:href="#MJX-31-TEX-N-2C"></use></g><g data-mml-node="msub" transform="translate(3626.1,0)"><g data-mml-node="mi"><use data-c="3A3" xlink:href="#MJX-31-TEX-N-3A3"></use></g><g data-mml-node="mi" transform="translate(755,-150) scale(0.707)"><use data-c="1D458" xlink:href="#MJX-31-TEX-I-1D458"></use></g></g><g data-mml-node="mo" transform="translate(4799.5,0)"><use data-c="29" xlink:href="#MJX-31-TEX-N-29"></use></g></g></g></svg></mjx-container>是以均值<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.489ex;" xmlns="http://www.w3.org/2000/svg" width="2.386ex" height="1.489ex" role="img" focusable="false" viewBox="0 -442 1054.4 658" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-30-TEX-I-1D707" d="M58 -216Q44 -216 34 -208T23 -186Q23 -176 96 116T173 414Q186 442 219 442Q231 441 239 435T249 423T251 413Q251 401 220 279T187 142Q185 131 185 107V99Q185 26 252 26Q261 26 270 27T287 31T302 38T315 45T327 55T338 65T348 77T356 88T365 100L372 110L408 253Q444 395 448 404Q461 431 491 431Q504 431 512 424T523 412T525 402L449 84Q448 79 448 68Q448 43 455 35T476 26Q485 27 496 35Q517 55 537 131Q543 151 547 152Q549 153 557 153H561Q580 153 580 144Q580 138 575 117T555 63T523 13Q510 0 491 -8Q483 -10 467 -10Q446 -10 429 -4T402 11T385 29T376 44T374 51L368 45Q362 39 350 30T324 12T288 -4T246 -11Q199 -11 153 12L129 -85Q108 -167 104 -180T92 -202Q76 -216 58 -216Z"></path><path id="MJX-30-TEX-I-1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="1D707" xlink:href="#MJX-30-TEX-I-1D707"></use></g><g data-mml-node="mi" transform="translate(636,-150) scale(0.707)"><use data-c="1D458" xlink:href="#MJX-30-TEX-I-1D458"></use></g></g></g></g></svg></mjx-container>和协方差<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="2.655ex" height="1.902ex" role="img" focusable="false" viewBox="0 -683 1173.4 840.8" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-30-TEX-N-3A3" d="M666 247Q664 244 652 126T638 4V0H351Q131 0 95 0T57 5V6Q54 12 57 17L73 36Q89 54 121 90T182 159L305 299L56 644L55 658Q55 677 60 681Q63 683 351 683H638V679Q640 674 652 564T666 447V443H626V447Q618 505 604 543T559 605Q529 626 478 631T333 637H294H189L293 494Q314 465 345 422Q400 346 400 340Q400 338 399 337L154 57Q407 57 428 58Q476 60 508 68T551 83T575 103Q595 125 608 162T624 225L626 251H666V247Z"></path><path id="MJX-30-TEX-I-1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="3A3" xlink:href="#MJX-30-TEX-N-3A3"></use></g><g data-mml-node="mi" transform="translate(755,-150) scale(0.707)"><use data-c="1D458" xlink:href="#MJX-30-TEX-I-1D458"></use></g></g></g></g></svg></mjx-container>为参数的高斯分布。</li>
</ul>
<p><strong>高斯混合模型</strong>(<code>GMM</code>)通常使用<strong>期望最大化</strong>(<code>Expectation-Maximization, EM</code>)算法进行参数估计。<code>EM</code>算法包含两个步骤：</p>
<ul>
<li><strong>期望步骤</strong>（<code>E</code>步）：计算每个数据点属于各个成分的后验概率。</li>
<li><strong>最大化步骤</strong>（<code>M</code>步）：根据后验概率更新模型参数，包括均值、协方差和权重。</li>
</ul>
<p>这个过程会反复进行，直到收敛于某个稳定状态。<strong>高斯混合模型</strong>(<code>GMM</code>)在多个领域有广泛应用，包括：</p>
<ul>
<li>聚类分析：相比于<code>K-means</code>，<strong>高斯混合模型</strong>(<code>GMM</code>)可以处理形状各异、大小不同的簇，并允许数据点有一定的模糊分类（软分类）。</li>
<li>密度估计：通过<strong>高斯混合模型</strong>(<code>GMM</code>)，可以对复杂的数据分布进行建模，从而生成新的样本或进行异常检测。</li>
<li>图像处理与计算机视觉：在图像分割、目标检测等任务中，<strong>高斯混合模型</strong>(<code>GMM</code>)可以有效地提取特征。</li>
<li>语音识别：在语音信号处理领域，<strong>高斯混合模型</strong>(<code>GMM</code>)被用来建模声音特征，以提高识别精度。</li>
</ul>
<p><strong>高斯混合模型</strong>(<code>GMM</code>)是一种概率模型，它假设所有数据点都是由有限数量的<strong>高斯分布</strong>与未知参数的混合生成的。我们可以将<strong>高斯混合模型</strong>(<code>GMM</code>)视为扩展的<code>K-means</code>聚类，并纳入有关数据协方差结构以及潜在高斯中心的信息。这里举例说明，<strong>高斯混合模型</strong>(<code>GMM</code>)的<strong>协方差类型</strong>。我们使用鸢尾花数据集上的各种<strong>高斯混合模型</strong>(<code>GMM</code>)协方差类型在训练和测试数据上绘制预测标签。将<strong>高斯混合模型</strong>(<code>GMM</code>)与球面、对角、完整和绑定协方差矩阵进行比较，按性能的升序排列。虽然看起来<strong>完整协方差</strong>表现最佳，但它在小型数据集上容易<strong>过度拟合</strong>，并且不能很好地推广到测试数据集。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.mixture <span class="keyword">import</span> GaussianMixture</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold</span><br><span class="line"></span><br><span class="line">colors = [<span class="string">&quot;navy&quot;</span>, <span class="string">&quot;turquoise&quot;</span>, <span class="string">&quot;darkorange&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_ellipses</span>(<span class="params">gmm, ax</span>):</span><br><span class="line">    <span class="keyword">for</span> n, color <span class="keyword">in</span> <span class="built_in">enumerate</span>(colors):</span><br><span class="line">        <span class="keyword">if</span> gmm.covariance_type == <span class="string">&quot;full&quot;</span>:</span><br><span class="line">            covariances = gmm.covariances_[n][:<span class="number">2</span>, :<span class="number">2</span>]</span><br><span class="line">        <span class="keyword">elif</span> gmm.covariance_type == <span class="string">&quot;tied&quot;</span>:</span><br><span class="line">            covariances = gmm.covariances_[:<span class="number">2</span>, :<span class="number">2</span>]</span><br><span class="line">        <span class="keyword">elif</span> gmm.covariance_type == <span class="string">&quot;diag&quot;</span>:</span><br><span class="line">            covariances = np.diag(gmm.covariances_[n][:<span class="number">2</span>])</span><br><span class="line">        <span class="keyword">elif</span> gmm.covariance_type == <span class="string">&quot;spherical&quot;</span>:</span><br><span class="line">            covariances = np.eye(gmm.means_.shape[<span class="number">1</span>]) * gmm.covariances_[n]</span><br><span class="line">        v, w = np.linalg.eigh(covariances)</span><br><span class="line">        u = w[<span class="number">0</span>] / np.linalg.norm(w[<span class="number">0</span>])</span><br><span class="line">        angle = np.arctan2(u[<span class="number">1</span>], u[<span class="number">0</span>])</span><br><span class="line">        angle = <span class="number">180</span> * angle / np.pi  <span class="comment"># convert to degrees</span></span><br><span class="line">        v = <span class="number">2.0</span> * np.sqrt(<span class="number">2.0</span>) * np.sqrt(v)</span><br><span class="line">        ell = mpl.patches.Ellipse(gmm.means_[n, :<span class="number">2</span>], v[<span class="number">0</span>], v[<span class="number">1</span>], angle=<span class="number">180</span> + angle, color=color)</span><br><span class="line">        ell.set_clip_box(ax.bbox)</span><br><span class="line">        ell.set_alpha(<span class="number">0.5</span>)</span><br><span class="line">        ax.add_artist(ell)</span><br><span class="line">        ax.set_aspect(<span class="string">&quot;equal&quot;</span>, <span class="string">&quot;datalim&quot;</span>)</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Break up the dataset into non-overlapping training (75%) and testing</span></span><br><span class="line"><span class="comment"># (25%) sets.</span></span><br><span class="line">skf = StratifiedKFold(n_splits=<span class="number">4</span>)</span><br><span class="line"><span class="comment"># Only take the first fold.</span></span><br><span class="line">train_index, test_index = <span class="built_in">next</span>(<span class="built_in">iter</span>(skf.split(iris.data, iris.target)))</span><br><span class="line"></span><br><span class="line">X_train = iris.data[train_index]</span><br><span class="line">y_train = iris.target[train_index]</span><br><span class="line">X_test = iris.data[test_index]</span><br><span class="line">y_test = iris.target[test_index]</span><br><span class="line"></span><br><span class="line">n_classes = <span class="built_in">len</span>(np.unique(y_train))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Try GMMs using different types of covariances.</span></span><br><span class="line">estimators = &#123;</span><br><span class="line">    cov_type: GaussianMixture(n_components=n_classes, covariance_type=cov_type, max_iter=<span class="number">20</span>, random_state=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">for</span> cov_type <span class="keyword">in</span> [<span class="string">&quot;spherical&quot;</span>, <span class="string">&quot;diag&quot;</span>, <span class="string">&quot;tied&quot;</span>, <span class="string">&quot;full&quot;</span>]</span><br><span class="line">&#125;</span><br><span class="line">n_estimators = <span class="built_in">len</span>(estimators)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">3</span> * n_estimators // <span class="number">2</span>, <span class="number">6</span>))</span><br><span class="line">plt.subplots_adjust(bottom=<span class="number">0.01</span>, top=<span class="number">0.95</span>, hspace=<span class="number">0.15</span>, wspace=<span class="number">0.05</span>, left=<span class="number">0.01</span>, right=<span class="number">0.99</span>)</span><br><span class="line"><span class="keyword">for</span> index, (name, estimator) <span class="keyword">in</span> <span class="built_in">enumerate</span>(estimators.items()):</span><br><span class="line">    <span class="comment"># Since we have class labels for the training data, we can</span></span><br><span class="line">    <span class="comment"># initialize the GMM parameters in a supervised manner.</span></span><br><span class="line">    estimator.means_init = np.array([X_train[y_train == i].mean(axis=<span class="number">0</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_classes)])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Train the other parameters using the EM algorithm.</span></span><br><span class="line">    estimator.fit(X_train)</span><br><span class="line"></span><br><span class="line">    h = plt.subplot(<span class="number">2</span>, n_estimators // <span class="number">2</span>, index + <span class="number">1</span>)</span><br><span class="line">    make_ellipses(estimator, h)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> n, color <span class="keyword">in</span> <span class="built_in">enumerate</span>(colors):</span><br><span class="line">        data = iris.data[iris.target == n]</span><br><span class="line">        plt.scatter(data[:, <span class="number">0</span>], data[:, <span class="number">1</span>], s=<span class="number">0.8</span>, color=color, label=iris.target_names[n])</span><br><span class="line">    <span class="comment"># Plot the test data with crosses</span></span><br><span class="line">    <span class="keyword">for</span> n, color <span class="keyword">in</span> <span class="built_in">enumerate</span>(colors):</span><br><span class="line">        data = X_test[y_test == n]</span><br><span class="line">        plt.scatter(data[:, <span class="number">0</span>], data[:, <span class="number">1</span>], marker=<span class="string">&quot;x&quot;</span>, color=color)</span><br><span class="line"></span><br><span class="line">    y_train_pred = estimator.predict(X_train)</span><br><span class="line">    train_accuracy = np.mean(y_train_pred.ravel() == y_train.ravel()) * <span class="number">100</span></span><br><span class="line">    plt.text(<span class="number">0.05</span>, <span class="number">0.9</span>, <span class="string">&quot;Train accuracy: %.1f&quot;</span> % train_accuracy, transform=h.transAxes)</span><br><span class="line"></span><br><span class="line">    y_test_pred = estimator.predict(X_test)</span><br><span class="line">    test_accuracy = np.mean(y_test_pred.ravel() == y_test.ravel()) * <span class="number">100</span></span><br><span class="line">    plt.text(<span class="number">0.05</span>, <span class="number">0.8</span>, <span class="string">&quot;Test accuracy: %.1f&quot;</span> % test_accuracy, transform=h.transAxes)</span><br><span class="line"></span><br><span class="line">    plt.xticks(())</span><br><span class="line">    plt.yticks(())</span><br><span class="line">    plt.title(name)</span><br><span class="line"></span><br><span class="line">plt.legend(scatterpoints=<span class="number">1</span>, loc=<span class="string">&quot;lower right&quot;</span>, prop=<span class="built_in">dict</span>(size=<span class="number">12</span>))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<img data-src="/2024/10/09/artificial-intelligence/ML9_theory_study/ml_2.png" class="">

<p>在图中，训练数据以点显示，而测试数据以十字显示。</p>
<h5 id="变分贝叶斯高斯混合模型-VB-GMM"><a href="#变分贝叶斯高斯混合模型-VB-GMM" class="headerlink" title="变分贝叶斯高斯混合模型(VB-GMM)"></a>变分贝叶斯高斯混合模型(VB-GMM)</h5><p><strong>变分贝叶斯高斯混合模型</strong>(<code>VB-GMM</code>)是一种强大的统计技术，用于数据分析中的<strong>聚类</strong>和<strong>密度估计</strong>。它将<strong>高斯混合模型</strong>(<code>GMM</code>)的概念与<strong>变分推断</strong>结合在一起，允许有效地<strong>近似后验分布</strong>。这里再提一下<strong>高斯混合模型</strong>(<code>GMM</code>)的原理：<strong>高斯混合模型</strong>(<code>GMM</code>)假设数据点是从多个<strong>高斯分布</strong>的混合中生成的。每个分布对应一个<strong>聚类</strong>，由其<strong>均值</strong>和<strong>协方差</strong>特征化。该模型由以下内容定义：<strong>潜在变量</strong>，每个数据点与一个<strong>潜在变量</strong>相关联，指示其属于哪个<strong>高斯成分</strong>；<strong>参数</strong>，模型参数包括<strong>高斯成分</strong>的<strong>均值</strong>、<strong>协方差</strong>和<strong>混合系数</strong>。目标是从观察到的数据中估计这些参数。</p>
<p><strong>变分推断</strong>：<strong>变分推断</strong>提供了一种<strong>近似复杂后验分布</strong>的框架。它不是直接计算真实后验（通常计算上不可行），而是通过优化一个更简单的分布来寻求近似。关键概念包括：<strong>均场近似</strong>，假设<strong>联合分布</strong>可以<strong>因子化</strong>为独立成分，从而简化计算；<strong>证据下界</strong>(<code>ELBO</code>)，<strong>变分推断</strong>中的优化目标是最大化<code>ELBO</code>，它作为观察数据<strong>边际似然</strong>的下界。这涉及最小化<strong>近似分布</strong>与<strong>真实后验</strong>之间的<code>Kullback-Leibler(KL)</code><strong>散度</strong>。在<code>GMM</code>的背景下，<strong>变分推断</strong>可以完成以下工作：</p>
<ul>
<li><strong>参数估计</strong>：可以使用<strong>变分推断</strong>迭代更新每个<strong>高斯成分</strong>的参数。这包括根据当前数据点对聚类的分配来估计<strong>均值</strong>、<strong>协方差</strong>和<strong>混合比例</strong>。</li>
<li><strong>处理不确定性</strong>：通过将参数视为分布而非固定值，<code>VB-GMM</code>捕捉参数估计中的不确定性，从而导致更稳定的聚类结果。</li>
<li><strong>可扩展性</strong>：与传统方法（如<strong>期望最大化</strong>(<code>EM</code>)相比，<strong>变分推断</strong>通常更具可扩展性，尤其是在处理大数据集时。</li>
</ul>
<p>实施步骤：</p>
<ul>
<li><strong>模型规范</strong>：定义成分（<strong>聚类</strong>）的数量及其<strong>先验分布</strong>。</li>
<li><strong>变分分布</strong>：选择一个家族的分布来近似潜在变量和参数的<strong>后验</strong>。</li>
<li><strong>优化</strong>：使用迭代更新最大化<strong>证据下界</strong>(<code>ELBO</code>)&#96;，调整变分参数直到收敛。</li>
<li><strong>推断</strong>：一旦优化完成，使用<strong>变分分布</strong>对新数据点进行预测或分析聚类特征。</li>
</ul>
<p><strong>狄利克雷</strong>(<code>Dirichlet</code>)<strong>分布</strong>是一种连续的<strong>多元概率分布</strong>，通常用于<strong>贝叶斯统计</strong>中的<strong>先验分布</strong>。它是<strong>分类分布</strong>和<strong>多项分布</strong>的<strong>共轭先验</strong>，因此在处理这些类型的数据时，使用<strong>狄利克雷</strong>(<code>Dirichlet</code>)<strong>分布</strong>可以简化计算。<strong>狄利克雷</strong>(<code>Dirichlet</code>)<strong>分布</strong>是由一个正实数向量<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.448ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 640 453" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-30-TEX-I-1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D6FC" xlink:href="#MJX-30-TEX-I-1D6FC"></use></g></g></g></svg></mjx-container>参数化，通常表示为：<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="6.452ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 2852 1000" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-29-TEX-N-44" d="M130 622Q123 629 119 631T103 634T60 637H27V683H228Q399 682 419 682T461 676Q504 667 546 641T626 573T685 470T708 336Q708 210 634 116T442 3Q429 1 228 0H27V46H60Q102 47 111 49T130 61V622ZM593 338Q593 439 571 501T493 602Q439 637 355 637H322H294Q238 637 234 628Q231 624 231 344Q231 62 232 59Q233 49 248 48T339 46H350Q456 46 515 95Q561 133 577 191T593 338Z"></path><path id="MJX-29-TEX-N-69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z"></path><path id="MJX-29-TEX-N-72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z"></path><path id="MJX-29-TEX-N-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path id="MJX-29-TEX-I-1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path><path id="MJX-29-TEX-N-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><use data-c="44" xlink:href="#MJX-29-TEX-N-44"></use><use data-c="69" xlink:href="#MJX-29-TEX-N-69" transform="translate(764,0)"></use><use data-c="72" xlink:href="#MJX-29-TEX-N-72" transform="translate(1042,0)"></use></g><g data-mml-node="mo" transform="translate(1434,0)"><use data-c="28" xlink:href="#MJX-29-TEX-N-28"></use></g><g data-mml-node="mi" transform="translate(1823,0)"><use data-c="1D6FC" xlink:href="#MJX-29-TEX-I-1D6FC"></use></g><g data-mml-node="mo" transform="translate(2463,0)"><use data-c="29" xlink:href="#MJX-29-TEX-N-29"></use></g></g></g></svg></mjx-container>，它的概率密度函数(<code>PDF</code>)适用于<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="2.011ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 889 683" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-29-TEX-I-1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D43E" xlink:href="#MJX-29-TEX-I-1D43E"></use></g></g></g></svg></mjx-container>维向量<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.294ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 572 453" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-29-TEX-I-1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D465" xlink:href="#MJX-29-TEX-I-1D465"></use></g></g></g></svg></mjx-container>，其元素在区间<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="4.526ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 2000.7 1000" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-29-TEX-N-5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path><path id="MJX-29-TEX-N-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path id="MJX-29-TEX-N-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path><path id="MJX-29-TEX-N-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path id="MJX-29-TEX-N-5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><use data-c="5B" xlink:href="#MJX-29-TEX-N-5B"></use></g><g data-mml-node="mn" transform="translate(278,0)"><use data-c="30" xlink:href="#MJX-29-TEX-N-30"></use></g><g data-mml-node="mo" transform="translate(778,0)"><use data-c="2C" xlink:href="#MJX-29-TEX-N-2C"></use></g><g data-mml-node="mn" transform="translate(1222.7,0)"><use data-c="31" xlink:href="#MJX-29-TEX-N-31"></use></g><g data-mml-node="mo" transform="translate(1722.7,0)"><use data-c="5D" xlink:href="#MJX-29-TEX-N-5D"></use></g></g></g></svg></mjx-container>内，并且满足<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="8.693ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 3842.1 1000" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-29-TEX-N-2016" d="M133 736Q138 750 153 750Q164 750 170 739Q172 735 172 250T170 -239Q164 -250 152 -250Q144 -250 138 -244L137 -243Q133 -241 133 -179T132 250Q132 731 133 736ZM329 739Q334 750 346 750Q353 750 361 744L362 743Q366 741 366 679T367 250T367 -178T362 -243L361 -244Q355 -250 347 -250Q335 -250 329 -239Q327 -235 327 250T329 739Z"></path><path id="MJX-29-TEX-I-1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path id="MJX-29-TEX-N-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path id="MJX-29-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><use data-c="2016" xlink:href="#MJX-29-TEX-N-2016"></use></g><g data-mml-node="mi" transform="translate(500,0)"><use data-c="1D465" xlink:href="#MJX-29-TEX-I-1D465"></use></g><g data-mml-node="msub" transform="translate(1072,0)"><g data-mml-node="mo"><use data-c="2016" xlink:href="#MJX-29-TEX-N-2016"></use></g><g data-mml-node="mn" transform="translate(533,-150) scale(0.707)"><use data-c="31" xlink:href="#MJX-29-TEX-N-31"></use></g></g><g data-mml-node="mo" transform="translate(2286.3,0)"><use data-c="3D" xlink:href="#MJX-29-TEX-N-3D"></use></g><g data-mml-node="mn" transform="translate(3342.1,0)"><use data-c="31" xlink:href="#MJX-29-TEX-N-31"></use></g></g></g></svg></mjx-container>(即所有元素之和为1)，这使得<strong>狄利克雷</strong>(<code>Dirichlet</code>)<strong>分布</strong>可以被视为<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="2.011ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 889 683" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-29-TEX-I-1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D43E" xlink:href="#MJX-29-TEX-I-1D43E"></use></g></g></g></svg></mjx-container>类分类事件的概率分布。变分贝叶斯高斯混合提出了两种权重分布的先验类型：具有<strong>狄利克雷</strong>(<code>Dirichlet</code>)<strong>分布</strong>的<strong>有限混合模型</strong>和具有<strong>狄利克雷</strong>(<code>Dirichlet</code>)<strong>过程</strong>的<strong>无限混合模型</strong>。</p>
<p><strong>共轭先验</strong>：在<strong>贝叶斯统计</strong>中，如果<strong>后验分布</strong>和<strong>先验分布</strong>属于同一概率分布族，则称它们为<strong>共轭分布</strong>。<strong>狄利克雷</strong>(<code>Dirichlet</code>)<strong>分布</strong>作为<strong>多项分布</strong>的<strong>共轭先验</strong>，使得在更新后验时，计算变得更加简单。具体来说，如果我们有一个<strong>多项分布</strong>的参数<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.023ex;" xmlns="http://www.w3.org/2000/svg" width="1.061ex" height="1.618ex" role="img" focusable="false" viewBox="0 -705 469 715" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-29-TEX-I-1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D703" xlink:href="#MJX-29-TEX-I-1D703"></use></g></g></g></svg></mjx-container>，其<strong>后验分布</strong>依然是一个<strong>狄利克雷</strong>(<code>Dirichlet</code>)<strong>分布</strong>。</p>
<p><strong>对称狄利克雷</strong>(<code>Dirichlet</code>)<strong>分布</strong>：<strong>狄利克雷</strong>(<code>Dirichlet</code>)<strong>分布</strong>的一个特殊情况是<strong>对称狄利克雷</strong>(<code>Dirichlet</code>)<strong>分布</strong>，其中参数向量<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.448ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 640 453" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-29-TEX-I-1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D6FC" xlink:href="#MJX-29-TEX-I-1D6FC"></use></g></g></g></svg></mjx-container>的所有元素相同。在这种情况下，可以用一个标量值（浓度参数）来表示。对称情况下，当浓度参数<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.186ex;" xmlns="http://www.w3.org/2000/svg" width="5.596ex" height="1.692ex" role="img" focusable="false" viewBox="0 -666 2473.6 748" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-29-TEX-I-1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path><path id="MJX-29-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-29-TEX-N-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D6FC" xlink:href="#MJX-29-TEX-I-1D6FC"></use></g><g data-mml-node="mo" transform="translate(917.8,0)"><use data-c="3D" xlink:href="#MJX-29-TEX-N-3D"></use></g><g data-mml-node="mn" transform="translate(1973.6,0)"><use data-c="31" xlink:href="#MJX-29-TEX-N-31"></use></g></g></g></svg></mjx-container>时，<strong>对称狄利克雷</strong>(<code>Dirichlet</code>)<strong>分布</strong>等价于标准<code>(K-1)-simplex</code>上的<strong>均匀分布</strong>。当浓度参数大于<code>1</code>时，倾向于生成<strong>均匀分布</strong>；当小于<code>1</code>时，则倾向于生成<strong>稀疏分布</strong>。</p>
<p><strong>狄利克雷</strong>(<code>Dirichlet</code>)<strong>过程</strong>是一种重要的随机过程，广泛应用于<strong>贝叶斯非参数统计</strong>中。它的主要特点是能够生成<strong>随机概率分布</strong>，这些分布可以用于建模数据的潜在结构，尤其是在数据的类别数未知或不固定的情况下。<strong>狄利克雷</strong>(<code>Dirichlet</code>)<strong>过程</strong>由两个主要参构成：</p>
<ul>
<li><strong>基准分布</strong><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="2.009ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 888 683" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-26-TEX-I-1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D43B" xlink:href="#MJX-26-TEX-I-1D43B"></use></g></g></g></svg></mjx-container>：这是一个<strong>概率分布</strong>，表示数据分布的先验知识。它提供了<strong>狄利克雷</strong>(<code>Dirichlet</code>)<strong>过程</strong>生成的分布的“中心”。</li>
<li><strong>浓度参数</strong><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.448ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 640 453" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-26-TEX-I-1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D6FC" xlink:href="#MJX-26-TEX-I-1D6FC"></use></g></g></g></svg></mjx-container>：这是一个正实数，控制生成分布的<strong>离散程度</strong>。较大的<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.448ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 640 453" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-24-TEX-I-1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D6FC" xlink:href="#MJX-24-TEX-I-1D6FC"></use></g></g></g></svg></mjx-container>值意味着生成的分布可能包含更多的类别，而较小的<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.448ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 640 453" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-24-TEX-I-1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D6FC" xlink:href="#MJX-24-TEX-I-1D6FC"></use></g></g></g></svg></mjx-container>值则倾向于集中在少数几个类别上。</li>
</ul>
<p><strong>狄利克雷</strong>(<code>Dirichlet</code>)<strong>过程</strong>性质和特征为：<strong>随机性</strong>，从<strong>狄利克雷</strong>(<code>Dirichlet</code>)<strong>过程</strong>中生成的分布几乎总是离散的，即使基准分布<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="2.009ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 888 683" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-24-TEX-I-1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D43B" xlink:href="#MJX-24-TEX-I-1D43B"></use></g></g></g></svg></mjx-container>是连续的。这种特性使得<strong>狄利克雷</strong>(<code>Dirichlet</code>)<strong>过程</strong>特别适合用于聚类和混合模型；<strong>共轭先验</strong>，<strong>狄利克雷</strong>(<code>Dirichlet</code>)<strong>过程</strong>在<strong>贝叶斯推断</strong>中作为无限混合模型的<strong>共轭先验</strong>，可以有效地更新<strong>后验分布</strong>；<strong>自适应性</strong>，<strong>狄利克雷</strong>(<code>Dirichlet</code>)<strong>过程</strong>能够根据数据自动调整其复杂度，无需预先指定类别数量。这使得它在处理未知类别数的数据时非常有用。</p>
<p>下面是一个基于权重浓度先验类型（<strong>变分贝叶斯高斯混合</strong>）来分析数据的例子。这里会涉及到<strong>狄利克雷</strong>(<code>Dirichlet</code>)<strong>分布</strong>的<strong>有限混合模型</strong>和<strong>狄利克雷</strong>(<code>Dirichlet</code>)<strong>过程</strong>的<strong>无限混合模型</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl</span><br><span class="line"><span class="keyword">import</span> matplotlib.gridspec <span class="keyword">as</span> gridspec</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.mixture <span class="keyword">import</span> BayesianGaussianMixture</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_ellipses</span>(<span class="params">ax, weights, means, covars</span>):</span><br><span class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(means.shape[<span class="number">0</span>]):</span><br><span class="line">        eig_vals, eig_vecs = np.linalg.eigh(covars[n])</span><br><span class="line">        unit_eig_vec = eig_vecs[<span class="number">0</span>] / np.linalg.norm(eig_vecs[<span class="number">0</span>])</span><br><span class="line">        angle = np.arctan2(unit_eig_vec[<span class="number">1</span>], unit_eig_vec[<span class="number">0</span>])</span><br><span class="line">        <span class="comment"># Ellipse needs degrees</span></span><br><span class="line">        angle = <span class="number">180</span> * angle / np.pi</span><br><span class="line">        <span class="comment"># eigenvector normalization</span></span><br><span class="line">        eig_vals = <span class="number">2</span> * np.sqrt(<span class="number">2</span>) * np.sqrt(eig_vals)</span><br><span class="line">        ell = mpl.patches.Ellipse(means[n], eig_vals[<span class="number">0</span>], eig_vals[<span class="number">1</span>], angle=<span class="number">180</span> + angle, edgecolor=<span class="string">&quot;black&quot;</span>)</span><br><span class="line">        ell.set_clip_box(ax.bbox)</span><br><span class="line">        ell.set_alpha(weights[n])</span><br><span class="line">        ell.set_facecolor(<span class="string">&quot;#56B4E9&quot;</span>)</span><br><span class="line">        ax.add_artist(ell)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_results</span>(<span class="params">ax1, ax2, estimator, X, y, title, plot_title=<span class="literal">False</span></span>):</span><br><span class="line">    ax1.set_title(title)</span><br><span class="line">    ax1.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], s=<span class="number">5</span>, marker=<span class="string">&quot;o&quot;</span>, color=colors[y], alpha=<span class="number">0.8</span>)</span><br><span class="line">    ax1.set_xlim(-<span class="number">2.0</span>, <span class="number">2.0</span>)</span><br><span class="line">    ax1.set_ylim(-<span class="number">3.0</span>, <span class="number">3.0</span>)</span><br><span class="line">    ax1.set_xticks(())</span><br><span class="line">    ax1.set_yticks(())</span><br><span class="line">    plot_ellipses(ax1, estimator.weights_, estimator.means_, estimator.covariances_)</span><br><span class="line"></span><br><span class="line">    ax2.get_xaxis().set_tick_params(direction=<span class="string">&quot;out&quot;</span>)</span><br><span class="line">    ax2.yaxis.grid(<span class="literal">True</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line">    <span class="keyword">for</span> k, w <span class="keyword">in</span> <span class="built_in">enumerate</span>(estimator.weights_):</span><br><span class="line">        ax2.bar(k,w,width=<span class="number">0.9</span>,color=<span class="string">&quot;#56B4E9&quot;</span>,zorder=<span class="number">3</span>,align=<span class="string">&quot;center&quot;</span>,edgecolor=<span class="string">&quot;black&quot;</span>,)</span><br><span class="line">        ax2.text(k, w + <span class="number">0.007</span>, <span class="string">&quot;%.1f%%&quot;</span> % (w * <span class="number">100.0</span>), horizontalalignment=<span class="string">&quot;center&quot;</span>)</span><br><span class="line">    ax2.set_xlim(-<span class="number">0.6</span>, <span class="number">2</span> * n_components - <span class="number">0.4</span>)</span><br><span class="line">    ax2.set_ylim(<span class="number">0.0</span>, <span class="number">1.1</span>)</span><br><span class="line">    ax2.tick_params(axis=<span class="string">&quot;y&quot;</span>, which=<span class="string">&quot;both&quot;</span>, left=<span class="literal">False</span>, right=<span class="literal">False</span>, labelleft=<span class="literal">False</span>)</span><br><span class="line">    ax2.tick_params(axis=<span class="string">&quot;x&quot;</span>, which=<span class="string">&quot;both&quot;</span>, top=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> plot_title:</span><br><span class="line">        ax1.set_ylabel(<span class="string">&quot;Estimated Mixtures&quot;</span>)</span><br><span class="line">        ax2.set_ylabel(<span class="string">&quot;Weight of each component&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Parameters of the dataset</span></span><br><span class="line">random_state, n_components, n_features = <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span></span><br><span class="line">colors = np.array([<span class="string">&quot;#0072B2&quot;</span>, <span class="string">&quot;#F0E442&quot;</span>, <span class="string">&quot;#D55E00&quot;</span>])</span><br><span class="line"></span><br><span class="line">covars = np.array([[[<span class="number">0.7</span>, <span class="number">0.0</span>], [<span class="number">0.0</span>, <span class="number">0.1</span>]], [[<span class="number">0.5</span>, <span class="number">0.0</span>], [<span class="number">0.0</span>, <span class="number">0.1</span>]], [[<span class="number">0.5</span>, <span class="number">0.0</span>], [<span class="number">0.0</span>, <span class="number">0.1</span>]]])</span><br><span class="line">samples = np.array([<span class="number">200</span>, <span class="number">500</span>, <span class="number">200</span>])</span><br><span class="line">means = np.array([[<span class="number">0.0</span>, -<span class="number">0.70</span>], [<span class="number">0.0</span>, <span class="number">0.0</span>], [<span class="number">0.0</span>, <span class="number">0.70</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># mean_precision_prior= 0.8 to minimize the influence of the prior</span></span><br><span class="line">estimators = [</span><br><span class="line">    (</span><br><span class="line">        <span class="string">&quot;Finite mixture with a Dirichlet distribution\nprior and &quot;</span> <span class="string">r&quot;$\gamma_0=$&quot;</span>,</span><br><span class="line">        BayesianGaussianMixture(</span><br><span class="line">            weight_concentration_prior_type=<span class="string">&quot;dirichlet_distribution&quot;</span>,</span><br><span class="line">            n_components=<span class="number">2</span> * n_components,</span><br><span class="line">            reg_covar=<span class="number">0</span>,</span><br><span class="line">            init_params=<span class="string">&quot;random&quot;</span>,</span><br><span class="line">            max_iter=<span class="number">1500</span>,</span><br><span class="line">            mean_precision_prior=<span class="number">0.8</span>,</span><br><span class="line">            random_state=random_state,</span><br><span class="line">        ),</span><br><span class="line">        [<span class="number">0.001</span>, <span class="number">1</span>, <span class="number">1000</span>],</span><br><span class="line">    ),</span><br><span class="line">    (</span><br><span class="line">        <span class="string">&quot;Infinite mixture with a Dirichlet process\n prior and&quot;</span> <span class="string">r&quot;$\gamma_0=$&quot;</span>,</span><br><span class="line">        BayesianGaussianMixture(</span><br><span class="line">            weight_concentration_prior_type=<span class="string">&quot;dirichlet_process&quot;</span>,</span><br><span class="line">            n_components=<span class="number">2</span> * n_components,</span><br><span class="line">            reg_covar=<span class="number">0</span>,</span><br><span class="line">            init_params=<span class="string">&quot;random&quot;</span>,</span><br><span class="line">            max_iter=<span class="number">1500</span>,</span><br><span class="line">            mean_precision_prior=<span class="number">0.8</span>,</span><br><span class="line">            random_state=random_state,</span><br><span class="line">        ),</span><br><span class="line">        [<span class="number">1</span>, <span class="number">1000</span>, <span class="number">100000</span>],</span><br><span class="line">    ),</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Generate data</span></span><br><span class="line">rng = np.random.RandomState(random_state)</span><br><span class="line">X = np.vstack([rng.multivariate_normal(means[j], covars[j], samples[j]) <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n_components)])</span><br><span class="line">y = np.concatenate([np.full(samples[j], j, dtype=<span class="built_in">int</span>) <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n_components)])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot results in two different figures</span></span><br><span class="line"><span class="keyword">for</span> title, estimator, concentrations_prior <span class="keyword">in</span> estimators:</span><br><span class="line">    plt.figure(figsize=(<span class="number">4.7</span> * <span class="number">3</span>, <span class="number">8</span>))</span><br><span class="line">    plt.subplots_adjust(bottom=<span class="number">0.04</span>, top=<span class="number">0.90</span>, hspace=<span class="number">0.05</span>, wspace=<span class="number">0.05</span>, left=<span class="number">0.03</span>, right=<span class="number">0.99</span>)</span><br><span class="line"></span><br><span class="line">    gs = gridspec.GridSpec(<span class="number">3</span>, <span class="built_in">len</span>(concentrations_prior))</span><br><span class="line">    <span class="keyword">for</span> k, concentration <span class="keyword">in</span> <span class="built_in">enumerate</span>(concentrations_prior):</span><br><span class="line">        estimator.weight_concentration_prior = concentration</span><br><span class="line">        estimator.fit(X)</span><br><span class="line">        plot_results(plt.subplot(gs[<span class="number">0</span>:<span class="number">2</span>, k]),plt.subplot(gs[<span class="number">2</span>, k]),estimator,X,y,<span class="string">r&quot;%s$%.1e$&quot;</span> % (title, concentration),plot_title=k == <span class="number">0</span>,)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<img data-src="/2024/10/09/artificial-intelligence/ML9_theory_study/ml_3.png" class="">

<hr>
<img data-src="/2024/10/09/artificial-intelligence/ML9_theory_study/ml_4.png" class="">

<h4 id="流形学习-Manifold-Learning"><a href="#流形学习-Manifold-Learning" class="headerlink" title="流形学习(Manifold Learning)"></a>流形学习(Manifold Learning)</h4><p><strong>流形学习</strong>(<code>Manifold Learning</code>)是一种<strong>非线性降维</strong>技术，旨在从<strong>高维数据</strong>中提取低维流形结构。它基于这样一个假设：高维数据通常分布在一个<strong>低维流形</strong>上，这种流形可以通过捕捉数据的内在几何特征来进行建模。<strong>流形</strong>：在数学中，<strong>流形</strong>是一个局部类似于<strong>欧几里得空间</strong>的空间。简单来说，<strong>流形</strong>可以被视为一种“<strong>曲面</strong>”，在高维空间中具有低维的特性。例如，二维球面是三维空间中的一个<strong>流形</strong>。<strong>高维数据</strong>：许多实际应用中的数据（如图像、文本、音频等）通常位于高维空间中。<strong>流形学习</strong>的目标是找到这些<strong>高维数据</strong>的低维表示，同时尽可能保留数据的结构和特征。<strong>流形学习</strong>包含多种算法和技术，如<strong>主成分分析</strong>(<code>PCA</code>)、<code>t-</code>分布随机邻域嵌入(<code>t-SNE</code>)、等距映射(<code>Isomap</code>)、局部线性嵌入(<code>LLE</code>)、多维尺度分析(<code>MDS</code>)、<code>Hessian</code>特征映射(<code>HLLE</code>)、谱嵌入(<code>Spectral Embedding</code>)、统一流形近似与投影(<code>UMAP</code>)等。</p>
<h5 id="主成分分析-PCA"><a href="#主成分分析-PCA" class="headerlink" title="主成分分析(PCA)"></a>主成分分析(PCA)</h5><p><strong>主成分分析</strong>(<code>Principal Component Analysis, PCA</code>)是一种常用的<strong>线性降维技术</strong>，旨在通过提取数据中的主要特征来减少数据的维度，同时尽可能保留原始数据的变异性。<strong>主成分分析</strong>(<code>PCA</code>)在<strong>数据预处理</strong>、<strong>特征提取</strong>和<strong>可视化</strong>等领域中广泛应用。<strong>主成分分析</strong>(<code>PCA</code>)原理：<strong>主成分分析</strong>(<code>PCA</code>)的核心思想是将<strong>高维数据</strong>投影到<strong>低维空间</strong>中，使得投影后的数据在新的坐标系中具有最大的<strong>方差</strong>。具体步骤如下：<br><strong>标准化数据</strong>：首先对数据进行标准化处理，确保每个特征的<strong>均值</strong>为<code>0</code>，<strong>方差</strong>为<code>1</code>。这一步是为了消除不同特征之间的<strong>量纲影响</strong>。<br><strong>计算协方差矩阵</strong>：计算标准化后数据的<strong>协方差矩阵</strong> <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="1.719ex" height="1.645ex" role="img" focusable="false" viewBox="0 -705 760 727" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-24-TEX-I-1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D436" xlink:href="#MJX-24-TEX-I-1D436"></use></g></g></g></svg></mjx-container>，其公式为：<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.912ex;" xmlns="http://www.w3.org/2000/svg" width="15.782ex" height="2.869ex" role="img" focusable="false" viewBox="0 -864.9 6975.5 1267.9" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-24-TEX-I-1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path><path id="MJX-24-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-24-TEX-N-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path id="MJX-24-TEX-I-1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-24-TEX-N-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path id="MJX-24-TEX-N-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path id="MJX-24-TEX-I-1D44B" d="M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z"></path><path id="MJX-24-TEX-I-1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path><path id="MJX-24-TEX-N-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D436" xlink:href="#MJX-24-TEX-I-1D436"></use></g><g data-mml-node="mo" transform="translate(1037.8,0)"><use data-c="3D" xlink:href="#MJX-24-TEX-N-3D"></use></g><g data-mml-node="mfrac" transform="translate(2093.6,0)"><g data-mml-node="mn" transform="translate(707.2,394) scale(0.707)"><use data-c="31" xlink:href="#MJX-24-TEX-N-31"></use></g><g data-mml-node="mrow" transform="translate(220,-345) scale(0.707)"><g data-mml-node="mi"><use data-c="1D45B" xlink:href="#MJX-24-TEX-I-1D45B"></use></g><g data-mml-node="mo" transform="translate(600,0)"><use data-c="2212" xlink:href="#MJX-24-TEX-N-2212"></use></g><g data-mml-node="mn" transform="translate(1378,0)"><use data-c="31" xlink:href="#MJX-24-TEX-N-31"></use></g></g><rect width="1527.9" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(3861.5,0)"><use data-c="28" xlink:href="#MJX-24-TEX-N-28"></use></g><g data-mml-node="msup" transform="translate(4250.5,0)"><g data-mml-node="mi"><use data-c="1D44B" xlink:href="#MJX-24-TEX-I-1D44B"></use></g><g data-mml-node="mi" transform="translate(936.2,363) scale(0.707)"><use data-c="1D447" xlink:href="#MJX-24-TEX-I-1D447"></use></g></g><g data-mml-node="mi" transform="translate(5734.5,0)"><use data-c="1D44B" xlink:href="#MJX-24-TEX-I-1D44B"></use></g><g data-mml-node="mo" transform="translate(6586.5,0)"><use data-c="29" xlink:href="#MJX-24-TEX-N-29"></use></g></g></g></svg></mjx-container>。其中<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="1.928ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 852 683" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-24-TEX-I-1D44B" d="M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D44B" xlink:href="#MJX-24-TEX-I-1D44B"></use></g></g></g></svg></mjx-container>是标准化后的数据矩阵，<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.357ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 600 453" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-24-TEX-I-1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D45B" xlink:href="#MJX-24-TEX-I-1D45B"></use></g></g></g></svg></mjx-container>是样本数量。</p>
<ul>
<li><strong>特征值分解</strong>：对<strong>协方差矩阵</strong>进行<strong>特征值分解</strong>，得到特征值和对应的特征向量。<strong>特征值</strong>表示每个主成分所解释的方差大小，而<strong>特征向量</strong>则表示新坐标系的方向。</li>
<li><strong>选择主成分</strong>：根据<strong>特征值</strong>的大小选择前<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.179ex" height="1.595ex" role="img" focusable="false" viewBox="0 -694 521 705" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-24-TEX-I-1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D458" xlink:href="#MJX-24-TEX-I-1D458"></use></g></g></g></svg></mjx-container>个<strong>主成分</strong>，这些<strong>主成分</strong>对应于最大的<strong>特征值</strong>。</li>
<li><strong>转换数据</strong>：将原始数据投影到选定的<strong>主成分</strong>上，得到降维后的数据表示。</li>
</ul>
<p>下面是鸢尾花数据集的一个示例，它由4个特征组成，投影在可以解释<strong>最大方差</strong>的2个维度上：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> mpl_toolkits.mplot3d  </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets, decomposition</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">X = iris.data</span><br><span class="line">y = iris.target</span><br><span class="line"></span><br><span class="line">fig = plt.figure(<span class="number">1</span>, figsize=(<span class="number">4</span>, <span class="number">3</span>))</span><br><span class="line">plt.clf()</span><br><span class="line"></span><br><span class="line">ax = fig.add_subplot(<span class="number">111</span>, projection=<span class="string">&quot;3d&quot;</span>, elev=<span class="number">48</span>, azim=<span class="number">134</span>)</span><br><span class="line">ax.set_position([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0.95</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">plt.cla()</span><br><span class="line">pca = decomposition.PCA(n_components=<span class="number">3</span>)</span><br><span class="line">pca.fit(X)</span><br><span class="line">X = pca.transform(X)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> name, label <span class="keyword">in</span> [(<span class="string">&quot;Setosa&quot;</span>, <span class="number">0</span>), (<span class="string">&quot;Versicolour&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;Virginica&quot;</span>, <span class="number">2</span>)]:</span><br><span class="line">    ax.text3D(X[y == label, <span class="number">0</span>].mean(),X[y == label, <span class="number">1</span>].mean() + <span class="number">1.5</span>,X[y == label, <span class="number">2</span>].mean(),name,horizontalalignment=<span class="string">&quot;center&quot;</span>,</span><br><span class="line">        bbox=<span class="built_in">dict</span>(alpha=<span class="number">0.5</span>, edgecolor=<span class="string">&quot;w&quot;</span>, facecolor=<span class="string">&quot;w&quot;</span>),)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Reorder the labels to have colors matching the cluster results</span></span><br><span class="line">y = np.choose(y, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>]).astype(<span class="built_in">float</span>)</span><br><span class="line">ax.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], X[:, <span class="number">2</span>], c=y, cmap=plt.cm.nipy_spectral, edgecolor=<span class="string">&quot;k&quot;</span>)</span><br><span class="line"></span><br><span class="line">ax.xaxis.set_ticklabels([])</span><br><span class="line">ax.yaxis.set_ticklabels([])</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<img data-src="/2024/10/09/artificial-intelligence/ML9_theory_study/ml_5.png" class="">

<h6 id="增量主成分分析-IPCA"><a href="#增量主成分分析-IPCA" class="headerlink" title="增量主成分分析(IPCA)"></a>增量主成分分析(IPCA)</h6><p><strong>增量主成分分析</strong>(<code>IPCA</code>)是一种用于处理大规模数据集的降维技术，特别适合于不能一次性加载到内存中的数据。与传统的主成分分析(<code>PCA</code>)不同，<strong>增量主成分分析</strong>(<code>IPCA</code>)允许逐步更新模型，通过分批处理数据来实现高效的计算。<strong>增量主成分分析</strong>(<code>IPCA</code>)基本原理：<strong>数据分批处理</strong>，将大数据集划分为多个小批次，每次只处理一个批次的数据。这种方式使得内存使用量与输入数据样本数量无关，而是与特征数量相关；<strong>更新模型</strong>，每当新的一批数据到达时，使用当前模型的状态（如<strong>主成分</strong>和<strong>协方差矩阵</strong>）来更新<strong>主成分</strong>。这通常涉及到对当前<strong>主成分</strong>进行调整，以反映新数据的影响；<strong>特征值和特征向量计算</strong>，通过对当前的<strong>协方差矩阵</strong>进行<strong>特征值分解</strong>，提取新的<strong>主成分</strong>。</p>
<p>当要分解的数据集太大而无法装入内存时，<strong>增量主成分分析</strong>(<code>IPCA</code>)通常用于替代<strong>主成分分析</strong>(<code>PCA</code>)。<strong>增量主成分分析</strong>(<code>IPCA</code>)使用与输入数据样本数量无关的内存量为输入数据构建<strong>低秩近似</strong>。它仍然依赖于输入数据特征，但更改批处理大小可以控制内存使用量。此示例可直观地检查<strong>增量主成分分析</strong>(<code>IPCA</code>)是否能够找到与<strong>主成分分析</strong>(<code>PCA</code>)相似的数据投影（符号翻转），<strong>增量主成分分析</strong>(<code>IPCA</code>)适用于无法装入内存的大型数据集，这时需要增量方法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA, IncrementalPCA</span><br><span class="line"></span><br><span class="line">iris = load_iris()</span><br><span class="line">X = iris.data</span><br><span class="line">y = iris.target</span><br><span class="line"></span><br><span class="line">n_components = <span class="number">2</span></span><br><span class="line">ipca = IncrementalPCA(n_components=n_components, batch_size=<span class="number">10</span>)</span><br><span class="line">X_ipca = ipca.fit_transform(X)</span><br><span class="line"></span><br><span class="line">pca = PCA(n_components=n_components)</span><br><span class="line">X_pca = pca.fit_transform(X)</span><br><span class="line"></span><br><span class="line">colors = [<span class="string">&quot;navy&quot;</span>, <span class="string">&quot;turquoise&quot;</span>, <span class="string">&quot;darkorange&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> X_transformed, title <span class="keyword">in</span> [(X_ipca, <span class="string">&quot;Incremental PCA&quot;</span>), (X_pca, <span class="string">&quot;PCA&quot;</span>)]:</span><br><span class="line">    plt.figure(figsize=(<span class="number">8</span>, <span class="number">8</span>))</span><br><span class="line">    <span class="keyword">for</span> color, i, target_name <span class="keyword">in</span> <span class="built_in">zip</span>(colors, [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], iris.target_names):</span><br><span class="line">        plt.scatter(X_transformed[y == i, <span class="number">0</span>],X_transformed[y == i, <span class="number">1</span>],color=color,lw=<span class="number">2</span>,label=target_name,)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;Incremental&quot;</span> <span class="keyword">in</span> title:</span><br><span class="line">        err = np.<span class="built_in">abs</span>(np.<span class="built_in">abs</span>(X_pca) - np.<span class="built_in">abs</span>(X_ipca)).mean()</span><br><span class="line">        plt.title(title + <span class="string">&quot; of iris dataset\nMean absolute unsigned error %.6f&quot;</span> % err)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        plt.title(title + <span class="string">&quot; of iris dataset&quot;</span>)</span><br><span class="line">    plt.legend(loc=<span class="string">&quot;best&quot;</span>, shadow=<span class="literal">False</span>, scatterpoints=<span class="number">1</span>)</span><br><span class="line">    plt.axis([-<span class="number">4</span>, <span class="number">4</span>, -<span class="number">1.5</span>, <span class="number">1.5</span>])</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<img data-src="/2024/10/09/artificial-intelligence/ML9_theory_study/ml_6.png" class="">

<h6 id="随机奇异值分解的主成分分析-PCA-using-Randomized-SVD"><a href="#随机奇异值分解的主成分分析-PCA-using-Randomized-SVD" class="headerlink" title="随机奇异值分解的主成分分析(PCA using Randomized SVD)"></a>随机奇异值分解的主成分分析(PCA using Randomized SVD)</h6><p><strong>随机奇异值分解</strong>(<code>Randomized SVD</code>)是一种高效的算法，用于执行<strong>主成分分析</strong>(<code>PCA</code>)，特别是在处理大规模数据集时。与传统的<strong>主成分分析</strong>(<code>PCA</code>)方法相比，<strong>随机奇异值分解</strong>(<code>Randomized SVD</code>)可以显著减少计算时间和内存使用。<strong>主成分分析</strong>(<code>PCA</code>)的目标是通过提取数据中主要的方差方向来降低数据维度。<strong>随机奇异值分解</strong>(<code>Randomized SVD</code>)通过引入随机化技术来加速这一过程，具体步骤如下：</p>
<ul>
<li><strong>数据预处理</strong>：首先，对数据进行中心化，即减去每个特征的<strong>均值</strong>。</li>
<li><strong>构建随机投影</strong>：生成一个<strong>随机矩阵</strong>，通常是<strong>高斯随机矩阵</strong>，将原始数据投影到一个较小的子空间中。这一步骤减少了需要处理的数据量。</li>
<li><strong>计算</strong><code>SVD</code>：对投影后的数据执行标准的<strong>奇异值分解</strong>，得到<strong>奇异值</strong>和对应的<strong>奇异向量</strong>。这些<strong>奇异向量</strong>用于构建<strong>主成分分析</strong>(<code>PCA</code>)的主成分。</li>
<li><strong>选择主成分</strong>：根据<strong>奇异值</strong>选择前<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.179ex" height="1.595ex" role="img" focusable="false" viewBox="0 -694 521 705" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-24-TEX-I-1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D458" xlink:href="#MJX-24-TEX-I-1D458"></use></g></g></g></svg></mjx-container>个主成分，这些主成分对应于<strong>最大方差</strong>方向。</li>
</ul>
<p>通过删除与较低<strong>奇异值</strong>相关的分量的<strong>奇异向量</strong>，将数据投影到保留大部分方差的<strong>低维空间</strong>通常很有趣。例如使用<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="7.291ex" height="1.581ex" role="img" focusable="false" viewBox="0 -677 3222.4 699" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-24-TEX-N-36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path><path id="MJX-24-TEX-N-34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path><path id="MJX-24-TEX-N-D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><use data-c="36" xlink:href="#MJX-24-TEX-N-36"></use><use data-c="34" xlink:href="#MJX-24-TEX-N-34" transform="translate(500,0)"></use></g><g data-mml-node="mo" transform="translate(1222.2,0)"><use data-c="D7" xlink:href="#MJX-24-TEX-N-D7"></use></g><g data-mml-node="mn" transform="translate(2222.4,0)"><use data-c="36" xlink:href="#MJX-24-TEX-N-36"></use><use data-c="34" xlink:href="#MJX-24-TEX-N-34" transform="translate(500,0)"></use></g></g></g></svg></mjx-container>像素灰度图片进行人脸识别，数据的维数为<code>4096</code>，在如此宽的数据上训练<code>RBF</code><strong>支持向量机</strong>的速度很慢。此外，数据的固有维数远低于<code>4096</code>，因为所有人脸图片看起来都有些相似。样本位于维数低得多的<strong>流形</strong>上（例如大约<code>200</code>）。<strong>主成分分析</strong>(<code>PCA</code>)算法可用于线性变换数据，同时降低维数并同时保留大部分方差。例如，下图显示了<code>Olivetti</code>数据集中的<code>16</code>个样本肖像（以<code>0.0</code>为中心）。右侧是重新<strong>流形</strong>为肖像的前<code>16</code>个<strong>奇异向量</strong>。由于我们只需数据集前<code>16</code>个<strong>奇异向量</strong>样本大小为<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.65ex;" xmlns="http://www.w3.org/2000/svg" width="12.763ex" height="2.181ex" role="img" focusable="false" viewBox="0 -677 5641.4 964.2" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-23-TEX-I-1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-23-TEX-N-73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path id="MJX-23-TEX-N-61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path id="MJX-23-TEX-N-6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path id="MJX-23-TEX-N-70" d="M36 -148H50Q89 -148 97 -134V-126Q97 -119 97 -107T97 -77T98 -38T98 6T98 55T98 106Q98 140 98 177T98 243T98 296T97 335T97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 61 434T98 436Q115 437 135 438T165 441T176 442H179V416L180 390L188 397Q247 441 326 441Q407 441 464 377T522 216Q522 115 457 52T310 -11Q242 -11 190 33L182 40V-45V-101Q182 -128 184 -134T195 -145Q216 -148 244 -148H260V-194H252L228 -193Q205 -192 178 -192T140 -191Q37 -191 28 -194H20V-148H36ZM424 218Q424 292 390 347T305 402Q234 402 182 337V98Q222 26 294 26Q345 26 384 80T424 218Z"></path><path id="MJX-23-TEX-N-6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path><path id="MJX-23-TEX-N-65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z"></path><path id="MJX-23-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-23-TEX-N-34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path><path id="MJX-23-TEX-N-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="1D45B" xlink:href="#MJX-23-TEX-I-1D45B"></use></g><g data-mml-node="TeXAtom" transform="translate(633,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><use data-c="73" xlink:href="#MJX-23-TEX-N-73"></use><use data-c="61" xlink:href="#MJX-23-TEX-N-61" transform="translate(394,0)"></use><use data-c="6D" xlink:href="#MJX-23-TEX-N-6D" transform="translate(894,0)"></use><use data-c="70" xlink:href="#MJX-23-TEX-N-70" transform="translate(1727,0)"></use><use data-c="6C" xlink:href="#MJX-23-TEX-N-6C" transform="translate(2283,0)"></use><use data-c="65" xlink:href="#MJX-23-TEX-N-65" transform="translate(2561,0)"></use></g></g></g><g data-mml-node="mo" transform="translate(3085.6,0)"><use data-c="3D" xlink:href="#MJX-23-TEX-N-3D"></use></g><g data-mml-node="mn" transform="translate(4141.4,0)"><use data-c="34" xlink:href="#MJX-23-TEX-N-34"></use><use data-c="30" xlink:href="#MJX-23-TEX-N-30" transform="translate(500,0)"></use><use data-c="30" xlink:href="#MJX-23-TEX-N-30" transform="translate(1000,0)"></use></g></g></g></svg></mjx-container>且特征数为<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="24.874ex" height="1.889ex" role="img" focusable="false" viewBox="0 -677 10994.4 834.8" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-23-TEX-I-1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-23-TEX-N-66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z"></path><path id="MJX-23-TEX-N-65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z"></path><path id="MJX-23-TEX-N-61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path id="MJX-23-TEX-N-74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z"></path><path id="MJX-23-TEX-N-75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z"></path><path id="MJX-23-TEX-N-72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z"></path><path id="MJX-23-TEX-N-73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path id="MJX-23-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-23-TEX-N-36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path><path id="MJX-23-TEX-N-34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path><path id="MJX-23-TEX-N-D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path><path id="MJX-23-TEX-N-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path id="MJX-23-TEX-N-39" d="M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="1D45B" xlink:href="#MJX-23-TEX-I-1D45B"></use></g><g data-mml-node="TeXAtom" transform="translate(633,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><use data-c="66" xlink:href="#MJX-23-TEX-N-66"></use><use data-c="65" xlink:href="#MJX-23-TEX-N-65" transform="translate(306,0)"></use><use data-c="61" xlink:href="#MJX-23-TEX-N-61" transform="translate(750,0)"></use><use data-c="74" xlink:href="#MJX-23-TEX-N-74" transform="translate(1250,0)"></use><use data-c="75" xlink:href="#MJX-23-TEX-N-75" transform="translate(1639,0)"></use><use data-c="72" xlink:href="#MJX-23-TEX-N-72" transform="translate(2195,0)"></use><use data-c="65" xlink:href="#MJX-23-TEX-N-65" transform="translate(2587,0)"></use><use data-c="73" xlink:href="#MJX-23-TEX-N-73" transform="translate(3031,0)"></use></g></g></g><g data-mml-node="mo" transform="translate(3382.6,0)"><use data-c="3D" xlink:href="#MJX-23-TEX-N-3D"></use></g><g data-mml-node="mn" transform="translate(4438.4,0)"><use data-c="36" xlink:href="#MJX-23-TEX-N-36"></use><use data-c="34" xlink:href="#MJX-23-TEX-N-34" transform="translate(500,0)"></use></g><g data-mml-node="mo" transform="translate(5660.6,0)"><use data-c="D7" xlink:href="#MJX-23-TEX-N-D7"></use></g><g data-mml-node="mn" transform="translate(6660.8,0)"><use data-c="36" xlink:href="#MJX-23-TEX-N-36"></use><use data-c="34" xlink:href="#MJX-23-TEX-N-34" transform="translate(500,0)"></use></g><g data-mml-node="mo" transform="translate(7938.6,0)"><use data-c="3D" xlink:href="#MJX-23-TEX-N-3D"></use></g><g data-mml-node="mn" transform="translate(8994.4,0)"><use data-c="34" xlink:href="#MJX-23-TEX-N-34"></use><use data-c="30" xlink:href="#MJX-23-TEX-N-30" transform="translate(500,0)"></use><use data-c="39" xlink:href="#MJX-23-TEX-N-39" transform="translate(1000,0)"></use><use data-c="36" xlink:href="#MJX-23-TEX-N-36" transform="translate(1500,0)"></use></g></g></g></svg></mjx-container>，计算时间小于<code>1s</code>。注意<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.65ex;" xmlns="http://www.w3.org/2000/svg" width="27.893ex" height="2.347ex" role="img" focusable="false" viewBox="0 -750 12328.8 1037.2" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-23-TEX-I-1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-23-TEX-N-6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path id="MJX-23-TEX-N-61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path id="MJX-23-TEX-N-78" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z"></path><path id="MJX-23-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-23-TEX-N-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path id="MJX-23-TEX-N-73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path id="MJX-23-TEX-N-70" d="M36 -148H50Q89 -148 97 -134V-126Q97 -119 97 -107T97 -77T98 -38T98 6T98 55T98 106Q98 140 98 177T98 243T98 296T97 335T97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 61 434T98 436Q115 437 135 438T165 441T176 442H179V416L180 390L188 397Q247 441 326 441Q407 441 464 377T522 216Q522 115 457 52T310 -11Q242 -11 190 33L182 40V-45V-101Q182 -128 184 -134T195 -145Q216 -148 244 -148H260V-194H252L228 -193Q205 -192 178 -192T140 -191Q37 -191 28 -194H20V-148H36ZM424 218Q424 292 390 347T305 402Q234 402 182 337V98Q222 26 294 26Q345 26 384 80T424 218Z"></path><path id="MJX-23-TEX-N-6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path><path id="MJX-23-TEX-N-65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z"></path><path id="MJX-23-TEX-N-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path><path id="MJX-23-TEX-N-66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z"></path><path id="MJX-23-TEX-N-74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z"></path><path id="MJX-23-TEX-N-75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z"></path><path id="MJX-23-TEX-N-72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z"></path><path id="MJX-23-TEX-N-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="1D45B" xlink:href="#MJX-23-TEX-I-1D45B"></use></g><g data-mml-node="TeXAtom" transform="translate(633,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><use data-c="6D" xlink:href="#MJX-23-TEX-N-6D"></use><use data-c="61" xlink:href="#MJX-23-TEX-N-61" transform="translate(833,0)"></use><use data-c="78" xlink:href="#MJX-23-TEX-N-78" transform="translate(1333,0)"></use></g></g></g><g data-mml-node="mo" transform="translate(2276.7,0)"><use data-c="3D" xlink:href="#MJX-23-TEX-N-3D"></use></g><g data-mml-node="mo" transform="translate(3332.5,0)"><use data-c="6D" xlink:href="#MJX-23-TEX-N-6D"></use><use data-c="61" xlink:href="#MJX-23-TEX-N-61" transform="translate(833,0)"></use><use data-c="78" xlink:href="#MJX-23-TEX-N-78" transform="translate(1333,0)"></use></g><g data-mml-node="mo" transform="translate(5193.5,0)"><use data-c="28" xlink:href="#MJX-23-TEX-N-28"></use></g><g data-mml-node="msub" transform="translate(5582.5,0)"><g data-mml-node="mi"><use data-c="1D45B" xlink:href="#MJX-23-TEX-I-1D45B"></use></g><g data-mml-node="TeXAtom" transform="translate(633,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><use data-c="73" xlink:href="#MJX-23-TEX-N-73"></use><use data-c="61" xlink:href="#MJX-23-TEX-N-61" transform="translate(394,0)"></use><use data-c="6D" xlink:href="#MJX-23-TEX-N-6D" transform="translate(894,0)"></use><use data-c="70" xlink:href="#MJX-23-TEX-N-70" transform="translate(1727,0)"></use><use data-c="6C" xlink:href="#MJX-23-TEX-N-6C" transform="translate(2283,0)"></use><use data-c="65" xlink:href="#MJX-23-TEX-N-65" transform="translate(2561,0)"></use></g></g></g><g data-mml-node="mo" transform="translate(8390.3,0)"><use data-c="2C" xlink:href="#MJX-23-TEX-N-2C"></use></g><g data-mml-node="msub" transform="translate(8835,0)"><g data-mml-node="mi"><use data-c="1D45B" xlink:href="#MJX-23-TEX-I-1D45B"></use></g><g data-mml-node="TeXAtom" transform="translate(633,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><use data-c="66" xlink:href="#MJX-23-TEX-N-66"></use><use data-c="65" xlink:href="#MJX-23-TEX-N-65" transform="translate(306,0)"></use><use data-c="61" xlink:href="#MJX-23-TEX-N-61" transform="translate(750,0)"></use><use data-c="74" xlink:href="#MJX-23-TEX-N-74" transform="translate(1250,0)"></use><use data-c="75" xlink:href="#MJX-23-TEX-N-75" transform="translate(1639,0)"></use><use data-c="72" xlink:href="#MJX-23-TEX-N-72" transform="translate(2195,0)"></use><use data-c="65" xlink:href="#MJX-23-TEX-N-65" transform="translate(2587,0)"></use><use data-c="73" xlink:href="#MJX-23-TEX-N-73" transform="translate(3031,0)"></use></g></g></g><g data-mml-node="mo" transform="translate(11939.8,0)"><use data-c="29" xlink:href="#MJX-23-TEX-N-29"></use></g></g></g></svg></mjx-container>和<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.65ex;" xmlns="http://www.w3.org/2000/svg" width="27.144ex" height="2.347ex" role="img" focusable="false" viewBox="0 -750 11997.7 1037.2" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-23-TEX-I-1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-23-TEX-N-6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path id="MJX-23-TEX-N-69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z"></path><path id="MJX-23-TEX-N-6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path id="MJX-23-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-23-TEX-N-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path id="MJX-23-TEX-N-73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path id="MJX-23-TEX-N-61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path id="MJX-23-TEX-N-70" d="M36 -148H50Q89 -148 97 -134V-126Q97 -119 97 -107T97 -77T98 -38T98 6T98 55T98 106Q98 140 98 177T98 243T98 296T97 335T97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 61 434T98 436Q115 437 135 438T165 441T176 442H179V416L180 390L188 397Q247 441 326 441Q407 441 464 377T522 216Q522 115 457 52T310 -11Q242 -11 190 33L182 40V-45V-101Q182 -128 184 -134T195 -145Q216 -148 244 -148H260V-194H252L228 -193Q205 -192 178 -192T140 -191Q37 -191 28 -194H20V-148H36ZM424 218Q424 292 390 347T305 402Q234 402 182 337V98Q222 26 294 26Q345 26 384 80T424 218Z"></path><path id="MJX-23-TEX-N-6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path><path id="MJX-23-TEX-N-65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z"></path><path id="MJX-23-TEX-N-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path><path id="MJX-23-TEX-N-66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z"></path><path id="MJX-23-TEX-N-74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z"></path><path id="MJX-23-TEX-N-75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z"></path><path id="MJX-23-TEX-N-72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z"></path><path id="MJX-23-TEX-N-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="1D45B" xlink:href="#MJX-23-TEX-I-1D45B"></use></g><g data-mml-node="TeXAtom" transform="translate(633,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><use data-c="6D" xlink:href="#MJX-23-TEX-N-6D"></use><use data-c="69" xlink:href="#MJX-23-TEX-N-69" transform="translate(833,0)"></use><use data-c="6E" xlink:href="#MJX-23-TEX-N-6E" transform="translate(1111,0)"></use></g></g></g><g data-mml-node="mo" transform="translate(2139.5,0)"><use data-c="3D" xlink:href="#MJX-23-TEX-N-3D"></use></g><g data-mml-node="mo" transform="translate(3195.3,0)"><use data-c="6D" xlink:href="#MJX-23-TEX-N-6D"></use><use data-c="69" xlink:href="#MJX-23-TEX-N-69" transform="translate(833,0)"></use><use data-c="6E" xlink:href="#MJX-23-TEX-N-6E" transform="translate(1111,0)"></use></g><g data-mml-node="mo" transform="translate(4862.3,0)"><use data-c="28" xlink:href="#MJX-23-TEX-N-28"></use></g><g data-mml-node="msub" transform="translate(5251.3,0)"><g data-mml-node="mi"><use data-c="1D45B" xlink:href="#MJX-23-TEX-I-1D45B"></use></g><g data-mml-node="TeXAtom" transform="translate(633,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><use data-c="73" xlink:href="#MJX-23-TEX-N-73"></use><use data-c="61" xlink:href="#MJX-23-TEX-N-61" transform="translate(394,0)"></use><use data-c="6D" xlink:href="#MJX-23-TEX-N-6D" transform="translate(894,0)"></use><use data-c="70" xlink:href="#MJX-23-TEX-N-70" transform="translate(1727,0)"></use><use data-c="6C" xlink:href="#MJX-23-TEX-N-6C" transform="translate(2283,0)"></use><use data-c="65" xlink:href="#MJX-23-TEX-N-65" transform="translate(2561,0)"></use></g></g></g><g data-mml-node="mo" transform="translate(8059.2,0)"><use data-c="2C" xlink:href="#MJX-23-TEX-N-2C"></use></g><g data-mml-node="msub" transform="translate(8503.8,0)"><g data-mml-node="mi"><use data-c="1D45B" xlink:href="#MJX-23-TEX-I-1D45B"></use></g><g data-mml-node="TeXAtom" transform="translate(633,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><use data-c="66" xlink:href="#MJX-23-TEX-N-66"></use><use data-c="65" xlink:href="#MJX-23-TEX-N-65" transform="translate(306,0)"></use><use data-c="61" xlink:href="#MJX-23-TEX-N-61" transform="translate(750,0)"></use><use data-c="74" xlink:href="#MJX-23-TEX-N-74" transform="translate(1250,0)"></use><use data-c="75" xlink:href="#MJX-23-TEX-N-75" transform="translate(1639,0)"></use><use data-c="72" xlink:href="#MJX-23-TEX-N-72" transform="translate(2195,0)"></use><use data-c="65" xlink:href="#MJX-23-TEX-N-65" transform="translate(2587,0)"></use><use data-c="73" xlink:href="#MJX-23-TEX-N-73" transform="translate(3031,0)"></use></g></g></g><g data-mml-node="mo" transform="translate(11608.7,0)"><use data-c="29" xlink:href="#MJX-23-TEX-N-29"></use></g></g></g></svg></mjx-container>，则其时间复杂度为<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.65ex;" xmlns="http://www.w3.org/2000/svg" width="19.537ex" height="2.536ex" role="img" focusable="false" viewBox="0 -833.9 8635.5 1121.1" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-23-TEX-C-4F" d="M308 428Q289 428 289 438Q289 457 318 508T378 593Q417 638 475 671T599 705Q688 705 732 643T777 483Q777 380 733 285T620 123T464 18T293 -22Q188 -22 123 51T58 245Q58 327 87 403T159 533T249 626T333 685T388 705Q404 705 404 693Q404 674 363 649Q333 632 304 606T239 537T181 429T158 290Q158 179 214 114T364 48Q489 48 583 165T677 438Q677 473 670 505T648 568T601 617T528 636Q518 636 513 635Q486 629 460 600T419 544T392 490Q383 470 372 459Q341 430 308 428Z"></path><path id="MJX-23-TEX-N-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path id="MJX-23-TEX-I-1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-23-TEX-N-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path id="MJX-23-TEX-N-6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path id="MJX-23-TEX-N-61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path id="MJX-23-TEX-N-78" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z"></path><path id="MJX-23-TEX-N-22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path><path id="MJX-23-TEX-N-63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path id="MJX-23-TEX-N-6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z"></path><path id="MJX-23-TEX-N-70" d="M36 -148H50Q89 -148 97 -134V-126Q97 -119 97 -107T97 -77T98 -38T98 6T98 55T98 106Q98 140 98 177T98 243T98 296T97 335T97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 61 434T98 436Q115 437 135 438T165 441T176 442H179V416L180 390L188 397Q247 441 326 441Q407 441 464 377T522 216Q522 115 457 52T310 -11Q242 -11 190 33L182 40V-45V-101Q182 -128 184 -134T195 -145Q216 -148 244 -148H260V-194H252L228 -193Q205 -192 178 -192T140 -191Q37 -191 28 -194H20V-148H36ZM424 218Q424 292 390 347T305 402Q234 402 182 337V98Q222 26 294 26Q345 26 384 80T424 218Z"></path><path id="MJX-23-TEX-N-6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path id="MJX-23-TEX-N-65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z"></path><path id="MJX-23-TEX-N-74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z"></path><path id="MJX-23-TEX-N-73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path id="MJX-23-TEX-N-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="4F" xlink:href="#MJX-23-TEX-C-4F"></use></g></g><g data-mml-node="mo" transform="translate(796,0)"><use data-c="28" xlink:href="#MJX-23-TEX-N-28"></use></g><g data-mml-node="msubsup" transform="translate(1185,0)"><g data-mml-node="mi"><use data-c="1D45B" xlink:href="#MJX-23-TEX-I-1D45B"></use></g><g data-mml-node="mn" transform="translate(633,363) scale(0.707)"><use data-c="32" xlink:href="#MJX-23-TEX-N-32"></use></g><g data-mml-node="TeXAtom" transform="translate(633,-247) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><use data-c="6D" xlink:href="#MJX-23-TEX-N-6D"></use><use data-c="61" xlink:href="#MJX-23-TEX-N-61" transform="translate(833,0)"></use><use data-c="78" xlink:href="#MJX-23-TEX-N-78" transform="translate(1333,0)"></use></g></g></g><g data-mml-node="mo" transform="translate(3406.1,0)"><use data-c="22C5" xlink:href="#MJX-23-TEX-N-22C5"></use></g><g data-mml-node="msub" transform="translate(3906.4,0)"><g data-mml-node="mi"><use data-c="1D45B" xlink:href="#MJX-23-TEX-I-1D45B"></use></g><g data-mml-node="TeXAtom" transform="translate(633,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><use data-c="63" xlink:href="#MJX-23-TEX-N-63"></use><use data-c="6F" xlink:href="#MJX-23-TEX-N-6F" transform="translate(444,0)"></use><use data-c="6D" xlink:href="#MJX-23-TEX-N-6D" transform="translate(944,0)"></use><use data-c="70" xlink:href="#MJX-23-TEX-N-70" transform="translate(1777,0)"></use><use data-c="6F" xlink:href="#MJX-23-TEX-N-6F" transform="translate(2333,0)"></use><use data-c="6E" xlink:href="#MJX-23-TEX-N-6E" transform="translate(2833,0)"></use><use data-c="65" xlink:href="#MJX-23-TEX-N-65" transform="translate(3389,0)"></use><use data-c="6E" xlink:href="#MJX-23-TEX-N-6E" transform="translate(3833,0)"></use><use data-c="74" xlink:href="#MJX-23-TEX-N-74" transform="translate(4389,0)"></use><use data-c="73" xlink:href="#MJX-23-TEX-N-73" transform="translate(4778,0)"></use></g></g></g><g data-mml-node="mo" transform="translate(8246.5,0)"><use data-c="29" xlink:href="#MJX-23-TEX-N-29"></use></g></g></g></svg></mjx-container>而不是<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.576ex;" xmlns="http://www.w3.org/2000/svg" width="13.93ex" height="2.463ex" role="img" focusable="false" viewBox="0 -833.9 6157.1 1088.7" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-23-TEX-C-4F" d="M308 428Q289 428 289 438Q289 457 318 508T378 593Q417 638 475 671T599 705Q688 705 732 643T777 483Q777 380 733 285T620 123T464 18T293 -22Q188 -22 123 51T58 245Q58 327 87 403T159 533T249 626T333 685T388 705Q404 705 404 693Q404 674 363 649Q333 632 304 606T239 537T181 429T158 290Q158 179 214 114T364 48Q489 48 583 165T677 438Q677 473 670 505T648 568T601 617T528 636Q518 636 513 635Q486 629 460 600T419 544T392 490Q383 470 372 459Q341 430 308 428Z"></path><path id="MJX-23-TEX-N-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path id="MJX-23-TEX-I-1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-23-TEX-N-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path id="MJX-23-TEX-N-6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path id="MJX-23-TEX-N-61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path id="MJX-23-TEX-N-78" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z"></path><path id="MJX-23-TEX-N-22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path><path id="MJX-23-TEX-N-69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z"></path><path id="MJX-23-TEX-N-6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path id="MJX-23-TEX-N-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="4F" xlink:href="#MJX-23-TEX-C-4F"></use></g></g><g data-mml-node="mo" transform="translate(796,0)"><use data-c="28" xlink:href="#MJX-23-TEX-N-28"></use></g><g data-mml-node="msubsup" transform="translate(1185,0)"><g data-mml-node="mi"><use data-c="1D45B" xlink:href="#MJX-23-TEX-I-1D45B"></use></g><g data-mml-node="mn" transform="translate(633,363) scale(0.707)"><use data-c="32" xlink:href="#MJX-23-TEX-N-32"></use></g><g data-mml-node="TeXAtom" transform="translate(633,-247) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><use data-c="6D" xlink:href="#MJX-23-TEX-N-6D"></use><use data-c="61" xlink:href="#MJX-23-TEX-N-61" transform="translate(833,0)"></use><use data-c="78" xlink:href="#MJX-23-TEX-N-78" transform="translate(1333,0)"></use></g></g></g><g data-mml-node="mo" transform="translate(3406.1,0)"><use data-c="22C5" xlink:href="#MJX-23-TEX-N-22C5"></use></g><g data-mml-node="msub" transform="translate(3906.4,0)"><g data-mml-node="mi"><use data-c="1D45B" xlink:href="#MJX-23-TEX-I-1D45B"></use></g><g data-mml-node="TeXAtom" transform="translate(633,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><use data-c="6D" xlink:href="#MJX-23-TEX-N-6D"></use><use data-c="69" xlink:href="#MJX-23-TEX-N-69" transform="translate(833,0)"></use><use data-c="6E" xlink:href="#MJX-23-TEX-N-6E" transform="translate(1111,0)"></use></g></g></g><g data-mml-node="mo" transform="translate(5768.1,0)"><use data-c="29" xlink:href="#MJX-23-TEX-N-29"></use></g></g></g></svg></mjx-container>。</p>
<p>下边是一个人脸识别的例子，使用<code>Olivetti</code>人脸数据集，使用<strong>奇异值分解</strong>(<code>SVD</code>)对数据进行<strong>线性降维</strong>，将其投影到较低维空间中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> numpy.random <span class="keyword">import</span> RandomState</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> cluster, decomposition</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> fetch_olivetti_faces</span><br><span class="line"></span><br><span class="line">rng = RandomState(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Display progress logs on stdout</span></span><br><span class="line">logging.basicConfig(level=logging.INFO, <span class="built_in">format</span>=<span class="string">&quot;%(asctime)s %(levelname)s %(message)s&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载并预处理Olivetti人脸数据集</span></span><br><span class="line">faces, _ = fetch_olivetti_faces(return_X_y=<span class="literal">True</span>, shuffle=<span class="literal">True</span>, random_state=rng)</span><br><span class="line">n_samples, n_features = faces.shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># Global centering (focus on one feature, centering all samples)</span></span><br><span class="line">faces_centered = faces - faces.mean(axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Local centering (focus on one sample, centering all features)</span></span><br><span class="line">faces_centered -= faces_centered.mean(axis=<span class="number">1</span>).reshape(n_samples, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(&quot;Dataset consists of %d faces&quot; % n_samples)</span></span><br><span class="line">n_row, n_col = <span class="number">2</span>, <span class="number">3</span></span><br><span class="line">n_components = n_row * n_col</span><br><span class="line">image_shape = (<span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个函数来绘制面部图</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_gallery</span>(<span class="params">title, images, n_col=n_col, n_row=n_row, cmap=plt.cm.gray</span>):</span><br><span class="line">    fig, axs = plt.subplots(nrows=n_row,ncols=n_col,figsize=(<span class="number">2.0</span> * n_col, <span class="number">2.3</span> * n_row),facecolor=<span class="string">&quot;white&quot;</span>,constrained_layout=<span class="literal">True</span>,)</span><br><span class="line">    fig.set_constrained_layout_pads(w_pad=<span class="number">0.01</span>, h_pad=<span class="number">0.02</span>, hspace=<span class="number">0</span>, wspace=<span class="number">0</span>)</span><br><span class="line">    fig.set_edgecolor(<span class="string">&quot;black&quot;</span>)</span><br><span class="line">    fig.suptitle(title, size=<span class="number">16</span>)</span><br><span class="line">    <span class="keyword">for</span> ax, vec <span class="keyword">in</span> <span class="built_in">zip</span>(axs.flat, images):</span><br><span class="line">        vmax = <span class="built_in">max</span>(vec.<span class="built_in">max</span>(), -vec.<span class="built_in">min</span>())</span><br><span class="line">        im = ax.imshow(vec.reshape(image_shape),cmap=cmap,interpolation=<span class="string">&quot;nearest&quot;</span>,vmin=-vmax,vmax=vmax,)</span><br><span class="line">        ax.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line"></span><br><span class="line">    fig.colorbar(im, ax=axs, orientation=<span class="string">&quot;horizontal&quot;</span>, shrink=<span class="number">0.99</span>, aspect=<span class="number">40</span>, pad=<span class="number">0.01</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">plot_gallery(<span class="string">&quot;Faces from dataset&quot;</span>, faces_centered[:n_components])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用随机奇异值分解(SVD)对数据进行线性降维，将其投影到较低维空间</span></span><br><span class="line">pca_estimator = decomposition.PCA(n_components=n_components, svd_solver=<span class="string">&quot;randomized&quot;</span>, whiten=<span class="literal">True</span>)</span><br><span class="line">pca_estimator.fit(faces_centered)</span><br><span class="line">plot_gallery(<span class="string">&quot;Eigenfaces - PCA using randomized SVD&quot;</span>, pca_estimator.components_[:n_components])</span><br></pre></td></tr></table></figure>
<img data-src="/2024/10/09/artificial-intelligence/ML9_theory_study/ml_7.png" class="" title="左边是原始人脸面部数据，右边是通过随机奇异值分解(SVD)的PCA降维后的数据">

<h6 id="稀疏主成分分析-SPCA"><a href="#稀疏主成分分析-SPCA" class="headerlink" title="稀疏主成分分析(SPCA)"></a>稀疏主成分分析(SPCA)</h6><p><strong>稀疏主成分分析</strong>(<code>SPCA</code>)是一种统计方法，旨在在保留数据主要特征的同时，增强结果的<strong>可解释性</strong>。与传统的<strong>主成分分析</strong>(<code>PCA</code>)相比，<strong>稀疏主成分分析</strong>(<code>SPCA</code>)通过引入<strong>稀疏性</strong>，使得<strong>主成分</strong>的系数大多数为<code>0</code>，从而突出主要变量，减少冗余信息。<strong>稀疏主成分分析</strong>(<code>SPCA</code>)在<strong>主成分分析</strong>(<code>PCA</code>)的基础上，引入了<strong>稀疏性</strong>，通过优化目标中的<code>L1</code><strong>正则化项</strong>，使得大部分系数变为<code>0</code>。这种方法不仅保留了数据的主要特征，还提高了结果的<strong>可解释性</strong>，因为它强调了对结果影响最大的变量。<strong>主成分分析</strong>(<code>PCA</code>)的缺点是，通过该方法提取的成分具有完全密集的表达式，当它们表示为原始变量的<strong>线性组合</strong>时，它们具有非零系数。这可能使解释变得困难。在许多情况下，真实的底层成分可以想象为<strong>稀疏向量</strong>；例如在人脸识别中，<strong>成分</strong>可能自然地映射到面部的各个部分。<strong>稀疏主成分</strong>产生更简约、更易于解释的表示，清楚地强调哪些原始特征导致了样本之间的差异。</p>
<p>以下示例使用<strong>稀疏主成分分析</strong>(<code>SPCA</code>)从<code>Olivetti</code>人脸数据集中提取16个成分，使用<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="7.291ex" height="1.581ex" role="img" focusable="false" viewBox="0 -677 3222.4 699" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-23-TEX-N-36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path><path id="MJX-23-TEX-N-34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path><path id="MJX-23-TEX-N-D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><use data-c="36" xlink:href="#MJX-23-TEX-N-36"></use><use data-c="34" xlink:href="#MJX-23-TEX-N-34" transform="translate(500,0)"></use></g><g data-mml-node="mo" transform="translate(1222.2,0)"><use data-c="D7" xlink:href="#MJX-23-TEX-N-D7"></use></g><g data-mml-node="mn" transform="translate(2222.4,0)"><use data-c="36" xlink:href="#MJX-23-TEX-N-36"></use><use data-c="34" xlink:href="#MJX-23-TEX-N-34" transform="translate(500,0)"></use></g></g></g></svg></mjx-container>像素灰度图片进行人脸识别，数据的维数为<code>4096</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> numpy.random <span class="keyword">import</span> RandomState</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> cluster, decomposition</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> fetch_olivetti_faces</span><br><span class="line"></span><br><span class="line">rng = RandomState(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Display progress logs on stdout</span></span><br><span class="line">logging.basicConfig(level=logging.INFO, <span class="built_in">format</span>=<span class="string">&quot;%(asctime)s %(levelname)s %(message)s&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载并预处理Olivetti人脸数据集</span></span><br><span class="line">faces, _ = fetch_olivetti_faces(return_X_y=<span class="literal">True</span>, shuffle=<span class="literal">True</span>, random_state=rng)</span><br><span class="line">n_samples, n_features = faces.shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># Global centering (focus on one feature, centering all samples)</span></span><br><span class="line">faces_centered = faces - faces.mean(axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Local centering (focus on one sample, centering all features)</span></span><br><span class="line">faces_centered -= faces_centered.mean(axis=<span class="number">1</span>).reshape(n_samples, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(&quot;Dataset consists of %d faces&quot; % n_samples)</span></span><br><span class="line">n_row, n_col = <span class="number">2</span>, <span class="number">3</span></span><br><span class="line">n_components = n_row * n_col</span><br><span class="line">image_shape = (<span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个函数来绘制面部图</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_gallery</span>(<span class="params">title, images, n_col=n_col, n_row=n_row, cmap=plt.cm.gray</span>):</span><br><span class="line">    fig, axs = plt.subplots(nrows=n_row,ncols=n_col,figsize=(<span class="number">2.0</span> * n_col, <span class="number">2.3</span> * n_row),facecolor=<span class="string">&quot;white&quot;</span>,constrained_layout=<span class="literal">True</span>,)</span><br><span class="line">    fig.set_constrained_layout_pads(w_pad=<span class="number">0.01</span>, h_pad=<span class="number">0.02</span>, hspace=<span class="number">0</span>, wspace=<span class="number">0</span>)</span><br><span class="line">    fig.set_edgecolor(<span class="string">&quot;black&quot;</span>)</span><br><span class="line">    fig.suptitle(title, size=<span class="number">16</span>)</span><br><span class="line">    <span class="keyword">for</span> ax, vec <span class="keyword">in</span> <span class="built_in">zip</span>(axs.flat, images):</span><br><span class="line">        vmax = <span class="built_in">max</span>(vec.<span class="built_in">max</span>(), -vec.<span class="built_in">min</span>())</span><br><span class="line">        im = ax.imshow(vec.reshape(image_shape),cmap=cmap,interpolation=<span class="string">&quot;nearest&quot;</span>,vmin=-vmax,vmax=vmax,)</span><br><span class="line">        ax.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line"></span><br><span class="line">    fig.colorbar(im, ax=axs, orientation=<span class="string">&quot;horizontal&quot;</span>, shrink=<span class="number">0.99</span>, aspect=<span class="number">40</span>, pad=<span class="number">0.01</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用随机奇异值分解(SVD)对数据进行线性降维，将其投影到较低维空间</span></span><br><span class="line">pca_estimator = decomposition.PCA(n_components=n_components, svd_solver=<span class="string">&quot;randomized&quot;</span>, whiten=<span class="literal">True</span>)</span><br><span class="line">pca_estimator.fit(faces_centered)</span><br><span class="line">plot_gallery(<span class="string">&quot;Eigenfaces - PCA using randomized SVD&quot;</span>, pca_estimator.components_[:n_components])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用小批量稀疏主成分分析(SPCA)对数据进行先线性降维，将其投影到较低维空间</span></span><br><span class="line">batch_pca_estimator = decomposition.MiniBatchSparsePCA(n_components=n_components, alpha=<span class="number">0.1</span>, max_iter=<span class="number">100</span>, batch_size=<span class="number">3</span>, random_state=rng)</span><br><span class="line">batch_pca_estimator.fit(faces_centered)</span><br><span class="line">plot_gallery(<span class="string">&quot;Sparse components - MiniBatchSparsePCA&quot;</span>,batch_pca_estimator.components_[:n_components],)</span><br></pre></td></tr></table></figure>
<img data-src="/2024/10/09/artificial-intelligence/ML9_theory_study/ml_8.png" class="" title="左边是通过随机奇异值分解(SVD)的PCA降维后的数据，右边是通过稀疏主成分分析(SPCA)降维后的数据">

<h5 id="核主成分分析-KPCA"><a href="#核主成分分析-KPCA" class="headerlink" title="核主成分分析(KPCA)"></a>核主成分分析(KPCA)</h5><p><strong>核主成分分析</strong>(<code>KPCA</code>)是一种扩展的<strong>主成分分析</strong>(<code>PCA</code>)技术，旨在处理非线性数据。与传统的<code>PCA</code>不同，<strong>核主成分分析</strong>(<code>KPCA</code>)通过引入<strong>核函数</strong>将数据映射到<strong>高维特征空间</strong>，从而能够在这个空间中进行<strong>线性降维</strong>。<strong>核主成分分析</strong>(<code>KPCA</code>)原理是利用<strong>核函数</strong>将原始数据映射到<strong>高维特征空间</strong>，使得在低维空间中非线性可分的数据在<strong>高维空间</strong>中变得<strong>线性可分</strong>。具体步骤如下：</p>
<ul>
<li><strong>计算核矩阵</strong>：使用<strong>核函数</strong>计算每对样本之间的相似度，形成<strong>核矩阵</strong>。</li>
<li><strong>中心化核矩阵</strong>：将核矩阵中的每个元素减去均值，以确保数据在高维空间中的中心为<code>0</code>。</li>
<li><strong>特征值分解</strong>：对中心化后的<strong>核矩阵</strong>进行<strong>特征值分解</strong>，提取<strong>特征向量</strong>和<strong>特征值</strong>。</li>
<li><strong>选择主成分</strong>：根据特征值的大小选择前<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.179ex" height="1.595ex" role="img" focusable="false" viewBox="0 -694 521 705" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-23-TEX-I-1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D458" xlink:href="#MJX-23-TEX-I-1D458"></use></g></g></g></svg></mjx-container>个主成分。</li>
<li><strong>投影</strong>：将原始数据集投影到选定的主成分上，从而得到降维后的数据。</li>
</ul>
<p><strong>核主成分分析</strong>(<code>KPCA</code>)的特征求解器包括：<strong>随机求解器</strong>、<strong>密集求解器</strong>、<code>arpack</code><strong>求解器</strong>。接下来举一个例子<strong>主成分分析</strong>(<code>PCA</code>)和<strong>核主成分分析</strong>(<code>KPCA</code>)投影数据的比较：</p>
<img data-src="/2024/10/09/artificial-intelligence/ML9_theory_study/ml_9.png" class="" title="左边是训练数据集，右边是测试数据集">

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_circles</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA, KernelPCA</span><br><span class="line"></span><br><span class="line">X, y = make_circles(n_samples=<span class="number">1_000</span>, factor=<span class="number">0.3</span>, noise=<span class="number">0.05</span>, random_state=<span class="number">0</span>)</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=<span class="number">0</span>)</span><br><span class="line">_, (train_ax, test_ax) = plt.subplots(ncols=<span class="number">2</span>, sharex=<span class="literal">True</span>, sharey=<span class="literal">True</span>, figsize=(<span class="number">8</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">pca = PCA(n_components=<span class="number">2</span>)</span><br><span class="line">kernel_pca = KernelPCA(n_components=<span class="literal">None</span>, kernel=<span class="string">&quot;rbf&quot;</span>, gamma=<span class="number">10</span>, fit_inverse_transform=<span class="literal">True</span>, alpha=<span class="number">0.1</span>)</span><br><span class="line">X_test_pca = pca.fit(X_train).transform(X_test)</span><br><span class="line">X_test_kernel_pca = kernel_pca.fit(X_train).transform(X_test)</span><br><span class="line"></span><br><span class="line">fig, (orig_data_ax, pca_proj_ax, kernel_pca_proj_ax) = plt.subplots( ncols=<span class="number">3</span>, figsize=(<span class="number">14</span>, <span class="number">4</span>))</span><br><span class="line">orig_data_ax.scatter(X_test[:, <span class="number">0</span>], X_test[:, <span class="number">1</span>], c=y_test)</span><br><span class="line">orig_data_ax.set_ylabel(<span class="string">&quot;Feature #1&quot;</span>)</span><br><span class="line">orig_data_ax.set_xlabel(<span class="string">&quot;Feature #0&quot;</span>)</span><br><span class="line">orig_data_ax.set_title(<span class="string">&quot;Testing data&quot;</span>)</span><br><span class="line"></span><br><span class="line">pca_proj_ax.scatter(X_test_pca[:, <span class="number">0</span>], X_test_pca[:, <span class="number">1</span>], c=y_test)</span><br><span class="line">pca_proj_ax.set_ylabel(<span class="string">&quot;Principal component #1&quot;</span>)</span><br><span class="line">pca_proj_ax.set_xlabel(<span class="string">&quot;Principal component #0&quot;</span>)</span><br><span class="line">pca_proj_ax.set_title(<span class="string">&quot;Projection of testing data\n using PCA&quot;</span>)</span><br><span class="line"></span><br><span class="line">kernel_pca_proj_ax.scatter(X_test_kernel_pca[:, <span class="number">0</span>], X_test_kernel_pca[:, <span class="number">1</span>], c=y_test)</span><br><span class="line">kernel_pca_proj_ax.set_ylabel(<span class="string">&quot;Principal component #1&quot;</span>)</span><br><span class="line">kernel_pca_proj_ax.set_xlabel(<span class="string">&quot;Principal component #0&quot;</span>)</span><br><span class="line">kernel_pca_proj_ax.set_title(<span class="string">&quot;Projection of testing data\n using KernelPCA&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<img data-src="/2024/10/09/artificial-intelligence/ML9_theory_study/ml_10.png" class="" title="左边是测试数据集，中间使用PCA投影的测试数据，右边使用内核PCA投影的测试数据">

<p><code>PCA</code>线性变换数据导致坐标系将居中，根据其<strong>方差</strong>在每个分量上重新缩放，再旋转。从而获得的数据，各向是同性的且投影到其<strong>主成分</strong>上。使用<code>PCA</code>的投影（即中间图），我们发现缩放没有变化；实际上，数据是两个以<code>0</code>为中心的同心圆，原始数据已经是各向同性的。但是，数据已经旋转。如果定义一个<strong>线性分类器</strong>来区分两个类别的样本，这样的投影将将无法区分。使用核可以进行<strong>非线性投影</strong>。通过使用<code>RBF</code><strong>核</strong>，<strong>投影</strong>将展开数据集，同时保留原始空间中彼此接近的数据点的相对距离。在右图中发现给定类的样本彼此之间的距离比来自相反类的样本之间的距离更近，从而解开了两个样本集。现在可以使用<strong>线性分类器</strong>将样本从两个类中分离出来。</p>
<p><strong>主成分分析</strong>(<code>PCA</code>)和<strong>核主成分分析</strong>(<code>KPCA</code>)可以投影到<strong>原始特征空间</strong>中进行<strong>重建</strong>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_circles</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA, KernelPCA</span><br><span class="line"></span><br><span class="line">X, y = make_circles(n_samples=<span class="number">1_000</span>, factor=<span class="number">0.3</span>, noise=<span class="number">0.05</span>, random_state=<span class="number">0</span>)</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">pca = PCA(n_components=<span class="number">2</span>)</span><br><span class="line">kernel_pca = KernelPCA(n_components=<span class="literal">None</span>, kernel=<span class="string">&quot;rbf&quot;</span>, gamma=<span class="number">10</span>, fit_inverse_transform=<span class="literal">True</span>, alpha=<span class="number">0.1</span>)</span><br><span class="line">X_test_pca = pca.fit(X_train).transform(X_test)</span><br><span class="line">X_test_kernel_pca = kernel_pca.fit(X_train).transform(X_test)</span><br><span class="line"></span><br><span class="line">X_reconstructed_pca = pca.inverse_transform(pca.transform(X_test))</span><br><span class="line">X_reconstructed_kernel_pca = kernel_pca.inverse_transform(kernel_pca.transform(X_test))</span><br><span class="line">fig, (orig_data_ax, pca_back_proj_ax, kernel_pca_back_proj_ax) = plt.subplots(ncols=<span class="number">3</span>, sharex=<span class="literal">True</span>, sharey=<span class="literal">True</span>, figsize=(<span class="number">13</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">orig_data_ax.scatter(X_test[:, <span class="number">0</span>], X_test[:, <span class="number">1</span>], c=y_test)</span><br><span class="line">orig_data_ax.set_ylabel(<span class="string">&quot;Feature #1&quot;</span>)</span><br><span class="line">orig_data_ax.set_xlabel(<span class="string">&quot;Feature #0&quot;</span>)</span><br><span class="line">orig_data_ax.set_title(<span class="string">&quot;Original test data&quot;</span>)</span><br><span class="line"></span><br><span class="line">pca_back_proj_ax.scatter(X_reconstructed_pca[:, <span class="number">0</span>], X_reconstructed_pca[:, <span class="number">1</span>], c=y_test)</span><br><span class="line">pca_back_proj_ax.set_xlabel(<span class="string">&quot;Feature #0&quot;</span>)</span><br><span class="line">pca_back_proj_ax.set_title(<span class="string">&quot;Reconstruction via PCA&quot;</span>)</span><br><span class="line"></span><br><span class="line">kernel_pca_back_proj_ax.scatter(X_reconstructed_kernel_pca[:, <span class="number">0</span>], X_reconstructed_kernel_pca[:, <span class="number">1</span>], c=y_test)</span><br><span class="line">kernel_pca_back_proj_ax.set_xlabel(<span class="string">&quot;Feature #0&quot;</span>)</span><br><span class="line">kernel_pca_back_proj_ax.set_title(<span class="string">&quot;Reconstruction via KernelPCA&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<img data-src="/2024/10/09/artificial-intelligence/ML9_theory_study/ml_11.png" class="" title="左边是测试数据集，中间使用PCA重建原始特征空间，右边使用内核PCA重建原始特征空间">

<h5 id="截断奇异值分解-TSVD-和潜在语义分析-LSA"><a href="#截断奇异值分解-TSVD-和潜在语义分析-LSA" class="headerlink" title="截断奇异值分解(TSVD)和潜在语义分析(LSA)"></a>截断奇异值分解(TSVD)和潜在语义分析(LSA)</h5><p><strong>截断奇异值分解</strong>(<code>TSVD</code>)和<strong>潜在语义分析</strong>(<code>LSA</code>)是两种在<strong>数据分析</strong>和<strong>自然语言处理</strong>领域中常用的技术。它们之间有着密切的联系，尤其是在处理文本数据时。</p>
<p><strong>截断奇异值分解</strong>(<code>TSVD</code>)是一种<strong>矩阵分解技术</strong>，用于将一个矩阵分解为其组成部分，以降低数据的维度，同时保留最重要的特征。其基本步骤如下：<strong>奇异值分解</strong>(<code>SVD</code>)，首先，对原始矩阵进行<strong>奇异值分解</strong>，得到三个矩阵<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.186ex;" xmlns="http://www.w3.org/2000/svg" width="11.271ex" height="2.09ex" role="img" focusable="false" viewBox="0 -841.7 4981.7 923.7" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-23-TEX-I-1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path><path id="MJX-23-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-23-TEX-I-1D448" d="M107 637Q73 637 71 641Q70 643 70 649Q70 673 81 682Q83 683 98 683Q139 681 234 681Q268 681 297 681T342 682T362 682Q378 682 378 672Q378 670 376 658Q371 641 366 638H364Q362 638 359 638T352 638T343 637T334 637Q295 636 284 634T266 623Q265 621 238 518T184 302T154 169Q152 155 152 140Q152 86 183 55T269 24Q336 24 403 69T501 205L552 406Q599 598 599 606Q599 633 535 637Q511 637 511 648Q511 650 513 660Q517 676 519 679T529 683Q532 683 561 682T645 680Q696 680 723 681T752 682Q767 682 767 672Q767 650 759 642Q756 637 737 637Q666 633 648 597Q646 592 598 404Q557 235 548 205Q515 105 433 42T263 -22Q171 -22 116 34T60 167V183Q60 201 115 421Q164 622 164 628Q164 635 107 637Z"></path><path id="MJX-23-TEX-N-3A3" d="M666 247Q664 244 652 126T638 4V0H351Q131 0 95 0T57 5V6Q54 12 57 17L73 36Q89 54 121 90T182 159L305 299L56 644L55 658Q55 677 60 681Q63 683 351 683H638V679Q640 674 652 564T666 447V443H626V447Q618 505 604 543T559 605Q529 626 478 631T333 637H294H189L293 494Q314 465 345 422Q400 346 400 340Q400 338 399 337L154 57Q407 57 428 58Q476 60 508 68T551 83T575 103Q595 125 608 162T624 225L626 251H666V247Z"></path><path id="MJX-23-TEX-I-1D449" d="M52 648Q52 670 65 683H76Q118 680 181 680Q299 680 320 683H330Q336 677 336 674T334 656Q329 641 325 637H304Q282 635 274 635Q245 630 242 620Q242 618 271 369T301 118L374 235Q447 352 520 471T595 594Q599 601 599 609Q599 633 555 637Q537 637 537 648Q537 649 539 661Q542 675 545 679T558 683Q560 683 570 683T604 682T668 681Q737 681 755 683H762Q769 676 769 672Q769 655 760 640Q757 637 743 637Q730 636 719 635T698 630T682 623T670 615T660 608T652 599T645 592L452 282Q272 -9 266 -16Q263 -18 259 -21L241 -22H234Q216 -22 216 -15Q213 -9 177 305Q139 623 138 626Q133 637 76 637H59Q52 642 52 648Z"></path><path id="MJX-23-TEX-I-1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D434" xlink:href="#MJX-23-TEX-I-1D434"></use></g><g data-mml-node="mo" transform="translate(1027.8,0)"><use data-c="3D" xlink:href="#MJX-23-TEX-N-3D"></use></g><g data-mml-node="mi" transform="translate(2083.6,0)"><use data-c="1D448" xlink:href="#MJX-23-TEX-I-1D448"></use></g><g data-mml-node="mi" transform="translate(2850.6,0)"><use data-c="3A3" xlink:href="#MJX-23-TEX-N-3A3"></use></g><g data-mml-node="msup" transform="translate(3572.6,0)"><g data-mml-node="mi"><use data-c="1D449" xlink:href="#MJX-23-TEX-I-1D449"></use></g><g data-mml-node="mi" transform="translate(861.3,363) scale(0.707)"><use data-c="1D447" xlink:href="#MJX-23-TEX-I-1D447"></use></g></g></g></g></svg></mjx-container>。其中<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="1.735ex" height="1.595ex" role="img" focusable="false" viewBox="0 -683 767 705" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-23-TEX-I-1D448" d="M107 637Q73 637 71 641Q70 643 70 649Q70 673 81 682Q83 683 98 683Q139 681 234 681Q268 681 297 681T342 682T362 682Q378 682 378 672Q378 670 376 658Q371 641 366 638H364Q362 638 359 638T352 638T343 637T334 637Q295 636 284 634T266 623Q265 621 238 518T184 302T154 169Q152 155 152 140Q152 86 183 55T269 24Q336 24 403 69T501 205L552 406Q599 598 599 606Q599 633 535 637Q511 637 511 648Q511 650 513 660Q517 676 519 679T529 683Q532 683 561 682T645 680Q696 680 723 681T752 682Q767 682 767 672Q767 650 759 642Q756 637 737 637Q666 633 648 597Q646 592 598 404Q557 235 548 205Q515 105 433 42T263 -22Q171 -22 116 34T60 167V183Q60 201 115 421Q164 622 164 628Q164 635 107 637Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D448" xlink:href="#MJX-23-TEX-I-1D448"></use></g></g></g></svg></mjx-container>是左奇异向量矩阵，<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="1.633ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 722 683" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-23-TEX-N-3A3" d="M666 247Q664 244 652 126T638 4V0H351Q131 0 95 0T57 5V6Q54 12 57 17L73 36Q89 54 121 90T182 159L305 299L56 644L55 658Q55 677 60 681Q63 683 351 683H638V679Q640 674 652 564T666 447V443H626V447Q618 505 604 543T559 605Q529 626 478 631T333 637H294H189L293 494Q314 465 345 422Q400 346 400 340Q400 338 399 337L154 57Q407 57 428 58Q476 60 508 68T551 83T575 103Q595 125 608 162T624 225L626 251H666V247Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="3A3" xlink:href="#MJX-23-TEX-N-3A3"></use></g></g></g></svg></mjx-container>是对角矩阵，包含奇异值。<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="3.188ex" height="1.954ex" role="img" focusable="false" viewBox="0 -841.7 1409.1 863.7" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-23-TEX-I-1D449" d="M52 648Q52 670 65 683H76Q118 680 181 680Q299 680 320 683H330Q336 677 336 674T334 656Q329 641 325 637H304Q282 635 274 635Q245 630 242 620Q242 618 271 369T301 118L374 235Q447 352 520 471T595 594Q599 601 599 609Q599 633 555 637Q537 637 537 648Q537 649 539 661Q542 675 545 679T558 683Q560 683 570 683T604 682T668 681Q737 681 755 683H762Q769 676 769 672Q769 655 760 640Q757 637 743 637Q730 636 719 635T698 630T682 623T670 615T660 608T652 599T645 592L452 282Q272 -9 266 -16Q263 -18 259 -21L241 -22H234Q216 -22 216 -15Q213 -9 177 305Q139 623 138 626Q133 637 76 637H59Q52 642 52 648Z"></path><path id="MJX-23-TEX-I-1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><use data-c="1D449" xlink:href="#MJX-23-TEX-I-1D449"></use></g><g data-mml-node="mi" transform="translate(861.3,363) scale(0.707)"><use data-c="1D447" xlink:href="#MJX-23-TEX-I-1D447"></use></g></g></g></g></svg></mjx-container>是右奇异向量矩阵；<strong>截断操作</strong>，选择前<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.179ex" height="1.595ex" role="img" focusable="false" viewBox="0 -694 521 705" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-23-TEX-I-1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D458" xlink:href="#MJX-23-TEX-I-1D458"></use></g></g></g></svg></mjx-container>个最大的<strong>奇异值</strong>，并相应地截取<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="1.735ex" height="1.595ex" role="img" focusable="false" viewBox="0 -683 767 705" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-23-TEX-I-1D448" d="M107 637Q73 637 71 641Q70 643 70 649Q70 673 81 682Q83 683 98 683Q139 681 234 681Q268 681 297 681T342 682T362 682Q378 682 378 672Q378 670 376 658Q371 641 366 638H364Q362 638 359 638T352 638T343 637T334 637Q295 636 284 634T266 623Q265 621 238 518T184 302T154 169Q152 155 152 140Q152 86 183 55T269 24Q336 24 403 69T501 205L552 406Q599 598 599 606Q599 633 535 637Q511 637 511 648Q511 650 513 660Q517 676 519 679T529 683Q532 683 561 682T645 680Q696 680 723 681T752 682Q767 682 767 672Q767 650 759 642Q756 637 737 637Q666 633 648 597Q646 592 598 404Q557 235 548 205Q515 105 433 42T263 -22Q171 -22 116 34T60 167V183Q60 201 115 421Q164 622 164 628Q164 635 107 637Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D448" xlink:href="#MJX-23-TEX-I-1D448"></use></g></g></g></svg></mjx-container>和<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="1.74ex" height="1.595ex" role="img" focusable="false" viewBox="0 -683 769 705" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-23-TEX-I-1D449" d="M52 648Q52 670 65 683H76Q118 680 181 680Q299 680 320 683H330Q336 677 336 674T334 656Q329 641 325 637H304Q282 635 274 635Q245 630 242 620Q242 618 271 369T301 118L374 235Q447 352 520 471T595 594Q599 601 599 609Q599 633 555 637Q537 637 537 648Q537 649 539 661Q542 675 545 679T558 683Q560 683 570 683T604 682T668 681Q737 681 755 683H762Q769 676 769 672Q769 655 760 640Q757 637 743 637Q730 636 719 635T698 630T682 623T670 615T660 608T652 599T645 592L452 282Q272 -9 266 -16Q263 -18 259 -21L241 -22H234Q216 -22 216 -15Q213 -9 177 305Q139 623 138 626Q133 637 76 637H59Q52 642 52 648Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D449" xlink:href="#MJX-23-TEX-I-1D449"></use></g></g></g></svg></mjx-container>的前<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.179ex" height="1.595ex" role="img" focusable="false" viewBox="0 -694 521 705" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-23-TEX-I-1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D458" xlink:href="#MJX-23-TEX-I-1D458"></use></g></g></g></svg></mjx-container>列，从而得到一个<strong>低秩近似矩阵</strong>。这种<strong>低秩近似</strong>有助于减少计算复杂度并去除噪声；<strong>应用</strong>，<strong>截断奇异值分解</strong>(<code>TSVD</code>)广泛应用于<strong>图像处理</strong>、<strong>推荐系统</strong>和<strong>信息检索</strong>等领域，通过保留最重要的信息来提高模型的性能。</p>
<p>潜在语义分析(<code>LSA</code>)是一种自然语言处理技术，旨在通过分析文档和术语之间的关系来发现隐藏的语义结构。其主要步骤包括：<strong>构建词项-文档矩阵</strong>，将文档集合转换为一个矩阵，其中行表示<strong>词项</strong>，列表示<strong>文档</strong>，单元格包含相应的<strong>词频</strong>或<strong>加权值</strong>；应用<code>TSVD</code>，对构建的<strong>词项-文档矩阵</strong>使用<strong>截断奇异值分解</strong>(<code>TSVD</code>)。通过保留前<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.179ex" height="1.595ex" role="img" focusable="false" viewBox="0 -694 521 705" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-23-TEX-I-1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D458" xlink:href="#MJX-23-TEX-I-1D458"></use></g></g></g></svg></mjx-container>个<strong>奇异值</strong>和对应的向量，可以降低维度，从而提取出潜在的<strong>主题</strong>或<strong>概念</strong>。<strong>语义比较</strong>，通过计算文档之间的<strong>余弦相似度</strong>，可以比较不同文档的相似性，从而实现信息检索、文本分类等任务。</p>
<p><strong>截断奇异值分解</strong>(<code>TSVD</code>)与<strong>潜在语义分析</strong>(<code>LSA</code>)的关系包括：</p>
<ul>
<li><strong>数学基础</strong>：<strong>潜在语义分析</strong>(<code>LSA</code>)依赖于<strong>截断奇异值分解</strong>(<code>TSVD</code>)来实现其降维功能。通过对<strong>词项-文档矩阵</strong>进行<strong>截断奇异值分解</strong>(<code>TSVD</code>)，<strong>潜在语义分析</strong>(<code>LSA</code>)能够提取出潜在的主题结构，并将文本数据转换为更易处理的形式。</li>
<li><strong>降噪效果</strong>：使用<strong>截断奇异值分解</strong>(<code>TSVD</code>)进行<strong>降维</strong>可以去除不重要的信息，从而提高<strong>潜在语义分析</strong>(<code>LSA</code>)模型对文本数据的理解能力。</li>
<li><strong>应用场景</strong>：两者结合在许多领域中都有应用，如自动文档分类、信息检索和推荐系统等。</li>
</ul>
<p><strong>截断奇异值分解</strong>(<code>TSVD</code>)和<strong>潜在语义分析</strong>(<code>LSA</code>)是现代数据分析中不可或缺的工具。通过有效地处理高维数据，可以揭示数据中的潜在<strong>结构</strong>和<strong>关系</strong>，为信息检索和自然语言处理提供了强大的支持。</p>
<h5 id="字典学习-Dictionary-Learning"><a href="#字典学习-Dictionary-Learning" class="headerlink" title="字典学习(Dictionary Learning)"></a>字典学习(Dictionary Learning)</h5><p><strong>字典学习</strong>(<code>Dictionary Learning</code>)是一种重要的机器学习技术，主要用于信号处理、图像分析和模式识别等领域。它的核心目标是从输入数据中学习一个字典，使得数据可以用该字典中的<strong>原子</strong>进行<strong>稀疏表示</strong>。<strong>字典学习</strong>(<code>Dictionary Learning</code>)的原理为：<strong>字典构建阶段</strong>，在这一阶段，算法尝试从训练数据中学习一个<strong>最优字典</strong>。这个字典由多个原子（或特征）组成，每个原子可以看作是对输入数据的一种基础表示。常用的算法包括<code>K-SVD</code>(<code>K-singular value decomposition</code>)、<strong>正交匹配追踪</strong>(<code>OMP</code>)等，这些算法旨在<strong>最小化重构误差</strong>，即通过字典重构原始数据时的误差；<strong>稀疏编码阶段</strong>，一旦字典被学习到，接下来的任务是利用这个字典对新数据进行<strong>稀疏表示</strong>。新数据将表示为字典原子的<strong>线性组合</strong>，其中大多数系数为<code>0</code>。<strong>稀疏表示</strong>有助于降低数据的<strong>冗余度</strong>，提高模型的效率和性能。</p>
<p><strong>字典学习</strong>(<code>Dictionary Learning</code>)是一种强大的工具，通过学习适合特定数据集的字典，可以有效地进行<strong>数据降维</strong>和<strong>特征提取</strong>。随着深度学习的发展，结合深度神经网络的方法也逐渐成为研究热点，使得<strong>字典学习</strong>(<code>Dictionary Learning</code>)能够处理更加复杂的数据结构。</p>
<p>举例说明利用计算好的字典进行<strong>稀疏编码</strong>，将信号转换为<code>Ricker</code>（称高斯的二阶导数）<strong>小波</strong>的<strong>稀疏组合</strong>。示例使用<code>SparseCoder</code>(<code>sklearn</code>)<strong>估计器</strong>比较了不同的<strong>稀疏编码</strong>方法。<code>Ricker</code>并不是一个特别好的内核，无法表示<strong>分段常数信号</strong>。可以看出添加不同宽度的原子有多重要，它激励<strong>学习字典</strong>使用最适合的信号类型。如下图所示，右边使用了更重的子采样。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> SparseCoder</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ricker_function</span>(<span class="params">resolution, center, width</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Discrete sub-sampled Ricker (Mexican hat) wavelet&quot;&quot;&quot;</span></span><br><span class="line">    x = np.linspace(<span class="number">0</span>, resolution - <span class="number">1</span>, resolution)</span><br><span class="line">    x = ((<span class="number">2</span> / (np.sqrt(<span class="number">3</span> * width) * np.pi**<span class="number">0.25</span>))* (<span class="number">1</span> - (x - center) ** <span class="number">2</span> / width**<span class="number">2</span>) * np.exp(-((x - center) ** <span class="number">2</span>) / (<span class="number">2</span> * width**<span class="number">2</span>)))</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ricker_matrix</span>(<span class="params">width, resolution, n_components</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Dictionary of Ricker (Mexican hat) wavelets&quot;&quot;&quot;</span></span><br><span class="line">    centers = np.linspace(<span class="number">0</span>, resolution - <span class="number">1</span>, n_components)</span><br><span class="line">    D = np.empty((n_components, resolution))</span><br><span class="line">    <span class="keyword">for</span> i, center <span class="keyword">in</span> <span class="built_in">enumerate</span>(centers):</span><br><span class="line">        D[i] = ricker_function(resolution, center, width)</span><br><span class="line">    </span><br><span class="line">    D /= np.sqrt(np.<span class="built_in">sum</span>(D**<span class="number">2</span>, axis=<span class="number">1</span>))[:, np.newaxis]</span><br><span class="line">    <span class="keyword">return</span> D</span><br><span class="line"></span><br><span class="line">resolution = <span class="number">1024</span></span><br><span class="line">subsampling = <span class="number">3</span>  <span class="comment"># subsampling factor</span></span><br><span class="line">width = <span class="number">100</span></span><br><span class="line">n_components = resolution // subsampling</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute a wavelet dictionary</span></span><br><span class="line">D_fixed = ricker_matrix(width=width, resolution=resolution, n_components=n_components)</span><br><span class="line">D_multi = np.r_[</span><br><span class="line">    <span class="built_in">tuple</span>(</span><br><span class="line">        ricker_matrix(width=w, resolution=resolution, n_components=n_components // <span class="number">5</span>)</span><br><span class="line">        <span class="keyword">for</span> w <span class="keyword">in</span> (<span class="number">10</span>, <span class="number">50</span>, <span class="number">100</span>, <span class="number">500</span>, <span class="number">1000</span>)</span><br><span class="line">    )</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Generate a signal</span></span><br><span class="line">y = np.linspace(<span class="number">0</span>, resolution - <span class="number">1</span>, resolution)</span><br><span class="line">first_quarter = y &lt; resolution / <span class="number">4</span></span><br><span class="line">y[first_quarter] = <span class="number">3.0</span></span><br><span class="line">y[np.logical_not(first_quarter)] = -<span class="number">1.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># List the different sparse coding methods in the following format:</span></span><br><span class="line"><span class="comment"># (title, transform_algorithm, transform_alpha, transform_n_nozero_coefs, color)</span></span><br><span class="line">estimators = [(<span class="string">&quot;OMP&quot;</span>, <span class="string">&quot;omp&quot;</span>, <span class="literal">None</span>, <span class="number">15</span>, <span class="string">&quot;navy&quot;</span>),(<span class="string">&quot;Lasso&quot;</span>, <span class="string">&quot;lasso_lars&quot;</span>, <span class="number">2</span>, <span class="literal">None</span>, <span class="string">&quot;turquoise&quot;</span>),]</span><br><span class="line">lw = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">13</span>, <span class="number">6</span>))</span><br><span class="line"><span class="keyword">for</span> subplot, (D, title) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>((D_fixed, D_multi), (<span class="string">&quot;fixed width&quot;</span>, <span class="string">&quot;multiple widths&quot;</span>))):</span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">2</span>, subplot + <span class="number">1</span>)</span><br><span class="line">    plt.title(<span class="string">&quot;Sparse coding against %s dictionary&quot;</span> % title)</span><br><span class="line">    plt.plot(y, lw=lw, linestyle=<span class="string">&quot;--&quot;</span>, label=<span class="string">&quot;Original signal&quot;</span>)</span><br><span class="line">    <span class="comment"># Do a wavelet approximation</span></span><br><span class="line">    <span class="keyword">for</span> title, algo, alpha, n_nonzero, color <span class="keyword">in</span> estimators:</span><br><span class="line">        coder = SparseCoder(dictionary=D,transform_n_nonzero_coefs=n_nonzero,transform_alpha=alpha,transform_algorithm=algo,)</span><br><span class="line">        x = coder.transform(y.reshape(<span class="number">1</span>, -<span class="number">1</span>))</span><br><span class="line">        density = <span class="built_in">len</span>(np.flatnonzero(x))</span><br><span class="line">        x = np.ravel(np.dot(x, D))</span><br><span class="line">        squared_error = np.<span class="built_in">sum</span>((y - x) ** <span class="number">2</span>)</span><br><span class="line">        plt.plot(x,color=color,lw=lw,label=<span class="string">&quot;%s: %s nonzero coefs,\n%.2f error&quot;</span> % (title, density, squared_error),)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Soft thresholding debiasing</span></span><br><span class="line">    coder = SparseCoder(dictionary=D, transform_algorithm=<span class="string">&quot;threshold&quot;</span>, transform_alpha=<span class="number">20</span>)</span><br><span class="line">    x = coder.transform(y.reshape(<span class="number">1</span>, -<span class="number">1</span>))</span><br><span class="line">    _, idx = np.where(x != <span class="number">0</span>)</span><br><span class="line">    x[<span class="number">0</span>, idx], _, _, _ = np.linalg.lstsq(D[idx, :].T, y, rcond=<span class="literal">None</span>)</span><br><span class="line">    x = np.ravel(np.dot(x, D))</span><br><span class="line">    squared_error = np.<span class="built_in">sum</span>((y - x) ** <span class="number">2</span>)</span><br><span class="line">    plt.plot(x,color=<span class="string">&quot;darkorange&quot;</span>,lw=lw, label=<span class="string">&quot;Thresholding w/ debiasing:\n%d nonzero coefs, %.2f error&quot;</span>% (<span class="built_in">len</span>(idx), squared_error),)</span><br><span class="line">    plt.axis(<span class="string">&quot;tight&quot;</span>)</span><br><span class="line">    plt.legend(shadow=<span class="literal">False</span>, loc=<span class="string">&quot;best&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplots_adjust(<span class="number">0.04</span>, <span class="number">0.07</span>, <span class="number">0.97</span>, <span class="number">0.90</span>, <span class="number">0.09</span>, <span class="number">0.2</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<img data-src="/2024/10/09/artificial-intelligence/ML9_theory_study/ml_12.png" class="">

<p><strong>小批量字典学习</strong>(<code>Mini-batch Dictionary Learning</code>)是一种改进的<strong>字典学习</strong>方法，旨在提高大规模数据集上<strong>字典学习</strong>的效率和可扩展性。与传统的<strong>字典学习</strong>方法相比，<strong>小批量字典学习</strong>(<code>Mini-batch Dictionary Learning</code>)通过使用小批量数据来更新字典，从而加速训练过程并减少内存消耗。<strong>小批量字典学习</strong>(<code>Mini-batch Dictionary Learning</code>)的原理为它将整个数据集划分为多个<strong>小批量</strong>(<code>mini-batch</code>)，并在每个<strong>小批量</strong>上进行字典更新。这一过程通常包括以下步骤：<strong>数据分批</strong>，将原始数据集划分为多个小批量，每个小批量包含一定数量的数据样本；<strong>稀疏编码</strong>，对于每个小批量，使用当前字典对数据进行<strong>稀疏编码</strong>。这一步通常涉及求解一个优化问题，以找到最优的<strong>稀疏表示</strong>；<strong>字典更新</strong>，在<strong>稀疏编码</strong>完成后，使用该<strong>小批量</strong>的数据和对应的<strong>稀疏表示</strong>来更新字典。更新过程通常通过<strong>最小化重构误差</strong>来实现；<strong>迭代</strong>，重复上述步骤，直到达到预定的迭代次数或满足收敛条件。</p>
<p><strong>小批量字典学习</strong>(<code>Mini-batch Dictionary Learning</code>)的优势：<strong>计算效率</strong>，通过在每次迭代中仅使用小批量数据，可以显著减少计算时间，尤其是在处理大规模数据集时；<strong>内存节省</strong>，小批量学习减少了对内存的需求，使得可以在资源有限的环境中处理更大的数据集；<strong>更好的收敛性</strong>，由于引入了随机性，<strong>小批量字典学习</strong>(<code>Mini-batch Dictionary Learning</code>)避免陷入了<strong>局部最优解</strong>，从而提高模型的收敛速度和性能。<strong>小批量字典学习</strong>(<code>Mini-batch Dictionary Learning</code>)是一种高效且灵活的<strong>字典学习</strong>方法，适用于大规模数据集。通过结合小批量处理技术，它不仅提高了训练速度，还增强了模型的可<strong>扩展性</strong>和<strong>鲁棒性</strong>。</p>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>umbrella
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://fresh88888888.github.io/2024/10/09/artificial-intelligence/ML9_theory_study/" title="机器学习(ML)(九) — 探析">https://fresh88888888.github.io/2024/10/09/artificial-intelligence/ML9_theory_study/</a>
  </li>
  <li class="post-copyright-license">
      <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/AI/" rel="tag"># AI</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2024/10/04/artificial-intelligence/ML8_theory_study/" rel="prev" title="机器学习(ML)(八) — 探析">
                  <i class="fa fa-chevron-left"></i> 机器学习(ML)(八) — 探析
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2024/10/13/artificial-intelligence/ML10_theory_study/" rel="next" title="机器学习(ML)(十) — 探析">
                  机器学习(ML)(十) — 探析 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments utterances-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">辽ICP备15012817号-2 </a>
  </div>
  <div class="copyright">
    &copy; 2022 – 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">umbrella</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">1.2m</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">69:19</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/fresh88888888" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script size="300" alpha="0.6" zIndex="-1" src="https://cdnjs.cloudflare.com/ajax/libs/ribbon.js/1.0.2/ribbon.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.0/jquery.min.js" integrity="sha256-2Pmvv0kuTBOenSvLm6bvfBSSHrUJ+3A7x6P5Ebd07/g=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.8/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/comments.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/utils.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/motion.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/next-boot.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/pjax.min.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/search/local-search.min.js"></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdnjs.cloudflare.com/ajax/libs/pdfobject/2.2.12/pdfobject.min.js","integrity":"sha256-g2xji1rlE3KsGVClvuxTbcR0Kn2+wtQADSff2Tbb4zA="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/tags/pdf.min.js"></script>



  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/fancybox.min.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/pace.min.js"></script>


  
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  <script src="https://cdnjs.cloudflare.com/ajax/libs/quicklink/2.3.0/quicklink.umd.js" integrity="sha256-yvJQOINiH9fWemHn0vCA5lsHWJaHs6/ZmO+1Ft04SvM=" crossorigin="anonymous"></script>
  <script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":true,"archive":true,"delay":true,"timeout":5000,"priority":true,"url":"https://fresh88888888.github.io/2024/10/09/artificial-intelligence/ML9_theory_study/"}</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/quicklink.min.js"></script>
<script class="next-config" data-name="utterances" type="application/json">{"enable":true,"repo":"fresh88888888.github.io","issue_term":"title","theme":"github-light"}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/comments/utterances.min.js"></script>

</body>
</html>
