<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.2">
<link rel="preconnect" href="https://fonts.googleapis.com" crossorigin>
<link rel="preconnect" href="https://cdnjs.cloudflare.com" crossorigin>
  <link rel="apple-touch-icon" sizes="180x180" href="/favicon.ico">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon.ico">
  <link rel="mask-icon" href="/favicon.ico" color="#222">
  <meta name="google-site-verification" content="lk2gSYFP_NyLNFob-fFnt7fm-I_n1ZYws-WZll7mshg">
  <meta name="msvalidate.01" content="6Jdc01DjYOLguhS5">
  <meta name="baidu-site-verification" content="code-NR10G09zww">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic%7Ccursive:300,300italic,400,400italic,700,700italic%7CSource+Code+Pro:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/yellow/pace-theme-minimal.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"fresh88888888.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.17.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"flat"},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":true,"nav":null},"stickytabs":true,"motion":{"enable":true,"async":true,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/local-search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":10,"unescape":false,"preload":true}}</script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/config.min.js"></script>

    <meta name="description" content="编译器和解释器命令式编程命令式编程(imperative programming)。命令式编程使用诸如print、“+”和if之类的语句来更改程序的状态。考虑下面这段简单的命令式程序：">
<meta property="og:type" content="article">
<meta property="og:title" content="计算性能 (机器学习)(TensorFlow)">
<meta property="og:url" content="https://fresh88888888.github.io/2024/05/23/artificial-intelligence/computing_theory_study/index.html">
<meta property="og:site_name" content="UMBRELLA">
<meta property="og:description" content="编译器和解释器命令式编程命令式编程(imperative programming)。命令式编程使用诸如print、“+”和if之类的语句来更改程序的状态。考虑下面这段简单的命令式程序：">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://fresh88888888.github.io/2024/05/23/artificial-intelligence/computing_theory_study/cp_1.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/05/23/artificial-intelligence/computing_theory_study/cp_2.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/05/23/artificial-intelligence/computing_theory_study/cp_3.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/05/23/artificial-intelligence/computing_theory_study/cp_4.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/05/23/artificial-intelligence/computing_theory_study/cp_5.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/05/23/artificial-intelligence/computing_theory_study/cp_6.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/05/23/artificial-intelligence/computing_theory_study/cp_7.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/05/23/artificial-intelligence/computing_theory_study/cp_8.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/05/23/artificial-intelligence/computing_theory_study/cp_9.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/05/23/artificial-intelligence/computing_theory_study/cp_10.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/05/23/artificial-intelligence/computing_theory_study/cp_11.jpeg">
<meta property="og:image" content="https://fresh88888888.github.io/2024/05/23/artificial-intelligence/computing_theory_study/cp_12.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/05/23/artificial-intelligence/computing_theory_study/cp_13.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/05/23/artificial-intelligence/computing_theory_study/cp_14.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/05/23/artificial-intelligence/computing_theory_study/cp_15.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/05/23/artificial-intelligence/computing_theory_study/cp_16.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/05/23/artificial-intelligence/computing_theory_study/cp_17.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/05/23/artificial-intelligence/computing_theory_study/cp_18.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/05/23/artificial-intelligence/computing_theory_study/cp_19.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/05/23/artificial-intelligence/computing_theory_study/cp_20.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/05/23/artificial-intelligence/computing_theory_study/cp_21.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/05/23/artificial-intelligence/computing_theory_study/cp_22.png">
<meta property="article:published_time" content="2024-05-23T01:00:11.000Z">
<meta property="article:modified_time" content="2024-05-23T01:00:11.000Z">
<meta property="article:author" content="umbrella">
<meta property="article:tag" content="AI">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://fresh88888888.github.io/2024/05/23/artificial-intelligence/computing_theory_study/cp_1.png">


<link rel="canonical" href="https://fresh88888888.github.io/2024/05/23/artificial-intelligence/computing_theory_study/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://fresh88888888.github.io/2024/05/23/artificial-intelligence/computing_theory_study/","path":"2024/05/23/artificial-intelligence/computing_theory_study/","title":"计算性能 (机器学习)(TensorFlow)"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>计算性能 (机器学习)(TensorFlow) | UMBRELLA</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">UMBRELLA</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">未雨绸缪，举重若轻</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-算法"><a href="/Algorithm/" rel="section"><i class="fa fa-calendar fa-fw"></i>算法</a></li><li class="menu-item menu-item-c++-&nbsp;编程"><a href="/Programming-C++/" rel="section"><i class="fa fa-heartbeat fa-fw"></i>C++ &nbsp;编程</a></li><li class="menu-item menu-item-rust-编程"><a href="/Programming-Rust/" rel="section"><i class="fa fa-cat fa-fw"></i>Rust 编程</a></li><li class="menu-item menu-item-go-&nbsp;&nbsp;&nbsp;编程"><a href="/Programming-Go/" rel="section"><i class="fa fa-hippo fa-fw"></i>Go &nbsp;&nbsp;&nbsp;编程</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BC%96%E8%AF%91%E5%99%A8%E5%92%8C%E8%A7%A3%E9%87%8A%E5%99%A8"><span class="nav-number">1.</span> <span class="nav-text">编译器和解释器</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%91%BD%E4%BB%A4%E5%BC%8F%E7%BC%96%E7%A8%8B"><span class="nav-number">1.1.</span> <span class="nav-text">命令式编程</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%AC%A6%E5%8F%B7%E5%BC%8F%E7%BC%96%E7%A8%8B"><span class="nav-number">1.2.</span> <span class="nav-text">符号式编程</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%B7%B7%E5%90%88%E5%BC%8F%E7%BC%96%E7%A8%8B"><span class="nav-number">1.3.</span> <span class="nav-text">混合式编程</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%BA%8F%E5%88%97%E5%8C%96"><span class="nav-number">1.4.</span> <span class="nav-text">序列化</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">1.5.</span> <span class="nav-text">总结</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BC%82%E6%AD%A5%E8%AE%A1%E7%AE%97"><span class="nav-number">2.</span> <span class="nav-text">异步计算</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%80%BB%E7%BB%93-1"><span class="nav-number">2.1.</span> <span class="nav-text">总结</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%87%AA%E5%8A%A8%E5%B9%B6%E8%A1%8C"><span class="nav-number">3.</span> <span class="nav-text">自动并行</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%80%BB%E7%BB%93-2"><span class="nav-number">3.1.</span> <span class="nav-text">总结</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%A1%AC%E4%BB%B6"><span class="nav-number">4.</span> <span class="nav-text">硬件</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97%E6%9C%BA"><span class="nav-number">4.1.</span> <span class="nav-text">计算机</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%86%85%E5%AD%98"><span class="nav-number">4.2.</span> <span class="nav-text">内存</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%AD%98%E5%82%A8%E5%99%A8"><span class="nav-number">4.3.</span> <span class="nav-text">存储器</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%A1%AC%E7%9B%98%E9%A9%B1%E5%8A%A8%E5%99%A8"><span class="nav-number">4.3.1.</span> <span class="nav-text">硬盘驱动器</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%9B%BA%E6%80%81%E9%A9%B1%E5%8A%A8%E5%99%A8"><span class="nav-number">4.3.2.</span> <span class="nav-text">固态驱动器</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E4%BA%91%E5%AD%98%E5%82%A8"><span class="nav-number">4.3.3.</span> <span class="nav-text">云存储</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#CPU"><span class="nav-number">4.4.</span> <span class="nav-text">CPU</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%BE%AE%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84"><span class="nav-number">4.4.1.</span> <span class="nav-text">微体系结构</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%9F%A2%E9%87%8F%E5%8C%96"><span class="nav-number">4.4.2.</span> <span class="nav-text">矢量化</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%BC%93%E5%AD%98"><span class="nav-number">4.4.3.</span> <span class="nav-text">缓存</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#GPU%E5%92%8C%E5%85%B6%E4%BB%96%E5%8A%A0%E9%80%9F%E5%8D%A1"><span class="nav-number">4.5.</span> <span class="nav-text">GPU和其他加速卡</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%BD%91%E7%BB%9C%E5%92%8C%E6%80%BB%E7%BA%BF"><span class="nav-number">4.6.</span> <span class="nav-text">网络和总线</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%80%BB%E7%BB%93-3"><span class="nav-number">4.7.</span> <span class="nav-text">总结</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A4%9AGPU%E8%AE%AD%E7%BB%83"><span class="nav-number">5.</span> <span class="nav-text">多GPU训练</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%97%AE%E9%A2%98%E6%8B%86%E5%88%86"><span class="nav-number">5.1.</span> <span class="nav-text">问题拆分</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C%E6%80%A7"><span class="nav-number">5.2.</span> <span class="nav-text">数据并行性</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%80%BB%E7%BB%93-4"><span class="nav-number">5.3.</span> <span class="nav-text">总结</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8F%82%E6%95%B0%E6%9C%8D%E5%8A%A1%E5%99%A8"><span class="nav-number">6.</span> <span class="nav-text">参数服务器</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C%E8%AE%AD%E7%BB%83"><span class="nav-number">6.1.</span> <span class="nav-text">数据并行训练</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%8E%AF%E5%90%8C%E6%AD%A5%EF%BC%88Ring-Synchronization%EF%BC%89"><span class="nav-number">6.2.</span> <span class="nav-text">环同步（Ring Synchronization）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%A4%9A%E6%9C%BA%E8%AE%AD%E7%BB%83"><span class="nav-number">6.3.</span> <span class="nav-text">多机训练</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%94%AE%E5%80%BC%E5%AD%98%E5%82%A8"><span class="nav-number">6.4.</span> <span class="nav-text">键值存储</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%80%BB%E7%BB%93-5"><span class="nav-number">6.5.</span> <span class="nav-text">总结</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="umbrella"
      src="/avatar.jpeg">
  <p class="site-author-name" itemprop="name">umbrella</p>
  <div class="site-description" itemprop="description">没事就多看看书</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">223</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">21</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">65</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/fresh88888888" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;fresh88888888" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:fresh888888@foxmail.com" title="E-Mail → mailto:fresh888888@foxmail.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
    </div>

    
    <div class="sidebar-inner sidebar-blogroll">
      <div class="links-of-blogroll animated">
        <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
          链接
        </div>
        <ul class="links-of-blogroll-list">
            <li class="links-of-blogroll-item">
              <a href="https://www.rust-lang.org/zh-CN/" title="https:&#x2F;&#x2F;www.rust-lang.org&#x2F;zh-CN&#x2F;" rel="noopener" target="_blank">Rust</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://go.dev/" title="https:&#x2F;&#x2F;go.dev&#x2F;" rel="noopener" target="_blank">Golang</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://isocpp.org/" title="https:&#x2F;&#x2F;isocpp.org&#x2F;" rel="noopener" target="_blank">C++</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://www.python.org/" title="https:&#x2F;&#x2F;www.python.org&#x2F;" rel="noopener" target="_blank">Python</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://doc.rust-lang.org/cargo/index.html" title="https:&#x2F;&#x2F;doc.rust-lang.org&#x2F;cargo&#x2F;index.html" rel="noopener" target="_blank">Cargo</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://gist.github.com/rxaviers/7360908" title="https:&#x2F;&#x2F;gist.github.com&#x2F;rxaviers&#x2F;7360908" rel="noopener" target="_blank">Emoji</a>
            </li>
        </ul>
      </div>
    </div>
        <div class="pjax">
        </div>
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://fresh88888888.github.io/2024/05/23/artificial-intelligence/computing_theory_study/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/avatar.jpeg">
      <meta itemprop="name" content="umbrella">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="UMBRELLA">
      <meta itemprop="description" content="没事就多看看书">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="计算性能 (机器学习)(TensorFlow) | UMBRELLA">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          计算性能 (机器学习)(TensorFlow)
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-05-23 09:00:11" itemprop="dateCreated datePublished" datetime="2024-05-23T09:00:11+08:00">2024-05-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" itemprop="url" rel="index"><span itemprop="name">人工智能</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>14k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>46 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h4 id="编译器和解释器"><a href="#编译器和解释器" class="headerlink" title="编译器和解释器"></a>编译器和解释器</h4><h5 id="命令式编程"><a href="#命令式编程" class="headerlink" title="命令式编程"></a>命令式编程</h5><p><strong>命令式编程</strong>(<code>imperative programming</code>)。命令式编程使用诸如<code>print、“+”</code>和<code>if</code>之类的语句来更改程序的状态。考虑下面这段简单的命令式程序：</p>
<span id="more"></span>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">a, b</span>):</span><br><span class="line">    <span class="keyword">return</span> a + b</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fancy_func</span>(<span class="params">a, b, c, d</span>):</span><br><span class="line">    e = add(a, b)</span><br><span class="line">    f = add(c, d)</span><br><span class="line">    g = add(e, f)</span><br><span class="line">    <span class="keyword">return</span> g</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(fancy_func(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 10</span></span><br></pre></td></tr></table></figure>
<p><code>Python</code>是一种解释型语言(<code>interpreted language</code>)。因此，当对上面的<code>fancy_func</code>函数求值时，它按顺序执行函数体的操作。也就是说，它将通过对<code>e = add(a, b)</code>求值，并将结果存储为变量<code>e</code>，从而更改程序的状态。接下来的两个语句<code>f = add(c, d)</code>和<code>g = add(e, f)</code>也将执行类似地操作，即执行加法计算并将结果存储为变量。下图说明了数据流。</p>
<img data-src="/2024/05/23/artificial-intelligence/computing_theory_study/cp_1.png" class="" title="命令式编程中的数据流">

<p>尽管命令式编程很方便，但可能效率不高。一方面原因，<code>Python</code>会单独执行这三个函数的调用，而没有考虑<code>add</code>函数在<code>fancy_func</code>中被重复调用。如果在一个<code>GPU</code>（甚至多个<code>GPU</code>）上执行这些命令，那么<code>Python</code>解释器产生的开销可能会非常大。此外，它需要保存<code>e</code>和<code>f</code>的变量值，直到<code>fancy_func</code>中的所有语句都执行完毕。这是因为程序不知道在执行语句<code>e = add(a, b)</code>和<code>f = add(c, d)</code>之后，其他部分是否会使用变量<code>e</code>和<code>f</code>。</p>
<h5 id="符号式编程"><a href="#符号式编程" class="headerlink" title="符号式编程"></a>符号式编程</h5><p>考虑另一种选择<strong>符号式编程</strong>(<code>symbolic programming</code>)，即代码通常只在完全定义了过程之后才执行计算。这个策略被多个深度学习框架使用，包括<code>Theano</code>和<code>TensorFlow</code>（后者已经获得了命令式编程的扩展）。一般包括以下步骤：</p>
<ul>
<li>定义计算流程。</li>
<li>将流程编译成可执行的程序。</li>
<li>给定输入，调用编译好的程序执行。</li>
</ul>
<p>这将允许进行大量的优化。首先，在大多数情况下，我们可以跳过<code>Python</code>解释器。从而消除因为多个更快的<code>GPU</code>与单个<code>CPU</code>上的单个<code>Python</code>线程搭配使用时产生的性能瓶颈。其次，编译器可以将上述代码优化和重写为<code>print((1 + 2) + (3 + 4))</code>甚至<code>print(10)</code>。因为编译器在将其转换为机器指令之前可以看到完整的代码，所以这种优化是可以实现的。例如，只要某个变量不再需要，编译器就可以释放内存（或者从不分配内存），或者将代码转换为一个完全等价的片段。下面，我们将通过模拟命令式编程来进一步了解符号式编程的概念。</p>
<p>命令式（解释型）编程和符号式编程的区别如下：</p>
<ul>
<li>命令式编程更容易使用。在<code>Python</code>中，命令式编程的大部分代码都是简单易懂的。命令式编程也更容易调试，这是因为无论是获取和打印所有的中间变量值，或者使用<code>Python</code>的内置调试工具都更加简单；</li>
<li>符号式编程运行效率更高，更易于移植。符号式编程更容易在编译期间优化代码，同时还能够将程序移植到与<code>Python</code>无关的格式中，从而允许程序在非<code>Python</code>环境中运行，避免了任何潜在的与<code>Python</code>解释器相关的性能问题。</li>
</ul>
<h5 id="混合式编程"><a href="#混合式编程" class="headerlink" title="混合式编程"></a>混合式编程</h5><p>历史上，大部分深度学习框架都在命令式编程与符号式编程之间进行选择。例如，<code>Theano、TensorFlow</code>（灵感来自前者）、<code>Keras</code>和<code>CNTK</code>采用了符号式编程。相反地，<code>Chainer</code>和<code>PyTorch</code>采取了命令式编程。在后来的版本更新中，<code>TensorFlow2.0</code>和<code>Keras</code>增加了命令式编程。</p>
<p>要了解混合式编程的工作原理，最简单的方法是考虑具有多层的深层网络。按照惯例，<code>Python</code>解释器需要执行所有层的代码来生成一条指令，然后将该指令转发到<code>CPU</code>或<code>GPU</code>。对于单个的（快速的）计算设备，这不会导致任何重大问题。另一方面，如果我们使用先进的<code>8-GPU</code>服务器，<code>Python</code>将很难让所有的<code>GPU</code>都保持忙碌。在这里，瓶颈是单线程的<code>Python</code>解释器。让我们看看如何通过将<code>Sequential</code>替换为<code>HybridSequential</code>来解决代码中这个瓶颈。首先，我们定义一个简单的多层感知机。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生产网络的工厂模式</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_net</span>():</span><br><span class="line">    net = tf.keras.Sequential()</span><br><span class="line">    net.add(Dense(<span class="number">256</span>, input_shape = (<span class="number">512</span>,), activation = <span class="string">&quot;relu&quot;</span>))</span><br><span class="line">    net.add(Dense(<span class="number">128</span>, activation = <span class="string">&quot;relu&quot;</span>))</span><br><span class="line">    net.add(Dense(<span class="number">2</span>, activation = <span class="string">&quot;linear&quot;</span>))</span><br><span class="line">    <span class="keyword">return</span> net</span><br><span class="line"></span><br><span class="line">x = tf.random.normal([<span class="number">1</span>,<span class="number">512</span>])</span><br><span class="line">net = get_net()</span><br><span class="line">net(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># &lt;tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[ 0.9541333 , -0.74289465]], dtype=float32)&gt;</span></span><br><span class="line"></span><br><span class="line">net = tf.function(net)</span><br><span class="line">net(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># &lt;tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[ 0.9541333 , -0.74289465]], dtype=float32)&gt;</span></span><br></pre></td></tr></table></figure>
<p>一开始，<code>TensorFlow</code>中构建的所有函数都是作为计算图构建的，因此默认情况下是<code>JIT</code>编译的。但是，随着<code>TensorFlow2.X</code>和<code>EargeTensor</code>的发布，计算图就不再是默认行为。我们可以使用<code>tf.function</code>重新启用这个功能。<code>tf.function</code>更常被用作函数装饰器，它也可以直接将其作为普通的<code>Python</code>函数调用。模型的计算结果保持不变。</p>
<p>我们编写与之前相同的代码，再使用<code>tf.function</code>简单地转换模型，当完成这些任务后，网络将以<code>TensorFlow</code>的<code>MLIR</code>中间表示形式构建为一个计算图，并在编译器级别进行大量优化以满足快速执行的需要（我们将在下面对性能进行基准测试）。通过将<code>jit_compile = True</code>标志添加到<code>tf.function()</code>的函数调用中可以显式地启用<code>TensorFlow</code>中的<code>XLA</code>（线性代数加速）功能。在某些情况下，<code>XLA</code>可以进一步优化JIT的编译代码。如果没有这种显式定义，图形模式将会被启用，但是<code>XLA</code>可以使某些大规模的线性代数的运算速度更快（与我们在深度学习程序中看到的操作类似），特别是在<code>GPU</code>环境中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Benchmark</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;用于测量运行时间&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, description=<span class="string">&#x27;Done&#x27;</span></span>):</span><br><span class="line">        self.description = description</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__enter__</span>(<span class="params">self</span>):</span><br><span class="line">        self.t1 = time.clock()</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__exit__</span>(<span class="params">self, *args</span>):</span><br><span class="line">        self.t2 = time.clock()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;self.description&#125;</span>: <span class="subst">&#123;(self.t2 - self.t1):<span class="number">.4</span>f&#125;</span> sec&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 现在我们可以调用网络三次，一次使用eager模式，一次是使用图模式。</span></span><br><span class="line">net = get_net()</span><br><span class="line"><span class="keyword">with</span> Benchmark(<span class="string">&#x27;Eager模式&#x27;</span>):</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>): net(x)</span><br><span class="line"></span><br><span class="line">net = tf.function(net)</span><br><span class="line"><span class="keyword">with</span> Benchmark(<span class="string">&#x27;Graph模式&#x27;</span>):</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>): net(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Eager模式: 1.2769 sec</span></span><br><span class="line"><span class="comment"># Graph模式: 0.5811 sec</span></span><br></pre></td></tr></table></figure>
<p>如以上结果所示，在<code>tf.keras.Sequential</code>的实例被函数<code>tf.function</code>脚本化后，通过使用<code>TensorFlow</code>中的图模式执行方式实现的符号式编程提高了计算性能。</p>
<h5 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a>序列化</h5><p>编译模型的好处之一是我们可以将模型及其参数序列化（保存）到磁盘。这允许这些训练好的模型部署到其他设备上，并且还能方便地使用其他前端编程语言。同时，通常编译模型的代码执行速度也比命令式编程更快。在<code>TensorFlow</code>中保存模型的底层<code>API</code>是<code>tf.saved_model</code>，让我们来看看<code>saved_model</code>的运行情况。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">net = get_net()</span><br><span class="line">tf.saved_model.save(net, <span class="string">&#x27;my_mlp&#x27;</span>)</span><br><span class="line">!<span class="built_in">ls</span> -lh my_mlp*</span><br></pre></td></tr></table></figure>
<p>输出结果为：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">INFO:tensorflow:Assets written to: my_mlp/assets</span><br><span class="line">total 64K</span><br><span class="line">drwxr-xr-x 2 ci ci   6 Aug 18 07:38 assets</span><br><span class="line">-rw-r--r-- 1 ci ci 64K Aug 18 07:38 saved_model.pb</span><br><span class="line">drwxr-xr-x 2 ci ci  66 Aug 18 07:38 variables</span><br></pre></td></tr></table></figure>
<h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><p>命令式编程使得新模型的设计变得容易，因为可以依据控制流编写代码，并拥有相对成熟的<code>Python</code>软件生态。符号式编程要求我们先定义并且编译程序，然后再执行程序，其好处是提高了计算性能。</p>
<h4 id="异步计算"><a href="#异步计算" class="headerlink" title="异步计算"></a>异步计算</h4><p>今天的计算机是高度并行的系统，由多个<code>CPU</code>核、多个<code>GPU</code>、多个处理单元组成。通常每个<code>CPU</code>核有多个线程，每个设备通常有多个<code>GPU</code>，每个<code>GPU</code>有多个处理单元。总之，我们可以同时处理许多不同的事情，并且通常是在不同的设备上。不幸的是，<code>Python</code>并不善于编写并行和异步代码，至少在没有额外帮助的情况下不是好选择。归根结底，<code>Python</code>是单线程的，将来也是不太可能改变的。因此在诸多的深度学习框架中，<code>TensorFlow</code>则采用了一种<strong>异步编程</strong>(<code>asynchronous programming</code>)模型来提高性能，而<code>PyTorch</code>则使用了<code>Python</code>自己的调度器来实现不同的性能权衡。对<code>PyTorch</code>来说<code>GPU</code>操作在默认情况下是异步的。当调用一个使用<code>GPU</code>的函数时，操作会排队到特定的设备上，但不一定要等到以后才执行。这允许我们并行执行更多的计算，包括在<code>CPU</code>或其他<code>GPU</code>上的操作。</p>
<h5 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h5><p>深度学习框架可以将<code>Python</code>前端的控制与后端的执行解耦，使得命令可以快速地异步插入后端、并行执行。异步产生了一个相当灵活的前端，但请注意：过度填充任务队列可能会导致内存消耗过多。建议对每个小批量进行同步，以保持前端和后端大致同步。芯片供应商提供了复杂的性能分析工具，以获得对深度学习效率更精确的洞察。</p>
<h4 id="自动并行"><a href="#自动并行" class="headerlink" title="自动并行"></a>自动并行</h4><p>深度学习框架会在后端自动构建计算图。利用计算图，系统可以了解所有依赖关系，并且可以选择性地并行执行多个不相互依赖的任务以提高速度。通常情况下单个操作符将使用所有<code>CPU</code>或单个<code>GPU</code>上的所有计算资源。例如，即使在一台机器上有多个<code>CPU</code>处理器，<code>dot</code>操作符也将使用所有<code>CPU</code>上的所有核心（和线程）。这样的行为同样适用于单个<code>GPU</code>。因此，并行化对单设备计算机来说并不是很有用，而并行化对于多个设备就很重要了。虽然并行化通常应用在多个<code>GPU</code>之间，但增加本地<code>CPU</code>以后还将提高少许性能。例如，则把结合<code>GPU</code>和<code>CPU</code>的训练应用到计算机视觉模型中。借助自动并行化框架的便利性，我们可以依靠几行<code>Python</code>代码实现相同的目标。</p>
<img data-src="/2024/05/23/artificial-intelligence/computing_theory_study/cp_2.png" class="" title="在一个CPU和两个GPU上的两层的多层感知机的计算图及其依赖关系">

<h5 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h5><p>现代系统拥有多种设备，如多个<code>GPU</code>和多个<code>CPU</code>，还可以并行地、异步地使用它们。现代系统还拥有各种通信资源，如<code>PCI Express</code>、存储（通常是固态硬盘或网络存储）和网络带宽，为了达到最高效率可以并行使用它们。后端可以通过自动化地并行计算和通信来提高性能。</p>
<h4 id="硬件"><a href="#硬件" class="headerlink" title="硬件"></a>硬件</h4><p>很好地理解算法和模型才可以捕获统计方面的问题，构建出具有出色性能的系统。同时，至少对底层硬件有一定的了解也是必不可少的。一个好的设计可以很容易地在性能上造就数量级的差异，这也是后续产生的能够训练网络（例如，训练时间为<code>1</code>周）和无法训练网络（训练时间为<code>3</code>个月，导致错过截止期）之间的差异。我们先从计算机的研究开始。然后深入查看<code>CPU</code>和<code>GPU</code>。最后，再查看数据中心或云中的多台计算机的连接方式。</p>
<img data-src="/2024/05/23/artificial-intelligence/computing_theory_study/cp_3.png" class="" title="每种计算的延迟时间">

<h5 id="计算机"><a href="#计算机" class="headerlink" title="计算机"></a>计算机</h5><p>大多数深度学习研究者和实践者都可以使用一台具有相当数量的内存、计算资源、某种形式的加速器（如一个或者多个<code>GPU</code>）的计算机。计算机由以下关键部件组成：</p>
<ul>
<li>一个处理器（也被称为<code>CPU</code>），它除了能够运行操作系统和许多其他功能之外，还能够执行给定的程序。它通常由<code>8</code>个或更多个核心组成；</li>
<li>内存（随机访问存储，<code>RAM</code>）用于存储和检索计算结果，如权重向量和激活参数，以及训练数据；</li>
<li>一个或多个以太网连接，速度从<code>1GB/s</code>到<code>100GB/s</code>不等。在高端服务器上可能用到更高级的互连；</li>
<li>高速扩展总线（<code>PCIe</code>）用于系统连接一个或多个<code>GPU</code>。服务器最多有8个加速卡，通常以更高级的拓扑方式连接，而桌面系统则有<code>1</code>个或<code>2</code>个加速卡，具体取决于用户的预算和电源负载的大小；</li>
<li>持久性存储设备，如磁盘驱动器、固态驱动器，在许多情况下使用高速扩展总线连接。它为系统需要的训练数据和中间检查点需要的存储提供了足够的传输速度。</li>
</ul>
<img data-src="/2024/05/23/artificial-intelligence/computing_theory_study/cp_4.png" class="" title="计算机组件的连接">

<p>如上图所示，高速扩展总线由直接连接到<code>CPU</code>的多个通道组成，将<code>CPU</code>与大多数组件（网络、<code>GPU</code>和存储）连接在一起。例如，<code>AMD</code>的<code>Threadripper3</code>有<code>64</code>个<code>PCIe4.0</code>通道，每个通道都能够双向传输<code>16Gbit/s</code>的数据。内存直接连接到<code>CPU</code>，总带宽高达<code>100GB/s</code>。当我们在计算机上运行代码时，需要将数据转移到处理器上（<code>CPU</code>或<code>GPU</code>）执行计算，然后将结果从处理器移回到随机访问存储和持久存储器中。因此，为了获得良好的性能，需要确保每一步工作都能无缝链接，而不希望系统中的任何一部分成为主要的瓶颈。例如，如果不能快速加载图像，那么处理器就无事可做。同样地，如果不能快速移动矩阵到<code>CPU</code>（或<code>GPU</code>）上，那么<code>CPU</code>（或<code>GPU</code>）就会无法全速运行。最后，如果希望在网络上同步多台计算机，那么网络就不应该拖累计算速度。一种选择是通信和计算交错进行。接下来将详细地介绍各个组件。</p>
<h5 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h5><p>最基本的内存主要用于存储需要随时访问的数据。目前，<code>CPU</code>的内存通常为<code>DDR4</code>类型，每个模块提供<code>20-25Gb/s</code>的带宽。每个模块都有一条<code>64</code>位宽的总线。通常使用成对的内存模块来允许多个通道。<code>CPU</code>有<code>2</code>到<code>4</code>个内存通道，也就是说，它们内存带宽的峰值在<code>40GB/s</code>到<code>100GB/s</code>之间。一般每个通道有两个物理存储体(<code>bank</code>)。例如<code>AMD</code>的<code>Zen 3 Threadripper</code>有<code>8</code>个插槽。虽然这些数字令人印象深刻，但实际上它们只能说明了一部分故事。当我们想要从内存中读取一部分内容时，需要先告诉内存模块在哪里可以找到信息。也就是说，我们需要先将地址(<code>address</code>)发送到<code>RAM</code>。然后我们可以选择只读取一条<code>64</code>位记录还是一长串记录。后者称为突发读取(<code>burst read</code>)。概括地说，向内存发送地址并设置传输大约需要<code>100ns</code>（细节取决于所用内存芯片的特定定时系数），每个后续传输只需要<code>0.2ns</code>。总之，第一次读取的成本是后续读取的<code>500</code>倍！请注意，每秒最多可以执行一千万次随机读取。这说明应该尽可能地避免随机内存访问，而是使用突发模式读取和写入。</p>
<p>当考虑到拥有多个物理存储体时，事情就更加复杂了。每个存储体大部分时候都可以独立地读取内存。这意味着两件事。一方面，如果随机读操作均匀分布在内存中，那么有效的随机读操作次数将高达<code>4</code>倍。这也意味着执行随机读取仍然不是一个好主意，因为突发读取的速度也快了<code>4</code>倍。另一方面，由于内存对齐是<code>64</code>位边界，因此最好将任何数据结构与相同的边界对齐。当设置了适当的标志时，编译器基本上就是自动化地执行对齐操作。<code>GPU</code>内存的带宽要求甚至更高，因为它们的处理单元比<code>CPU</code>多得多。总的来说，解决这些问题有两种选择。首先是使内存总线变得更宽。例如，<code>NVIDIA</code>的<code>RTX 2080Ti</code>有一条<code>352</code>位宽的总线。这样就可以同时传输更多的信息。其次，<code>GPU</code>使用特定的高性能内存。消费级设备，如<code>NVIDIA</code>的<code>RTX</code>和<code>Titan</code>系列，通常使用<code>GDDR6</code>模块。它们使用截然不同的接口，直接与专用硅片上的<code>GPU</code>连接。这使得它们非常昂贵，通常仅限于高端服务器芯片，如<code>NVIDIA Volta V100</code>系列加速卡。毫不意外的是<code>GPU</code>的内存通常比<code>CPU</code>的内存小得多，因为前者的成本更高。就目的而言，它们的性能与特征大体上是相似的，只是<code>GPU</code>的速度更快。</p>
<h5 id="存储器"><a href="#存储器" class="headerlink" title="存储器"></a>存储器</h5><p>随机访问存储的一些关键特性是带宽(<code>bandwidth</code>)和延迟(<code>latency</code>)。存储设备也是如此，只是不同设备之间的特性差异可能更大。</p>
<h6 id="硬盘驱动器"><a href="#硬盘驱动器" class="headerlink" title="硬盘驱动器"></a>硬盘驱动器</h6><p>硬盘驱动器(<code>hard disk drive，HDD</code>)已经使用了半个多世纪。简单的说，它们包含许多旋转的盘片，这些盘片的磁头可以放置在任何给定的磁道上进行读写。高端磁盘在<code>9</code>个盘片上可容纳高达<code>16TB</code>的容量。硬盘的主要优点之一是相对便宜，而它们的众多缺点之一是典型的灾难性故障模式和相对较高的读取延迟。要理解后者，请了解一个事实即硬盘驱动器的转速大约为<code>7200RPM</code>（每分钟转数）。它们如果转速再快些，就会由于施加在碟片上的离心力而破碎。在访问磁盘上的特定扇区时，还有一个关键问题：需要等待碟片旋转到位（可以移动磁头，但是无法对磁盘加速）。因此，可能需要<code>8</code>毫秒才能使用请求的数据。一种常见的描述方式是，硬盘驱动器可以以大约<code>100IOPs</code>（每秒输入&#x2F;输出操作）的速度工作，并且在过去二十年中这个数字基本上没变。同样糟糕的是，带宽（大约为<code>100-200MB/s</code>）也很难增加。毕竟，每个磁头读取一个磁道的比特，因此比特率只随信息密度的平方根缩放。因此，对于非常大的数据集，<code>HDD</code>正迅速降级为归档存储和低级存储。</p>
<h6 id="固态驱动器"><a href="#固态驱动器" class="headerlink" title="固态驱动器"></a>固态驱动器</h6><p>固态驱动器(<code>solid state drives，SSD</code>)使用闪存持久地存储信息。这允许更快地访问存储的记录。现代的固态驱动器的<code>IOPs</code>可以达到<code>10</code>万到<code>50</code>万，比硬盘驱动器快<code>3</code>个数量级。而且，它们的带宽可以达到<code>1-3GB/s</code>，比硬盘驱动器快一个数量级。这些改进听起来好的难以置信，而事实上受固态驱动器的设计方式，它仍然存在下面的附加条件。</p>
<ul>
<li>固态驱动器以块的方式（<code>256KB</code>或更大）存储信息。块只能作为一个整体来写入，因此需要耗费大量的时间，导致固态驱动器在按位随机写入时性能非常差。而且通常数据写入需要大量的时间还因为块必须被读取、擦除，然后再重新写入新的信息。如今固态驱动器的控制器和固件已经开发出了缓解这种情况的算法。尽管有了算法，写入速度仍然会比读取慢得多，特别是对于<code>QLC</code>（四层单元）固态驱动器。提高性能的关键是维护操作的“队列”，在队列中尽可能地优先读取和写入大的块。</li>
<li>固态驱动器中的存储单元磨损得比较快（通常在几千次写入之后就已经老化了）。磨损程度保护算法能够将退化平摊到许多单元。也就是说，不建议将固态驱动器用于交换分区文件或大型日志文件。</li>
<li>最后，带宽的大幅增加迫使计算机设计者将固态驱动器与<code>PCIe</code>总线相连接，这种驱动器称为<code>NVMe</code>（非易失性内存增强），其最多可以使用<code>4</code>个<code>PCIe</code>通道。在<code>PCIe4.0</code>上最高可达<code>8GB/s</code>。</li>
</ul>
<h6 id="云存储"><a href="#云存储" class="headerlink" title="云存储"></a>云存储</h6><p>云存储提供了一系列可配置的性能。也就是说，虚拟机的存储在数量和速度上都能根据用户需要进行动态分配。建议用户在延迟太高时（例如，在训练期间存在许多小记录时）增加<code>IOPs</code>的配置数。</p>
<h5 id="CPU"><a href="#CPU" class="headerlink" title="CPU"></a>CPU</h5><p>中央处理器(<code>central processing unit，CPU</code>)是任何计算机的核心。它们由许多关键组件组成：处理器核心(<code>processor cores</code>)用于执行机器代码的；总线(<code>bus</code>)用于连接不同组件（注意，总线会因为处理器型号、各代产品和供应商之间的特定拓扑结构有明显不同）；缓存(<code>cach</code>)相比主内存实现更高的读取带宽和更低的延迟内存访问。最后，因为高性能线性代数和卷积运算常见于媒体处理和机器学习中，所以几乎所有的现代<code>CPU</code>都包含向量处理单元(<code>vector processing unit</code>)为这些计算提供辅助。</p>
<img data-src="/2024/05/23/artificial-intelligence/computing_theory_study/cp_5.png" class="" title="Intel Skylake消费级四核CPU">

<p>上图描述了<code>Intel Skylake</code>消费级四核<code>CPU</code>。它包含一个集成<code>GPU</code>、缓存和一个连接四个核心的环总线。例如，以太网、WiFi、蓝牙、<code>SSD</code>控制器和<code>USB</code>这些外围设备要么是芯片组的一部分，要么通过<code>PCIe</code>直接连接到<code>CPU</code>。</p>
<h6 id="微体系结构"><a href="#微体系结构" class="headerlink" title="微体系结构"></a>微体系结构</h6><p>每个处理器核心都由一组相当复杂的组件组成。虽然不同时代的产品和供应商的细节有所不同，但基本功能都是标准的。前端加载指令并尝试预测将采用哪条路径（例如，为了控制流），然后将指令从汇编代码解码为微指令。汇编代码通常不是处理器执行的最低级别代码，而复杂的微指令却可以被解码成一组更低级的操作，然后由实际的执行核心处理。通常执行核心能够同时执行许多操作，例如，下图的<code>ARM Cortex A77</code>核心可以同时执行多达<code>8</code>个操作。</p>
<img data-src="/2024/05/23/artificial-intelligence/computing_theory_study/cp_6.png" class="" title="ARM Cortex A77微体系结构">

<p>这意味着高效的程序可以在每个时钟周期内执行多条指令，前提是这些指令可以独立执行。不是所有的处理单元都是平等的。一些专用于处理整数指令，而另一些则针对浮点性能进行了优化。为了提高吞吐量，处理器还可以在分支指令中同时执行多条代码路径，然后丢弃未选择分支的结果。这就是为什么前端的分支预测单元很重要，因为只有最有希望的路径才会被继续执行。</p>
<h6 id="矢量化"><a href="#矢量化" class="headerlink" title="矢量化"></a>矢量化</h6><p>深度学习的计算量非常大。因此，为了满足机器学习的需要，<code>CPU</code>需要在一个时钟周期内执行许多操作。这种执行方式是通过向量处理单元实现的。这些处理单元有不同的名称:在<code>ARM</code>上叫做<code>NEON</code>,在<code>x86</code>上被称为<code>AVX2</code>。一个常见的功能是它们能够执行<strong>单指令多数据</strong>(<code>single instruction multiple data，SIMD</code>)操作。下图显示了如何在ARM上的一个时钟周期中完成<code>8</code>个整数加法。</p>
<img data-src="/2024/05/23/artificial-intelligence/computing_theory_study/cp_7.png" class="" title="128位NEON矢量化">

<p>根据体系结构的选择，此类寄存器最长可达512位，最多可组合64对数字。例如，我们可能会将两个数字相乘，然后与第三个数字相加，这也称为<strong>乘加融合</strong>(<code>fused multiply-add</code>)。<code>Intel</code>的<code>OpenVino</code>就是使用这些处理器来获得可观的吞吐量，以便在服务器级<code>CPU</code>上进行深度学习。不过请注意，这个数字与<code>GPU</code>的能力相比则相形见绌。例如，<code>NVIDIA</code>的<code>RTX 2080Ti</code>拥有<code>4352个CUDA</code>核心，每个核心都能够在任何时候处理这样的操作。</p>
<h6 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h6><p>考虑以下情况：我们有一个中等规模的<code>4</code>核心的<code>CPU</code>，运行在<code>2GHz</code>频率。此外，假设向量处理单元启用了<code>256</code>位带宽的<code>AVX2</code>，其<code>IPC</code>（指令&#x2F;时钟）计数为<code>1</code>。进一步假设从内存中获取用于<code>AVX2</code>操作的指令至少需要一个寄存器。这意味着<code>CPU</code>每个时钟周期需要消耗<code>4 x 256 bit = 128 bytes</code>的数据。除非我们能够每秒向处理器传输<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.186ex;" xmlns="http://www.w3.org/2000/svg" width="25.733ex" height="2.14ex" role="img" focusable="false" viewBox="0 -864 11374 946" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-39-TEX-N-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path id="MJX-39-TEX-N-D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path><path id="MJX-39-TEX-N-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path id="MJX-39-TEX-N-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path id="MJX-39-TEX-N-39" d="M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z"></path><path id="MJX-39-TEX-N-38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z"></path><path id="MJX-39-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-39-TEX-N-35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z"></path><path id="MJX-39-TEX-N-36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><use data-c="32" xlink:href="#MJX-39-TEX-N-32"></use></g><g data-mml-node="mo" transform="translate(722.2,0)"><use data-c="D7" xlink:href="#MJX-39-TEX-N-D7"></use></g><g data-mml-node="msup" transform="translate(1722.4,0)"><g data-mml-node="mn"><use data-c="31" xlink:href="#MJX-39-TEX-N-31"></use><use data-c="30" xlink:href="#MJX-39-TEX-N-30" transform="translate(500,0)"></use></g><g data-mml-node="mn" transform="translate(1033,393.1) scale(0.707)"><use data-c="39" xlink:href="#MJX-39-TEX-N-39"></use></g></g><g data-mml-node="mo" transform="translate(3381.2,0)"><use data-c="D7" xlink:href="#MJX-39-TEX-N-D7"></use></g><g data-mml-node="mn" transform="translate(4381.4,0)"><use data-c="31" xlink:href="#MJX-39-TEX-N-31"></use><use data-c="32" xlink:href="#MJX-39-TEX-N-32" transform="translate(500,0)"></use><use data-c="38" xlink:href="#MJX-39-TEX-N-38" transform="translate(1000,0)"></use></g><g data-mml-node="mo" transform="translate(6159.2,0)"><use data-c="3D" xlink:href="#MJX-39-TEX-N-3D"></use></g><g data-mml-node="mn" transform="translate(7215,0)"><use data-c="32" xlink:href="#MJX-39-TEX-N-32"></use><use data-c="35" xlink:href="#MJX-39-TEX-N-35" transform="translate(500,0)"></use><use data-c="36" xlink:href="#MJX-39-TEX-N-36" transform="translate(1000,0)"></use></g><g data-mml-node="mo" transform="translate(8937.2,0)"><use data-c="D7" xlink:href="#MJX-39-TEX-N-D7"></use></g><g data-mml-node="msup" transform="translate(9937.4,0)"><g data-mml-node="mn"><use data-c="31" xlink:href="#MJX-39-TEX-N-31"></use><use data-c="30" xlink:href="#MJX-39-TEX-N-30" transform="translate(500,0)"></use></g><g data-mml-node="mn" transform="translate(1033,393.1) scale(0.707)"><use data-c="39" xlink:href="#MJX-39-TEX-N-39"></use></g></g></g></g></svg></mjx-container>字节，否则用于处理的数据将会不足。不幸的是，这种芯片的存储器接口仅支持<code>20-40Gb/s</code>的数据传输，即少了一个数量级。解决方法是尽可能避免从内存中加载新数据，而是将数据放在<code>CPU</code>的缓存上。这就是使用缓存的地方。通常使用以下名称或概念。</p>
<ul>
<li>寄存器，严格来说不是缓存的一部分，用于帮助组织指令。也就是说，寄存器是CPU可以以时钟速度访问而没有延迟的存储位置。<code>CPU</code>有几十个寄存器，因此有效地使用寄存器取决于编译器（或程序员）。例如，<code>C</code>语言有一个<code>register</code>关键字。</li>
<li>一级缓存是应对高内存带宽要求的第一道防线。一级缓存很小（常见的大小可能是<code>32-64KB</code>），内容通常分为数据和指令。当数据在一级缓存中被找到时，其访问速度非常快，如果没有在那里找到，搜索将沿着缓存层次结构向下寻找。</li>
<li>二级缓存是下一站。根据架构设计和处理器大小的不同，它们可能是独占的也可能是共享的。即它们可能只能由给定的核心访问，或者在多个核心之间共享。二级缓存比一级缓存大（通常每个核心<code>256-512KB</code>），而速度也更慢。此外，我们首先需要检查以确定数据不在一级缓存中，才会访问二级缓存中的内容，这会增加少量的额外延迟。</li>
<li>三级缓存在多个核之间共享，并且可以非常大。<code>AMD</code>的<code>EPYC 3</code>服务器的<code>CPU</code>在多个芯片上拥有高达<code>256MB</code>的高速缓存。更常见的数字在<code>4-8MB</code>范围内。</li>
</ul>
<p>预测下一步需要哪个存储设备是优化芯片设计的关键参数之一。例如，建议以向前的方向遍历内存，因为大多数缓存算法将试图<strong>向前读取</strong>(<code>read forward</code>)而不是向后读取。同样，将内存访问模式保持在本地也是提高性能的一个好方法。</p>
<p>添加缓存是一把双刃剑。一方面，它能确保处理器核心不缺乏数据。但同时，它也增加了芯片尺寸，消耗了原本可以用来提高处理能力的面积。此外，缓存未命中的代价可能会很昂贵。考虑最坏的情况，如下图所示的<strong>错误共享</strong>(<code>false sharing</code>)。当处理器<code>1</code>上的线程请求数据时，内存位置缓存在处理器<code>0</code>上。为了满足获取需要，处理器<code>0</code>需要停止它正在做的事情，将信息写回主内存，然后让处理器<code>1</code>从内存中读取它。在此操作期间，两个处理器都需要等待。与高效的单处理器实现相比，这种代码在多个处理器上运行的速度可能要慢得多。这就是为什么缓存大小（除了物理大小之外）有实际限制的另一个原因。</p>
<img data-src="/2024/05/23/artificial-intelligence/computing_theory_study/cp_8.png" class="" title="错误共享">
<h5 id="GPU和其他加速卡"><a href="#GPU和其他加速卡" class="headerlink" title="GPU和其他加速卡"></a>GPU和其他加速卡</h5><p>毫不夸张地说，如果没有<code>GPU</code>，深度学习就不会成功。基于同样的原因，有理由认为<code>GPU</code>制造商的财富由于深度学习而显著增加。这种硬件和算法的协同进化导致了这样一种情况：无论好坏，深度学习都是更可取的统计建模范式。因此，了解<code>GPU</code>和其他加速卡（如<code>TPU</code>）的具体好处是值得的。值得注意的是，在实践中经常会有这样一个判别：加速卡是为训练还是推断而优化的。对于后者，我们只需要计算网络中的前向传播。而反向传播不需要存储中间数据。还有，我们可能不需要非常精确的计算（<code>FP16</code>或<code>INT8</code>通常就足够了）。对于前者，即训练过程中需要存储所有的中间结果用来计算梯度。而且，累积梯度也需要更高的精度，以避免数值下溢（或溢出）。这意味着最低要求也是<code>FP16</code>（或<code>FP16</code>与<code>FP32</code>的混合精度）。所有这些都需要更快、更大的内存（<code>HBM2</code>或者<code>GDDR6</code>）和更高的处理能力。例如，<code>NVIDIA</code>优化了<code>Turing T4 GPU</code>用于推断和<code>V100 GPU</code>用于训练。</p>
<img data-src="/2024/05/23/artificial-intelligence/computing_theory_study/cp_9.png" class="" title="NVIDIA Turing处理块（图片由英伟达提供）">

<p>回想一下矢量化。处理器核心中添加向量处理单元可以显著提高吞吐量。例如，在矢量化的例子中，我们能够同时执行<code>16</code>个操作。首先，如果我们添加的运算不仅优化了向量运算，而且优化了矩阵运算，会有什么好处？稍后我们将讨论基于这个策略引入的张量核(<code>tensor cores</code>)。第二，如果我们增加更多的核心呢？简而言之，以上就是<code>GPU</code>设计决策中的两种策略。下图给出了基本处理块的概述。它包含<code>16</code>个整数单位和<code>16</code>个浮点单位。除此之外，两个张量核加速了与深度学习相关的附加操作的狭窄的子集。每个流式多处理器都由这样的四个块组成。</p>
<img data-src="/2024/05/23/artificial-intelligence/computing_theory_study/cp_10.png" class="" title="NVIDIA Turing架构（图片由英伟达提供）">

<p>接下来，将<code>12</code>个流式多处理器分组为图形处理集群，这些集群构成了高端<code>TU102</code>处理器。充足的内存通道和二级缓存完善了配置。下图有相关的细节。设计这种设备的原因之一是可以根据需要独立地添加或删除模块，从而满足设计更紧凑的芯片和处理良品率问题（故障模块可能无法激活）的需要。幸运的是，在<code>CUDA</code>和框架代码层之下，这类设备的编程对深度学习的临时研究员隐藏得很好。特别是，只要有可用的资源<code>GPU</code>上就可以同时执行多个程序。尽管如此，了解设备的局限性是值得的，以避免对应的设备内存的型号不合适。</p>
<img data-src="/2024/05/23/artificial-intelligence/computing_theory_study/cp_11.jpeg" class="" title="NVIDIA Turing架构中的张量核心（图片由英伟达提供）">

<p>最后值得一提的是张量核(<code>tensor core</code>)。它们是最近增加更多优化电路趋势的一个例子，这些优化电路对深度学习特别有效。例如，<code>TPU</code>添加了用于快速矩阵乘法的脉动阵列，这种设计是为了支持非常小数量（第一代<code>TPU</code>支持数量为<code>1</code>）的大型操作。而张量核是另一个极端。它们针对<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="5.028ex" height="1.532ex" role="img" focusable="false" viewBox="0 -677 2222.4 677" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-38-TEX-N-34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path><path id="MJX-38-TEX-N-D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><use data-c="34" xlink:href="#MJX-38-TEX-N-34"></use></g><g data-mml-node="mo" transform="translate(722.2,0)"><use data-c="D7" xlink:href="#MJX-38-TEX-N-D7"></use></g><g data-mml-node="mn" transform="translate(1722.4,0)"><use data-c="34" xlink:href="#MJX-38-TEX-N-34"></use></g></g></g></svg></mjx-container>和<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="7.291ex" height="1.557ex" role="img" focusable="false" viewBox="0 -666 3222.4 688" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-37-TEX-N-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path id="MJX-37-TEX-N-36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path><path id="MJX-37-TEX-N-D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><use data-c="31" xlink:href="#MJX-37-TEX-N-31"></use><use data-c="36" xlink:href="#MJX-37-TEX-N-36" transform="translate(500,0)"></use></g><g data-mml-node="mo" transform="translate(1222.2,0)"><use data-c="D7" xlink:href="#MJX-37-TEX-N-D7"></use></g><g data-mml-node="mn" transform="translate(2222.4,0)"><use data-c="31" xlink:href="#MJX-37-TEX-N-31"></use><use data-c="36" xlink:href="#MJX-37-TEX-N-36" transform="translate(500,0)"></use></g></g></g></svg></mjx-container>矩阵之间的小型运算进行了优化，具体取决于它们的数值精度。下图给出了优化的概述。</p>
<p>显然，我们最终会在优化计算时做出某些妥协。其中之一是<code>GPU</code>不太擅长处理稀疏数据和中断。尽管有一些明显的例外，如<code>Gunrock</code>，但<code>GPU</code><strong>擅长的高带宽突发读取操作并不适合稀疏的矩阵和向量的访问模式</strong>。访问稀疏数据和处理中断这两个目标是一个积极研究的领域。例如：<code>DGL</code>，一个专为图深度学习而设计的库。</p>
<h5 id="网络和总线"><a href="#网络和总线" class="headerlink" title="网络和总线"></a>网络和总线</h5><p>每当单个设备不足以进行优化时，我们就需要来回传输数据以实现同步处理，于是网络和总线就派上了用场。我们有许多设计参数：带宽、成本、距离和灵活性。应用的末端有<code>WiFi</code>，它有非常好的使用范围，非常容易使用（毕竟没有线缆），而且还便宜，但它提供的带宽和延迟相对一般。头脑正常的机器学习研究人员都不会用它来构建服务器集群。</p>
<ul>
<li><code>PCIe</code>，一种专用总线，用于每个通道点到点连接的高带宽需求（在<code>16</code>通道插槽中的<code>PCIe4.0</code>上高达<code>32GB/s</code>），延迟时间为个位数的微秒（<code>5μs</code>）。<code>PCIe</code>链接非常宝贵。处理器拥有的数量：<code>AMD</code>的<code>EPYC 3</code>有<code>128</code>个通道，<code>Intel</code>的<code>Xeon</code>每个芯片有<code>48</code>个通道；在桌面级<code>CPU</code>上，数字分别是<code>20（Ryzen9）</code>和<code>17（Core i9）</code>。由于<code>GPU</code>通常有<code>16</code>个通道，这就限制了以全带宽与<code>CPU</code>连接的<code>GPU</code>数量。毕竟，它们还需要与其他高带宽外围设备（如存储和以太网）共享链路。与<code>RAM</code>访问一样，由于减少了数据包的开销，因此更适合大批量数据传输。</li>
<li>以太网，连接计算机最常用的方式。虽然它比<code>PCIe</code>慢得多，但它的安装成本非常低，而且具有很强的弹性，覆盖的距离也要长得多。低级服务器的典型带宽为<code>1GBit/s</code>。高端设备（如云中的<code>C5</code>实例。这进一步增加了开销。与<code>PCIe</code>类似，以太网旨在连接两个设备，例如计算机和交换机。</li>
<li>交换机，一种连接多个设备的方式，该连接方式下的任何一对设备都可以同时执行（通常是全带宽）点对点连接。例如，以太网交换机可能以高带宽连接<code>40</code>台服务器。请注意，交换机并不是传统计算机网络所独有的。甚至<code>PCIe</code>通道也可以是可交换的，例如：<code>P2</code>实例就是将大量<code>GPU</code>连接到主机处理器。</li>
<li><code>NVLink</code>，是<code>PCIe</code>的替代品，适用于非常高带宽的互连。它为每条链路提供高达<code>300Gbit/s</code>的数据传输速率。服务器<code>GPU（Volta V100）</code>有六个链路。而消费级<code>GPU（RTX 2080Ti）</code>只有一个链路，运行速度也降低到<code>100Gbit/s</code>。建议使用<code>NCCL</code>来实现<code>GPU</code>之间的高速数据传输。</li>
</ul>
<h5 id="总结-3"><a href="#总结-3" class="headerlink" title="总结"></a>总结</h5><p>设备有运行开销。因此，数据传输要争取量大次少而不是量少次多。这适用于<code>RAM</code>、固态驱动器、网络和<code>GPU</code>。矢量化是性能的关键。确保充分了解加速器的特定功能。例如，一些<code>Intel Xeon CPU</code>特别适用于<code>INT8</code>操作，<code>NVIDIA Volta GPU</code>擅长<code>FP16</code>矩阵操作，<code>NVIDIA Turing</code>擅长<code>FP16、INT8</code>和<code>INT4</code>操作。在训练过程中数据类型过小导致的数值溢出可能是个问题（在推断过程中则影响不大）。数据混叠现象会导致严重的性能退化。<code>64</code>位<code>CPU</code>应该按照<code>64</code>位边界进行内存对齐。在<code>GPU</code>上建议保持卷积大小对齐，例如：与张量核对齐。将算法与硬件相匹配（例如，内存占用和带宽）。将命中参数装入缓存后，可以实现很大数量级的加速比。在验证实验结果之前，建议先在纸上勾勒出新算法的性能。关注的原因是数量级及以上的差异。使用调试器跟踪调试寻找性能的瓶颈。训练硬件和推断硬件在性能和价格方面有不同的优点。</p>
<h4 id="多GPU训练"><a href="#多GPU训练" class="headerlink" title="多GPU训练"></a>多GPU训练</h4><h5 id="问题拆分"><a href="#问题拆分" class="headerlink" title="问题拆分"></a>问题拆分</h5><p>我们从一个简单的计算机视觉问题和一个稍稍过时的网络开始。这个网络有多个卷积层和汇聚层，最后可能有几个全连接的层，看起来非常类似于<code>LeNet</code>或<code>AlexNet</code>。假设我们有多个<code>GPU</code>。我们希望以一种方式对训练进行拆分，为实现良好的加速比，还能同时受益于简单且可重复的设计选择。毕竟，多个<code>GPU</code>同时增加了内存和计算能力。简而言之，对于需要分类的小批量训练数据，我们有以下选择。</p>
<p>第一种方法，在多个<code>GPU</code>之间拆分网络。也就是说，每个<code>GPU</code>将流入特定层的数据作为输入，跨多个后续层对数据进行处理，然后将数据发送到下一个<code>GPU</code>。与单个<code>GPU</code>所能处理的数据相比，我们可以用更大的网络处理数据。此外，每个<code>GPU</code>占用的<strong>显存</strong>(<code>memory footprint</code>)可以得到很好的控制，虽然它只是整个网络显存的一小部分。然而，<code>GPU</code>的接口之间需要的密集同步可能是很难办的，特别是层之间计算的工作负载不能正确匹配的时候，还有层之间的接口需要大量的数据传输的时候（例如：激活值和梯度，数据量可能会超出<code>GPU</code>总线的带宽）。此外，计算密集型操作的顺序对拆分来说也是非常重要的，其本质仍然是一个困难的问题，目前还不清楚研究是否能在特定问题上实现良好的线性缩放。综上所述，除非存框架或操作系统本身支持将多个<code>GPU</code>连接在一起，否则不建议这种方法。</p>
<p>第二种方法，拆分层内的工作。例如，将问题分散到<code>4</code>个<code>GPU</code>，每个<code>GPU</code>生成<code>16</code>个通道的数据，而不是在单个<code>GPU</code>上计算<code>64</code>个通道。对于全连接的层，同样可以拆分输出单元的数量。下图描述了这种设计，其策略用于处理显存非常小（当时为<code>2GB</code>）的<code>GPU</code>。当通道或单元的数量不太小时，使计算性能有良好的提升。此外，由于可用的显存呈线性扩展，多个<code>GPU</code>能够处理不断变大的网络。</p>
<img data-src="/2024/05/23/artificial-intelligence/computing_theory_study/cp_12.png" class="" title="由于GPU显存有限，原有AlexNet设计中的模型并行">

<p>然而，我们需要大量的同步或<strong>屏障操作</strong>(<code>barrier operation</code>)，因为每一层都依赖于所有其他层的结果。此外，需要传输的数据量也可能比跨<code>GPU</code>拆分层时还要大。因此，基于带宽的成本和复杂性，我们同样不推荐这种方法。</p>
<p>最后一种方法，跨多个<code>GPU</code>对数据进行拆分。 这种方式下，所有<code>GPU</code>尽管有不同的观测结果，但是执行着相同类型的工作。在完成每个小批量数据的训练之后，梯度在<code>GPU</code>上聚合。这种方法最简单，并可以应用于任何情况，同步只需要在每个小批量数据处理之后进行。也就是说，当其他梯度参数仍在计算时，完成计算的梯度参数就可以开始交换。而且，<code>GPU</code>的数量越多，小批量包含的数据量就越大，从而就能提高训练效率。但是，添加更多的<code>GPU</code>并不能让我们训练更大的模型。</p>
<img data-src="/2024/05/23/artificial-intelligence/computing_theory_study/cp_13.png" class="" title="在多个GPU上并行化。从左到右：原始问题、网络并行、分层并行、数据并行">

<p>上图中比较了多个<code>GPU</code>上不同的并行方式。总体而言，只要<code>GPU</code>的显存足够大，数据并行是最方便的。在深度学习的早期，<code>GPU</code>的显存曾经是一个棘手的问题，然而如今除了非常特殊的情况，这个问题已经解决。下面我们将重点讨论数据并行性。</p>
<h5 id="数据并行性"><a href="#数据并行性" class="headerlink" title="数据并行性"></a>数据并行性</h5><p>假设一台机器有<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.179ex" height="1.595ex" role="img" focusable="false" viewBox="0 -694 521 705" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-36-TEX-I-1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D458" xlink:href="#MJX-36-TEX-I-1D458"></use></g></g></g></svg></mjx-container>个<code>GPU</code>。给定需要训练的模型，虽然每个GPU上的参数值都是相同且同步的，但是每个<code>GPU</code>都将独立地维护一组完整的模型参数。例如，下图演示了在<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.186ex;" xmlns="http://www.w3.org/2000/svg" width="5.327ex" height="1.756ex" role="img" focusable="false" viewBox="0 -694 2354.6 776" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-35-TEX-I-1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path><path id="MJX-35-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-35-TEX-N-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D458" xlink:href="#MJX-35-TEX-I-1D458"></use></g><g data-mml-node="mo" transform="translate(798.8,0)"><use data-c="3D" xlink:href="#MJX-35-TEX-N-3D"></use></g><g data-mml-node="mn" transform="translate(1854.6,0)"><use data-c="32" xlink:href="#MJX-35-TEX-N-32"></use></g></g></g></svg></mjx-container>时基于数据并行方法训练模型。</p>
<img data-src="/2024/05/23/artificial-intelligence/computing_theory_study/cp_14.png" class="" title="利用两个GPU上的数据，并行计算小批量随机梯度下降">

<p>一般来说，<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.179ex" height="1.595ex" role="img" focusable="false" viewBox="0 -694 521 705" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-35-TEX-I-1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D458" xlink:href="#MJX-35-TEX-I-1D458"></use></g></g></g></svg></mjx-container>个<code>GPU</code>并行训练过程如下：</p>
<ul>
<li>在任何一次训练迭代中，给定的随机的小批量样本都将被分成<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.179ex" height="1.595ex" role="img" focusable="false" viewBox="0 -694 521 705" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-33-TEX-I-1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D458" xlink:href="#MJX-33-TEX-I-1D458"></use></g></g></g></svg></mjx-container>个部分，并均匀地分配到<code>GPU</code>上；</li>
<li>每个<code>GPU</code>根据分配给它的小批量子集，计算模型参数的损失和梯度；</li>
<li>将<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.179ex" height="1.595ex" role="img" focusable="false" viewBox="0 -694 521 705" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-32-TEX-I-1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D458" xlink:href="#MJX-32-TEX-I-1D458"></use></g></g></g></svg></mjx-container>个<code>GPU</code>中的局部梯度聚合，以获得当前小批量的随机梯度；</li>
<li>聚合梯度被重新分发到每个<code>GPU</code>中；</li>
<li>每个<code>GPU</code>使用这个小批量随机梯度，来更新它所维护的完整的模型参数集。</li>
</ul>
<p>在实践中请注意，当在<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.179ex" height="1.595ex" role="img" focusable="false" viewBox="0 -694 521 705" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-30-TEX-I-1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D458" xlink:href="#MJX-30-TEX-I-1D458"></use></g></g></g></svg></mjx-container>个<code>GPU</code>上训练时，需要扩大小批量的大小为<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.179ex" height="1.595ex" role="img" focusable="false" viewBox="0 -694 521 705" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-29-TEX-I-1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D458" xlink:href="#MJX-29-TEX-I-1D458"></use></g></g></g></svg></mjx-container>的倍数，这样每个<code>GPU</code>都有相同的工作量，就像只在单个<code>GPU</code>上训练一样。因此，在<code>16-GPU</code>服务器上可以显著地增加小批量数据量的大小，同时可能还需要相应地提高学习率。</p>
<h5 id="总结-4"><a href="#总结-4" class="headerlink" title="总结"></a>总结</h5><p>有多种方法可以在多个<code>GPU</code>上拆分深度网络的训练。拆分可以在层之间、跨层或跨数据上实现。前两者需要对数据传输过程进行严格编排，而最后一种则是最简单的策略。数据并行训练本身是不复杂的，它通过增加有效的小批量数据量的大小提高了训练效率。在数据并行中，数据需要跨多个<code>GPU</code>拆分，其中每个<code>GPU</code>执行自己的前向传播和反向传播，随后所有的梯度被聚合为一，之后聚合结果向所有的<code>GPU</code>广播。小批量数据量更大时，学习率也需要稍微提高一些。</p>
<h4 id="参数服务器"><a href="#参数服务器" class="headerlink" title="参数服务器"></a>参数服务器</h4><p>当我们从一个<code>GPU</code>迁移到多个<code>GPU</code>时，以及再迁移到包含多个<code>GPU</code>的多个服务器时（可能所有服务器的分布跨越了多个机架和多个网络交换机），分布式并行训练算法也需要变得更加复杂。通过细节可以知道，一方面是不同的互连方式的带宽存在极大的区别（例如，<code>NVLink</code>可以通过设置实现跨<code>6</code>条链路的高达<code>100GB/s</code>的带宽，<code>16</code>通道的<code>PCIe4.0</code>提供<code>32GB/s</code>的带宽，而即使是高速<code>100GbE</code>以太网也只能提供大约<code>10GB/s</code>的带宽）；另一方面是期望开发者既能完成统计学习建模还精通系统和网络也是不切实际的。参数服务器的核心思想首先是在分布式隐变量模型的背景下引入的。</p>
<h5 id="数据并行训练"><a href="#数据并行训练" class="headerlink" title="数据并行训练"></a>数据并行训练</h5><p>让我们回顾一下在分布式架构中数据并行的训练方法。由于当今的<code>GPU</code>拥有大量的显存，因此在实际场景中（不包括图深度学习）只有数据并行这种并行训练策略值得推荐。下图中描述了实现的数据并行的变体。其中的关键是梯度的聚合需要在单个<code>GPU</code>(<code>GPU 0</code>)上完成，然后再将更新后的参数广播给所有<code>GPU</code>。</p>
<img data-src="/2024/05/23/artificial-intelligence/computing_theory_study/cp_15.png" class="" title="左图是单GPU训练；右图是多GPU训练的一个变体">

<p>选择<code>GPU 0</code>进行聚合似乎是个很随便的决定，当然也可以选择<code>CPU</code>上聚合，事实上只要优化算法支持，在实际操作中甚至可以在某个<code>GPU</code>上聚合其中一些参数，而在另一个<code>GPU</code>上聚合另一些参数。例如，如果有四个与参数向量相关的梯度<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.455ex;" xmlns="http://www.w3.org/2000/svg" width="9.618ex" height="1.484ex" role="img" focusable="false" viewBox="0 -455 4251.1 656" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-29-TEX-B-1D420" d="M50 300Q50 368 105 409T255 450Q328 450 376 426L388 420Q435 455 489 455Q517 455 533 441T554 414T558 389Q558 367 544 353T508 339Q484 339 471 354T458 387Q458 397 462 400Q464 401 461 400Q459 400 454 399Q429 392 427 390Q454 353 459 328Q461 315 461 300Q461 240 419 202Q364 149 248 149Q185 149 136 172Q129 158 129 148Q129 105 170 93Q176 91 263 91Q273 91 298 91T334 91T366 89T400 85T432 77T466 64Q544 22 544 -69Q544 -114 506 -145Q438 -201 287 -201Q149 -201 90 -161T30 -70Q30 -58 33 -47T42 -27T54 -13T69 -1T82 6T94 12T101 15Q66 57 66 106Q66 151 90 187L97 197L89 204Q50 243 50 300ZM485 403H492Q491 404 488 404L485 403V403ZM255 200Q279 200 295 206T319 219T331 242T335 268T336 300Q336 337 333 352T317 380Q298 399 255 399Q228 399 211 392T187 371T178 345T176 312V300V289Q176 235 194 219Q215 200 255 200ZM287 -150Q357 -150 400 -128T443 -71Q443 -65 442 -61T436 -50T420 -37T389 -27T339 -21L308 -20Q276 -20 253 -20Q190 -20 180 -20T156 -26Q130 -38 130 -69Q130 -105 173 -127T287 -150Z"></path><path id="MJX-29-TEX-N-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path id="MJX-29-TEX-N-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path><path id="MJX-29-TEX-N-2026" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z"></path><path id="MJX-29-TEX-N-34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D420" xlink:href="#MJX-29-TEX-B-1D420"></use></g></g><g data-mml-node="mn" transform="translate(608,-150) scale(0.707)"><use data-c="31" xlink:href="#MJX-29-TEX-N-31"></use></g></g><g data-mml-node="mo" transform="translate(1011.6,0)"><use data-c="2C" xlink:href="#MJX-29-TEX-N-2C"></use></g><g data-mml-node="mo" transform="translate(1456.2,0)"><use data-c="2026" xlink:href="#MJX-29-TEX-N-2026"></use></g><g data-mml-node="mo" transform="translate(2794.9,0)"><use data-c="2C" xlink:href="#MJX-29-TEX-N-2C"></use></g><g data-mml-node="msub" transform="translate(3239.6,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D420" xlink:href="#MJX-29-TEX-B-1D420"></use></g></g><g data-mml-node="mn" transform="translate(608,-150) scale(0.707)"><use data-c="34" xlink:href="#MJX-29-TEX-N-34"></use></g></g></g></g></svg></mjx-container>，还可以一个<code>GPU</code>对一个<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="14.902ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 6586.5 1000" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-26-TEX-B-1D420" d="M50 300Q50 368 105 409T255 450Q328 450 376 426L388 420Q435 455 489 455Q517 455 533 441T554 414T558 389Q558 367 544 353T508 339Q484 339 471 354T458 387Q458 397 462 400Q464 401 461 400Q459 400 454 399Q429 392 427 390Q454 353 459 328Q461 315 461 300Q461 240 419 202Q364 149 248 149Q185 149 136 172Q129 158 129 148Q129 105 170 93Q176 91 263 91Q273 91 298 91T334 91T366 89T400 85T432 77T466 64Q544 22 544 -69Q544 -114 506 -145Q438 -201 287 -201Q149 -201 90 -161T30 -70Q30 -58 33 -47T42 -27T54 -13T69 -1T82 6T94 12T101 15Q66 57 66 106Q66 151 90 187L97 197L89 204Q50 243 50 300ZM485 403H492Q491 404 488 404L485 403V403ZM255 200Q279 200 295 206T319 219T331 242T335 268T336 300Q336 337 333 352T317 380Q298 399 255 399Q228 399 211 392T187 371T178 345T176 312V300V289Q176 235 194 219Q215 200 255 200ZM287 -150Q357 -150 400 -128T443 -71Q443 -65 442 -61T436 -50T420 -37T389 -27T339 -21L308 -20Q276 -20 253 -20Q190 -20 180 -20T156 -26Q130 -38 130 -69Q130 -105 173 -127T287 -150Z"></path><path id="MJX-26-TEX-I-1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path id="MJX-26-TEX-N-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path id="MJX-26-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-26-TEX-N-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path id="MJX-26-TEX-N-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path><path id="MJX-26-TEX-N-2026" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z"></path><path id="MJX-26-TEX-N-34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path><path id="MJX-26-TEX-N-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D420" xlink:href="#MJX-26-TEX-B-1D420"></use></g></g><g data-mml-node="mi" transform="translate(608,-150) scale(0.707)"><use data-c="1D456" xlink:href="#MJX-26-TEX-I-1D456"></use></g></g><g data-mml-node="mo" transform="translate(902,0)"><use data-c="28" xlink:href="#MJX-26-TEX-N-28"></use></g><g data-mml-node="mi" transform="translate(1291,0)"><use data-c="1D456" xlink:href="#MJX-26-TEX-I-1D456"></use></g><g data-mml-node="mo" transform="translate(1913.7,0)"><use data-c="3D" xlink:href="#MJX-26-TEX-N-3D"></use></g><g data-mml-node="mn" transform="translate(2969.5,0)"><use data-c="31" xlink:href="#MJX-26-TEX-N-31"></use></g><g data-mml-node="mo" transform="translate(3469.5,0)"><use data-c="2C" xlink:href="#MJX-26-TEX-N-2C"></use></g><g data-mml-node="mo" transform="translate(3914.2,0)"><use data-c="2026" xlink:href="#MJX-26-TEX-N-2026"></use></g><g data-mml-node="mo" transform="translate(5252.8,0)"><use data-c="2C" xlink:href="#MJX-26-TEX-N-2C"></use></g><g data-mml-node="mn" transform="translate(5697.5,0)"><use data-c="34" xlink:href="#MJX-26-TEX-N-34"></use></g><g data-mml-node="mo" transform="translate(6197.5,0)"><use data-c="29" xlink:href="#MJX-26-TEX-N-29"></use></g></g></g></svg></mjx-container>）地进行梯度聚合。</p>
<img data-src="/2024/05/23/artificial-intelligence/computing_theory_study/cp_16.png" class="" title="一个4路GPU服务器">

<p>为了便于讨论，我们假设所有梯度共需<code>160MB</code>。在这种情况下，将其中<code>3</code>个<code>GPU</code>的梯度发送到第<code>4</code>个<code>GPU</code>上需要<code>30</code>毫秒（每次传输需要<code>10</code>毫秒<code>=160MB/16GB/s</code>）。再加上<code>30</code>毫秒将权重向量传输回来，得到的结果是总共需要<code>60</code>毫秒。如果将所有的数据发送到<code>CPU</code>，总共需要<code>80</code>毫秒，其中将有<code>40</code>毫秒的惩罚，因为<code>4</code>个<code>GPU</code>每个都需要将数据发送到<code>CPU</code>。最后，假设能够将梯度分为<code>4</code>个部分，每个部分为<code>40MB</code>，现在可以在不同的<code>GPU</code>上同时聚合每个部分。因为<code>PCIe</code>交换机在所有链路之间提供全带宽操作，所以传输需要<code>2.5 x 3 = 7.5</code>毫秒，而不是<code>30</code>毫秒，因此同步操作总共需要<code>15</code>毫秒。简而言之，一样的参数同步操作基于不同的策略时间可能在<code>15</code>毫秒到<code>80</code>毫秒之间。下图描述了交换参数的不同策略。</p>
<img data-src="/2024/05/23/artificial-intelligence/computing_theory_study/cp_17.png" class="" title="参数同步策略">

<p>请注意，我们还可以使用另一个工具来改善性能：在深度网络中，从顶部到底部计算所有梯度需要一些时间，因此即使还在忙着为某些参数计算梯度时，就可以开始为准备好的参数同步梯度了。</p>
<h5 id="环同步（Ring-Synchronization）"><a href="#环同步（Ring-Synchronization）" class="headerlink" title="环同步（Ring Synchronization）"></a>环同步（Ring Synchronization）</h5><p>当谈及现代深度学习硬件的同步问题时，我们经常会遇到大量的定制的网络连接。每个<code>GPU</code>通过<code>PCIe</code>链路连接到主机<code>CPU</code>，该链路最多只能以<code>16GB/s</code>的速度运行。此外，每个<code>GPU</code>还具有<code>6</code>个<code>NVLink</code>连接，每个<code>NVLink</code>连接都能够以<code>300Gbit/s</code>进行双向传输。这相当于每个链路每个方向约<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="22.555ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 9969.4 1000" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-26-TEX-N-33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path id="MJX-26-TEX-N-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path id="MJX-26-TEX-N-F7" d="M318 466Q318 500 339 518T386 537Q418 537 438 517T458 466Q458 438 440 417T388 396Q355 396 337 417T318 466ZM56 237T56 250T70 270H706Q721 262 721 250T706 230H70Q56 237 56 250ZM318 34Q318 68 339 86T386 105Q418 105 438 85T458 34Q458 6 440 -15T388 -36Q355 -36 337 -15T318 34Z"></path><path id="MJX-26-TEX-N-38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z"></path><path id="MJX-26-TEX-N-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path id="MJX-26-TEX-N-2248" d="M55 319Q55 360 72 393T114 444T163 472T205 482Q207 482 213 482T223 483Q262 483 296 468T393 413L443 381Q502 346 553 346Q609 346 649 375T694 454Q694 465 698 474T708 483Q722 483 722 452Q722 386 675 338T555 289Q514 289 468 310T388 357T308 404T224 426Q164 426 125 393T83 318Q81 289 69 289Q55 289 55 319ZM55 85Q55 126 72 159T114 210T163 238T205 248Q207 248 213 248T223 249Q262 249 296 234T393 179L443 147Q502 112 553 112Q609 112 649 141T694 220Q694 249 708 249T722 217Q722 153 675 104T555 55Q514 55 468 76T388 123T308 170T224 192Q164 192 125 159T83 84Q80 55 69 55Q55 55 55 85Z"></path><path id="MJX-26-TEX-N-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path id="MJX-26-TEX-B-1D406" d="M465 -10Q281 -10 173 88T64 343Q64 413 85 471T143 568T217 631T298 670Q371 697 449 697Q452 697 459 697T470 696Q502 696 531 690T582 675T618 658T644 641T656 632L732 695Q734 697 745 697Q758 697 761 692T765 668V627V489V449Q765 428 761 424T741 419H731H724Q705 419 702 422T695 444Q683 520 631 577T495 635Q364 635 295 563Q261 528 247 477T232 343Q232 296 236 260T256 185T296 120T366 76T472 52Q481 51 498 51Q544 51 573 67T607 108Q608 111 608 164V214H464V276H479Q506 273 680 273Q816 273 834 276H845V214H765V113V51Q765 16 763 8T750 0Q742 2 709 16T658 40L648 46Q592 -10 465 -10Z"></path><path id="MJX-26-TEX-B-1D401" d="M720 510Q720 476 704 448T665 404T619 377T580 362L564 359L583 356Q602 353 632 342T690 312Q712 292 725 276Q752 235 752 189V183Q752 160 741 125Q698 18 547 2Q543 1 288 0H39V62H147V624H39V686H264H409Q502 686 542 681T624 655Q720 607 720 510ZM563 513Q563 553 548 578T518 611T486 622Q479 624 385 624H293V382H375Q458 383 467 385Q563 405 563 513ZM590 192Q590 307 505 329Q504 330 503 330L398 331H293V62H391H400H444Q496 62 528 75T580 131Q590 155 590 192Z"></path><path id="MJX-26-TEX-N-2F" d="M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z"></path><path id="MJX-26-TEX-I-1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><use data-c="33" xlink:href="#MJX-26-TEX-N-33"></use><use data-c="30" xlink:href="#MJX-26-TEX-N-30" transform="translate(500,0)"></use><use data-c="30" xlink:href="#MJX-26-TEX-N-30" transform="translate(1000,0)"></use></g><g data-mml-node="mo" transform="translate(1722.2,0)"><use data-c="F7" xlink:href="#MJX-26-TEX-N-F7"></use></g><g data-mml-node="mn" transform="translate(2722.4,0)"><use data-c="38" xlink:href="#MJX-26-TEX-N-38"></use></g><g data-mml-node="mo" transform="translate(3444.7,0)"><use data-c="F7" xlink:href="#MJX-26-TEX-N-F7"></use></g><g data-mml-node="mn" transform="translate(4444.9,0)"><use data-c="32" xlink:href="#MJX-26-TEX-N-32"></use></g><g data-mml-node="mo" transform="translate(5222.7,0)"><use data-c="2248" xlink:href="#MJX-26-TEX-N-2248"></use></g><g data-mml-node="mn" transform="translate(6278.4,0)"><use data-c="31" xlink:href="#MJX-26-TEX-N-31"></use><use data-c="38" xlink:href="#MJX-26-TEX-N-38" transform="translate(500,0)"></use></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(7278.4,0)"><g data-mml-node="mi"><use data-c="1D406" xlink:href="#MJX-26-TEX-B-1D406"></use><use data-c="1D401" xlink:href="#MJX-26-TEX-B-1D401" transform="translate(904,0)"></use></g></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(9000.4,0)"><g data-mml-node="mo"><use data-c="2F" xlink:href="#MJX-26-TEX-N-2F"></use></g></g><g data-mml-node="mi" transform="translate(9500.4,0)"><use data-c="1D460" xlink:href="#MJX-26-TEX-I-1D460"></use></g></g></g></svg></mjx-container>。简言之，聚合的<code>NVLink</code>带宽明显高于<code>PCIe</code>带宽，问题是如何有效地使用它。</p>
<img data-src="/2024/05/23/artificial-intelligence/computing_theory_study/cp_18.png" class="" title="在8台V100 GPU服务器上连接NVLink（图片由英伟达提供）">

<p>的研究结果表明最优的同步策略是将网络分解成两个环，并基于两个环直接同步数据。下图描述了网络可以分解为一个具有双<code>NVLink</code>带宽的环（<code>1-2-3-4-5-6-7-8-1</code>）和一个具有常规带宽的环（<code>1-4-6-3-5-8-2-7-1</code>）。在这种情况下，设计一个高效的同步协议是非常重要的。</p>
<img data-src="/2024/05/23/artificial-intelligence/computing_theory_study/cp_19.png" class="" title="将NVLink网络分解为两个环">

<p>考虑下面的思维试验：给定由<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.357ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 600 453" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-26-TEX-I-1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D45B" xlink:href="#MJX-26-TEX-I-1D45B"></use></g></g></g></svg></mjx-container>个计算节点（或<code>GPU</code>）组成的一个环，梯度可以从第一个节点发送到第二个节点，在第二个结点将本地的梯度与传送的梯度相加并发送到第三个节点，依此类推。在<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.186ex;" xmlns="http://www.w3.org/2000/svg" width="5.254ex" height="1.692ex" role="img" focusable="false" viewBox="0 -666 2322.4 748" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-25-TEX-I-1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-25-TEX-N-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path id="MJX-25-TEX-N-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D45B" xlink:href="#MJX-25-TEX-I-1D45B"></use></g><g data-mml-node="mo" transform="translate(822.2,0)"><use data-c="2212" xlink:href="#MJX-25-TEX-N-2212"></use></g><g data-mml-node="mn" transform="translate(1822.4,0)"><use data-c="31" xlink:href="#MJX-25-TEX-N-31"></use></g></g></g></svg></mjx-container>步之后，可以在最后访问的节点中找到聚合梯度。也就是说，聚合梯度的时间随节点数线性增长。但如果照此操作，算法是相当低效的。归根结底，在任何时候都只有一个节点在通信。如果我们将梯度分为<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.357ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 600 453" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-25-TEX-I-1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D45B" xlink:href="#MJX-25-TEX-I-1D45B"></use></g></g></g></svg></mjx-container>个块，并从节点<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="0.781ex" height="1.52ex" role="img" focusable="false" viewBox="0 -661 345 672" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-25-TEX-I-1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D456" xlink:href="#MJX-25-TEX-I-1D456"></use></g></g></g></svg></mjx-container>开始同步块<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="0.781ex" height="1.52ex" role="img" focusable="false" viewBox="0 -661 345 672" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-24-TEX-I-1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D456" xlink:href="#MJX-24-TEX-I-1D456"></use></g></g></g></svg></mjx-container>，会怎么样？因为每个块的大小是<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="3.62ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 1600 1000" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-24-TEX-N-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path id="MJX-24-TEX-N-2F" d="M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z"></path><path id="MJX-24-TEX-I-1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><use data-c="31" xlink:href="#MJX-24-TEX-N-31"></use></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(500,0)"><g data-mml-node="mo"><use data-c="2F" xlink:href="#MJX-24-TEX-N-2F"></use></g></g><g data-mml-node="mi" transform="translate(1000,0)"><use data-c="1D45B" xlink:href="#MJX-24-TEX-I-1D45B"></use></g></g></g></svg></mjx-container>，所以总时间现在是<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="13.652ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 6034 1000" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-24-TEX-N-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path id="MJX-24-TEX-I-1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-24-TEX-N-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path id="MJX-24-TEX-N-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path id="MJX-24-TEX-N-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path><path id="MJX-24-TEX-N-2F" d="M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z"></path><path id="MJX-24-TEX-N-2248" d="M55 319Q55 360 72 393T114 444T163 472T205 482Q207 482 213 482T223 483Q262 483 296 468T393 413L443 381Q502 346 553 346Q609 346 649 375T694 454Q694 465 698 474T708 483Q722 483 722 452Q722 386 675 338T555 289Q514 289 468 310T388 357T308 404T224 426Q164 426 125 393T83 318Q81 289 69 289Q55 289 55 319ZM55 85Q55 126 72 159T114 210T163 238T205 248Q207 248 213 248T223 249Q262 249 296 234T393 179L443 147Q502 112 553 112Q609 112 649 141T694 220Q694 249 708 249T722 217Q722 153 675 104T555 55Q514 55 468 76T388 123T308 170T224 192Q164 192 125 159T83 84Q80 55 69 55Q55 55 55 85Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><use data-c="28" xlink:href="#MJX-24-TEX-N-28"></use></g><g data-mml-node="mi" transform="translate(389,0)"><use data-c="1D45B" xlink:href="#MJX-24-TEX-I-1D45B"></use></g><g data-mml-node="mo" transform="translate(1211.2,0)"><use data-c="2212" xlink:href="#MJX-24-TEX-N-2212"></use></g><g data-mml-node="mn" transform="translate(2211.4,0)"><use data-c="31" xlink:href="#MJX-24-TEX-N-31"></use></g><g data-mml-node="mo" transform="translate(2711.4,0)"><use data-c="29" xlink:href="#MJX-24-TEX-N-29"></use></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(3100.4,0)"><g data-mml-node="mo"><use data-c="2F" xlink:href="#MJX-24-TEX-N-2F"></use></g></g><g data-mml-node="mi" transform="translate(3600.4,0)"><use data-c="1D45B" xlink:href="#MJX-24-TEX-I-1D45B"></use></g><g data-mml-node="mo" transform="translate(4478.2,0)"><use data-c="2248" xlink:href="#MJX-24-TEX-N-2248"></use></g><g data-mml-node="mn" transform="translate(5534,0)"><use data-c="31" xlink:href="#MJX-24-TEX-N-31"></use></g></g></g></svg></mjx-container>。换句话说，当我们增大环的大小时，聚合梯度所花费的时间不会增加。这是一个相当惊人的结果。下图说明了<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.186ex;" xmlns="http://www.w3.org/2000/svg" width="5.506ex" height="1.717ex" role="img" focusable="false" viewBox="0 -677 2433.6 759" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-24-TEX-I-1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-24-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-24-TEX-N-34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D45B" xlink:href="#MJX-24-TEX-I-1D45B"></use></g><g data-mml-node="mo" transform="translate(877.8,0)"><use data-c="3D" xlink:href="#MJX-24-TEX-N-3D"></use></g><g data-mml-node="mn" transform="translate(1933.6,0)"><use data-c="34" xlink:href="#MJX-24-TEX-N-34"></use></g></g></g></svg></mjx-container>个节点上的步骤顺序。</p>
<img data-src="/2024/05/23/artificial-intelligence/computing_theory_study/cp_20.png" class="" title="将NVLink网络分解为两个环">

<p>如果我们使用相同的例子，跨<code>8</code>个<code>V100 GPU</code>同步<code>160MB</code>，我们得到的结果大约是<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="35.355ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 15626.9 1000" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-24-TEX-N-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path id="MJX-24-TEX-N-D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path><path id="MJX-24-TEX-N-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path id="MJX-24-TEX-N-36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path><path id="MJX-24-TEX-N-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path id="MJX-24-TEX-I-1D440" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path><path id="MJX-24-TEX-I-1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path><path id="MJX-24-TEX-N-F7" d="M318 466Q318 500 339 518T386 537Q418 537 438 517T458 466Q458 438 440 417T388 396Q355 396 337 417T318 466ZM56 237T56 250T70 270H706Q721 262 721 250T706 230H70Q56 237 56 250ZM318 34Q318 68 339 86T386 105Q418 105 438 85T458 34Q458 6 440 -15T388 -36Q355 -36 337 -15T318 34Z"></path><path id="MJX-24-TEX-N-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path id="MJX-24-TEX-N-33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path id="MJX-24-TEX-N-38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z"></path><path id="MJX-24-TEX-B-1D406" d="M465 -10Q281 -10 173 88T64 343Q64 413 85 471T143 568T217 631T298 670Q371 697 449 697Q452 697 459 697T470 696Q502 696 531 690T582 675T618 658T644 641T656 632L732 695Q734 697 745 697Q758 697 761 692T765 668V627V489V449Q765 428 761 424T741 419H731H724Q705 419 702 422T695 444Q683 520 631 577T495 635Q364 635 295 563Q261 528 247 477T232 343Q232 296 236 260T256 185T296 120T366 76T472 52Q481 51 498 51Q544 51 573 67T607 108Q608 111 608 164V214H464V276H479Q506 273 680 273Q816 273 834 276H845V214H765V113V51Q765 16 763 8T750 0Q742 2 709 16T658 40L648 46Q592 -10 465 -10Z"></path><path id="MJX-24-TEX-B-1D401" d="M720 510Q720 476 704 448T665 404T619 377T580 362L564 359L583 356Q602 353 632 342T690 312Q712 292 725 276Q752 235 752 189V183Q752 160 741 125Q698 18 547 2Q543 1 288 0H39V62H147V624H39V686H264H409Q502 686 542 681T624 655Q720 607 720 510ZM563 513Q563 553 548 578T518 611T486 622Q479 624 385 624H293V382H375Q458 383 467 385Q563 405 563 513ZM590 192Q590 307 505 329Q504 330 503 330L398 331H293V62H391H400H444Q496 62 528 75T580 131Q590 155 590 192Z"></path><path id="MJX-24-TEX-N-2F" d="M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z"></path><path id="MJX-24-TEX-I-1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path><path id="MJX-24-TEX-N-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path><path id="MJX-24-TEX-N-2248" d="M55 319Q55 360 72 393T114 444T163 472T205 482Q207 482 213 482T223 483Q262 483 296 468T393 413L443 381Q502 346 553 346Q609 346 649 375T694 454Q694 465 698 474T708 483Q722 483 722 452Q722 386 675 338T555 289Q514 289 468 310T388 357T308 404T224 426Q164 426 125 393T83 318Q81 289 69 289Q55 289 55 319ZM55 85Q55 126 72 159T114 210T163 238T205 248Q207 248 213 248T223 249Q262 249 296 234T393 179L443 147Q502 112 553 112Q609 112 649 141T694 220Q694 249 708 249T722 217Q722 153 675 104T555 55Q514 55 468 76T388 123T308 170T224 192Q164 192 125 159T83 84Q80 55 69 55Q55 55 55 85Z"></path><path id="MJX-24-TEX-I-1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><use data-c="32" xlink:href="#MJX-24-TEX-N-32"></use></g><g data-mml-node="mo" transform="translate(722.2,0)"><use data-c="D7" xlink:href="#MJX-24-TEX-N-D7"></use></g><g data-mml-node="mn" transform="translate(1722.4,0)"><use data-c="31" xlink:href="#MJX-24-TEX-N-31"></use><use data-c="36" xlink:href="#MJX-24-TEX-N-36" transform="translate(500,0)"></use><use data-c="30" xlink:href="#MJX-24-TEX-N-30" transform="translate(1000,0)"></use></g><g data-mml-node="mi" transform="translate(3222.4,0)"><use data-c="1D440" xlink:href="#MJX-24-TEX-I-1D440"></use></g><g data-mml-node="mi" transform="translate(4273.4,0)"><use data-c="1D435" xlink:href="#MJX-24-TEX-I-1D435"></use></g><g data-mml-node="mo" transform="translate(5254.7,0)"><use data-c="F7" xlink:href="#MJX-24-TEX-N-F7"></use></g><g data-mml-node="mo" transform="translate(6254.9,0)"><use data-c="28" xlink:href="#MJX-24-TEX-N-28"></use></g><g data-mml-node="mn" transform="translate(6643.9,0)"><use data-c="33" xlink:href="#MJX-24-TEX-N-33"></use></g><g data-mml-node="mo" transform="translate(7366.1,0)"><use data-c="D7" xlink:href="#MJX-24-TEX-N-D7"></use></g><g data-mml-node="mn" transform="translate(8366.3,0)"><use data-c="31" xlink:href="#MJX-24-TEX-N-31"></use><use data-c="38" xlink:href="#MJX-24-TEX-N-38" transform="translate(500,0)"></use></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(9366.3,0)"><g data-mml-node="mi"><use data-c="1D406" xlink:href="#MJX-24-TEX-B-1D406"></use><use data-c="1D401" xlink:href="#MJX-24-TEX-B-1D401" transform="translate(904,0)"></use></g></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(11088.3,0)"><g data-mml-node="mo"><use data-c="2F" xlink:href="#MJX-24-TEX-N-2F"></use></g></g><g data-mml-node="mi" transform="translate(11588.3,0)"><use data-c="1D460" xlink:href="#MJX-24-TEX-I-1D460"></use></g><g data-mml-node="mo" transform="translate(12057.3,0)"><use data-c="29" xlink:href="#MJX-24-TEX-N-29"></use></g><g data-mml-node="mo" transform="translate(12724.1,0)"><use data-c="2248" xlink:href="#MJX-24-TEX-N-2248"></use></g><g data-mml-node="mn" transform="translate(13779.9,0)"><use data-c="36" xlink:href="#MJX-24-TEX-N-36"></use></g><g data-mml-node="mi" transform="translate(14279.9,0)"><use data-c="1D45A" xlink:href="#MJX-24-TEX-I-1D45A"></use></g><g data-mml-node="mi" transform="translate(15157.9,0)"><use data-c="1D460" xlink:href="#MJX-24-TEX-I-1D460"></use></g></g></g></svg></mjx-container>。这比使用<code>PCIe</code>总线要好，即使我们现在使用的是<code>8</code>个<code>GPU</code>，注意到有一种常见的误解认为环同步与其他同步算法在本质上是不同的，实际上与简单的树算法相比其唯一的区别是同步路径稍微精细一些。</p>
<h5 id="多机训练"><a href="#多机训练" class="headerlink" title="多机训练"></a>多机训练</h5><p>新的挑战出现在多台机器上进行分布式训练：我们需要服务器之间相互通信，而这些服务器又只通过相对较低的带宽结构连接，在某些情况下这种连接的速度可能会慢一个数量级，因此跨设备同步是个棘手的问题。毕竟，在不同机器上运行训练代码的速度会有细微的差别，因此如果想使用分布式优化的同步算法就需要<strong>同步</strong>(<code>synchronize</code>)这些机器。下图说明了分布式并行训练是如何发生的。</p>
<ul>
<li>在每台机器上读取一组（不同的）批量数据，在多个<code>GPU</code>之间分割数据并传输到<code>GPU</code>的显存中。基于每个<code>GPU</code>上的批量数据分别计算预测和梯度。</li>
<li>来自一台机器上的所有的本地<code>GPU</code>的梯度聚合在一个<code>GPU</code>上（或者在不同的<code>GPU</code>上聚合梯度的某些部分）。</li>
<li>每台机器的梯度被发送到其本地<code>CPU</code>中。</li>
<li>所有的<code>CPU</code>将梯度发送到中央参数服务器中，由该服务器聚合所有梯度。</li>
<li>然后使用聚合后的梯度来更新参数，并将更新后的参数广播回各个<code>CPU</code>中。</li>
<li>更新后的参数信息发送到本地一个（或多个）<code>GPU</code>中。</li>
<li>所有<code>GPU</code>上的参数更新完成。</li>
</ul>
<img data-src="/2024/05/23/artificial-intelligence/computing_theory_study/cp_21.png" class="" title="多机多GPU分布式并行训练">

<p>以上这些操作似乎都相当简单，而且事实上它们可以在一台机器内高效地执行，但是当我们考虑多台机器时，就会发现中央的参数服务器成为了瓶颈。毕竟，每个服务器的带宽是有限的，因此对<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.986ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 878 453" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-23-TEX-I-1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D45A" xlink:href="#MJX-23-TEX-I-1D45A"></use></g></g></g></svg></mjx-container>个工作节点来说，将所有梯度发送到服务器所需的时间是<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="5.548ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 2452 1000" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-20-TEX-C-4F" d="M308 428Q289 428 289 438Q289 457 318 508T378 593Q417 638 475 671T599 705Q688 705 732 643T777 483Q777 380 733 285T620 123T464 18T293 -22Q188 -22 123 51T58 245Q58 327 87 403T159 533T249 626T333 685T388 705Q404 705 404 693Q404 674 363 649Q333 632 304 606T239 537T181 429T158 290Q158 179 214 114T364 48Q489 48 583 165T677 438Q677 473 670 505T648 568T601 617T528 636Q518 636 513 635Q486 629 460 600T419 544T392 490Q383 470 372 459Q341 430 308 428Z"></path><path id="MJX-20-TEX-N-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path id="MJX-20-TEX-I-1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-20-TEX-N-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="4F" xlink:href="#MJX-20-TEX-C-4F"></use></g></g><g data-mml-node="mo" transform="translate(796,0)"><use data-c="28" xlink:href="#MJX-20-TEX-N-28"></use></g><g data-mml-node="mi" transform="translate(1185,0)"><use data-c="1D45A" xlink:href="#MJX-20-TEX-I-1D45A"></use></g><g data-mml-node="mo" transform="translate(2063,0)"><use data-c="29" xlink:href="#MJX-20-TEX-N-29"></use></g></g></g></svg></mjx-container>。我们也可以通过将参数服务器数量增加到<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.357ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 600 453" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-19-TEX-I-1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D45B" xlink:href="#MJX-19-TEX-I-1D45B"></use></g></g></g></svg></mjx-container>来突破这一障碍。此时，每个服务器只需要存储<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="7.181ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 3174 1000" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-17-TEX-C-4F" d="M308 428Q289 428 289 438Q289 457 318 508T378 593Q417 638 475 671T599 705Q688 705 732 643T777 483Q777 380 733 285T620 123T464 18T293 -22Q188 -22 123 51T58 245Q58 327 87 403T159 533T249 626T333 685T388 705Q404 705 404 693Q404 674 363 649Q333 632 304 606T239 537T181 429T158 290Q158 179 214 114T364 48Q489 48 583 165T677 438Q677 473 670 505T648 568T601 617T528 636Q518 636 513 635Q486 629 460 600T419 544T392 490Q383 470 372 459Q341 430 308 428Z"></path><path id="MJX-17-TEX-N-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path id="MJX-17-TEX-N-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path id="MJX-17-TEX-N-2F" d="M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z"></path><path id="MJX-17-TEX-I-1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-17-TEX-N-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="4F" xlink:href="#MJX-17-TEX-C-4F"></use></g></g><g data-mml-node="mo" transform="translate(796,0)"><use data-c="28" xlink:href="#MJX-17-TEX-N-28"></use></g><g data-mml-node="mn" transform="translate(1185,0)"><use data-c="31" xlink:href="#MJX-17-TEX-N-31"></use></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(1685,0)"><g data-mml-node="mo"><use data-c="2F" xlink:href="#MJX-17-TEX-N-2F"></use></g></g><g data-mml-node="mi" transform="translate(2185,0)"><use data-c="1D45B" xlink:href="#MJX-17-TEX-I-1D45B"></use></g><g data-mml-node="mo" transform="translate(2785,0)"><use data-c="29" xlink:href="#MJX-17-TEX-N-29"></use></g></g></g></svg></mjx-container>个参数，因此更新和优化的总时间变为<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="8.036ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 3552 1000" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-17-TEX-C-4F" d="M308 428Q289 428 289 438Q289 457 318 508T378 593Q417 638 475 671T599 705Q688 705 732 643T777 483Q777 380 733 285T620 123T464 18T293 -22Q188 -22 123 51T58 245Q58 327 87 403T159 533T249 626T333 685T388 705Q404 705 404 693Q404 674 363 649Q333 632 304 606T239 537T181 429T158 290Q158 179 214 114T364 48Q489 48 583 165T677 438Q677 473 670 505T648 568T601 617T528 636Q518 636 513 635Q486 629 460 600T419 544T392 490Q383 470 372 459Q341 430 308 428Z"></path><path id="MJX-17-TEX-N-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path id="MJX-17-TEX-I-1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-17-TEX-N-2F" d="M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z"></path><path id="MJX-17-TEX-I-1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-17-TEX-N-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="4F" xlink:href="#MJX-17-TEX-C-4F"></use></g></g><g data-mml-node="mo" transform="translate(796,0)"><use data-c="28" xlink:href="#MJX-17-TEX-N-28"></use></g><g data-mml-node="mi" transform="translate(1185,0)"><use data-c="1D45A" xlink:href="#MJX-17-TEX-I-1D45A"></use></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(2063,0)"><g data-mml-node="mo"><use data-c="2F" xlink:href="#MJX-17-TEX-N-2F"></use></g></g><g data-mml-node="mi" transform="translate(2563,0)"><use data-c="1D45B" xlink:href="#MJX-17-TEX-I-1D45B"></use></g><g data-mml-node="mo" transform="translate(3163,0)"><use data-c="29" xlink:href="#MJX-17-TEX-N-29"></use></g></g></g></svg></mjx-container>。这两个数字的匹配会产生稳定的伸缩性，而不用在乎我们需要处理多少工作节点。在实际应用中，我们使用同一台机器既作为工作节点还作为服务器。设计说明请参考下图。特别是，确保多台机器只在没有不合理延迟的情况下工作是相当困难的。</p>
<img data-src="/2024/05/23/artificial-intelligence/computing_theory_study/cp_22.png" class="" title="上图：单参数服务器是一个瓶颈，因为它的带宽是有限的；下图：多参数服务器使用聚合带宽存储部分参数">

<h5 id="键值存储"><a href="#键值存储" class="headerlink" title="键值存储"></a>键值存储</h5><p>在实践中，实现分布式多<code>GPU</code>训练所需要的步骤绝非易事。这就是公共抽象值得使用的原因，<strong>公共抽象</strong>即重新定义具有更新语义的<strong>键－值存储</strong>(<code>key-value store</code>)的抽象。在许多工作节点和许多<code>GPU</code>中，梯度<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="0.781ex" height="1.52ex" role="img" focusable="false" viewBox="0 -661 345 672" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-17-TEX-I-1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D456" xlink:href="#MJX-17-TEX-I-1D456"></use></g></g></g></svg></mjx-container>的计算可以定义为：</p>
<mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -3.076ex;" xmlns="http://www.w3.org/2000/svg" width="22.542ex" height="5.226ex" role="img" focusable="false" viewBox="0 -950 9963.4 2309.8" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-17-TEX-B-1D420" d="M50 300Q50 368 105 409T255 450Q328 450 376 426L388 420Q435 455 489 455Q517 455 533 441T554 414T558 389Q558 367 544 353T508 339Q484 339 471 354T458 387Q458 397 462 400Q464 401 461 400Q459 400 454 399Q429 392 427 390Q454 353 459 328Q461 315 461 300Q461 240 419 202Q364 149 248 149Q185 149 136 172Q129 158 129 148Q129 105 170 93Q176 91 263 91Q273 91 298 91T334 91T366 89T400 85T432 77T466 64Q544 22 544 -69Q544 -114 506 -145Q438 -201 287 -201Q149 -201 90 -161T30 -70Q30 -58 33 -47T42 -27T54 -13T69 -1T82 6T94 12T101 15Q66 57 66 106Q66 151 90 187L97 197L89 204Q50 243 50 300ZM485 403H492Q491 404 488 404L485 403V403ZM255 200Q279 200 295 206T319 219T331 242T335 268T336 300Q336 337 333 352T317 380Q298 399 255 399Q228 399 211 392T187 371T178 345T176 312V300V289Q176 235 194 219Q215 200 255 200ZM287 -150Q357 -150 400 -128T443 -71Q443 -65 442 -61T436 -50T420 -37T389 -27T339 -21L308 -20Q276 -20 253 -20Q190 -20 180 -20T156 -26Q130 -38 130 -69Q130 -105 173 -127T287 -150Z"></path><path id="MJX-17-TEX-I-1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path id="MJX-17-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-17-TEX-LO-2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path><path id="MJX-17-TEX-I-1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path><path id="MJX-17-TEX-N-2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path><path id="MJX-17-TEX-N-77" d="M90 368Q84 378 76 380T40 385H18V431H24L43 430Q62 430 84 429T116 428Q206 428 221 431H229V385H215Q177 383 177 368Q177 367 221 239L265 113L339 328L333 345Q323 374 316 379Q308 384 278 385H258V431H264Q270 428 348 428Q439 428 454 431H461V385H452Q404 385 404 369Q404 366 418 324T449 234T481 143L496 100L537 219Q579 341 579 347Q579 363 564 373T530 385H522V431H529Q541 428 624 428Q692 428 698 431H703V385H697Q696 385 691 385T682 384Q635 377 619 334L559 161Q546 124 528 71Q508 12 503 1T487 -11H479Q460 -11 456 -4Q455 -3 407 133L361 267Q359 263 266 -4Q261 -11 243 -11H238Q225 -11 220 -3L90 368Z"></path><path id="MJX-17-TEX-N-6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z"></path><path id="MJX-17-TEX-N-72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z"></path><path id="MJX-17-TEX-N-6B" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T97 124T98 167T98 217T98 272T98 329Q98 366 98 407T98 482T98 542T97 586T97 603Q94 622 83 628T38 637H20V660Q20 683 22 683L32 684Q42 685 61 686T98 688Q115 689 135 690T165 693T176 694H179V463L180 233L240 287Q300 341 304 347Q310 356 310 364Q310 383 289 385H284V431H293Q308 428 412 428Q475 428 484 431H489V385H476Q407 380 360 341Q286 278 286 274Q286 273 349 181T420 79Q434 60 451 53T500 46H511V0H505Q496 3 418 3Q322 3 307 0H299V46H306Q330 48 330 65Q330 72 326 79Q323 84 276 153T228 222L176 176V120V84Q176 65 178 59T189 49Q210 46 238 46H254V0H246Q231 3 137 3T28 0H20V46H36Z"></path><path id="MJX-17-TEX-N-65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z"></path><path id="MJX-17-TEX-N-73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path id="MJX-17-TEX-I-1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path><path id="MJX-17-TEX-N-47" d="M56 342Q56 428 89 500T174 615T283 681T391 705Q394 705 400 705T408 704Q499 704 569 636L582 624L612 663Q639 700 643 704Q644 704 647 704T653 705H657Q660 705 666 699V419L660 413H626Q620 419 619 430Q610 512 571 572T476 651Q457 658 426 658Q401 658 376 654T316 633T254 592T205 519T177 411Q173 369 173 335Q173 259 192 201T238 111T302 58T370 31T431 24Q478 24 513 45T559 100Q562 110 562 160V212Q561 213 557 216T551 220T542 223T526 225T502 226T463 227H437V273H449L609 270Q715 270 727 273H735V227H721Q674 227 668 215Q666 211 666 108V6Q660 0 657 0Q653 0 639 10Q617 25 600 42L587 54Q571 27 524 3T406 -22Q317 -22 238 22T108 151T56 342Z"></path><path id="MJX-17-TEX-N-50" d="M130 622Q123 629 119 631T103 634T60 637H27V683H214Q237 683 276 683T331 684Q419 684 471 671T567 616Q624 563 624 489Q624 421 573 372T451 307Q429 302 328 301H234V181Q234 62 237 58Q245 47 304 46H337V0H326Q305 3 182 3Q47 3 38 0H27V46H60Q102 47 111 49T130 61V622ZM507 488Q507 514 506 528T500 564T483 597T450 620T397 635Q385 637 307 637H286Q237 637 234 628Q231 624 231 483V342H302H339Q390 342 423 349T481 382Q507 411 507 488Z"></path><path id="MJX-17-TEX-N-55" d="M128 622Q121 629 117 631T101 634T58 637H25V683H36Q57 680 180 680Q315 680 324 683H335V637H302Q262 636 251 634T233 622L232 418V291Q232 189 240 145T280 67Q325 24 389 24Q454 24 506 64T571 183Q575 206 575 410V598Q569 608 565 613T541 627T489 637H472V683H481Q496 680 598 680T715 683H724V637H707Q634 633 622 598L621 399Q620 194 617 180Q617 179 615 171Q595 83 531 31T389 -22Q304 -22 226 33T130 192Q129 201 128 412V622Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D420" xlink:href="#MJX-17-TEX-B-1D420"></use></g></g><g data-mml-node="mi" transform="translate(608,-150) scale(0.707)"><use data-c="1D456" xlink:href="#MJX-17-TEX-I-1D456"></use></g></g><g data-mml-node="mo" transform="translate(1179.7,0)"><use data-c="3D" xlink:href="#MJX-17-TEX-N-3D"></use></g><g data-mml-node="munder" transform="translate(2235.5,0)"><g data-mml-node="mo" transform="translate(890.2,0)"><use data-c="2211" xlink:href="#MJX-17-TEX-LO-2211"></use></g><g data-mml-node="TeXAtom" transform="translate(0,-1107.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D458" xlink:href="#MJX-17-TEX-I-1D458"></use></g><g data-mml-node="mo" transform="translate(521,0)"><use data-c="2208" xlink:href="#MJX-17-TEX-N-2208"></use></g><g data-mml-node="mtext" transform="translate(1188,0)"><use data-c="77" xlink:href="#MJX-17-TEX-N-77"></use><use data-c="6F" xlink:href="#MJX-17-TEX-N-6F" transform="translate(722,0)"></use><use data-c="72" xlink:href="#MJX-17-TEX-N-72" transform="translate(1222,0)"></use><use data-c="6B" xlink:href="#MJX-17-TEX-N-6B" transform="translate(1614,0)"></use><use data-c="65" xlink:href="#MJX-17-TEX-N-65" transform="translate(2142,0)"></use><use data-c="72" xlink:href="#MJX-17-TEX-N-72" transform="translate(2586,0)"></use><use data-c="73" xlink:href="#MJX-17-TEX-N-73" transform="translate(2978,0)"></use></g></g></g><g data-mml-node="munder" transform="translate(5626.6,0)"><g data-mml-node="mo" transform="translate(582.3,0)"><use data-c="2211" xlink:href="#MJX-17-TEX-LO-2211"></use></g><g data-mml-node="TeXAtom" transform="translate(0,-1115.5) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D457" xlink:href="#MJX-17-TEX-I-1D457"></use></g><g data-mml-node="mo" transform="translate(412,0)"><use data-c="2208" xlink:href="#MJX-17-TEX-N-2208"></use></g><g data-mml-node="mtext" transform="translate(1079,0)"><use data-c="47" xlink:href="#MJX-17-TEX-N-47"></use><use data-c="50" xlink:href="#MJX-17-TEX-N-50" transform="translate(785,0)"></use><use data-c="55" xlink:href="#MJX-17-TEX-N-55" transform="translate(1466,0)"></use><use data-c="73" xlink:href="#MJX-17-TEX-N-73" transform="translate(2216,0)"></use></g></g></g><g data-mml-node="msub" transform="translate(8401.8,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D420" xlink:href="#MJX-17-TEX-B-1D420"></use></g></g><g data-mml-node="TeXAtom" transform="translate(608,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D456" xlink:href="#MJX-17-TEX-I-1D456"></use></g><g data-mml-node="mi" transform="translate(345,0)"><use data-c="1D457" xlink:href="#MJX-17-TEX-I-1D457"></use></g><g data-mml-node="mi" transform="translate(757,0)"><use data-c="1D458" xlink:href="#MJX-17-TEX-I-1D458"></use></g></g></g></g></g></svg></mjx-container>
<p>其中<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.666ex;" xmlns="http://www.w3.org/2000/svg" width="3.533ex" height="1.695ex" role="img" focusable="false" viewBox="0 -455 1561.7 749.2" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-17-TEX-B-1D420" d="M50 300Q50 368 105 409T255 450Q328 450 376 426L388 420Q435 455 489 455Q517 455 533 441T554 414T558 389Q558 367 544 353T508 339Q484 339 471 354T458 387Q458 397 462 400Q464 401 461 400Q459 400 454 399Q429 392 427 390Q454 353 459 328Q461 315 461 300Q461 240 419 202Q364 149 248 149Q185 149 136 172Q129 158 129 148Q129 105 170 93Q176 91 263 91Q273 91 298 91T334 91T366 89T400 85T432 77T466 64Q544 22 544 -69Q544 -114 506 -145Q438 -201 287 -201Q149 -201 90 -161T30 -70Q30 -58 33 -47T42 -27T54 -13T69 -1T82 6T94 12T101 15Q66 57 66 106Q66 151 90 187L97 197L89 204Q50 243 50 300ZM485 403H492Q491 404 488 404L485 403V403ZM255 200Q279 200 295 206T319 219T331 242T335 268T336 300Q336 337 333 352T317 380Q298 399 255 399Q228 399 211 392T187 371T178 345T176 312V300V289Q176 235 194 219Q215 200 255 200ZM287 -150Q357 -150 400 -128T443 -71Q443 -65 442 -61T436 -50T420 -37T389 -27T339 -21L308 -20Q276 -20 253 -20Q190 -20 180 -20T156 -26Q130 -38 130 -69Q130 -105 173 -127T287 -150Z"></path><path id="MJX-17-TEX-I-1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path id="MJX-17-TEX-I-1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path><path id="MJX-17-TEX-I-1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D420" xlink:href="#MJX-17-TEX-B-1D420"></use></g></g><g data-mml-node="TeXAtom" transform="translate(608,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D456" xlink:href="#MJX-17-TEX-I-1D456"></use></g><g data-mml-node="mi" transform="translate(345,0)"><use data-c="1D457" xlink:href="#MJX-17-TEX-I-1D457"></use></g><g data-mml-node="mi" transform="translate(757,0)"><use data-c="1D458" xlink:href="#MJX-17-TEX-I-1D458"></use></g></g></g></g></g></svg></mjx-container>是在工作节点<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.179ex" height="1.595ex" role="img" focusable="false" viewBox="0 -694 521 705" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-17-TEX-I-1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D458" xlink:href="#MJX-17-TEX-I-1D458"></use></g></g></g></svg></mjx-container>的GPU<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.462ex;" xmlns="http://www.w3.org/2000/svg" width="0.932ex" height="1.957ex" role="img" focusable="false" viewBox="0 -661 412 865" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-17-TEX-I-1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D457" xlink:href="#MJX-17-TEX-I-1D457"></use></g></g></g></svg></mjx-container>上拆分的梯度<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="0.781ex" height="1.52ex" role="img" focusable="false" viewBox="0 -661 345 672" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-17-TEX-I-1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D456" xlink:href="#MJX-17-TEX-I-1D456"></use></g></g></g></svg></mjx-container>的一部分。这个运算的关键在于它是一个<strong>交换归约</strong>(<code>commutative reduction</code>)，也就是说，它把许多向量变换成一个向量，而运算顺序在完成向量变换时并不重要。这对实现我们的目标来说是非常好的，因为不需要为何时接收哪个梯度进行细粒度的控制。此外，请注意，这个操作在不同的<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="0.781ex" height="1.52ex" role="img" focusable="false" viewBox="0 -661 345 672" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-17-TEX-I-1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D456" xlink:href="#MJX-17-TEX-I-1D456"></use></g></g></g></svg></mjx-container>之间是独立的。这就允许我们定义下面两个操作：<code>push</code>（用于累积梯度）和<code>pull</code>（用于取得聚合梯度）。因为我们有很多层，也就有很多不同的梯度集合，因此需要用一个键<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="0.036ex" height="0.036ex" role="img" focusable="false" viewBox="0 0 16 16" xmlns:xlink="http://www.w3.org/1999/xlink"><defs></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"></g></g></svg></mjx-container>来对梯度建索引。这个与<code>Dynamo</code>中引入的键－值存储之间存在相似性并非巧合。它们两个定义都拥有许多相似的性质，特别是在多个服务器之间分发参数时。</p>
<p>键－值存储的<code>push</code>与<code>pull</code>操作描述如下：</p>
<ul>
<li><code>push(key，value)</code>将特定的梯度值从工作节点发送到公共存储，在那里通过某种方式（例如，相加）来聚合值；</li>
<li><code>pull(key，value)</code>从公共存储中取得某种方式（例如，组合来自所有工作节点的梯度）的聚合值。</li>
</ul>
<p>通过将同步的所有复杂性隐藏在一个简单的<code>push</code>和<code>pull</code>操作背后，我们可以将统计建模人员（他们希望能够用简单的术语表达优化）和系统工程师（他们需要处理分布式同步中固有的复杂性）的关注点解耦。</p>
<h5 id="总结-5"><a href="#总结-5" class="headerlink" title="总结"></a>总结</h5><p>同步需要高度适应特定的网络基础设施和服务器内的连接，这种适应会严重影响同步所需的时间。环同步对于<code>p3</code>和<code>DGX-2</code>服务器是最佳的，而对于其他服务器则未必。当添加多个参数服务器以增加带宽时，分层同步策略可以工作的很好。</p>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>umbrella
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://fresh88888888.github.io/2024/05/23/artificial-intelligence/computing_theory_study/" title="计算性能 (机器学习)(TensorFlow)">https://fresh88888888.github.io/2024/05/23/artificial-intelligence/computing_theory_study/</a>
  </li>
  <li class="post-copyright-license">
      <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/AI/" rel="tag"># AI</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2024/05/21/artificial-intelligence/attention_theory_study/" rel="prev" title="注意力机制 (Transformer)(TensorFlow)">
                  <i class="fa fa-chevron-left"></i> 注意力机制 (Transformer)(TensorFlow)
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2024/05/24/artificial-intelligence/optimiaztion_algorithm_study/" rel="next" title="优化算法 (机器学习)(TensorFlow)">
                  优化算法 (机器学习)(TensorFlow) <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments utterances-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">辽ICP备15012817号-2 </a>
  </div>
  <div class="copyright">
    &copy; 2022 – 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">umbrella</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">1m</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">56:14</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/fresh88888888" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script size="300" alpha="0.6" zIndex="-1" src="https://cdnjs.cloudflare.com/ajax/libs/ribbon.js/1.0.2/ribbon.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.0/jquery.min.js" integrity="sha256-2Pmvv0kuTBOenSvLm6bvfBSSHrUJ+3A7x6P5Ebd07/g=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.8/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/comments.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/utils.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/motion.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/next-boot.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/pjax.min.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/search/local-search.min.js"></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdnjs.cloudflare.com/ajax/libs/pdfobject/2.2.12/pdfobject.min.js","integrity":"sha256-g2xji1rlE3KsGVClvuxTbcR0Kn2+wtQADSff2Tbb4zA="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/tags/pdf.min.js"></script>



  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/fancybox.min.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/pace.min.js"></script>


  
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  <script src="https://cdnjs.cloudflare.com/ajax/libs/quicklink/2.3.0/quicklink.umd.js" integrity="sha256-yvJQOINiH9fWemHn0vCA5lsHWJaHs6/ZmO+1Ft04SvM=" crossorigin="anonymous"></script>
  <script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":true,"archive":true,"delay":true,"timeout":5000,"priority":true,"url":"https://fresh88888888.github.io/2024/05/23/artificial-intelligence/computing_theory_study/"}</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/quicklink.min.js"></script>
<script class="next-config" data-name="utterances" type="application/json">{"enable":true,"repo":"fresh88888888.github.io","issue_term":"title","theme":"github-light"}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/comments/utterances.min.js"></script>

</body>
</html>
