<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.2">
<link rel="preconnect" href="https://fonts.googleapis.com" crossorigin>
<link rel="preconnect" href="https://cdnjs.cloudflare.com" crossorigin>
  <link rel="apple-touch-icon" sizes="180x180" href="/favicon.ico">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon.ico">
  <link rel="mask-icon" href="/favicon.ico" color="#222">
  <meta name="google-site-verification" content="lk2gSYFP_NyLNFob-fFnt7fm-I_n1ZYws-WZll7mshg">
  <meta name="msvalidate.01" content="6Jdc01DjYOLguhS5">
  <meta name="baidu-site-verification" content="code-NR10G09zww">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic%7Ccursive:300,300italic,400,400italic,700,700italic%7CSource+Code+Pro:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/yellow/pace-theme-minimal.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"fresh88888888.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.17.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"flat"},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":true,"nav":null},"stickytabs":true,"motion":{"enable":true,"async":true,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/local-search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":10,"unescape":false,"preload":true}}</script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/config.min.js"></script>

    <meta name="description" content="模型见解的用例许多人说机器学习模型是“黑匣子”，从某种意义上说，它们可以做出很好的预测，但你无法理解这些预测背后的逻辑。这种说法是正确的，因为大多数数据科学家还不知道如何从模型中提取见解。  模型认为数据中哪些特征最重要？ 对于模型的任何单个预测，数据中的每个特征如何影响该特定预测？ 每个特征如何从大的角度影响模型的预测（考虑大量可能的预测时，其典型效果是什么）？">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习可解释性">
<meta property="og:url" content="https://fresh88888888.github.io/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/index.html">
<meta property="og:site_name" content="UMBRELLA">
<meta property="og:description" content="模型见解的用例许多人说机器学习模型是“黑匣子”，从某种意义上说，它们可以做出很好的预测，但你无法理解这些预测背后的逻辑。这种说法是正确的，因为大多数数据科学家还不知道如何从模型中提取见解。  模型认为数据中哪些特征最重要？ 对于模型的任何单个预测，数据中的每个特征如何影响该特定预测？ 每个特征如何从大的角度影响模型的预测（考虑大量可能的预测时，其典型效果是什么）？">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/mlx_1.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/mlx_2.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/mlx_3.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/mlx_4.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/mlx_5.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/mlx_6.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/mlx_7.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/mlx_8.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/mlx_9.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/mlx_10.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/mlx_11.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/mlx_12.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/mlx_13.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/mlx_14.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/mlx_15.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/mlx_16.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/mlx_17.png">
<meta property="article:published_time" content="2024-03-05T12:20:32.000Z">
<meta property="article:modified_time" content="2024-03-05T12:20:32.000Z">
<meta property="article:author" content="umbrella">
<meta property="article:tag" content="AI">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://fresh88888888.github.io/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/mlx_1.png">


<link rel="canonical" href="https://fresh88888888.github.io/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://fresh88888888.github.io/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/","path":"2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/","title":"机器学习可解释性"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>机器学习可解释性 | UMBRELLA</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">UMBRELLA</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">未雨绸缪，举重若轻</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-算法"><a href="/Algorithm/" rel="section"><i class="fa fa-calendar fa-fw"></i>算法</a></li><li class="menu-item menu-item-c++-&nbsp;编程"><a href="/Programming-C++/" rel="section"><i class="fa fa-heartbeat fa-fw"></i>C++ &nbsp;编程</a></li><li class="menu-item menu-item-rust-编程"><a href="/Programming-Rust/" rel="section"><i class="fa fa-cat fa-fw"></i>Rust 编程</a></li><li class="menu-item menu-item-go-&nbsp;&nbsp;&nbsp;编程"><a href="/Programming-Go/" rel="section"><i class="fa fa-hippo fa-fw"></i>Go &nbsp;&nbsp;&nbsp;编程</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E8%A7%81%E8%A7%A3%E7%9A%84%E7%94%A8%E4%BE%8B"><span class="nav-number">1.</span> <span class="nav-text">模型见解的用例</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%BA%9B%E8%A7%81%E8%A7%A3%E5%BE%88%E6%9C%89%E4%BB%B7%E5%80%BC%EF%BC%9F"><span class="nav-number">1.1.</span> <span class="nav-text">为什么这些见解很有价值？</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%B0%83%E8%AF%95"><span class="nav-number">1.2.</span> <span class="nav-text">调试</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B"><span class="nav-number">1.3.</span> <span class="nav-text">特征工程</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%8C%87%E5%AF%BC%E6%9C%AA%E6%9D%A5%E7%9A%84%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86"><span class="nav-number">1.4.</span> <span class="nav-text">指导未来的数据收集</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%B8%BA%E4%BA%BA%E7%B1%BB%E5%86%B3%E7%AD%96%E6%8F%90%E4%BE%9B%E4%BF%A1%E6%81%AF"><span class="nav-number">1.5.</span> <span class="nav-text">为人类决策提供信息</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%BB%BA%E7%AB%8B%E4%BF%A1%E4%BB%BB"><span class="nav-number">1.6.</span> <span class="nav-text">建立信任</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%8E%92%E5%88%97%E9%87%8D%E8%A6%81%E6%80%A7"><span class="nav-number">2.</span> <span class="nav-text">排列重要性</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BB%96%E6%98%AF%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C%E7%9A%84%EF%BC%9F"><span class="nav-number">2.1.</span> <span class="nav-text">他是如何工作的？</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E4%BE%8B%E5%AD%90"><span class="nav-number">2.2.</span> <span class="nav-text">代码例子</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%A7%A3%E9%87%8A%E6%8E%92%E5%88%97%E9%87%8D%E8%A6%81%E6%80%A7"><span class="nav-number">2.3.</span> <span class="nav-text">解释排列重要性</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%AF%8F%E4%B8%AA%E7%89%B9%E5%BE%81%E5%A6%82%E4%BD%95%E5%BD%B1%E5%93%8D%E6%82%A8%E7%9A%84%E9%A2%84%E6%B5%8B%EF%BC%9F"><span class="nav-number">3.</span> <span class="nav-text">每个特征如何影响您的预测？</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%83%A8%E5%88%86%E7%9B%B8%E5%85%B3%E5%9B%BE"><span class="nav-number">3.1.</span> <span class="nav-text">部分相关图</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%80%8E%E4%B9%88%E8%BF%90%E8%A1%8C%E7%9A%84"><span class="nav-number">3.2.</span> <span class="nav-text">怎么运行的?</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B"><span class="nav-number">3.3.</span> <span class="nav-text">代码示例</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BA%8C%E7%BB%B4%E9%83%A8%E5%88%86%E7%9B%B8%E5%85%B3%E5%9B%BE"><span class="nav-number">3.4.</span> <span class="nav-text">二维部分相关图</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#SHAP%E5%80%BC"><span class="nav-number">4.</span> <span class="nav-text">SHAP值</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BB%8B%E7%BB%8D"><span class="nav-number">4.1.</span> <span class="nav-text">介绍</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%AE%83%E4%BB%AC%E6%98%AF%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C%E7%9A%84%EF%BC%9F"><span class="nav-number">4.2.</span> <span class="nav-text">它们是如何工作的？</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97SHAP%E5%80%BC%E7%9A%84%E4%BB%A3%E7%A0%81"><span class="nav-number">4.3.</span> <span class="nav-text">计算SHAP值的代码</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%81%9A%E5%90%88SHAP%E5%80%BC%E4%BB%A5%E8%8E%B7%E5%BE%97%E6%9B%B4%E8%AF%A6%E7%BB%86%E7%9A%84%E6%A8%A1%E5%9E%8B%E8%A7%81%E8%A7%A3"><span class="nav-number">5.</span> <span class="nav-text">聚合SHAP值以获得更详细的模型见解</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%9B%9E%E9%A1%BE"><span class="nav-number">5.1.</span> <span class="nav-text">回顾</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#SHA%E4%BB%B7%E5%80%BC%E8%A7%82%E5%9B%9E%E9%A1%BE"><span class="nav-number">5.2.</span> <span class="nav-text">SHA价值观回顾</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%91%98%E8%A6%81%E5%9B%BE"><span class="nav-number">5.3.</span> <span class="nav-text">摘要图</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E4%B8%AD%E7%9A%84%E6%91%98%E8%A6%81%E5%9B%BE"><span class="nav-number">5.4.</span> <span class="nav-text">代码中的摘要图</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#SHAP%E4%BE%9D%E8%B5%96%E6%80%A7%E8%B4%A1%E7%8C%AE%E5%9B%BE"><span class="nav-number">5.5.</span> <span class="nav-text">SHAP依赖性贡献图</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E4%B8%AD%E7%9A%84%E4%BE%9D%E8%B5%96%E8%B4%A1%E7%8C%AE%E5%9B%BE"><span class="nav-number">5.6.</span> <span class="nav-text">代码中的依赖贡献图</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="umbrella"
      src="/avatar.jpeg">
  <p class="site-author-name" itemprop="name">umbrella</p>
  <div class="site-description" itemprop="description">没事就多看看书</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">236</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">21</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">65</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/fresh88888888" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;fresh88888888" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:fresh888888@foxmail.com" title="E-Mail → mailto:fresh888888@foxmail.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
    </div>

    
    <div class="sidebar-inner sidebar-blogroll">
      <div class="links-of-blogroll animated">
        <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
          链接
        </div>
        <ul class="links-of-blogroll-list">
            <li class="links-of-blogroll-item">
              <a href="https://www.rust-lang.org/zh-CN/" title="https:&#x2F;&#x2F;www.rust-lang.org&#x2F;zh-CN&#x2F;" rel="noopener" target="_blank">Rust</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://go.dev/" title="https:&#x2F;&#x2F;go.dev&#x2F;" rel="noopener" target="_blank">Golang</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://isocpp.org/" title="https:&#x2F;&#x2F;isocpp.org&#x2F;" rel="noopener" target="_blank">C++</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://www.python.org/" title="https:&#x2F;&#x2F;www.python.org&#x2F;" rel="noopener" target="_blank">Python</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://doc.rust-lang.org/cargo/index.html" title="https:&#x2F;&#x2F;doc.rust-lang.org&#x2F;cargo&#x2F;index.html" rel="noopener" target="_blank">Cargo</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://gist.github.com/rxaviers/7360908" title="https:&#x2F;&#x2F;gist.github.com&#x2F;rxaviers&#x2F;7360908" rel="noopener" target="_blank">Emoji</a>
            </li>
        </ul>
      </div>
    </div>
        <div class="pjax">
        </div>
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://fresh88888888.github.io/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/avatar.jpeg">
      <meta itemprop="name" content="umbrella">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="UMBRELLA">
      <meta itemprop="description" content="没事就多看看书">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="机器学习可解释性 | UMBRELLA">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          机器学习可解释性
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-03-05 20:20:32" itemprop="dateCreated datePublished" datetime="2024-03-05T20:20:32+08:00">2024-03-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" itemprop="url" rel="index"><span itemprop="name">人工智能</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>7k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>23 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h4 id="模型见解的用例"><a href="#模型见解的用例" class="headerlink" title="模型见解的用例"></a>模型见解的用例</h4><p>许多人说机器学习模型是“黑匣子”，从某种意义上说，它们可以做出很好的预测，但你无法理解这些预测背后的逻辑。这种说法是正确的，因为大多数数据科学家还不知道如何从模型中提取见解。</p>
<ul>
<li>模型认为数据中哪些特征最重要？</li>
<li>对于模型的任何单个预测，数据中的每个特征如何影响该特定预测？</li>
<li>每个特征如何从大的角度影响模型的预测（考虑大量可能的预测时，其典型效果是什么）？<span id="more"></span></li>
</ul>
<h5 id="为什么这些见解很有价值？"><a href="#为什么这些见解很有价值？" class="headerlink" title="为什么这些见解很有价值？"></a>为什么这些见解很有价值？</h5><p>这些见解有很多用途，包括：</p>
<ul>
<li>调试</li>
<li>特征工程</li>
<li>指导未来的数据收集</li>
<li>为人类决策提供信息</li>
<li>建立信任</li>
</ul>
<h5 id="调试"><a href="#调试" class="headerlink" title="调试"></a>调试</h5><p>世界上有大量不可靠、无组织且通常是脏的数据。当您编写预处理代码时，您会添加潜在的错误源。再加上目标泄漏的可能性，在真实的数据科学项目中，在某个时刻出现错误是常态，而不是例外。考虑到错误的频率和潜在的灾难性后果，调试是数据科学中最有价值的技能之一。了解模型发现的模式将帮助您识别这些模式何时与您对现实世界的了解不一致，这通常是追踪错误的第一步。</p>
<h5 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h5><p>特征工程通常是提高模型精度的最有效方法。特征工程通常涉及使用原始数据或之前创建的特征的转换来重复创建新特征。有时，您可以仅凭对基础主题的直觉来完成此过程。但是，当您拥有数百个原始功能或缺乏有关您正在研究的主题的背景知识时，您将需要更多指导。预测贷款违约的<code>Kaggle</code>竞赛给出了一个极端的例子。本次竞赛有数百个原始功能。出于隐私原因，这些功能的名称为 f1、f2、f3，而不是常见的英文名称。这模拟了您对原始数据缺乏直觉的场景。一位竞争对手发现其中两个功能（特别是<code>f527 - f528</code>）之间的差异创建了一个非常强大的新功能。包含这种差异作为特征的模型比不包含这种差异的模型要好得多。但是，当您从数百个变量开始时，您会如何考虑创建这个变量呢？<code>f527</code>和<code>f528</code>是重要的功能，并且它们的作用是紧密相连的。这将引导您考虑这两个变量的转换，并可能找到<code>f527 - f528</code>的“黄金特征”。随着越来越多的数据集从数百或数千个原始特征开始，这种方法变得越来越重要。</p>
<h5 id="指导未来的数据收集"><a href="#指导未来的数据收集" class="headerlink" title="指导未来的数据收集"></a>指导未来的数据收集</h5><p>您无法控制在线下载的数据集。但许多使用数据科学的企业和组织都有机会扩展他们收集的数据类型。收集新类型的数据可能会很昂贵或不方便，因此他们只有在知道值得时才愿意这样做。基于模型的见解可以让您很好地了解当前拥有的功能的价值，这将帮助您推断哪些新值可能最有帮助。</p>
<h5 id="为人类决策提供信息"><a href="#为人类决策提供信息" class="headerlink" title="为人类决策提供信息"></a>为人类决策提供信息</h5><p>有些决策是由模型自动做出的。亚马逊不会让人类（或精灵）匆忙决定每当您访问他们的网站时向您展示什么。但许多重要的决定是由人类做出的。对于这些决策，见解可能比预测更有价值。</p>
<h5 id="建立信任"><a href="#建立信任" class="headerlink" title="建立信任"></a>建立信任</h5><p>在没有验证一些基本事实的情况下，许多人不会认为他们可以相信您的模型做出重要决策。考虑到数据错误的频率，这是一项明智的预防措施。在实践中，展示符合他们对问题的一般理解的见解将有助于建立信任，即使是在对数据科学了解甚少的人之间也是如此。</p>
<h4 id="排列重要性"><a href="#排列重要性" class="headerlink" title="排列重要性"></a>排列重要性</h4><p>我们可能会问模型的最基本问题之一是：哪些特征对预测影响最大？这个概念称为“特征重要性”。有多种方法可以衡量特征重要性。有些方法回答了上述问题的略有不同的版本。其他方法也有缺陷。与大多数其他方法相比，排列重要性为：</p>
<ul>
<li>计算速度快</li>
<li>广泛使用和理解</li>
<li>与我们希望特征重要性度量具有的属性一致</li>
</ul>
<h5 id="他是如何工作的？"><a href="#他是如何工作的？" class="headerlink" title="他是如何工作的？"></a>他是如何工作的？</h5><p>排列重要性使用的模型与您迄今为止看到的任何模型都不同，许多人一开始会觉得它令人困惑。因此，我们将从一个示例开始，使其更加具体。考虑具有以下格式的数据：</p>
<img data-src="/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/mlx_1.png" class="">

<p>我们希望使用<code>10</code>岁时的数据来预测一个人<code>20</code>岁时的身高。我们的数据包括有用的特征（<code>10</code>岁时的身高）、几乎没有预测能力的特征（拥有的袜子）以及我们在本说明中不会重点关注的一些其他特征。排列重要性是在模型拟合后计算的。因此，我们不会更改模型或更改对于给定的身高、袜子数量等值的预测。相反，我们会问以下问题：如果我随机打乱验证数据的单列，而将目标和所有其他列留在原处，这将如何影响现在打乱的数据中的预测准确性？</p>
<img data-src="/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/mlx_2.png" class="">

<p>随机重新排序单个列会导致预测不太准确，因为结果数据不再对应于现实世界中观察到的任何内容。如果我们对模型严重依赖于预测的列进行洗牌，模型的准确性尤其会受到影响。在这种情况下，调整<code>10</code>岁时的身高会导致糟糕的预测。如果我们对拥有的袜子进行洗牌，那么最终的预测就不会受到那么大的影响。</p>
<p>有了这种认识，流程如下：</p>
<ul>
<li>获得经过训练的模型。</li>
<li>将值打乱在单列中，使用生成的数据集进行预测。使用这些预测和真实目标值来计算损失函数遭受洗牌的程度。性能下降衡量了您刚刚洗牌的变量的重要性。</li>
<li>将数据恢复到原始顺序（撤消步骤<code>2</code>中的随机播放）。现在，对数据集中的下一列重复步骤<code>2</code>，直到计算出每列的重要性。</li>
</ul>
<h5 id="代码例子"><a href="#代码例子" class="headerlink" title="代码例子"></a>代码例子</h5><p>我们的示例将使用一个模型，根据球队的统计数据来预测足球队是否会获得“最佳球员”获胜者。“游戏最佳球员”奖颁发给游戏中的最佳球员。模型构建不是我们当前的重点，因此下面的单元格加载数据并构建基本模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;../input/fifa-2018-match-statistics/FIFA 2018 Statistics.csv&#x27;</span>)</span><br><span class="line">y = (data[<span class="string">&#x27;Man of the Match&#x27;</span>] == <span class="string">&quot;Yes&quot;</span>)  <span class="comment"># Convert from string &quot;Yes&quot;/&quot;No&quot; to binary</span></span><br><span class="line">feature_names = [i <span class="keyword">for</span> i <span class="keyword">in</span> data.columns <span class="keyword">if</span> data[i].dtype <span class="keyword">in</span> [np.int64]]</span><br><span class="line">X = data[feature_names]</span><br><span class="line">train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=<span class="number">1</span>)</span><br><span class="line">my_model = RandomForestClassifier(n_estimators=<span class="number">100</span>, random_state=<span class="number">0</span>).fit(train_X, train_y)</span><br></pre></td></tr></table></figure>
<p>以下是如何使用 eli5 库计算和显示重要性:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> eli5</span><br><span class="line"><span class="keyword">from</span> eli5.sklearn <span class="keyword">import</span> PermutationImportance</span><br><span class="line"></span><br><span class="line">perm = PermutationImportance(my_model, random_state=<span class="number">1</span>).fit(val_X, val_y)</span><br><span class="line">eli5.show_weights(perm, feature_names = val_X.columns.tolist())</span><br></pre></td></tr></table></figure>
<p>输出结果为：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Weight	Feature</span><br><span class="line">0.1750 ± 0.0848	Goal Scored(进球数)</span><br><span class="line">0.0500 ± 0.0637	Distance Covered (Kms)</span><br><span class="line">0.0437 ± 0.0637	Yellow Card</span><br><span class="line">0.0187 ± 0.0500	Off-Target</span><br><span class="line">0.0187 ± 0.0637	Free Kicks</span><br><span class="line">0.0187 ± 0.0637	Fouls Committed</span><br><span class="line">0.0125 ± 0.0637	Pass Accuracy %</span><br><span class="line">0.0125 ± 0.0306	Blocked</span><br><span class="line">0.0063 ± 0.0612	Saves</span><br><span class="line">0.0063 ± 0.0250	Ball Possession %</span><br><span class="line">0 ± 0.0000	Red</span><br><span class="line">0 ± 0.0000	Yellow &amp; Red</span><br><span class="line">0.0000 ± 0.0559	On-Target</span><br><span class="line">-0.0063 ± 0.0729	Offsides</span><br><span class="line">-0.0063 ± 0.0919	Corners</span><br><span class="line">-0.0063 ± 0.0250	Goals <span class="keyword">in</span> PSO</span><br><span class="line">-0.0187 ± 0.0306	Attempts</span><br><span class="line">-0.0500 ± 0.0637	Passes</span><br></pre></td></tr></table></figure>

<h5 id="解释排列重要性"><a href="#解释排列重要性" class="headerlink" title="解释排列重要性"></a>解释排列重要性</h5><p>顶部的值是最重要的特征，而底部的值最不重要。每行的第一个数字显示随机改组后模型性能下降的程度（在本例中，使用“准确性”作为性能指标）。与数据科学中的大多数事情一样，洗牌列带来的确切性能变化存在一定的随机性。我们通过多次洗牌重复该过程来测量排列重要性计算中的随机性。<code>±</code>后面的数字衡量从一次重组到下一次重组的性能变化情况。您偶尔会看到排列重要性的负值。在这些情况下，对混洗（或噪声）数据的预测恰好比真实数据更准确。当特征无关紧要（重要性应该接近<code>0</code>）但随机导致对混洗数据的预测更加准确时，就会发生这种情况。这种情况在小数据集（如本例中的数据集）中更为常见，因为运气&#x2F;机会的空间更大。在我们的示例中，最重要的特征是进球数。这似乎是明智的。足球迷可能对其他变量的排序是否令人惊讶有一些直觉。</p>
<h4 id="每个特征如何影响您的预测？"><a href="#每个特征如何影响您的预测？" class="headerlink" title="每个特征如何影响您的预测？"></a>每个特征如何影响您的预测？</h4><h5 id="部分相关图"><a href="#部分相关图" class="headerlink" title="部分相关图"></a>部分相关图</h5><p>这对于回答以下问题很有用:</p>
<ul>
<li>控制所有其他房屋特征后，经度和纬度对房价有何影响？重申一下，类似大小的房屋在不同地区的定价如何？</li>
<li>两组之间的预测健康差异是由于饮食差异还是其他因素造成的？</li>
</ul>
<p>如果您熟悉线性或逻辑回归模型，则可以像这些模型中的系数一样解释部分相关图。不过，复杂模型的部分依赖图可以捕获比简单模型的系数更复杂的模式。如果您不熟悉线性或逻辑回归，请不要担心这种比较。我们将展示几个示例，解释这些图，然后查看创建这些图的代码。</p>
<h5 id="怎么运行的"><a href="#怎么运行的" class="headerlink" title="怎么运行的?"></a>怎么运行的?</h5><p>与排列重要性一样，部分依赖图是在模型拟合后计算的。该模型适合未经以任何方式人为操纵的真实数据。在我们的足球示例中，球队可能在很多方面有所不同。他们的传球次数、射门次数、进球数等等。乍一看，似乎很难理清这些特征的影响。为了了解部分图如何区分每个特征的影响，我们首先考虑单行数据。例如，该行数据可能代表一支球队，控球率为<code>50%</code>，传球<code>100</code>次，射门<code>10</code>次，进球<code>1</code>个。我们将使用拟合模型来预测我们的结果（他们的球员赢得“比赛最佳球员”的概率）。但我们反复改变一个变量的值来做出一系列预测。如果球队只有<code>40%</code>的控球率，我们就可以预测结果。然后我们预测他们有<code>50%</code>的机会拥有球权。然后再次预测<code>60%</code>。等等。当我们从较小的控球权值转向较大的控球权值（在水平轴上）时，我们会追踪出预测结果（在垂直轴上）。在本描述中，我们仅使用单行数据。 特征之间的相互作用可能会导致单行的绘图不典型。因此，我们使用原始数据集中的多行重复该心理实验，并在垂直轴上绘制平均预测结果。</p>
<h5 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;../input/fifa-2018-match-statistics/FIFA 2018 Statistics.csv&#x27;</span>)</span><br><span class="line">y = (data[<span class="string">&#x27;Man of the Match&#x27;</span>] == <span class="string">&quot;Yes&quot;</span>)  <span class="comment"># Convert from string &quot;Yes&quot;/&quot;No&quot; to binary</span></span><br><span class="line">feature_names = [i <span class="keyword">for</span> i <span class="keyword">in</span> data.columns <span class="keyword">if</span> data[i].dtype <span class="keyword">in</span> [np.int64]]</span><br><span class="line">X = data[feature_names]</span><br><span class="line">train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=<span class="number">1</span>)</span><br><span class="line">tree_model = DecisionTreeClassifier(random_state=<span class="number">0</span>, max_depth=<span class="number">5</span>, min_samples_split=<span class="number">5</span>).fit(train_X, train_y)</span><br></pre></td></tr></table></figure>
<p>我们的第一个示例使用决策树，您可以在下面看到。在实践中，您将针对实际应用程序使用更复杂的模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line"><span class="keyword">import</span> graphviz</span><br><span class="line"></span><br><span class="line">tree_graph = tree.export_graphviz(tree_model, out_file=<span class="literal">None</span>, feature_names=feature_names)</span><br><span class="line">graphviz.Source(tree_graph)</span><br></pre></td></tr></table></figure>
<p>输出结果为：</p>
<img data-src="/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/mlx_3.png" class="">

<p>作为阅读树的指导：</p>
<ul>
<li>有孩子的叶子在顶部显示他们的分裂标准。</li>
<li>底部的一对值分别显示树的该节点中的数据点的目标的<code>False</code>值和<code>True</code>值的计数。</li>
</ul>
<p>以下是使用<code>scikit-learn</code>库创建部分依赖图的代码。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.inspection <span class="keyword">import</span> PartialDependenceDisplay</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create and plot the data</span></span><br><span class="line">disp1 = PartialDependenceDisplay.from_estimator(tree_model, val_X, [<span class="string">&#x27;Goal Scored&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>输出结果为：</p>
<img data-src="/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/mlx_4.png" class="">

<p><code>y</code>轴被解释为预测相对于基线或最左边值的预测变化。从这个特定的图表中，我们看到进球大大增加了您赢得“全场最佳球员”的机会。但除此之外的额外目标似乎对预测影响不大。这是另一个示例图：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">feature_to_plot = <span class="string">&#x27;Distance Covered (Kms)&#x27;</span></span><br><span class="line">disp2 = PartialDependenceDisplay.from_estimator(tree_model, val_X, [feature_to_plot])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>输出结果为：</p>
<img data-src="/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/mlx_5.png" class="">

<p>该图似乎太简单，无法代表现实。但那是因为模型太简单了。您应该能够从上面的决策树中看到，这准确地代表了模型的结构。您可以轻松比较不同模型的结构或含义。这是随机森林模型的相同图。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Build Random Forest model</span></span><br><span class="line">rf_model = RandomForestClassifier(random_state=<span class="number">0</span>).fit(train_X, train_y)</span><br><span class="line"></span><br><span class="line">disp3 = PartialDependenceDisplay.from_estimator(rf_model, val_X, [feature_to_plot])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>输出结果为：</p>
<img data-src="/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/mlx_6.png" class="">

<p>该模型认为，如果您的球员在比赛过程中总共跑了<code>100</code>公里，您更有可能赢得全场最佳球员。尽管运行更多会导致预测降低。一般来说，这条曲线的平滑形状似乎比决策树模型的阶跃函数更合理。尽管这个数据集足够小，但我们在解释任何模型时都会小心。</p>
<h5 id="二维部分相关图"><a href="#二维部分相关图" class="headerlink" title="二维部分相关图"></a>二维部分相关图</h5><p>如果您对特征之间的相互作用感到好奇，二维部分依赖图也很有用。我们将再次对该图使用决策树模型。它将创建一个极其简单的图，但您应该能够将图中看到的内容与树本身相匹配。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line">f_names = [(<span class="string">&#x27;Goal Scored&#x27;</span>, <span class="string">&#x27;Distance Covered (Kms)&#x27;</span>)]</span><br><span class="line"><span class="comment"># Similar to previous PDP plot except we use tuple of features instead of single feature</span></span><br><span class="line">disp4 = PartialDependenceDisplay.from_estimator(tree_model, val_X, f_names, ax=ax)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>输出结果为：</p>
<img data-src="/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/mlx_7.png" class="">

<p>该图显示了对进球数和距离的任意组合的预测。例如，当一支球队至少进<code>1</code>球且跑动总距离接近<code>100</code>公里时，我们会看到最高的预测。如果他们进了<code>0</code>球，那么走过的距离就无关紧要了。通过追踪目标为<code>0</code>的决策树，您能看到这一点吗？但如果他们进球，距离会影响预测。确保您可以从二维部分相关图中看到这一点。你能在决策树中看到这种模式吗？</p>
<h4 id="SHAP值"><a href="#SHAP值" class="headerlink" title="SHAP值"></a>SHAP值</h4><h5 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h5><p>您已经了解（并使用）了从机器学习模型中提取一般见解的技术。但是，如果您想分解模型如何用于单个预测，该怎么办？<code>SHAP</code>值（<code>SHApley Additive exPlanations</code>的缩写）分解预测以显示每个特征的影响。你可以在哪里使用这个？</p>
<ul>
<li>一个模型表明银行不应该借钱给某人，法律要求银行解释每笔拒绝贷款的依据。</li>
<li>医疗保健提供者希望确定哪些因素导致每位患者患某种疾病的风险增加，以便他们可以通过有针对性的健康干预措施直接解决这些风险因素。</li>
</ul>
<h5 id="它们是如何工作的？"><a href="#它们是如何工作的？" class="headerlink" title="它们是如何工作的？"></a>它们是如何工作的？</h5><p><code>SHAP</code>值解释了给定特征具有特定值与我们在该特征采用某个基线值时所做的预测相比的影响。我们将继续排列重要性和部分依赖图课程中的足球&#x2F;橄榄球示例。在这个课程中，我们预测了一支球队是否会有一名球员赢得全场最佳球员奖。我们可以问：</p>
<ul>
<li>球队进了<code>3</code>个球这一事实在多大程度上推动了预测？<br>但如果我们将其重述为：</li>
<li>多少是由球队进了<code>3</code>个进球这一事实驱动的预测，而不是一些基线进球数。<br>当然，每个团队都有很多特点。因此，如果我们回答目标数量的问题，我们可以对所有其他特征重复该过程。<code>SHAP</code>值以保证良好属性的方式做到这一点。具体来说，您可以使用以下等式分解预测：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sum(SHAP values for all features) = pred_for_team - pred_for_baseline_values</span><br></pre></td></tr></table></figure>
也就是说，所有特征的<code>SHAP</code>值相加可以解释为什么我的预测与基线不同。这使我们能够分解图表中的预测，如下所示：<img data-src="/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/mlx_8.png" class=""></li>
</ul>
<p>我们预测为<code>0.7</code>，而<code>base_value</code>为<code>0.4979</code>。导致预测增加的特征值是粉红色的，它们的视觉大小显示了特征影响的大小。降低预测的特征值呈蓝色。最大的影响来自进球数为<code>2</code>。尽管控球权值对降低预测有显着影响。如果用粉红色条的长度减去蓝色条的长度，则它等于从基值到输出的距离。该技术存在一定的复杂性，以确保基线加上各个效应的总和达到预测（这并不像听起来那么简单）。我们不会在这里讨论这个细节，因为它对于使用该技术并不重要。这篇博文有更长的理论解释。</p>
<h5 id="计算SHAP值的代码"><a href="#计算SHAP值的代码" class="headerlink" title="计算SHAP值的代码"></a>计算SHAP值的代码</h5><p>我们使用完美的<code>Shap</code>库计算<code>SHAP</code>值。在此示例中，我们将重用您已经在足球数据中看到的模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;../input/fifa-2018-match-statistics/FIFA 2018 Statistics.csv&#x27;</span>)</span><br><span class="line">y = (data[<span class="string">&#x27;Man of the Match&#x27;</span>] == <span class="string">&quot;Yes&quot;</span>)  <span class="comment"># Convert from string &quot;Yes&quot;/&quot;No&quot; to binary</span></span><br><span class="line">feature_names = [i <span class="keyword">for</span> i <span class="keyword">in</span> data.columns <span class="keyword">if</span> data[i].dtype <span class="keyword">in</span> [np.int64, np.int64]]</span><br><span class="line">X = data[feature_names]</span><br><span class="line">train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=<span class="number">1</span>)</span><br><span class="line">my_model = RandomForestClassifier(random_state=<span class="number">0</span>).fit(train_X, train_y)</span><br></pre></td></tr></table></figure>
<p>我们将查看数据集单行的<code>SHAP</code>值（我们任意选择第<code>5</code>行）。对于上下文，我们将在查看<code>SHA</code>值之前查看原始预测。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">row_to_show = <span class="number">5</span></span><br><span class="line">data_for_prediction = val_X.iloc[row_to_show]  <span class="comment"># use 1 row of data here. Could use multiple rows if desired</span></span><br><span class="line">data_for_prediction_array = data_for_prediction.values.reshape(<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">my_model.predict_proba(data_for_prediction_array)</span><br></pre></td></tr></table></figure>
<p>输出结果为：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array([[0.29, 0.71]])</span><br></pre></td></tr></table></figure>
<p>该队有<code>70%</code>的可能性让一名球员获奖。现在，我们将继续编写代码来获取该单个预测的<code>SHAP</code>值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> shap  <span class="comment"># package used to calculate Shap values</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create object that can calculate shap values</span></span><br><span class="line">explainer = shap.TreeExplainer(my_model)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Calculate Shap values</span></span><br><span class="line">shap_values = explainer.shap_values(data_for_prediction)</span><br></pre></td></tr></table></figure>
<p>上面的<code>shap_values</code>对象是一个包含两个数组的列表。第一个数组是负面结果（未获奖）的<code>SHAP</code>值，第二个数组是正面结果（获奖）的<code>SHAP</code>值列表。我们通常根据积极结果的预测来考虑预测，因此我们将提取积极结果的<code>SHAP</code>值（提取<code>shap_values[1]</code>）。查看原始数组很麻烦，但是<code>shap</code>包有一个很好的方法来可视化结果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">shap.initjs()</span><br><span class="line">shap.force_plot(explainer.expected_value[<span class="number">1</span>], shap_values[<span class="number">1</span>], data_for_prediction)</span><br></pre></td></tr></table></figure>
<p>输出结果为：</p>
<img data-src="/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/mlx_9.png" class="">

<p>如果您仔细查看我们创建<code>SHAP</code>值的代码，您会注意到我们在<code>shap.TreeExplainer(my_model)</code>中引用了树。但<code>SHAP</code>包为每种类型的模型提供了解释。</p>
<ul>
<li><code>shap.DeepExplainer</code>适用于深度学习模型。</li>
<li><code>shap.KernelExplainer</code>适用于所有模型，尽管它比其他解释器慢，并且它提供近似值而不是精确的<code>Shap</code>值。</li>
</ul>
<p>下面是一个使用<code>KernelExplainer</code>获得类似结果的示例。结果并不相同，因为<code>KernelExplainer</code>给出了近似结果。但结果却讲述了同样的故事。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># use Kernel SHAP to explain test set predictions</span></span><br><span class="line">k_explainer = shap.KernelExplainer(my_model.predict_proba, train_X)</span><br><span class="line">k_shap_values = k_explainer.shap_values(data_for_prediction)</span><br><span class="line">shap.force_plot(k_explainer.expected_value[<span class="number">1</span>], k_shap_values[<span class="number">1</span>], data_for_prediction)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">X does not have valid feature names, but RandomForestClassifier was fitted with feature names</span><br><span class="line">X does not have valid feature names, but RandomForestClassifier was fitted with feature names</span><br><span class="line">X does not have valid feature names, but RandomForestClassifier was fitted with feature names</span><br><span class="line">The default of &#x27;normalize&#x27; will be set to False in version 1.2 and deprecated in version 1.4.</span><br><span class="line">If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:</span><br><span class="line"></span><br><span class="line">from sklearn.pipeline import make_pipeline</span><br><span class="line"></span><br><span class="line">model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())</span><br><span class="line"></span><br><span class="line">If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:</span><br><span class="line"></span><br><span class="line">kwargs = &#123;s[0] + &#x27;__sample_weight&#x27;: sample_weight for s in model.steps&#125;</span><br><span class="line">model.fit(X, y, **kwargs)</span><br><span class="line"></span><br><span class="line">Set parameter alpha to: original_alpha * np.sqrt(n_samples). </span><br><span class="line">The default of &#x27;normalize&#x27; will be set to False in version 1.2 and deprecated in version 1.4.</span><br><span class="line">If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:</span><br><span class="line"></span><br><span class="line">from sklearn.pipeline import make_pipeline</span><br><span class="line"></span><br><span class="line">model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())</span><br><span class="line"></span><br><span class="line">If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:</span><br><span class="line"></span><br><span class="line">kwargs = &#123;s[0] + &#x27;__sample_weight&#x27;: sample_weight for s in model.steps&#125;</span><br><span class="line">model.fit(X, y, **kwargs)</span><br><span class="line"></span><br><span class="line">Set parameter alpha to: original_alpha * np.sqrt(n_samples). </span><br></pre></td></tr></table></figure>
<p>输出结果为：</p>
<img data-src="/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/mlx_10.png" class="">

<h4 id="聚合SHAP值以获得更详细的模型见解"><a href="#聚合SHAP值以获得更详细的模型见解" class="headerlink" title="聚合SHAP值以获得更详细的模型见解"></a>聚合SHAP值以获得更详细的模型见解</h4><h5 id="回顾"><a href="#回顾" class="headerlink" title="回顾"></a>回顾</h5><p>我们首先了解排列重要性和部分依赖图，以概述模型所学到的内容。然后我们了解了<code>SHAP</code>值来分解各个预测的组成部分。现在我们将扩展<code>SHAP</code>值，了解聚合多个<code>SHAP</code>值如何为排列重要性和部分依赖图提供更详细的替代方案。</p>
<h5 id="SHA价值观回顾"><a href="#SHA价值观回顾" class="headerlink" title="SHA价值观回顾"></a>SHA价值观回顾</h5><p><code>SHAP</code>值显示给定特征对我们的预测的改变程度（与我们在该特征的某个基线值进行预测相比）。例如，考虑一个超简单的模型：<br>$$𝑦&#x3D;4∗𝑥1+2∗𝑥2$$</p>
<p>如果<code>𝑥1</code>取值<code>2</code>，而不是基线值<code>0</code>，那么<code>𝑥1</code>的<code>SHAP</code>值将为<code>8</code>（<code>4 * 2</code>）。使用我们在实践中使用的复杂模型来计算这些更困难。但通过一些巧妙的算法，<code>Shap</code>值允许我们将任何预测分解为每个特征值的效果总和，生成如下图：</p>
<img data-src="/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/mlx_11.png" class="">

<p>除了每个预测的良好细分之外，<code>Shap</code>库还提供<code>Shap</code>值组的出色可视化。我们将重点关注其中两个可视化。这些可视化与排列重要性和部分依赖图在概念上相似。因此，之前练习中的多个线程将在这里汇集在一起。</p>
<h5 id="摘要图"><a href="#摘要图" class="headerlink" title="摘要图"></a>摘要图</h5><p>排列重要性非常重要，因为它创建了简单的数字度量来查看哪些特征对模型很重要。这帮助我们轻松地比较功能，并且您可以向非技术受众展示生成的图表。但它并没有告诉您每个特征的重要性。如果一个特征具有中等排列重要性，则可能意味着它具有:</p>
<ul>
<li>对一些预测有很大影响，但总体上没有影响。</li>
<li>对所有预测都有中等影响。</li>
</ul>
<p><code>SHAP</code>摘要图让我们能够鸟瞰特征重要性及其驱动因素。我们将演示足球数据的示例图：</p>
<img data-src="/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/mlx_12.png" class="">

<p>该图由许多点组成。每个点具有三个特征：</p>
<ul>
<li>垂直位置显示它所描绘的特征。</li>
<li>颜色显示该特征对于数据集的该行是高还是低。</li>
<li>水平位置显示该值的影响是否导致更高或更低的预测。</li>
</ul>
<p>例如，左上角的点代表进球较少的球队，使预测值降低<code>0.25</code>。</p>
<ul>
<li>该模型忽略了红色和黄色<code>&amp;</code>红色特征。</li>
<li>通常黄牌不会影响预测，但有一个极端的情况，即高值导致预测低得多。</li>
<li>目标得分高值导致较高预测，低值导致低预测。</li>
</ul>
<p>如果你观察得足够长，这张图中就会包含很多信息。</p>
<h5 id="代码中的摘要图"><a href="#代码中的摘要图" class="headerlink" title="代码中的摘要图"></a>代码中的摘要图</h5><p>您已经看过加载足球&#x2F;橄榄球数据的代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;../input/fifa-2018-match-statistics/FIFA 2018 Statistics.csv&#x27;</span>)</span><br><span class="line">y = (data[<span class="string">&#x27;Man of the Match&#x27;</span>] == <span class="string">&quot;Yes&quot;</span>)  <span class="comment"># Convert from string &quot;Yes&quot;/&quot;No&quot; to binary</span></span><br><span class="line">feature_names = [i <span class="keyword">for</span> i <span class="keyword">in</span> data.columns <span class="keyword">if</span> data[i].dtype <span class="keyword">in</span> [np.int64, np.int64]]</span><br><span class="line">X = data[feature_names]</span><br><span class="line">train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=<span class="number">1</span>)</span><br><span class="line">my_model = RandomForestClassifier(random_state=<span class="number">0</span>).fit(train_X, train_y)</span><br></pre></td></tr></table></figure>
<p>我们使用以下代码获取所有验证数据的<code>SHAP</code>值。它足够短，我们可以在评论中进行解释。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> shap  <span class="comment"># package used to calculate Shap values</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create object that can calculate shap values</span></span><br><span class="line">explainer = shap.TreeExplainer(my_model)</span><br><span class="line"></span><br><span class="line"><span class="comment"># calculate shap values. This is what we will plot.</span></span><br><span class="line"><span class="comment"># Calculate shap_values for all of val_X rather than a single row, to have more data for plot.</span></span><br><span class="line">shap_values = explainer.shap_values(val_X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make plot. Index of [1] is explained in text below.</span></span><br><span class="line">shap.summary_plot(shap_values[<span class="number">1</span>], val_X)</span><br></pre></td></tr></table></figure>
<p>输出结果为：</p>
<img data-src="/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/mlx_13.png" class="">

<p>代码并不太复杂。但有一些注意事项。</p>
<ul>
<li>绘图时，我们调用<code>shap_values[1]</code>。对于分类问题，每个可能的结果都有一个单独的<code>SHAP</code>数组值。在本例中，我们索引以获取预测“<code>True</code>”的<code>SHA</code>值。</li>
<li>计算<code>SHAP</code>值可能会很慢。在这里不是问题，因为这个数据集很小。但是，在运行它们以使用合理大小的数据集进行绘图时，您需要小心。 例外情况是使用<code>xgboost</code>模型时，<code>SHAP</code>对其进行了一些优化，因此速度要快得多。</li>
</ul>
<p>这提供了模型的一个很好的概述，但我们可能想深入研究单个特征。这就是<code>SHAP</code>依赖图发挥作用的地方。</p>
<h5 id="SHAP依赖性贡献图"><a href="#SHAP依赖性贡献图" class="headerlink" title="SHAP依赖性贡献图"></a>SHAP依赖性贡献图</h5><p>我们之前使用部分依赖图来显示单个特征如何影响预测。这些内容富有洞察力，并且与许多现实世界的用例相关。另外，只需付出一点努力，就可以向非技术受众解释它们。但有很多东西他们没有表现出来。例如，效果的分布是什么？具有某个值的效果是相当恒定的，还是根据其他特征的值而变化很大。<code>SHAP</code>依赖贡献图提供了与<code>PDP</code>类似的见解，但它们添加了更多细节。</p>
<img data-src="/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/mlx_14.png" class="">

<p>首先关注形状，稍后我们将回到颜色。 每个点代表一行数据。水平位置是数据集中的实际值，垂直位置显示该值对预测的影响。这个向上倾斜的事实表明，你拥有的球越多，模型对赢得全场最佳球员奖的预测就越高。分布表明其他特征必须与控球率相互作用。例如，在这里我们突出显示了具有相似控球权值的两个点。 该值导致一个预测增加，并导致另一个预测减少。</p>
<img data-src="/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/mlx_15.png" class="">

<p>为了进行比较，简单的线性回归将生成完美的线图，而无需这种扩展。这表明我们要深入研究相互作用，并且绘图中包含颜色编码以帮助实现这一点。虽然主要趋势是向上，但您可以目视检查它是否因点颜色而变化。为了具体起见，请考虑以下非常狭窄的示例。</p>
<img data-src="/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/mlx_16.png" class="">

<p>这两点在空间上突出，远离上升趋势。它们都是紫色的，表明球队进了一球。您可以将其解释为：<strong>一般来说，控球会增加球队让其球员赢得奖项的机会。但如果他们只进一球，这种趋势就会逆转，如果他们进球那么少，评委可能会因为他们控球太多而惩罚他们</strong>。除了这几个异常值之外，颜色表示的相互作用在这里并不是很引人注目。但有时它会跳入你的视线。</p>
<h5 id="代码中的依赖贡献图"><a href="#代码中的依赖贡献图" class="headerlink" title="代码中的依赖贡献图"></a>代码中的依赖贡献图</h5><p>我们用下面的代码得到依赖贡献图。与<code>summary_plot</code>唯一不同的行是最后一行。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create object that can calculate shap values</span></span><br><span class="line">explainer = shap.TreeExplainer(my_model)</span><br><span class="line"></span><br><span class="line"><span class="comment"># calculate shap values. This is what we will plot.</span></span><br><span class="line">shap_values = explainer.shap_values(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># make plot.</span></span><br><span class="line">shap.dependence_plot(<span class="string">&#x27;Ball Possession %&#x27;</span>, shap_values[<span class="number">1</span>], X, interaction_index=<span class="string">&quot;Goal Scored&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>输出结果为：</p>
<img data-src="/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/mlx_17.png" class="">

<p>如果您没有为<code>interaction_index</code>提供参数，<code>Shapley</code>会使用一些逻辑来选择一个可能有趣的参数。这不需要编写大量代码。但这些技术的技巧在于批判性地思考结果，而不是编写代码本身。</p>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>umbrella
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://fresh88888888.github.io/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/" title="机器学习可解释性">https://fresh88888888.github.io/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/</a>
  </li>
  <li class="post-copyright-license">
      <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/AI/" rel="tag"># AI</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2024/03/04/artificial-intelligence/machine_learning_study/" rel="prev" title="机器学习（初级）">
                  <i class="fa fa-chevron-left"></i> 机器学习（初级）
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2024/03/07/artificial-intelligence/Intermediate_Machine_Learning_study/" rel="next" title="机器学习（中级）">
                  机器学习（中级） <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments utterances-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">辽ICP备15012817号-2 </a>
  </div>
  <div class="copyright">
    &copy; 2022 – 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">umbrella</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">1.2m</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">64:17</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/fresh88888888" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script size="300" alpha="0.6" zIndex="-1" src="https://cdnjs.cloudflare.com/ajax/libs/ribbon.js/1.0.2/ribbon.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.0/jquery.min.js" integrity="sha256-2Pmvv0kuTBOenSvLm6bvfBSSHrUJ+3A7x6P5Ebd07/g=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.8/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/comments.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/utils.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/motion.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/next-boot.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/pjax.min.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/search/local-search.min.js"></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdnjs.cloudflare.com/ajax/libs/pdfobject/2.2.12/pdfobject.min.js","integrity":"sha256-g2xji1rlE3KsGVClvuxTbcR0Kn2+wtQADSff2Tbb4zA="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/tags/pdf.min.js"></script>



  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/fancybox.min.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/pace.min.js"></script>


  
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  <script src="https://cdnjs.cloudflare.com/ajax/libs/quicklink/2.3.0/quicklink.umd.js" integrity="sha256-yvJQOINiH9fWemHn0vCA5lsHWJaHs6/ZmO+1Ft04SvM=" crossorigin="anonymous"></script>
  <script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":true,"archive":true,"delay":true,"timeout":5000,"priority":true,"url":"https://fresh88888888.github.io/2024/03/05/artificial-intelligence/Machine_Learning_Explainability_study/"}</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/quicklink.min.js"></script>
<script class="next-config" data-name="utterances" type="application/json">{"enable":true,"repo":"fresh88888888.github.io","issue_term":"title","theme":"github-light"}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/comments/utterances.min.js"></script>

</body>
</html>
