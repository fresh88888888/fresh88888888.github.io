<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.2">
<link rel="preconnect" href="https://fonts.googleapis.com" crossorigin>
<link rel="preconnect" href="https://cdnjs.cloudflare.com" crossorigin>
  <link rel="apple-touch-icon" sizes="180x180" href="/favicon.ico">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon.ico">
  <link rel="mask-icon" href="/favicon.ico" color="#222">
  <meta name="google-site-verification" content="lk2gSYFP_NyLNFob-fFnt7fm-I_n1ZYws-WZll7mshg">
  <meta name="msvalidate.01" content="6Jdc01DjYOLguhS5">
  <meta name="baidu-site-verification" content="code-NR10G09zww">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic%7Ccursive:300,300italic,400,400italic,700,700italic%7CSource+Code+Pro:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/yellow/pace-theme-minimal.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"fresh88888888.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.17.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"flat"},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":true,"nav":null},"stickytabs":true,"motion":{"enable":true,"async":true,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/local-search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":10,"unescape":false,"preload":true}}</script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/config.min.js"></script>

    <meta name="description" content="介绍特征工程的目标特征工程的目标很简单，就是让您的数据更适合当前的问题。考虑“表观温度”测量，例如炎热指数和风寒。这些量试图根据我们可以直接测量的气温、湿度和风速来测量人类感知的温度。您可以将表观温度视为一种特征工程的结果，试图使观察到的数据与我们真正关心的内容更相关。你可以使用特征工程来实现：  提高模型的预测性能。 减少计算或数据需求。 提高结果的可解释性。">
<meta property="og:type" content="article">
<meta property="og:title" content="特征工程（Python）">
<meta property="og:url" content="https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/index.html">
<meta property="og:site_name" content="UMBRELLA">
<meta property="og:description" content="介绍特征工程的目标特征工程的目标很简单，就是让您的数据更适合当前的问题。考虑“表观温度”测量，例如炎热指数和风寒。这些量试图根据我们可以直接测量的气温、湿度和风速来测量人类感知的温度。您可以将表观温度视为一种特征工程的结果，试图使观察到的数据与我们真正关心的内容更相关。你可以使用特征工程来实现：  提高模型的预测性能。 减少计算或数据需求。 提高结果的可解释性。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_1.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_2.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_3.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_4.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_5.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_6.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_7.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_8.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_9.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_10.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_11.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_12.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_13.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_14.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_15.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_16.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_17.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_18.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_19.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_20.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_21.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_22.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_23.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_24.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_25.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_26.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_27.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_28.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_29.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_30.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_31.png">
<meta property="article:published_time" content="2024-03-13T07:20:32.000Z">
<meta property="article:modified_time" content="2024-03-13T07:20:32.000Z">
<meta property="article:author" content="umbrella">
<meta property="article:tag" content="AI">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_1.png">


<link rel="canonical" href="https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/","path":"2024/03/13/artificial-intelligence/Feature_Engineering_study/","title":"特征工程（Python）"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>特征工程（Python） | UMBRELLA</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">UMBRELLA</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">未雨绸缪，举重若轻</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-算法"><a href="/Algorithm/" rel="section"><i class="fa fa-calendar fa-fw"></i>算法</a></li><li class="menu-item menu-item-c++-&nbsp;编程"><a href="/Programming-C++/" rel="section"><i class="fa fa-heartbeat fa-fw"></i>C++ &nbsp;编程</a></li><li class="menu-item menu-item-rust-编程"><a href="/Programming-Rust/" rel="section"><i class="fa fa-cat fa-fw"></i>Rust 编程</a></li><li class="menu-item menu-item-go-&nbsp;&nbsp;&nbsp;编程"><a href="/Programming-Go/" rel="section"><i class="fa fa-hippo fa-fw"></i>Go &nbsp;&nbsp;&nbsp;编程</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BB%8B%E7%BB%8D"><span class="nav-number">1.</span> <span class="nav-text">介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E7%9A%84%E7%9B%AE%E6%A0%87"><span class="nav-number">1.1.</span> <span class="nav-text">特征工程的目标</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E7%9A%84%E6%8C%87%E5%AF%BC%E5%8E%9F%E5%88%99"><span class="nav-number">1.2.</span> <span class="nav-text">特征工程的指导原则</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%B8%BE%E4%BE%8B-%E6%B7%B7%E5%87%9D%E5%9C%9F%E9%85%8D%E6%96%B9"><span class="nav-number">1.3.</span> <span class="nav-text">举例 - 混凝土配方</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BA%92%E4%BF%A1%E6%81%AF-Mutual-Information"><span class="nav-number">2.</span> <span class="nav-text">互信息(Mutual Information)</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BB%8B%E7%BB%8D-1"><span class="nav-number">2.1.</span> <span class="nav-text">介绍</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BA%92%E4%BF%A1%E6%81%AF%E5%8F%8A%E5%85%B6%E8%A1%A1%E9%87%8F%E7%9A%84%E5%86%85%E5%AE%B9"><span class="nav-number">2.2.</span> <span class="nav-text">互信息及其衡量的内容</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%A7%A3%E9%87%8A%E4%BA%92%E4%BF%A1%E6%81%AF%E5%88%86%E6%95%B0"><span class="nav-number">2.3.</span> <span class="nav-text">解释互信息分数</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%B8%BE%E4%BE%8B-1985-%E5%B9%B4%E6%B1%BD%E8%BD%A6"><span class="nav-number">2.4.</span> <span class="nav-text">举例 - 1985 年汽车</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%88%9B%E5%BB%BA%E7%89%B9%E5%BE%81"><span class="nav-number">3.</span> <span class="nav-text">创建特征</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BB%8B%E7%BB%8D-2"><span class="nav-number">3.1.</span> <span class="nav-text">介绍</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%95%B0%E5%AD%A6%E5%8F%98%E6%8D%A2"><span class="nav-number">3.2.</span> <span class="nav-text">数学变换</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%AE%A1%E6%95%B0"><span class="nav-number">3.3.</span> <span class="nav-text">计数</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%9E%84%E5%BB%BA%E5%92%8C%E5%88%86%E8%A7%A3%E7%89%B9%E5%BE%81"><span class="nav-number">3.4.</span> <span class="nav-text">构建和分解特征</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%BB%84%E5%8F%98%E6%8D%A2"><span class="nav-number">3.5.</span> <span class="nav-text">组变换</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#K-%E5%9D%87%E5%80%BC%E8%81%9A%E7%B1%BB"><span class="nav-number">4.</span> <span class="nav-text">K-均值聚类</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BB%8B%E7%BB%8D-3"><span class="nav-number">4.1.</span> <span class="nav-text">介绍</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%81%9A%E7%B1%BB%E6%A0%87%E7%AD%BE%E4%BD%9C%E4%B8%BA%E7%89%B9%E5%BE%81"><span class="nav-number">4.2.</span> <span class="nav-text">聚类标签作为特征</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#k-Means-Clustering"><span class="nav-number">4.3.</span> <span class="nav-text">k-Means Clustering</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%B8%BE%E4%BE%8B-%E5%8A%A0%E5%B7%9E%E4%BD%8F%E6%88%BF"><span class="nav-number">4.4.</span> <span class="nav-text">举例 - 加州住房</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90%EF%BC%88Principal-Component-Analysis%EF%BC%89"><span class="nav-number">5.</span> <span class="nav-text">主成分分析（Principal Component Analysis）</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BB%8B%E7%BB%8D-4"><span class="nav-number">5.1.</span> <span class="nav-text">介绍</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Principal-Component-Analysis"><span class="nav-number">5.2.</span> <span class="nav-text">Principal Component Analysis</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E7%9A%84PCA"><span class="nav-number">5.3.</span> <span class="nav-text">基于特征工程的PCA</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%B8%BE%E4%BE%8B-1985-%E5%B9%B4%E6%B1%BD%E8%BD%A6-1"><span class="nav-number">5.4.</span> <span class="nav-text">举例 - 1985 年汽车</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%9B%AE%E6%A0%87%E7%BC%96%E7%A0%81%EF%BC%88Target-Encoding%EF%BC%89"><span class="nav-number">6.</span> <span class="nav-text">目标编码（Target Encoding）</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BB%8B%E7%BB%8D-5"><span class="nav-number">6.1.</span> <span class="nav-text">介绍</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Target-Encoding"><span class="nav-number">6.2.</span> <span class="nav-text">Target Encoding</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Smoothing"><span class="nav-number">6.3.</span> <span class="nav-text">Smoothing</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%B8%BE%E4%BE%8B-MovieLens1M"><span class="nav-number">6.4.</span> <span class="nav-text">举例 - MovieLens1M</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="umbrella"
      src="/avatar.jpeg">
  <p class="site-author-name" itemprop="name">umbrella</p>
  <div class="site-description" itemprop="description">没事就多看看书</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">220</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">21</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">65</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/fresh88888888" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;fresh88888888" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:fresh888888@foxmail.com" title="E-Mail → mailto:fresh888888@foxmail.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
    </div>

    
    <div class="sidebar-inner sidebar-blogroll">
      <div class="links-of-blogroll animated">
        <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
          链接
        </div>
        <ul class="links-of-blogroll-list">
            <li class="links-of-blogroll-item">
              <a href="https://www.rust-lang.org/zh-CN/" title="https:&#x2F;&#x2F;www.rust-lang.org&#x2F;zh-CN&#x2F;" rel="noopener" target="_blank">Rust</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://go.dev/" title="https:&#x2F;&#x2F;go.dev&#x2F;" rel="noopener" target="_blank">Golang</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://isocpp.org/" title="https:&#x2F;&#x2F;isocpp.org&#x2F;" rel="noopener" target="_blank">C++</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://www.python.org/" title="https:&#x2F;&#x2F;www.python.org&#x2F;" rel="noopener" target="_blank">Python</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://doc.rust-lang.org/cargo/index.html" title="https:&#x2F;&#x2F;doc.rust-lang.org&#x2F;cargo&#x2F;index.html" rel="noopener" target="_blank">Cargo</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://gist.github.com/rxaviers/7360908" title="https:&#x2F;&#x2F;gist.github.com&#x2F;rxaviers&#x2F;7360908" rel="noopener" target="_blank">Emoji</a>
            </li>
        </ul>
      </div>
    </div>
        <div class="pjax">
        </div>
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/avatar.jpeg">
      <meta itemprop="name" content="umbrella">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="UMBRELLA">
      <meta itemprop="description" content="没事就多看看书">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="特征工程（Python） | UMBRELLA">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          特征工程（Python）
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-03-13 15:20:32" itemprop="dateCreated datePublished" datetime="2024-03-13T15:20:32+08:00">2024-03-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" itemprop="url" rel="index"><span itemprop="name">人工智能</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>9.2k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>31 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><h5 id="特征工程的目标"><a href="#特征工程的目标" class="headerlink" title="特征工程的目标"></a>特征工程的目标</h5><p>特征工程的目标很简单，<strong>就是让您的数据更适合当前的问题</strong>。考虑“表观温度”测量，例如炎热指数和风寒。这些量试图根据我们可以直接测量的气温、湿度和风速来测量人类感知的温度。您可以将表观温度视为一种特征工程的结果，试图使观察到的数据与我们真正关心的内容更相关。你可以使用特征工程来实现：</p>
<ul>
<li>提高模型的预测性能。</li>
<li>减少计算或数据需求。</li>
<li>提高结果的可解释性。<span id="more"></span></li>
</ul>
<h5 id="特征工程的指导原则"><a href="#特征工程的指导原则" class="headerlink" title="特征工程的指导原则"></a>特征工程的指导原则</h5><p>为了使某个特征有用，它必须与模型能够学习的目标有关系。例如，线性模型只能学习线性关系。因此，当使用线性模型时，您的目标是转换特征以使它们与目标的关系呈线性。这里的关键思想是，应用于特征的转换本质上成为模型本身的一部分。假设您试图根据一侧的长度来预测方形地块的价格。将线性模型直接拟合到长度会产生较差的结果：关系不是线性的。</p>
<img data-src="/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_1.png" class="">

<p>然而，如果我们对长度特征进行平方以获得“面积”，我们就会创建线性关系。将<code>Area</code>添加到特征集中意味着该线性模型现在可以拟合抛物线。换句话说，对特征进行平方使线性模型能够拟合平方特征。</p>
<img data-src="/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_2.png" class="">

<p>这应该向您展示为什么在特征工程上投入的时间可以获得如此高的回报。无论您的模型无法学习什么关系，您都可以通过转换来提供。在开发功能集时，请考虑您的模型可以使用哪些信息来实现其最佳性能。</p>
<h5 id="举例-混凝土配方"><a href="#举例-混凝土配方" class="headerlink" title="举例 - 混凝土配方"></a>举例 - 混凝土配方</h5><p>为了说明这些想法，我们将了解如何向数据集添加一些合成特征来提高随机森林模型的预测性能。混凝土数据集包含各种混凝土配方和最终产品的抗压强度，这是衡量该种混凝土可以承受多少载荷的指标。该数据集的任务是预测给定配方的混凝土的抗压强度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;../input/fe-course-data/concrete.csv&quot;</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>
<p>结果输出为：</p>
<img data-src="/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_3.png" class="">

<p>您可以在这里看到各种混凝土的各种成分。稍后我们将看到添加从这些特征派生的一些额外的综合特征如何帮助模型学习它们之间的重要关系。我们首先通过在未增强的数据集上训练模型来建立基线。这将帮助我们确定我们的新功能是否真正有用。在特征工程过程开始时建立这样的基线是一个很好的做法。基线分数可以帮助您决定您的新功能是否值得保留，或者您是否应该放弃它们并可能尝试其他功能。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">X = df.copy()</span><br><span class="line">y = X.pop(<span class="string">&quot;CompressiveStrength&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train and score baseline model</span></span><br><span class="line">baseline = RandomForestRegressor(criterion=<span class="string">&quot;absolute_error&quot;</span>, random_state=<span class="number">0</span>)</span><br><span class="line">baseline_score = cross_val_score(</span><br><span class="line">    baseline, X, y, cv=<span class="number">5</span>, scoring=<span class="string">&quot;neg_mean_absolute_error&quot;</span></span><br><span class="line">)</span><br><span class="line">baseline_score = -<span class="number">1</span> * baseline_score.mean()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;MAE Baseline Score: <span class="subst">&#123;baseline_score:<span class="number">.4</span>&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>结果输出为：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MAE Baseline Score: 8.232</span><br></pre></td></tr></table></figure>
<p>如果您曾经在家做饭，您可能知道食谱中成分的比例通常比其绝对数量更能预测食谱的结果。我们可能会推断，上述特征的比率将是压缩强度的良好预测指标。下面的单元格向数据集添加了三个新的比率特征。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">X = df.copy()</span><br><span class="line">y = X.pop(<span class="string">&quot;CompressiveStrength&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create synthetic features</span></span><br><span class="line">X[<span class="string">&quot;FCRatio&quot;</span>] = X[<span class="string">&quot;FineAggregate&quot;</span>] / X[<span class="string">&quot;CoarseAggregate&quot;</span>]</span><br><span class="line">X[<span class="string">&quot;AggCmtRatio&quot;</span>] = (X[<span class="string">&quot;CoarseAggregate&quot;</span>] + X[<span class="string">&quot;FineAggregate&quot;</span>]) / X[<span class="string">&quot;Cement&quot;</span>]</span><br><span class="line">X[<span class="string">&quot;WtrCmtRatio&quot;</span>] = X[<span class="string">&quot;Water&quot;</span>] / X[<span class="string">&quot;Cement&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train and score model on dataset with additional ratio features</span></span><br><span class="line">model = RandomForestRegressor(criterion=<span class="string">&quot;absolute_error&quot;</span>, random_state=<span class="number">0</span>)</span><br><span class="line">score = cross_val_score(</span><br><span class="line">    model, X, y, cv=<span class="number">5</span>, scoring=<span class="string">&quot;neg_mean_absolute_error&quot;</span></span><br><span class="line">)</span><br><span class="line">score = -<span class="number">1</span> * score.mean()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;MAE Score with Ratio Features: <span class="subst">&#123;score:<span class="number">.4</span>&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>结果输出为：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MAE Score with Ratio Features: 7.948</span><br></pre></td></tr></table></figure>
<p>果然，性能提高了！这证明这些新的比率特征向模型暴露了之前未检测到的重要信息。</p>
<h4 id="互信息-Mutual-Information"><a href="#互信息-Mutual-Information" class="headerlink" title="互信息(Mutual Information)"></a>互信息(Mutual Information)</h4><h5 id="介绍-1"><a href="#介绍-1" class="headerlink" title="介绍"></a>介绍</h5><p>第一次遇到新的数据集有时会让人感到不知所措。您可能会看到成百上千个特征，甚至没有任何说明。你从哪里开始呢？重要的第一步是使用特征效用指标构建排名，该指标是衡量特征与目标之间关联性的函数。然后，您可以选择一小部分最有用的特征进行最初开发。我们将使用的指标称为“互信息”。互信息很像相关性，因为它衡量两个量之间的关系。互信息的优点是可以检测任何类型的关系，而相关性只能检测线性关系。互信息是一个很好的通用指标，在功能开发开始时（当您可能还不知道要使用什么模型时）特别有用。 </p>
<p>互信息：</p>
<ul>
<li>易于使用和解释。</li>
<li>计算效率高。</li>
<li>理论上是有根据的。</li>
<li>抵抗过度拟合。</li>
<li>能够检测任何类型的关系。</li>
</ul>
<h5 id="互信息及其衡量的内容"><a href="#互信息及其衡量的内容" class="headerlink" title="互信息及其衡量的内容"></a>互信息及其衡量的内容</h5><p>互信息用不确定性来描述关系。两个量之间的互信息(<code>MI</code>)衡量一个量的知识减少另一个量的不确定性的程度。如果您知道某个特征的价值，您对目标的信心会有多大？这是艾姆斯住房数据的一个示例。该图显示了房屋的外部质量与其售价之间的关系。每个点代表一座房子。</p>
<img data-src="/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_4.png" class="">

<p>从图中我们可以看出，知道了<code>ExterQual</code>的值应该可以让你更加确定对应的<code>SalePrice——ExterQual</code>的每个类别都倾向于将<code>SalePrice</code>集中在一定的范围内。<code>ExterQual</code>与<code>SalePrice</code>的相互信息是<code>SalePrice</code>的不确定性对<code>ExterQual</code>的四个值的平均减少量。例如，由于“公平”出现的频率低于“典型”，因此“公平”在<code>MI</code>分数中的权重较小。（技术说明：我们所说的不确定性是使用信息论中称为“熵”的量来测量的。变量的熵大致意味着：“您需要多少是或否问题来描述该情况的发生。”您要问的问题越多，您对变量的不确定性就越大。互信息是您期望该功能回答有关目标的多少问题。）</p>
<h5 id="解释互信息分数"><a href="#解释互信息分数" class="headerlink" title="解释互信息分数"></a>解释互信息分数</h5><p>数量之间的最小可能互信息为<code>0.0</code>。当<code>MI</code>为零时，这些量是独立的：两者都无法告诉您有关对方的任何信息。相反，理论上<code>MI</code>没有上限。但实际上，高于<code>2.0</code>左右的值并不常见。（互信息是一对数量，因此增长非常缓慢。）下图将让您了解<code>MI</code>值如何对应于特征与目标的关联类型和程度。</p>
<img data-src="/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_5.png" class="">

<p>应用互信息时需要记住以下几点：</p>
<ul>
<li><code>MI</code>可以帮助您了解某个特征作为目标预测因子（单独考虑）的相对潜力。</li>
<li>一个特征在与其他特征交互时可能会提供非常丰富的信息，但单独使用时可能不会提供如此丰富的信息。<code>MI</code>无法检测特征之间的交互。它是一个单变量度量。</li>
<li>某个特征的实际用途取决于您使用该特征的型号。一项特征仅在其与目标的关系是您的模型可以学习的范围内才有用。仅仅因为某个特征具有高<code>MI</code>分数并不意味着您的模型能够利用该信息执行任何操作。您可能需要首先转换特征才能公开关联。</li>
</ul>
<h5 id="举例-1985-年汽车"><a href="#举例-1985-年汽车" class="headerlink" title="举例 - 1985 年汽车"></a>举例 - 1985 年汽车</h5><p>汽车数据集包含<code>1985</code>年车型的<code>193</code>辆汽车。该数据集的目标是根据汽车的<code>23</code>个特征（例如品牌、车身样式和马力）来预测汽车的价格（目标）。在此示例中，我们将利用互信息对特征进行排序，并通过数据可视化研究结果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line">plt.style.use(<span class="string">&quot;seaborn-whitegrid&quot;</span>)</span><br><span class="line"></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;../input/fe-course-data/autos.csv&quot;</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>
<p><code>MI</code>的<code>scikit-learn</code>算法以不同于连续特征的方式处理离散特征。因此，您需要告诉它哪些是哪些。根据经验，任何必须具有浮点数据类型的东西都不是离散的。通过分类（对象或分类数据类型）提供标签编码，可以将其视为离散的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">X = df.copy()</span><br><span class="line">y = X.pop(<span class="string">&quot;price&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Label encoding for categoricals</span></span><br><span class="line"><span class="keyword">for</span> colname <span class="keyword">in</span> X.select_dtypes(<span class="string">&quot;object&quot;</span>):</span><br><span class="line">    X[colname], _ = X[colname].factorize()</span><br><span class="line"></span><br><span class="line"><span class="comment"># All discrete features should now have integer dtypes (double-check this before using MI!)</span></span><br><span class="line">discrete_features = X.dtypes == <span class="built_in">int</span></span><br></pre></td></tr></table></figure>
<p><code>Scikit-learn</code>的<code>feature_selection</code>模块中有两种互信息指标：一种用于实值目标 (<code>mutual_info_regression</code>)，一种用于分类目标 (<code>mutual_info_classif</code>)。我们的目标价格是有真实价值的。下一个单元格计算特征的<code>MI</code>分数并将它们包装在一个漂亮的数据框中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> mutual_info_regression</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_mi_scores</span>(<span class="params">X, y, discrete_features</span>):</span><br><span class="line">    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)</span><br><span class="line">    mi_scores = pd.Series(mi_scores, name=<span class="string">&quot;MI Scores&quot;</span>, index=X.columns)</span><br><span class="line">    mi_scores = mi_scores.sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">return</span> mi_scores</span><br><span class="line"></span><br><span class="line">mi_scores = make_mi_scores(X, y, discrete_features)</span><br><span class="line">mi_scores[::<span class="number">3</span>]  <span class="comment"># show a few features with their MI scores</span></span><br></pre></td></tr></table></figure>
<p>结果输出为：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">curb_weight          1.540126</span><br><span class="line">highway_mpg          0.951700</span><br><span class="line">length               0.621566</span><br><span class="line">fuel_system          0.485085</span><br><span class="line">stroke               0.389321</span><br><span class="line">num_of_cylinders     0.330988</span><br><span class="line">compression_ratio    0.133927</span><br><span class="line">fuel_type            0.048139</span><br><span class="line">Name: MI Scores, dtype: float64</span><br></pre></td></tr></table></figure>
<p>下边转换为条形图展示更为直观：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">plot_mi_scores</span>(<span class="params">scores</span>):</span><br><span class="line">    scores = scores.sort_values(ascending=<span class="literal">True</span>)</span><br><span class="line">    width = np.arange(<span class="built_in">len</span>(scores))</span><br><span class="line">    ticks = <span class="built_in">list</span>(scores.index)</span><br><span class="line">    plt.barh(width, scores)</span><br><span class="line">    plt.yticks(width, ticks)</span><br><span class="line">    plt.title(<span class="string">&quot;Mutual Information Scores&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.figure(dpi=<span class="number">100</span>, figsize=(<span class="number">8</span>, <span class="number">5</span>))</span><br><span class="line">plot_mi_scores(mi_scores)</span><br></pre></td></tr></table></figure>
<img data-src="/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_6.png" class="">

<p>正如我们所预期的那样，高分遏制权重特征与目标价格表现出很强的关系。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.relplot(x=<span class="string">&quot;curb_weight&quot;</span>, y=<span class="string">&quot;price&quot;</span>, data=df);</span><br></pre></td></tr></table></figure>
<img data-src="/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_7.png" class="">

<p><code>Fuel_type</code>特征的<code>MI</code>分数相当低，但从图中可以看出，它清楚地区分了马力特征中具有不同趋势的两个价格群体。这表明<code>Fuel_type</code>具有交互作用，并且可能并非不重要。在根据<code>MI</code>分数确定某个特征不重要之前，最好调查一下任何可能的交互影响——领域知识可以在这里提供很多指导。</p>
<img data-src="/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_8.png" class="">

<p>数据可视化是对特征工程工具箱的一个很好的补充。除了互信息等实用指标之外，此类可视化可以帮助您发现数据中的重要关系。</p>
<h4 id="创建特征"><a href="#创建特征" class="headerlink" title="创建特征"></a>创建特征</h4><h5 id="介绍-2"><a href="#介绍-2" class="headerlink" title="介绍"></a>介绍</h5><p>发现新特征的技巧：</p>
<ul>
<li>研究问题领域以获得领域知识。如果您的问题是预测房价，请对房地产进行一些研究。维基百科可能是一个很好的起点，但书籍和期刊文章通常会提供最好的信息。</li>
<li>使用数据可视化。可视化可以揭示特征分布的情况或可以简化的复杂关系。在完成特征工程过程时，请务必可视化您的数据集。</li>
</ul>
<h5 id="数学变换"><a href="#数学变换" class="headerlink" title="数学变换"></a>数学变换</h5><p>数字特征之间的关系通常通过数学公式来表达，您在领域研究中经常会遇到这些公式。在<code>Pandas</code>中，您可以对列应用算术运算，就像它们是普通数字一样。汽车数据集中包含描述汽车发动机的特征。 研究产生了各种用于创建潜在有用的新特征的公式。例如，“冲程比”是衡量发动机效率与性能的指标：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">autos[<span class="string">&quot;stroke_ratio&quot;</span>] = autos.stroke / autos.bore</span><br><span class="line"></span><br><span class="line">autos[[<span class="string">&quot;stroke&quot;</span>, <span class="string">&quot;bore&quot;</span>, <span class="string">&quot;stroke_ratio&quot;</span>]].head()</span><br></pre></td></tr></table></figure>
<p>组合越复杂，模型学习就越困难，就像发动机“排量”（衡量其功率的指标）的公式一样：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">autos[<span class="string">&quot;displacement&quot;</span>] = (</span><br><span class="line">    np.pi * ((<span class="number">0.5</span> * autos.bore) ** <span class="number">2</span>) * autos.stroke * autos.num_of_cylinders</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>数据可视化可以建议转换，通常是通过幂或对数“重塑”特征。例如，<code>WindSpeed</code>在美国事故中的分布就非常不均匀。在这种情况下，对数可以有效地对其进行标准化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># If the feature has 0.0 values, use np.log1p (log(1+x)) instead of np.log</span></span><br><span class="line">accidents[<span class="string">&quot;LogWindSpeed&quot;</span>] = accidents.WindSpeed.apply(np.log1p)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot a comparison</span></span><br><span class="line">fig, axs = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">8</span>, <span class="number">4</span>))</span><br><span class="line">sns.kdeplot(accidents.WindSpeed, shade=<span class="literal">True</span>, ax=axs[<span class="number">0</span>])</span><br><span class="line">sns.kdeplot(accidents.LogWindSpeed, shade=<span class="literal">True</span>, ax=axs[<span class="number">1</span>]);</span><br></pre></td></tr></table></figure>
<h5 id="计数"><a href="#计数" class="headerlink" title="计数"></a>计数</h5><p>描述某种事物存在或不存在的特征通常是成组出现的，例如疾病的一组危险因素。您可以通过创建计数来聚合此类特征。这些特征将以二进制（<code>1</code>表示存在，<code>0</code>表示不存在）或布尔值（<code>True</code>或 <code>False</code>）。在<code>Python</code>中，布尔值可以像整数一样相加。在交通事故中，有几个特征指示事故附近是否存在某些道路物体。这将使用<code>sum</code>方法创建附近道路要素总数的计数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">roadway_features = [<span class="string">&quot;Amenity&quot;</span>, <span class="string">&quot;Bump&quot;</span>, <span class="string">&quot;Crossing&quot;</span>, <span class="string">&quot;GiveWay&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Junction&quot;</span>, <span class="string">&quot;NoExit&quot;</span>, <span class="string">&quot;Railway&quot;</span>, <span class="string">&quot;Roundabout&quot;</span>, <span class="string">&quot;Station&quot;</span>, <span class="string">&quot;Stop&quot;</span>,</span><br><span class="line">    <span class="string">&quot;TrafficCalming&quot;</span>, <span class="string">&quot;TrafficSignal&quot;</span>]</span><br><span class="line">accidents[<span class="string">&quot;RoadwayFeatures&quot;</span>] = accidents[roadway_features].<span class="built_in">sum</span>(axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">accidents[roadway_features + [<span class="string">&quot;RoadwayFeatures&quot;</span>]].head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<img data-src="/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_9.png" class="">

<p>您还可以使用数据框的内置方法来创建布尔值。混凝土数据集中是混凝土配方中组分的数量。许多配方缺少一种或多种成分（即成分值为<code>0</code>）。这将使用数据框的内置大于<code>gt</code>方法来计算配方中有多少个组件：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">components = [ <span class="string">&quot;Cement&quot;</span>, <span class="string">&quot;BlastFurnaceSlag&quot;</span>, <span class="string">&quot;FlyAsh&quot;</span>, <span class="string">&quot;Water&quot;</span>,</span><br><span class="line">               <span class="string">&quot;Superplasticizer&quot;</span>, <span class="string">&quot;CoarseAggregate&quot;</span>, <span class="string">&quot;FineAggregate&quot;</span>]</span><br><span class="line">concrete[<span class="string">&quot;Components&quot;</span>] = concrete[components].gt(<span class="number">0</span>).<span class="built_in">sum</span>(axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">concrete[components + [<span class="string">&quot;Components&quot;</span>]].head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<img data-src="/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_10.png" class="">

<h5 id="构建和分解特征"><a href="#构建和分解特征" class="headerlink" title="构建和分解特征"></a>构建和分解特征</h5><p>通常，您会拥有复杂的字符串，可以将其有效地分解为更简单的部分。</p>
<ul>
<li><code>ID numbers</code>: <code>&#39;123-45-6789&#39;</code></li>
<li><code>Phone numbers</code>: <code>&#39;(999) 555-0123&#39;</code></li>
<li><code>Street addresses</code>: <code>&#39;8241 Kaggle Ln., Goose City, NV&#39;</code></li>
<li><code>Internet addresses</code>: <code>&#39;http://www.kaggle.com</code></li>
<li><code>Product codes</code>: <code>&#39;0 36000 29145 2&#39;</code></li>
<li><code>Dates and times</code>: <code>&#39;Mon Sep 30 07:06:05 2013&#39;</code></li>
</ul>
<p>此类功能通常具有某种可供您使用的结构。例如，美国的电话号码有一个区号（“(<code>999</code>)”部分），可以告诉您呼叫者的位置。<code>str</code>访问器允许您应用字符串方法，例如直接将<code>split</code>应用于列。客户终身价值数据集包含描述保险公司客户的特征。从保单特征中，我们可以将类型与覆盖级别分开：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">customer[[<span class="string">&quot;Type&quot;</span>, <span class="string">&quot;Level&quot;</span>]] = (  <span class="comment"># Create two new features</span></span><br><span class="line">    customer[<span class="string">&quot;Policy&quot;</span>]           <span class="comment"># from the Policy feature</span></span><br><span class="line">    .<span class="built_in">str</span>                         <span class="comment"># through the string accessor</span></span><br><span class="line">    .split(<span class="string">&quot; &quot;</span>, expand=<span class="literal">True</span>)     <span class="comment"># by splitting on &quot; &quot;</span></span><br><span class="line">                                 <span class="comment"># and expanding the result into separate columns</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">customer[[<span class="string">&quot;Policy&quot;</span>, <span class="string">&quot;Type&quot;</span>, <span class="string">&quot;Level&quot;</span>]].head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<img data-src="/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_11.png" class="">

<p>如果您有理由相信组合中存在一些交互，您也可以将简单特征加入到组合特征中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">autos[<span class="string">&quot;make_and_style&quot;</span>] = autos[<span class="string">&quot;make&quot;</span>] + <span class="string">&quot;_&quot;</span> + autos[<span class="string">&quot;body_style&quot;</span>]</span><br><span class="line">autos[[<span class="string">&quot;make&quot;</span>, <span class="string">&quot;body_style&quot;</span>, <span class="string">&quot;make_and_style&quot;</span>]].head()</span><br></pre></td></tr></table></figure>
<img data-src="/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_12.png" class="">

<h5 id="组变换"><a href="#组变换" class="headerlink" title="组变换"></a>组变换</h5><p>最后，我们有<strong>组变换</strong>，它可以聚合按某个类别分组的多行信息。通过组变换，您可以创建诸如“一个人居住州的平均收入”或“按类型在工作日发行的电影的比例”等功能。如果您发现了类别交互，那么针对该类别的组变换可能是值得研究的好东西。使用聚合函数，组变换组合了两个特征：一个提供分组的分类特征和另一个要聚合其值的特征。对于“按州划分的平均收入”，您可以选择“州”作为分组特征，选择“平均值”作为聚合函数，选择“收入”作为聚合特征。为了在<code>Pandas</code>中计算这一点，我们使用<code>groupby</code>和<code>transform</code>方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">customer[<span class="string">&quot;AverageIncome&quot;</span>] = (</span><br><span class="line">    customer.groupby(<span class="string">&quot;State&quot;</span>)  <span class="comment"># for each state</span></span><br><span class="line">    [<span class="string">&quot;Income&quot;</span>]                 <span class="comment"># select the income</span></span><br><span class="line">    .transform(<span class="string">&quot;mean&quot;</span>)         <span class="comment"># and compute its mean</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">customer[[<span class="string">&quot;State&quot;</span>, <span class="string">&quot;Income&quot;</span>, <span class="string">&quot;AverageIncome&quot;</span>]].head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<img data-src="/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_13.png" class="">

<p><code>Mean</code>函数是一个内置的数据帧方法，这意味着我们可以将它作为字符串传递来进行转换。其他方便的方法包括<code>max、min、median、var、std</code>和<code>count</code>。以下是计算数据集中每个状态出现的频率的方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">customer[<span class="string">&quot;StateFreq&quot;</span>] = (</span><br><span class="line">    customer.groupby(<span class="string">&quot;State&quot;</span>)</span><br><span class="line">    [<span class="string">&quot;State&quot;</span>]</span><br><span class="line">    .transform(<span class="string">&quot;count&quot;</span>)</span><br><span class="line">    / customer.State.count()</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">customer[[<span class="string">&quot;State&quot;</span>, <span class="string">&quot;StateFreq&quot;</span>]].head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<img data-src="/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_14.png" class="">

<p>您可以使用这样的转换来为分类特征创建“频率编码”。如果您使用训练和验证拆分，为了保持它们的独立性，最好仅使用训练集创建分组特征，然后将其加入验证集。在训练集上使用 <code>drop_duplicates</code>创建一组唯一的值后，我们可以使用验证集的合并方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create splits</span></span><br><span class="line">df_train = customer.sample(frac=<span class="number">0.5</span>)</span><br><span class="line">df_valid = customer.drop(df_train.index)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the average claim amount by coverage type, on the training set</span></span><br><span class="line">df_train[<span class="string">&quot;AverageClaim&quot;</span>] = df_train.groupby(<span class="string">&quot;Coverage&quot;</span>)[<span class="string">&quot;ClaimAmount&quot;</span>].transform(<span class="string">&quot;mean&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Merge the values into the validation set</span></span><br><span class="line">df_valid = df_valid.merge(</span><br><span class="line">    df_train[[<span class="string">&quot;Coverage&quot;</span>, <span class="string">&quot;AverageClaim&quot;</span>]].drop_duplicates(),</span><br><span class="line">    on=<span class="string">&quot;Coverage&quot;</span>,</span><br><span class="line">    how=<span class="string">&quot;left&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">df_valid[[<span class="string">&quot;Coverage&quot;</span>, <span class="string">&quot;AverageClaim&quot;</span>]].head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<img data-src="/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_15.png" class="">

<p><strong>创建特征的技巧</strong>: 创建特征时最好记住模型自身的优点和缺点。以下是一些指导原则：</p>
<ul>
<li>线性模型自然地学习”和”与”差”，但无法学习更复杂的东西。</li>
<li>对于大多数模型来说，比率似乎很难学习。比率组合通常会带来一些简单的性能提升。</li>
<li>线性模型和神经网络通常在归一化特征方面表现更好。神经网络特别需要缩放到离<code>0</code>不太远的值的特征。基于树的模型（如随机森林和<code>XGBoost</code>）有时可以从归一化中受益，但通常效果要差得多。</li>
<li>树模型可以学习近似任何特征组合，但是当组合特别重要时，它们仍然可以从显式创建的组合中受益，尤其是在数据有限的情况下。</li>
<li>计数对于树模型特别有用，因为这些模型没有一种自然的方式来同时聚合多个特征的信息。</li>
</ul>
<h4 id="K-均值聚类"><a href="#K-均值聚类" class="headerlink" title="K-均值聚类"></a>K-均值聚类</h4><h5 id="介绍-3"><a href="#介绍-3" class="headerlink" title="介绍"></a>介绍</h5><p>无监督算法不利用目标；相反，它们的目的是学习数据的某些属性，以某种方式表示特征的结构。在预测特征工程的背景下，您可以将无监督算法视为“特征发现”技术。聚类意味着根据数据点彼此之间的相似程度将数据点分配到组中。可以说，聚类算法使“物以类聚”。例如，当用于特征工程时，我们可以尝试发现代表细分市场的客户群体，或具有相似天气模式的地理区域。添加集群标签的特征可以帮助机器学习模型理清复杂的空间或邻近关系。</p>
<h5 id="聚类标签作为特征"><a href="#聚类标签作为特征" class="headerlink" title="聚类标签作为特征"></a>聚类标签作为特征</h5><p>应用于单个实值特征时，聚类的作用类似于传统的“分箱”或“离散化”变换。在多个特征上，它就像“多维分箱”（有时称为矢量量化）。</p>
<img data-src="/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_16.png" class="">

<p>重要的是要记住，这个集群特征是分类的。在这里，它显示为标签编码（即，作为整数序列），如典型的聚类算法所产生的那样；根据您的型号<code>one-hot</code>编码可能更合适。添加集群标签的动机是集群会将特征之间的复杂关系分解为更简单的块。然后，我们的模型可以学习更简单的块，而不必一次学习复杂的整体。这是一种“分而治之”的策略。</p>
<img data-src="/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_17.png" class="">

<p>该图显示了聚类如何改进简单的线性模型。<code>YearBuilt</code>和<code>SalePrice</code>之间的曲线关系对于这种模型来说太复杂了——它不适合。然而，在较小的块上，关系几乎是线性的，并且模型可以轻松学习。</p>
<h5 id="k-Means-Clustering"><a href="#k-Means-Clustering" class="headerlink" title="k-Means Clustering"></a>k-Means Clustering</h5><p>聚类算法有很多。 它们的不同之处主要在于如何衡量“相似性”以及使用哪些类型的特征。我们将使用的算法<code>k-means</code>非常直观且易于在特征工程环境中应用。根据您的应用程序，另一种算法可能更合适。<code>K</code>均值聚类使用普通直线距离（换句话说，欧几里得距离）来衡量相似性。它通过在特征空间内放置许多点（称为质心）来创建簇。数据集中的每个点都分配给最接近的质心的簇。“<code>k-means</code>”中的“<code>k</code>”是它创建的质心（即簇）数量。您可以想象每个质心通过一系列辐射圆捕获点。当来自竞争质心的圆组重叠时，它们会形成一条线。结果就是所谓的<code>Voronoi</code>镶嵌。镶嵌会向您显示未来数据将分配到哪些集群；镶嵌本质上是<code>k-means</code>从训练数据中学习的内容。上面<code>Ames</code>数据集上的聚类是<code>k-means</code>聚类。这是同一张图，显示了镶嵌和质心。</p>
<img data-src="/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_18.png" class="">

<p>让我们回顾一下<code>k</code>均值算法如何学习聚类以及这对特征工程意味着什么。我们将重点关注<code>scikit-learn</code>实现中的三个参数：<code>n_clusters、max_iter</code>和<code>n_init</code>。这是一个简单的两步过程。该算法首先随机初始化一些预定义数量（<code>n_clusters</code>）的质心。然后它迭代这两个操作。</p>
<ul>
<li>将点分配给最近的簇质心。</li>
<li>移动每个质心以最小化到其点的距离。</li>
</ul>
<p>它迭代这两个步骤，直到质心不再移动，或者直到经过最大迭代次数 (<code>max_iter</code>)。质心的初始随机位置经常以较差的聚类结束。因此，该算法会重复多次（<code>n_init</code>）并返回每个点与其质心之间总距离最小的聚类，即最佳聚类。下面的动画显示了正在运行的算法。它说明了结果对初始质心的依赖性以及迭代直至收敛的重要性。</p>
<p>对于大量聚类，您可能需要增加<code>max_iter</code>，对于复杂数据集，您可能需要增加<code>n_init</code>。通常，您需要自己选择的唯一参数是<code>n_clusters</code>（即<code>k</code>）。一组特征的最佳划分取决于您正在使用的模型以及您想要预测的内容，因此最好像任何超参数一样对其进行调整（例如通过交叉验证）。</p>
<h5 id="举例-加州住房"><a href="#举例-加州住房" class="headerlink" title="举例 - 加州住房"></a>举例 - 加州住房</h5><p>作为空间特征，加州住房的“纬度”和“经度”自然成为<code>k</code>均值聚类的候选者。在此示例中，我们将这些与“<code>MedInc</code>”（收入中位数）聚集在一起，以在加利福尼亚州的不同地区创建经济细分。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"></span><br><span class="line">plt.style.use(<span class="string">&quot;seaborn-whitegrid&quot;</span>)</span><br><span class="line">plt.rc(<span class="string">&quot;figure&quot;</span>, autolayout=<span class="literal">True</span>)</span><br><span class="line">plt.rc(</span><br><span class="line">    <span class="string">&quot;axes&quot;</span>,</span><br><span class="line">    labelweight=<span class="string">&quot;bold&quot;</span>,</span><br><span class="line">    labelsize=<span class="string">&quot;large&quot;</span>,</span><br><span class="line">    titleweight=<span class="string">&quot;bold&quot;</span>,</span><br><span class="line">    titlesize=<span class="number">14</span>,</span><br><span class="line">    titlepad=<span class="number">10</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;../input/fe-course-data/housing.csv&quot;</span>)</span><br><span class="line">X = df.loc[:, [<span class="string">&quot;MedInc&quot;</span>, <span class="string">&quot;Latitude&quot;</span>, <span class="string">&quot;Longitude&quot;</span>]]</span><br><span class="line">X.head()</span><br></pre></td></tr></table></figure>
<p>由于<code>k</code>均值聚类对规模很敏感，因此重新调整或标准化具有极值的数据可能是一个好主意。我们的功能已经大致处于相同的规模，因此我们将保持原样。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create cluster feature</span></span><br><span class="line">kmeans = KMeans(n_clusters=<span class="number">6</span>)</span><br><span class="line">X[<span class="string">&quot;Cluster&quot;</span>] = kmeans.fit_predict(X)</span><br><span class="line">X[<span class="string">&quot;Cluster&quot;</span>] = X[<span class="string">&quot;Cluster&quot;</span>].astype(<span class="string">&quot;category&quot;</span>)</span><br><span class="line"></span><br><span class="line">X.head()</span><br></pre></td></tr></table></figure>
<p>结果输出为：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">   MedInc  Latitude  Longitude Cluster</span><br><span class="line">0  8.3252     37.88    -122.23       0</span><br><span class="line">1  8.3014     37.86    -122.22       0</span><br><span class="line">2  7.2574     37.85    -122.24       0</span><br><span class="line">3  5.6431     37.85    -122.25       0</span><br><span class="line">4  3.8462     37.85    -122.25       2</span><br></pre></td></tr></table></figure>
<p>现在让我们看几个图，看看这有多有效。首先，散点图显示集群的地理分布。该算法似乎为沿海高收入地区创建了单独的细分市场。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sns.relplot(</span><br><span class="line">    x=<span class="string">&quot;Longitude&quot;</span>, y=<span class="string">&quot;Latitude&quot;</span>, hue=<span class="string">&quot;Cluster&quot;</span>, data=X, height=<span class="number">6</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<img data-src="/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_19.png" class="">

<p>该数据集中的目标是<code>MedHouseVal</code>（房屋中位值）。这些箱线图显示了每个簇内目标的分布。如果聚类信息丰富，那么这些分布在大多数情况下应该在<code>MedHouseVal</code>中分离，这确实是我们所看到的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X[<span class="string">&quot;MedHouseVal&quot;</span>] = df[<span class="string">&quot;MedHouseVal&quot;</span>]</span><br><span class="line">sns.catplot(x=<span class="string">&quot;MedHouseVal&quot;</span>, y=<span class="string">&quot;Cluster&quot;</span>, data=X, kind=<span class="string">&quot;boxen&quot;</span>, height=<span class="number">6</span>);</span><br></pre></td></tr></table></figure>
<img data-src="/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_20.png" class="">

<h4 id="主成分分析（Principal-Component-Analysis）"><a href="#主成分分析（Principal-Component-Analysis）" class="headerlink" title="主成分分析（Principal Component Analysis）"></a>主成分分析（Principal Component Analysis）</h4><h5 id="介绍-4"><a href="#介绍-4" class="headerlink" title="介绍"></a>介绍</h5><p>我们了解了第一个基于模型的特征工程方法：聚类。我们接下来要学习：主成分分析 (<code>PCA</code>)。就像聚类是根据邻近度对数据集进行分区一样，您可以将<code>PCA</code>视为对数据变化的分区。<code>PCA</code>是一个很好的工具，可以帮助您发现数据中的重要关系，还可以用于创建信息更丰富的特征。（技术说明：<code>PCA</code>通常应用于标准化数据。对于标准化数据，“变异”意味着“相关性”。对于非标准化数据，“变异”意味着“协方差”。）</p>
<h5 id="Principal-Component-Analysis"><a href="#Principal-Component-Analysis" class="headerlink" title="Principal Component Analysis"></a>Principal Component Analysis</h5><p>鲍鱼数据集中是对数千只塔斯马尼亚鲍鱼进行的物理测量。（鲍鱼是一种海洋生物，很像蛤或牡蛎。）我们现在只看几个特征：壳的“高度”和“直径”。您可以想象，这些数据中存在“变异轴”，描述了鲍鱼之间的差异。从图中可以看出，这些轴显示为沿着数据的自然维度延伸的垂直线，每个原始特征对应一个轴。</p>
<img data-src="/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_21.png" class="">

<p>通常，我们可以为这些变化轴命名。较长的轴我们可以称为“尺寸”组件：小高度和小直径（左下）与大高度和大直径（右上）形成对比。 我们可以将较短的轴称为“形状”组件：小高度和大直径（扁平形状）与大高度和小直径（圆形）形成对比。请注意，我们不必通过“高度”和“直径”来描述鲍鱼，而是可以通过“大小”和“形状”来描述它们。事实上，这就是<code>PCA</code>的全部思想：我们不是用原始特征来描述数据，而是用它的变化轴来描述它。变化的轴成为新的特征。</p>
<img data-src="/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_22.png" class="">

<p>新特征<code>PCA</code>构造实际上只是原始特征的线性组合（加权和）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&quot;Size&quot;</span>] = <span class="number">0.707</span> * X[<span class="string">&quot;Height&quot;</span>] + <span class="number">0.707</span> * X[<span class="string">&quot;Diameter&quot;</span>]</span><br><span class="line">df[<span class="string">&quot;Shape&quot;</span>] = <span class="number">0.707</span> * X[<span class="string">&quot;Height&quot;</span>] - <span class="number">0.707</span> * X[<span class="string">&quot;Diameter&quot;</span>]</span><br></pre></td></tr></table></figure>
<p>这些新特征称为数据的<strong>主成分</strong>。权重本身称为载荷。原始数据集中有多少个特征，就有多少个主成分：如果我们使用十个特征而不是两个，我们最终会得到十个成分。此载荷表告诉我们，在“大小”成分中，“高度”和“直径”沿相同方向（相同符号）变化，但在“形状”组件中，它们沿相反方向（相反符号）变化。在每个成分中，载荷的大小都相同，因此特征在两个成分中的贡献相同。<code>PCA</code>还告诉我们每个分量的变化量。从图中我们可以看出，尺寸分量上的数据比形状分量上的数据变化更大。<code>PCA</code>通过每个分量的<strong>解释方差百分比</strong>使这一点更加精确。</p>
<img data-src="/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_23.png" class="">

<p>尺寸成分捕获高度和直径之间的大部分变化。然而，重要的是要记住，成分中的方差量并不一定与其作为预测变量的效果相对应：它取决于您想要预测的内容。</p>
<h5 id="基于特征工程的PCA"><a href="#基于特征工程的PCA" class="headerlink" title="基于特征工程的PCA"></a>基于特征工程的PCA</h5><p>有两种方法可以使用<code>PCA</code>进行特征工程。第一种方法是将其用作描述性技术。由于成分会告诉您变化，因此您可以计算成分的<code>MI</code>分数，并查看哪种变化最能预测您的目标。这可以为您提供创建各种特征的想法 - 如果“尺寸”很重要，则可以创建“高度”和“直径”的乘积，或者如果“形状”很重要，则可以创建“高度”和“直径”的比率。您甚至可以尝试对一个或多个高分成分进行聚类。第二种方法是使用成分本身作为特征。由于成分直接暴露数据的变分结构，因此它们通常比原始特征提供更多信息。以下是一些用例：</p>
<ul>
<li><strong>降维</strong>：当您的特征高度冗余（特别是多重共线性）时，<code>PCA</code>会将冗余划分为一个或多个接近零方差的分量，然后您可以将其删除，因为它们包含很少或不包含信息。</li>
<li><strong>异常检测</strong>：原始特征中不明显的异常变化通常会出现在低方差成分中。这些组件在异常或异常值检测任务中可能提供大量信息。</li>
<li><strong>降噪</strong>：传感器读数的集合通常会共享一些常见的背景噪声。<code>PCA</code>有时可以将（信息丰富的）信号收集到较少数量的特征中，同时保留噪声，从而提高信噪比。</li>
<li><strong>去相关</strong>：一些机器学习算法难以应对高度相关的特征。<code>PCA</code>将相关特征转换为不相关成分，这可以让您的算法更容易使用。</li>
</ul>
<p><code>PCA</code>基本上可以让您直接访问数据的相关结构。应用<code>PCA</code>时需要记住以下几点：</p>
<ul>
<li><code>PCA</code>仅适用于数字特征，例如连续数量或计数。</li>
<li><code>PCA</code>对规模很敏感。在应用<code>PCA</code>之前对数据进行标准化是一个很好的做法，除非您知道有充分的理由不这样做。</li>
<li>考虑删除或限制异常值，因为它们可能会对结果产生不当影响。</li>
</ul>
<h5 id="举例-1985-年汽车-1"><a href="#举例-1985-年汽车-1" class="headerlink" title="举例 - 1985 年汽车"></a>举例 - 1985 年汽车</h5><p>在此示例中，我们将返回汽车数据集并应用<code>PCA</code>，将其用作发现特征的描述性技术。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> display</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> mutual_info_regression</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.style.use(<span class="string">&quot;seaborn-whitegrid&quot;</span>)</span><br><span class="line">plt.rc(<span class="string">&quot;figure&quot;</span>, autolayout=<span class="literal">True</span>)</span><br><span class="line">plt.rc(</span><br><span class="line">    <span class="string">&quot;axes&quot;</span>,</span><br><span class="line">    labelweight=<span class="string">&quot;bold&quot;</span>,</span><br><span class="line">    labelsize=<span class="string">&quot;large&quot;</span>,</span><br><span class="line">    titleweight=<span class="string">&quot;bold&quot;</span>,</span><br><span class="line">    titlesize=<span class="number">14</span>,</span><br><span class="line">    titlepad=<span class="number">10</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_variance</span>(<span class="params">pca, width=<span class="number">8</span>, dpi=<span class="number">100</span></span>):</span><br><span class="line">    <span class="comment"># Create figure</span></span><br><span class="line">    fig, axs = plt.subplots(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">    n = pca.n_components_</span><br><span class="line">    grid = np.arange(<span class="number">1</span>, n + <span class="number">1</span>)</span><br><span class="line">    <span class="comment"># Explained variance</span></span><br><span class="line">    evr = pca.explained_variance_ratio_</span><br><span class="line">    axs[<span class="number">0</span>].bar(grid, evr)</span><br><span class="line">    axs[<span class="number">0</span>].<span class="built_in">set</span>(</span><br><span class="line">        xlabel=<span class="string">&quot;Component&quot;</span>, title=<span class="string">&quot;% Explained Variance&quot;</span>, ylim=(<span class="number">0.0</span>, <span class="number">1.0</span>)</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># Cumulative Variance</span></span><br><span class="line">    cv = np.cumsum(evr)</span><br><span class="line">    axs[<span class="number">1</span>].plot(np.r_[<span class="number">0</span>, grid], np.r_[<span class="number">0</span>, cv], <span class="string">&quot;o-&quot;</span>)</span><br><span class="line">    axs[<span class="number">1</span>].<span class="built_in">set</span>(</span><br><span class="line">        xlabel=<span class="string">&quot;Component&quot;</span>, title=<span class="string">&quot;% Cumulative Variance&quot;</span>, ylim=(<span class="number">0.0</span>, <span class="number">1.0</span>)</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># Set up figure</span></span><br><span class="line">    fig.<span class="built_in">set</span>(figwidth=<span class="number">8</span>, dpi=<span class="number">100</span>)</span><br><span class="line">    <span class="keyword">return</span> axs</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_mi_scores</span>(<span class="params">X, y, discrete_features</span>):</span><br><span class="line">    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)</span><br><span class="line">    mi_scores = pd.Series(mi_scores, name=<span class="string">&quot;MI Scores&quot;</span>, index=X.columns)</span><br><span class="line">    mi_scores = mi_scores.sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">return</span> mi_scores</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;../input/fe-course-data/autos.csv&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>我们选择了涵盖一系列属性的四个特征。这些功能中的每一个都具有与目标价格相关的高<code>MI</code>分数。我们将对数据进行标准化，因为这些特征不在同一尺度上。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">features = [<span class="string">&quot;highway_mpg&quot;</span>, <span class="string">&quot;engine_size&quot;</span>, <span class="string">&quot;horsepower&quot;</span>, <span class="string">&quot;curb_weight&quot;</span>]</span><br><span class="line"></span><br><span class="line">X = df.copy()</span><br><span class="line">y = X.pop(<span class="string">&#x27;price&#x27;</span>)</span><br><span class="line">X = X.loc[:, features]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Standardize</span></span><br><span class="line">X_scaled = (X - X.mean(axis=<span class="number">0</span>)) / X.std(axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>现在我们可以拟合<code>scikit-learn</code>的<code>PCA</code>估计器并创建主成分。您可以在此处看到转换后的数据集的前几行。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create principal components</span></span><br><span class="line">pca = PCA()</span><br><span class="line">X_pca = pca.fit_transform(X_scaled)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert to dataframe</span></span><br><span class="line">component_names = [<span class="string">f&quot;PC<span class="subst">&#123;i+<span class="number">1</span>&#125;</span>&quot;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(X_pca.shape[<span class="number">1</span>])]</span><br><span class="line">X_pca = pd.DataFrame(X_pca, columns=component_names)</span><br><span class="line"></span><br><span class="line">X_pca.head()</span><br></pre></td></tr></table></figure>
<img data-src="/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_24.png" class="">

<p>拟合后，<code>PCA</code>实例在其<code>elements_</code>属性中包含载荷。（不幸的是，<code>PCA</code>的术语不一致。我们遵循将<code>X_pca</code>中转换后的列称为成分的约定，否则这些成分没有名称。）我们将把加载包装在数据框中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">loadings = pd.DataFrame(</span><br><span class="line">    pca.components_.T,  <span class="comment"># transpose the matrix of loadings</span></span><br><span class="line">    columns=component_names,  <span class="comment"># so the columns are the principal components</span></span><br><span class="line">    index=X.columns,  <span class="comment"># and the rows are the original features</span></span><br><span class="line">)</span><br><span class="line">loadings</span><br></pre></td></tr></table></figure>
<img data-src="/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_25.png" class="">

<p>回想一下，组件载荷的符号和大小告诉我们它捕获了什么样的变化。第一个组成部分 (<code>PC1</code>) 显示了大型、动力强劲但油耗较低的车辆与较小、更经济且油耗较高的车辆之间的对比。我们可以称之为“豪华&#x2F;经济”轴。下图显示，我们选择的四个特征主要沿豪华&#x2F;经济轴变化。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Look at explained variance</span></span><br><span class="line">plot_variance(pca)</span><br></pre></td></tr></table></figure>
<img data-src="/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_26.png" class="">

<p>我们还看一下组件的<code>MI</code>分数。毫不奇怪，<code>PC1</code>信息量很大，而其余组件尽管差异很小，但仍然与价格有显着关系。检查这些组成部分可能有助于发现主要豪华&#x2F;经济轴未捕获的关系。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mi_scores = make_mi_scores(X_pca, y, discrete_features=<span class="literal">False</span>)</span><br><span class="line">mi_scores</span><br></pre></td></tr></table></figure>
<p>结果输出为：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">PC1    1.013264</span><br><span class="line">PC2    0.379156</span><br><span class="line">PC3    0.306703</span><br><span class="line">PC4    0.203329</span><br><span class="line">Name: MI Scores, dtype: float64</span><br></pre></td></tr></table></figure>
<p>第三个组成部分显示了马力和整备重量之间的对比——看起来是跑车与货车。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Show dataframe sorted by PC3</span></span><br><span class="line">idx = X_pca[<span class="string">&quot;PC3&quot;</span>].sort_values(ascending=<span class="literal">False</span>).index</span><br><span class="line">cols = [<span class="string">&quot;make&quot;</span>, <span class="string">&quot;body_style&quot;</span>, <span class="string">&quot;horsepower&quot;</span>, <span class="string">&quot;curb_weight&quot;</span>]</span><br><span class="line">df.loc[idx, cols]</span><br></pre></td></tr></table></figure>
<p>结果输出为：</p>
<img data-src="/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_27.png" class="">

<p>为了表达这种对比，让我们创建一个新的比率特征</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&quot;sports_or_wagon&quot;</span>] = X.curb_weight / X.horsepower</span><br><span class="line">sns.regplot(x=<span class="string">&quot;sports_or_wagon&quot;</span>, y=<span class="string">&#x27;price&#x27;</span>, data=df, order=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<img data-src="/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_28.png" class="">

<h4 id="目标编码（Target-Encoding）"><a href="#目标编码（Target-Encoding）" class="headerlink" title="目标编码（Target Encoding）"></a>目标编码（Target Encoding）</h4><h5 id="介绍-5"><a href="#介绍-5" class="headerlink" title="介绍"></a>介绍</h5><p>我们将在本课中介绍的技术“目标编码”适用于分类特征。它是一种将类别编码为数字的方法，类似于<code>one-hot</code>或标签编码，不同之处在于它还使用目标来创建编码。这就是我们所说的监督特征工程技术。</p>
<h5 id="Target-Encoding"><a href="#Target-Encoding" class="headerlink" title="Target Encoding"></a>Target Encoding</h5><p><strong>目标编码</strong>是用从目标派生的某个数字替换特征类别的任何类型的编码。一个简单而有效的版本是应用”组聚合“，例如平均值。使用汽车数据集，计算每辆车品牌的平均价格：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">autos = pd.read_csv(<span class="string">&quot;../input/fe-course-data/autos.csv&quot;</span>)</span><br><span class="line">autos[<span class="string">&quot;make_encoded&quot;</span>] = autos.groupby(<span class="string">&quot;make&quot;</span>)[<span class="string">&quot;price&quot;</span>].transform(<span class="string">&quot;mean&quot;</span>)</span><br><span class="line">autos[[<span class="string">&quot;make&quot;</span>, <span class="string">&quot;price&quot;</span>, <span class="string">&quot;make_encoded&quot;</span>]].head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<img data-src="/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_29.png" class="">

<p>这种目标编码有时称为”平均编码“。应用于二进制目标时，也称为<code>bin</code>计数。</p>
<h5 id="Smoothing"><a href="#Smoothing" class="headerlink" title="Smoothing"></a>Smoothing</h5><p>然而，像这样的编码会带来一些问题。首先是未知类别。目标编码会产生过度拟合的特殊风险，这意味着它们需要在独立的“编码”分割上进行训练。当您将编码加入到未来的分割中时，<code>Pandas</code>将填充编码分割中不存在的任何类别的缺失值。您必须以某种方式对这些缺失值进行估算。其次是稀有品类。当某个类别仅在数据集中出现几次时，对其组计算的任何统计数据都不太可能非常准确。在 <code>Automobiles</code>数据集中，<code>mercurcy make仅</code>出现一次。我们计算的“平均”价格只是那一辆车的价格，这可能不能很好地代表我们将来可能看到的。目标编码稀有类别可能会导致过度拟合的可能性更大。解决这些问题的方法是添加<strong>平滑</strong>。这个想法是将类别内平均值与整体平均值相结合。稀有类别在其类别平均值上的权重较小，而缺失类别仅获得总体平均值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">encoding = weight * in_category + (<span class="number">1</span> - weight) * overall</span><br></pre></td></tr></table></figure>
<p>其中权重是根据类别频率计算得出的<code>0</code>到<code>1</code>之间的值。确定权重值的一个简单方法是计算<code>m</code>估计：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">weight = n / (n + m)</span><br></pre></td></tr></table></figure>
<p>其中<code>n</code>是该类别在数据中出现的总次数。参数<code>m</code>决定“平滑因子”。<code>m</code>值越大，整体估计的权重就越大。</p>
<img data-src="/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_30.png" class="">

<p>在汽车数据集中，有三辆品牌为<code>chevrolet</code>的汽车。如果您选择<code>m=2.0</code>，则雪佛兰类别将使用雪佛兰平均价格的<code>60%</code>加上总体平均价格的<code>40%</code>进行编码。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chevrolet = 0.6 * 6000.00 + 0.4 * 13285.03</span><br></pre></td></tr></table></figure>
<p>选择<code>m</code>值时，请考虑您期望类别的噪声程度。不同品牌的车辆价格是否相差很大？您需要大量数据才能获得良好的估计？如果是这样，<code>m</code>最好选择一个更大的值；如果每个品牌的平均价格相对稳定，较小的值也可以。目标编码的用例:</p>
<ul>
<li><strong>高基数特征</strong>：具有大量类别的特征可能很难编码：<code>one-hot</code>编码会生成太多特征，而替代方案（例如标签编码）可能不适合该特征。目标编码使用特征最重要的属性（它与目标的关系）导出类别的数字。</li>
<li><strong>领域驱动的特征</strong>：根据之前的经验，您可能会怀疑分类特征应该很重要，即使它在特征指标上得分很低。目标编码可以帮助揭示特征的真实信息量。</li>
</ul>
<h5 id="举例-MovieLens1M"><a href="#举例-MovieLens1M" class="headerlink" title="举例 - MovieLens1M"></a>举例 - MovieLens1M</h5><p><code> MovieLens1M</code>数据集包含<code>MovieLens</code>网站用户对一百万部电影的评分，以及描述每个用户和电影的特征。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line">plt.style.use(<span class="string">&quot;seaborn-whitegrid&quot;</span>)</span><br><span class="line">plt.rc(<span class="string">&quot;figure&quot;</span>, autolayout=<span class="literal">True</span>)</span><br><span class="line">plt.rc(</span><br><span class="line">    <span class="string">&quot;axes&quot;</span>,</span><br><span class="line">    labelweight=<span class="string">&quot;bold&quot;</span>,</span><br><span class="line">    labelsize=<span class="string">&quot;large&quot;</span>,</span><br><span class="line">    titleweight=<span class="string">&quot;bold&quot;</span>,</span><br><span class="line">    titlesize=<span class="number">14</span>,</span><br><span class="line">    titlepad=<span class="number">10</span>,</span><br><span class="line">)</span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;../input/fe-course-data/movielens1m.csv&quot;</span>)</span><br><span class="line">df = df.astype(np.uint8, errors=<span class="string">&#x27;ignore&#x27;</span>) <span class="comment"># reduce memory footprint</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Number of Unique Zipcodes: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(df[<span class="string">&quot;Zipcode&quot;</span>].nunique()))</span><br></pre></td></tr></table></figure>
<p><code>Zipcode</code>功能拥有超过<code>3000</code>个类别，是目标编码的良好候选者，并且该数据集的大小（超过一百万行）意味着我们可以节省一些数据来创建编码。我们将首先创建<code>25%</code>的分割来训练目标编码器。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">X = df.copy()</span><br><span class="line">y = X.pop(<span class="string">&#x27;Rating&#x27;</span>)</span><br><span class="line"></span><br><span class="line">X_encode = X.sample(frac=<span class="number">0.25</span>)</span><br><span class="line">y_encode = y[X_encode.index]</span><br><span class="line">X_pretrain = X.drop(X_encode.index)</span><br><span class="line">y_train = y[X_pretrain.index]</span><br></pre></td></tr></table></figure>
<p>实现了一个<code>m</code>估计编码器，我们将使用它来编码我们的<code>Zipcode</code>特征。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> category_encoders <span class="keyword">import</span> MEstimateEncoder</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the encoder instance. Choose m to control noise.</span></span><br><span class="line">encoder = MEstimateEncoder(cols=[<span class="string">&quot;Zipcode&quot;</span>], m=<span class="number">5.0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fit the encoder on the encoding split.</span></span><br><span class="line">encoder.fit(X_encode, y_encode)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Encode the Zipcode column to create the final training data</span></span><br><span class="line">X_train = encoder.transform(X_pretrain)</span><br></pre></td></tr></table></figure>
<p>让我们将编码值与目标进行比较，看看我们的编码可以提供多少信息。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(dpi=<span class="number">90</span>)</span><br><span class="line">ax = sns.distplot(y, kde=<span class="literal">False</span>, norm_hist=<span class="literal">True</span>)</span><br><span class="line">ax = sns.kdeplot(X_train.Zipcode, color=<span class="string">&#x27;r&#x27;</span>, ax=ax)</span><br><span class="line">ax.set_xlabel(<span class="string">&quot;Rating&quot;</span>)</span><br><span class="line">ax.legend(labels=[<span class="string">&#x27;Zipcode&#x27;</span>, <span class="string">&#x27;Rating&#x27;</span>]);</span><br></pre></td></tr></table></figure>
<img data-src="/2024/03/13/artificial-intelligence/Feature_Engineering_study/fe_31.png" class="">

<p>编码后的邮政编码特征的分布大致遵循实际评分的分布，这意味着电影观看者对不同邮政编码的评分差异足够大，以至于我们的目标编码能够捕获有用的信息。</p>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>umbrella
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/" title="特征工程（Python）">https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/</a>
  </li>
  <li class="post-copyright-license">
      <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/AI/" rel="tag"># AI</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2024/03/12/artificial-intelligence/data_visual_study/" rel="prev" title="数据可视化（Seaborn）">
                  <i class="fa fa-chevron-left"></i> 数据可视化（Seaborn）
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2024/03/15/artificial-intelligence/Feature_Engineering_practice_study/" rel="next" title="特征工程实践之—房价预测">
                  特征工程实践之—房价预测 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments utterances-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">辽ICP备15012817号-2 </a>
  </div>
  <div class="copyright">
    &copy; 2022 – 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">umbrella</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">981k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">54:31</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/fresh88888888" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script size="300" alpha="0.6" zIndex="-1" src="https://cdnjs.cloudflare.com/ajax/libs/ribbon.js/1.0.2/ribbon.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.0/jquery.min.js" integrity="sha256-2Pmvv0kuTBOenSvLm6bvfBSSHrUJ+3A7x6P5Ebd07/g=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.8/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/comments.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/utils.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/motion.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/next-boot.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/pjax.min.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/search/local-search.min.js"></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdnjs.cloudflare.com/ajax/libs/pdfobject/2.2.12/pdfobject.min.js","integrity":"sha256-g2xji1rlE3KsGVClvuxTbcR0Kn2+wtQADSff2Tbb4zA="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/tags/pdf.min.js"></script>



  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/fancybox.min.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/pace.min.js"></script>


  
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  <script src="https://cdnjs.cloudflare.com/ajax/libs/quicklink/2.3.0/quicklink.umd.js" integrity="sha256-yvJQOINiH9fWemHn0vCA5lsHWJaHs6/ZmO+1Ft04SvM=" crossorigin="anonymous"></script>
  <script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":true,"archive":true,"delay":true,"timeout":5000,"priority":true,"url":"https://fresh88888888.github.io/2024/03/13/artificial-intelligence/Feature_Engineering_study/"}</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/quicklink.min.js"></script>
<script class="next-config" data-name="utterances" type="application/json">{"enable":true,"repo":"fresh88888888.github.io","issue_term":"title","theme":"github-light"}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/comments/utterances.min.js"></script>

</body>
</html>
