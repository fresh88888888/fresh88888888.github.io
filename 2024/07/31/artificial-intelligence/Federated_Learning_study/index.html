<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.2">
<link rel="preconnect" href="https://fonts.googleapis.com" crossorigin>
<link rel="preconnect" href="https://cdnjs.cloudflare.com" crossorigin>
  <link rel="apple-touch-icon" sizes="180x180" href="/favicon.ico">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon.ico">
  <link rel="mask-icon" href="/favicon.ico" color="#222">
  <meta name="google-site-verification" content="lk2gSYFP_NyLNFob-fFnt7fm-I_n1ZYws-WZll7mshg">
  <meta name="msvalidate.01" content="6Jdc01DjYOLguhS5">
  <meta name="baidu-site-verification" content="code-NR10G09zww">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic%7Ccursive:300,300italic,400,400italic,700,700italic%7CSource+Code+Pro:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/yellow/pace-theme-minimal.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"fresh88888888.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.17.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"flat"},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":true,"nav":null},"stickytabs":true,"motion":{"enable":true,"async":true,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/local-search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":10,"unescape":false,"preload":true}}</script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/config.min.js"></script>

    <meta name="description" content="介绍联邦学习(Federated Learning，FL)是一种分布式机器学习技术，旨在保护数据隐私的同时，利用分散在多个边缘设备或服务器上的本地数据进行模型训练。该方法由谷歌在2016年首次提出，主要用于解决数据孤岛和隐私保护问题。它本质上是一种保护隐私的多方协作机器学习框架，它允许参与方建立一个联合训练模型，但参与方均在本地维护其底层数据而不将原始数据进行共享。联邦学习的核心思想是将模型训练过">
<meta property="og:type" content="article">
<meta property="og:title" content="联邦学习(Federated Learning)-探析(分布式机器学习)">
<meta property="og:url" content="https://fresh88888888.github.io/2024/07/31/artificial-intelligence/Federated_Learning_study/index.html">
<meta property="og:site_name" content="UMBRELLA">
<meta property="og:description" content="介绍联邦学习(Federated Learning，FL)是一种分布式机器学习技术，旨在保护数据隐私的同时，利用分散在多个边缘设备或服务器上的本地数据进行模型训练。该方法由谷歌在2016年首次提出，主要用于解决数据孤岛和隐私保护问题。它本质上是一种保护隐私的多方协作机器学习框架，它允许参与方建立一个联合训练模型，但参与方均在本地维护其底层数据而不将原始数据进行共享。联邦学习的核心思想是将模型训练过">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://fresh88888888.github.io/2024/07/31/artificial-intelligence/Federated_Learning_study/fl_2.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/07/31/artificial-intelligence/Federated_Learning_study/fl_1.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/07/31/artificial-intelligence/Federated_Learning_study/fl_3.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/07/31/artificial-intelligence/Federated_Learning_study/fl_4.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/07/31/artificial-intelligence/Federated_Learning_study/fl_5.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/07/31/artificial-intelligence/Federated_Learning_study/fl_6.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/07/31/artificial-intelligence/Federated_Learning_study/fl_7.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/07/31/artificial-intelligence/Federated_Learning_study/fl_8.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/07/31/artificial-intelligence/Federated_Learning_study/fl_9.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/07/31/artificial-intelligence/Federated_Learning_study/fl_10.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/07/31/artificial-intelligence/Federated_Learning_study/fl_11.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/07/31/artificial-intelligence/Federated_Learning_study/fl_12.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/07/31/artificial-intelligence/Federated_Learning_study/fl_13.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/07/31/artificial-intelligence/Federated_Learning_study/fl_14.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/07/31/artificial-intelligence/Federated_Learning_study/fl_15.png">
<meta property="article:published_time" content="2024-07-31T03:15:11.000Z">
<meta property="article:modified_time" content="2024-07-31T03:15:11.000Z">
<meta property="article:author" content="umbrella">
<meta property="article:tag" content="AI">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://fresh88888888.github.io/2024/07/31/artificial-intelligence/Federated_Learning_study/fl_2.png">


<link rel="canonical" href="https://fresh88888888.github.io/2024/07/31/artificial-intelligence/Federated_Learning_study/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://fresh88888888.github.io/2024/07/31/artificial-intelligence/Federated_Learning_study/","path":"2024/07/31/artificial-intelligence/Federated_Learning_study/","title":"联邦学习(Federated Learning)-探析(分布式机器学习)"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>联邦学习(Federated Learning)-探析(分布式机器学习) | UMBRELLA</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">UMBRELLA</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">未雨绸缪，举重若轻</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-算法"><a href="/Algorithm/" rel="section"><i class="fa fa-calendar fa-fw"></i>算法</a></li><li class="menu-item menu-item-c++-&nbsp;编程"><a href="/Programming-C++/" rel="section"><i class="fa fa-heartbeat fa-fw"></i>C++ &nbsp;编程</a></li><li class="menu-item menu-item-rust-编程"><a href="/Programming-Rust/" rel="section"><i class="fa fa-cat fa-fw"></i>Rust 编程</a></li><li class="menu-item menu-item-go-&nbsp;&nbsp;&nbsp;编程"><a href="/Programming-Go/" rel="section"><i class="fa fa-hippo fa-fw"></i>Go &nbsp;&nbsp;&nbsp;编程</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BB%8B%E7%BB%8D"><span class="nav-number">1.</span> <span class="nav-text">介绍</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0"><span class="nav-number">2.</span> <span class="nav-text">联邦学习</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E4%BF%9D%E6%8A%A4%E9%9A%90%E7%A7%81"><span class="nav-number">3.</span> <span class="nav-text">联邦学习保护隐私</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F-%E8%AE%BE%E8%AE%A1"><span class="nav-number">3.1.</span> <span class="nav-text">联邦学习系统-设计</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E8%81%94%E9%82%A6%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.2.</span> <span class="nav-text">训练联邦模型</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%BC%82%E5%B8%B8%E5%80%BC"><span class="nav-number">3.3.</span> <span class="nav-text">异常值</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%B7%AE%E5%88%86%E9%9A%90%E7%A7%81"><span class="nav-number">3.4.</span> <span class="nav-text">差分隐私</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%A4%BA%E4%BE%8B"><span class="nav-number">4.</span> <span class="nav-text">示例</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%88%E7%AE%97%E6%B3%95%EF%BC%89"><span class="nav-number">4.1.</span> <span class="nav-text">联邦学习（算法）</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="umbrella"
      src="/avatar.jpeg">
  <p class="site-author-name" itemprop="name">umbrella</p>
  <div class="site-description" itemprop="description">没事就多看看书</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">252</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">21</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">65</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/fresh88888888" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;fresh88888888" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:fresh888888@foxmail.com" title="E-Mail → mailto:fresh888888@foxmail.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
    </div>

    
    <div class="sidebar-inner sidebar-blogroll">
      <div class="links-of-blogroll animated">
        <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
          链接
        </div>
        <ul class="links-of-blogroll-list">
            <li class="links-of-blogroll-item">
              <a href="https://www.rust-lang.org/zh-CN/" title="https:&#x2F;&#x2F;www.rust-lang.org&#x2F;zh-CN&#x2F;" rel="noopener" target="_blank">Rust</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://go.dev/" title="https:&#x2F;&#x2F;go.dev&#x2F;" rel="noopener" target="_blank">Golang</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://isocpp.org/" title="https:&#x2F;&#x2F;isocpp.org&#x2F;" rel="noopener" target="_blank">C++</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://www.python.org/" title="https:&#x2F;&#x2F;www.python.org&#x2F;" rel="noopener" target="_blank">Python</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://doc.rust-lang.org/cargo/index.html" title="https:&#x2F;&#x2F;doc.rust-lang.org&#x2F;cargo&#x2F;index.html" rel="noopener" target="_blank">Cargo</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://gist.github.com/rxaviers/7360908" title="https:&#x2F;&#x2F;gist.github.com&#x2F;rxaviers&#x2F;7360908" rel="noopener" target="_blank">Emoji</a>
            </li>
        </ul>
      </div>
    </div>
        <div class="pjax">
        </div>
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://fresh88888888.github.io/2024/07/31/artificial-intelligence/Federated_Learning_study/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/avatar.jpeg">
      <meta itemprop="name" content="umbrella">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="UMBRELLA">
      <meta itemprop="description" content="没事就多看看书">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="联邦学习(Federated Learning)-探析(分布式机器学习) | UMBRELLA">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          联邦学习(Federated Learning)-探析(分布式机器学习)
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-07-31 11:15:11" itemprop="dateCreated datePublished" datetime="2024-07-31T11:15:11+08:00">2024-07-31</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" itemprop="url" rel="index"><span itemprop="name">人工智能</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>16k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>14 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p><strong>联邦学习</strong>(<code>Federated Learning，FL</code>)是一种<strong>分布式机器学习</strong>技术，旨在保护<strong>数据隐私</strong>的同时，利用分散在多个边缘设备或服务器上的本地数据进行模型训练。该方法由谷歌在<code>2016</code>年首次提出，主要用于解决<strong>数据孤岛</strong>和<strong>隐私保护</strong>问题。它本质上是一种保护隐私的多方协作机器学习框架，它允许参与方建立一个联合训练模型，但参与方均在本地维护其底层数据而不将原始数据进行共享。<strong>联邦学习</strong>的核心思想是将模型训练过程分布在多个本地设备上，而不是将所有数据集中到一个中央服务器。每个设备在本地使用其数据进行模型训练，然后将模型参数（而非原始数据）发送到中央服务器进行聚合。通过这种方式，联邦学习能够有效保护<strong>数据隐私</strong>，减少数据传输的风险和成本。</p>
<span id="more"></span>

<p><strong>联邦学习</strong>的典型工作流程如下：</p>
<ul>
<li><strong>初始化模型</strong>：中央服务器初始化一个全局模型，并将其发送到各个客户端设备。</li>
<li><strong>本地训练</strong>：每个客户端设备在本地数据上训练模型，并更新模型参数。</li>
<li><strong>参数上传</strong>：各个客户端将更新后的模型参数发送回中央服务器。</li>
<li><strong>参数聚合</strong>：中央服务器对接收到的模型参数进行聚合，更新全局模型。</li>
<li><strong>重复迭代</strong>：重复上述步骤，直到模型收敛或达到预期的性能指标。</li>
</ul>
<p>根据数据<strong>样本空间和特征空间</strong>的分布模式不同，<strong>联邦学习</strong>可以分为以下三类：</p>
<ul>
<li><strong>水平联邦学习</strong>(<code>Horizontal Federated Learning</code>)：适用于数据特征重叠较多，但用户重叠较少的情况。数据集按用户维度水平分割，各个参与者的数据特征是对齐的。</li>
<li><strong>垂直联邦学习</strong>(<code>Vertical Federated Learning</code>)：适用于用户重叠较多，但数据特征重叠较少的情况。数据集按特征维度垂直分割，各个参与者的数据样本是对齐的。</li>
<li><strong>联邦迁移学习</strong>(<code>Federated Transfer Learning</code>)：适用于数据样本和数据特征重叠都很少的情况，通过迁移学习的方法进行模型训练。</li>
</ul>
<p><strong>联邦学习</strong>的优势：</p>
<ul>
<li><strong>数据隐私保护</strong>：数据不离开本地设备，仅传输模型参数，减少了数据泄露的风险。</li>
<li><strong>降低数据传输成本</strong>：避免了将大量数据上传到中央服务器的需求，降低了带宽和存储成本。</li>
<li><strong>适应性强</strong>：能够处理异构数据，适用于各种分布式数据环境。</li>
</ul>
<p><strong>联邦学习</strong>通过在分布式环境中进行模型训练，解决了传统集中式机器学习在<strong>数据隐私</strong>和<strong>数据孤岛</strong>方面的挑战。随着技术的不断发展，<strong>联邦学习</strong>在各种应用场景中的潜力将不断被挖掘和实现。</p>
<h4 id="联邦学习"><a href="#联邦学习" class="headerlink" title="联邦学习"></a>联邦学习</h4><p>多个数据拥有方<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="18.254ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 8068.2 1000" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-15-TEX-B-1D405" d="M425 0L228 3Q63 3 51 0H39V62H147V618H39V680H644V676Q647 670 659 552T675 428V424H613Q613 433 605 477Q599 511 589 535T562 574T530 599T488 612T441 617T387 618H368H304V371H333Q389 373 411 390T437 468V488H499V192H437V212Q436 244 430 263T408 292T378 305T333 309H304V62H439V0H425Z"></path><path id="MJX-15-TEX-I-1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path id="MJX-15-TEX-N-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path id="MJX-15-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-15-TEX-N-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path id="MJX-15-TEX-N-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path><path id="MJX-15-TEX-N-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path id="MJX-15-TEX-N-2026" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z"></path><path id="MJX-15-TEX-I-1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path><path id="MJX-15-TEX-N-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D405" xlink:href="#MJX-15-TEX-B-1D405"></use></g></g><g data-mml-node="mi" transform="translate(757,-150) scale(0.707)"><use data-c="1D456" xlink:href="#MJX-15-TEX-I-1D456"></use></g></g><g data-mml-node="mo" transform="translate(1051,0)"><use data-c="28" xlink:href="#MJX-15-TEX-N-28"></use></g><g data-mml-node="mi" transform="translate(1440,0)"><use data-c="1D456" xlink:href="#MJX-15-TEX-I-1D456"></use></g><g data-mml-node="mo" transform="translate(2062.7,0)"><use data-c="3D" xlink:href="#MJX-15-TEX-N-3D"></use></g><g data-mml-node="mn" transform="translate(3118.5,0)"><use data-c="31" xlink:href="#MJX-15-TEX-N-31"></use></g><g data-mml-node="mo" transform="translate(3618.5,0)"><use data-c="2C" xlink:href="#MJX-15-TEX-N-2C"></use></g><g data-mml-node="mn" transform="translate(4063.2,0)"><use data-c="32" xlink:href="#MJX-15-TEX-N-32"></use></g><g data-mml-node="mo" transform="translate(4563.2,0)"><use data-c="2C" xlink:href="#MJX-15-TEX-N-2C"></use></g><g data-mml-node="mo" transform="translate(5007.8,0)"><use data-c="2026" xlink:href="#MJX-15-TEX-N-2026"></use></g><g data-mml-node="mo" transform="translate(6346.5,0)"><use data-c="2C" xlink:href="#MJX-15-TEX-N-2C"></use></g><g data-mml-node="mi" transform="translate(6791.2,0)"><use data-c="1D441" xlink:href="#MJX-15-TEX-I-1D441"></use></g><g data-mml-node="mo" transform="translate(7679.2,0)"><use data-c="29" xlink:href="#MJX-15-TEX-N-29"></use></g></g></g></svg></mjx-container>的目的是将各自的数据<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="2.735ex" height="1.909ex" role="img" focusable="false" viewBox="0 -686 1209 843.8" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-14-TEX-B-1D403" d="M39 624V686H270H310H408Q500 686 545 680T638 649Q768 584 805 438Q817 388 817 338Q817 171 702 75Q628 17 515 2Q504 1 270 0H39V62H147V624H39ZM655 337Q655 370 655 390T650 442T639 494T616 540T580 580T526 607T451 623Q443 624 368 624H298V62H377H387H407Q445 62 472 65T540 83T606 129Q629 156 640 195T653 262T655 337Z"></path><path id="MJX-14-TEX-I-1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D403" xlink:href="#MJX-14-TEX-B-1D403"></use></g></g><g data-mml-node="mi" transform="translate(915,-150) scale(0.707)"><use data-c="1D456" xlink:href="#MJX-14-TEX-I-1D456"></use></g></g></g></g></svg></mjx-container>联合，共同训练机器学习模型。传统做法是把数据整合到一起，形成全局数据集<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="25.132ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 11108.4 1000" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-14-TEX-B-1D403" d="M39 624V686H270H310H408Q500 686 545 680T638 649Q768 584 805 438Q817 388 817 338Q817 171 702 75Q628 17 515 2Q504 1 270 0H39V62H147V624H39ZM655 337Q655 370 655 390T650 442T639 494T616 540T580 580T526 607T451 623Q443 624 368 624H298V62H377H387H407Q445 62 472 65T540 83T606 129Q629 156 640 195T653 262T655 337Z"></path><path id="MJX-14-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-14-TEX-N-7B" d="M434 -231Q434 -244 428 -250H410Q281 -250 230 -184Q225 -177 222 -172T217 -161T213 -148T211 -133T210 -111T209 -84T209 -47T209 0Q209 21 209 53Q208 142 204 153Q203 154 203 155Q189 191 153 211T82 231Q71 231 68 234T65 250T68 266T82 269Q116 269 152 289T203 345Q208 356 208 377T209 529V579Q209 634 215 656T244 698Q270 724 324 740Q361 748 377 749Q379 749 390 749T408 750H428Q434 744 434 732Q434 719 431 716Q429 713 415 713Q362 710 332 689T296 647Q291 634 291 499V417Q291 370 288 353T271 314Q240 271 184 255L170 250L184 245Q202 239 220 230T262 196T290 137Q291 131 291 1Q291 -134 296 -147Q306 -174 339 -192T415 -213Q429 -213 431 -216Q434 -219 434 -231Z"></path><path id="MJX-14-TEX-I-1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path id="MJX-14-TEX-N-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path><path id="MJX-14-TEX-N-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path id="MJX-14-TEX-N-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path id="MJX-14-TEX-N-2026" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z"></path><path id="MJX-14-TEX-I-1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path><path id="MJX-14-TEX-N-7D" d="M65 731Q65 745 68 747T88 750Q171 750 216 725T279 670Q288 649 289 635T291 501Q292 362 293 357Q306 312 345 291T417 269Q428 269 431 266T434 250T431 234T417 231Q380 231 345 210T298 157Q293 143 292 121T291 -28V-79Q291 -134 285 -156T256 -198Q202 -250 89 -250Q71 -250 68 -247T65 -230Q65 -224 65 -223T66 -218T69 -214T77 -213Q91 -213 108 -210T146 -200T183 -177T207 -139Q208 -134 209 3L210 139Q223 196 280 230Q315 247 330 250Q305 257 280 270Q225 304 212 352L210 362L209 498Q208 635 207 640Q195 680 154 696T77 713Q68 713 67 716T65 731Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D403" xlink:href="#MJX-14-TEX-B-1D403"></use></g></g><g data-mml-node="mo" transform="translate(1159.8,0)"><use data-c="3D" xlink:href="#MJX-14-TEX-N-3D"></use></g><g data-mml-node="mo" transform="translate(2215.6,0)"><use data-c="7B" xlink:href="#MJX-14-TEX-N-7B"></use></g><g data-mml-node="msub" transform="translate(2715.6,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D403" xlink:href="#MJX-14-TEX-B-1D403"></use></g></g><g data-mml-node="mi" transform="translate(915,-150) scale(0.707)"><use data-c="1D456" xlink:href="#MJX-14-TEX-I-1D456"></use></g></g><g data-mml-node="mo" transform="translate(3924.5,0)"><use data-c="2C" xlink:href="#MJX-14-TEX-N-2C"></use></g><g data-mml-node="mi" transform="translate(4369.2,0)"><use data-c="1D456" xlink:href="#MJX-14-TEX-I-1D456"></use></g><g data-mml-node="mo" transform="translate(4992,0)"><use data-c="3D" xlink:href="#MJX-14-TEX-N-3D"></use></g><g data-mml-node="mn" transform="translate(6047.7,0)"><use data-c="31" xlink:href="#MJX-14-TEX-N-31"></use></g><g data-mml-node="mo" transform="translate(6547.7,0)"><use data-c="2C" xlink:href="#MJX-14-TEX-N-2C"></use></g><g data-mml-node="mn" transform="translate(6992.4,0)"><use data-c="32" xlink:href="#MJX-14-TEX-N-32"></use></g><g data-mml-node="mo" transform="translate(7492.4,0)"><use data-c="2C" xlink:href="#MJX-14-TEX-N-2C"></use></g><g data-mml-node="mo" transform="translate(7937.1,0)"><use data-c="2026" xlink:href="#MJX-14-TEX-N-2026"></use></g><g data-mml-node="mo" transform="translate(9275.7,0)"><use data-c="2C" xlink:href="#MJX-14-TEX-N-2C"></use></g><g data-mml-node="mi" transform="translate(9720.4,0)"><use data-c="1D441" xlink:href="#MJX-14-TEX-I-1D441"></use></g><g data-mml-node="mo" transform="translate(10608.4,0)"><use data-c="7D" xlink:href="#MJX-14-TEX-N-7D"></use></g></g></g></svg></mjx-container>，并利用<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="1.995ex" height="1.552ex" role="img" focusable="false" viewBox="0 -686 882 686" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-14-TEX-B-1D403" d="M39 624V686H270H310H408Q500 686 545 680T638 649Q768 584 805 438Q817 388 817 338Q817 171 702 75Q628 17 515 2Q504 1 270 0H39V62H147V624H39ZM655 337Q655 370 655 390T650 442T639 494T616 540T580 580T526 607T451 623Q443 624 368 624H298V62H377H387H407Q445 62 472 65T540 83T606 129Q629 156 640 195T653 262T655 337Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D403" xlink:href="#MJX-14-TEX-B-1D403"></use></g></g></g></g></svg></mjx-container>训练生成模型<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="5.511ex" height="1.909ex" role="img" focusable="false" viewBox="0 -686 2435.8 843.8" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-13-TEX-B-1D40C" d="M314 0Q296 3 181 3T48 0H39V62H147V624H39V686H305Q316 679 323 667Q330 653 434 414L546 157L658 414Q766 662 773 674Q778 681 788 686H1052V624H944V62H1052V0H1040Q1016 3 874 3T708 0H696V62H804V341L803 618L786 580Q770 543 735 462T671 315Q540 13 536 9Q528 1 507 1Q485 1 477 9Q472 14 408 162T281 457T217 603Q215 603 215 334V62H323V0H314Z"></path><path id="MJX-13-TEX-N-73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path id="MJX-13-TEX-N-75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z"></path><path id="MJX-13-TEX-N-6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D40C" xlink:href="#MJX-13-TEX-B-1D40C"></use></g></g><g data-mml-node="TeXAtom" transform="translate(1125,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><use data-c="73" xlink:href="#MJX-13-TEX-N-73"></use><use data-c="75" xlink:href="#MJX-13-TEX-N-75" transform="translate(394,0)"></use><use data-c="6D" xlink:href="#MJX-13-TEX-N-6D" transform="translate(950,0)"></use></g></g></g></g></g></svg></mjx-container>。然而，该方案因违背数据隐私保护而难以实施。为了解决这一问题<strong>联邦学习</strong>定义如下：联邦学习是指使得这些数据拥有方<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="2.378ex" height="1.895ex" role="img" focusable="false" viewBox="0 -680 1051 837.8" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-13-TEX-B-1D405" d="M425 0L228 3Q63 3 51 0H39V62H147V618H39V680H644V676Q647 670 659 552T675 428V424H613Q613 433 605 477Q599 511 589 535T562 574T530 599T488 612T441 617T387 618H368H304V371H333Q389 373 411 390T437 468V488H499V192H437V212Q436 244 430 263T408 292T378 305T333 309H304V62H439V0H425Z"></path><path id="MJX-13-TEX-I-1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D405" xlink:href="#MJX-13-TEX-B-1D405"></use></g></g><g data-mml-node="mi" transform="translate(757,-150) scale(0.707)"><use data-c="1D456" xlink:href="#MJX-13-TEX-I-1D456"></use></g></g></g></g></svg></mjx-container>在不用给出己方数据<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="2.735ex" height="1.909ex" role="img" focusable="false" viewBox="0 -686 1209 843.8" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-12-TEX-B-1D403" d="M39 624V686H270H310H408Q500 686 545 680T638 649Q768 584 805 438Q817 388 817 338Q817 171 702 75Q628 17 515 2Q504 1 270 0H39V62H147V624H39ZM655 337Q655 370 655 390T650 442T639 494T616 540T580 580T526 607T451 623Q443 624 368 624H298V62H377H387H407Q445 62 472 65T540 83T606 129Q629 156 640 195T653 262T655 337Z"></path><path id="MJX-12-TEX-I-1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D403" xlink:href="#MJX-12-TEX-B-1D403"></use></g></g><g data-mml-node="mi" transform="translate(915,-150) scale(0.707)"><use data-c="1D456" xlink:href="#MJX-12-TEX-I-1D456"></use></g></g></g></g></svg></mjx-container>的情况下可以进行模型训练并得到全局模型<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="4.748ex" height="1.909ex" role="img" focusable="false" viewBox="0 -686 2098.5 843.8" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-12-TEX-B-1D40C" d="M314 0Q296 3 181 3T48 0H39V62H147V624H39V686H305Q316 679 323 667Q330 653 434 414L546 157L658 414Q766 662 773 674Q778 681 788 686H1052V624H944V62H1052V0H1040Q1016 3 874 3T708 0H696V62H804V341L803 618L786 580Q770 543 735 462T671 315Q540 13 536 9Q528 1 507 1Q485 1 477 9Q472 14 408 162T281 457T217 603Q215 603 215 334V62H323V0H314Z"></path><path id="MJX-12-TEX-N-66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z"></path><path id="MJX-12-TEX-N-65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z"></path><path id="MJX-12-TEX-N-64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D40C" xlink:href="#MJX-12-TEX-B-1D40C"></use></g></g><g data-mml-node="TeXAtom" transform="translate(1125,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><use data-c="66" xlink:href="#MJX-12-TEX-N-66"></use><use data-c="65" xlink:href="#MJX-12-TEX-N-65" transform="translate(306,0)"></use><use data-c="64" xlink:href="#MJX-12-TEX-N-64" transform="translate(750,0)"></use></g></g></g></g></g></svg></mjx-container>的计算过程，并能够保证模型<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="4.748ex" height="1.909ex" role="img" focusable="false" viewBox="0 -686 2098.5 843.8" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-10-TEX-B-1D40C" d="M314 0Q296 3 181 3T48 0H39V62H147V624H39V686H305Q316 679 323 667Q330 653 434 414L546 157L658 414Q766 662 773 674Q778 681 788 686H1052V624H944V62H1052V0H1040Q1016 3 874 3T708 0H696V62H804V341L803 618L786 580Q770 543 735 462T671 315Q540 13 536 9Q528 1 507 1Q485 1 477 9Q472 14 408 162T281 457T217 603Q215 603 215 334V62H323V0H314Z"></path><path id="MJX-10-TEX-N-66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z"></path><path id="MJX-10-TEX-N-65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z"></path><path id="MJX-10-TEX-N-64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D40C" xlink:href="#MJX-10-TEX-B-1D40C"></use></g></g><g data-mml-node="TeXAtom" transform="translate(1125,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><use data-c="66" xlink:href="#MJX-10-TEX-N-66"></use><use data-c="65" xlink:href="#MJX-10-TEX-N-65" transform="translate(306,0)"></use><use data-c="64" xlink:href="#MJX-10-TEX-N-64" transform="translate(750,0)"></use></g></g></g></g></g></svg></mjx-container>的效果<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="4.243ex" height="1.909ex" role="img" focusable="false" viewBox="0 -686 1875.5 843.8" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-10-TEX-B-1D415" d="M592 686H604Q615 685 631 685T666 684T700 684T724 683Q829 683 835 686H843V624H744L611 315Q584 254 546 165Q492 40 482 19T461 -6L460 -7H409Q398 -4 391 9Q385 20 257 315L124 624H25V686H36Q57 683 190 683Q340 683 364 686H377V624H289L384 403L480 185L492 212Q504 240 529 298T575 405L670 624H582V686H592Z"></path><path id="MJX-10-TEX-N-66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z"></path><path id="MJX-10-TEX-N-65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z"></path><path id="MJX-10-TEX-N-64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D415" xlink:href="#MJX-10-TEX-B-1D415"></use></g></g><g data-mml-node="TeXAtom" transform="translate(902,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><use data-c="66" xlink:href="#MJX-10-TEX-N-66"></use><use data-c="65" xlink:href="#MJX-10-TEX-N-65" transform="translate(306,0)"></use><use data-c="64" xlink:href="#MJX-10-TEX-N-64" transform="translate(750,0)"></use></g></g></g></g></g></svg></mjx-container>与传统模型<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="5.511ex" height="1.909ex" role="img" focusable="false" viewBox="0 -686 2435.8 843.8" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-10-TEX-B-1D40C" d="M314 0Q296 3 181 3T48 0H39V62H147V624H39V686H305Q316 679 323 667Q330 653 434 414L546 157L658 414Q766 662 773 674Q778 681 788 686H1052V624H944V62H1052V0H1040Q1016 3 874 3T708 0H696V62H804V341L803 618L786 580Q770 543 735 462T671 315Q540 13 536 9Q528 1 507 1Q485 1 477 9Q472 14 408 162T281 457T217 603Q215 603 215 334V62H323V0H314Z"></path><path id="MJX-10-TEX-N-73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path id="MJX-10-TEX-N-75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z"></path><path id="MJX-10-TEX-N-6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D40C" xlink:href="#MJX-10-TEX-B-1D40C"></use></g></g><g data-mml-node="TeXAtom" transform="translate(1125,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><use data-c="73" xlink:href="#MJX-10-TEX-N-73"></use><use data-c="75" xlink:href="#MJX-10-TEX-N-75" transform="translate(394,0)"></use><use data-c="6D" xlink:href="#MJX-10-TEX-N-6D" transform="translate(950,0)"></use></g></g></g></g></g></svg></mjx-container>的效果<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="5.006ex" height="1.909ex" role="img" focusable="false" viewBox="0 -686 2212.8 843.8" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-10-TEX-B-1D415" d="M592 686H604Q615 685 631 685T666 684T700 684T724 683Q829 683 835 686H843V624H744L611 315Q584 254 546 165Q492 40 482 19T461 -6L460 -7H409Q398 -4 391 9Q385 20 257 315L124 624H25V686H36Q57 683 190 683Q340 683 364 686H377V624H289L384 403L480 185L492 212Q504 240 529 298T575 405L670 624H582V686H592Z"></path><path id="MJX-10-TEX-N-73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path id="MJX-10-TEX-N-75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z"></path><path id="MJX-10-TEX-N-6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D415" xlink:href="#MJX-10-TEX-B-1D415"></use></g></g><g data-mml-node="TeXAtom" transform="translate(902,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><use data-c="73" xlink:href="#MJX-10-TEX-N-73"></use><use data-c="75" xlink:href="#MJX-10-TEX-N-75" transform="translate(394,0)"></use><use data-c="6D" xlink:href="#MJX-10-TEX-N-6D" transform="translate(950,0)"></use></g></g></g></g></g></svg></mjx-container>间的差距足够小，即：</p>
<mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.564ex;" xmlns="http://www.w3.org/2000/svg" width="17.295ex" height="2.26ex" role="img" focusable="false" viewBox="0 -749.5 7644.3 999" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-10-TEX-N-7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path><path id="MJX-10-TEX-B-1D415" d="M592 686H604Q615 685 631 685T666 684T700 684T724 683Q829 683 835 686H843V624H744L611 315Q584 254 546 165Q492 40 482 19T461 -6L460 -7H409Q398 -4 391 9Q385 20 257 315L124 624H25V686H36Q57 683 190 683Q340 683 364 686H377V624H289L384 403L480 185L492 212Q504 240 529 298T575 405L670 624H582V686H592Z"></path><path id="MJX-10-TEX-N-66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z"></path><path id="MJX-10-TEX-N-65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z"></path><path id="MJX-10-TEX-N-64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z"></path><path id="MJX-10-TEX-N-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path id="MJX-10-TEX-N-73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path id="MJX-10-TEX-N-75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z"></path><path id="MJX-10-TEX-N-6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path id="MJX-10-TEX-N-3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z"></path><path id="MJX-10-TEX-I-1D6FF" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo" transform="translate(0 -0.5)"><use data-c="7C" xlink:href="#MJX-10-TEX-N-7C"></use></g><g data-mml-node="msub" transform="translate(278,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D415" xlink:href="#MJX-10-TEX-B-1D415"></use></g></g><g data-mml-node="TeXAtom" transform="translate(902,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><use data-c="66" xlink:href="#MJX-10-TEX-N-66"></use><use data-c="65" xlink:href="#MJX-10-TEX-N-65" transform="translate(306,0)"></use><use data-c="64" xlink:href="#MJX-10-TEX-N-64" transform="translate(750,0)"></use></g></g></g><g data-mml-node="mo" transform="translate(2375.7,0)"><use data-c="2212" xlink:href="#MJX-10-TEX-N-2212"></use></g><g data-mml-node="msub" transform="translate(3375.9,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D415" xlink:href="#MJX-10-TEX-B-1D415"></use></g></g><g data-mml-node="TeXAtom" transform="translate(902,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><use data-c="73" xlink:href="#MJX-10-TEX-N-73"></use><use data-c="75" xlink:href="#MJX-10-TEX-N-75" transform="translate(394,0)"></use><use data-c="6D" xlink:href="#MJX-10-TEX-N-6D" transform="translate(950,0)"></use></g></g></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(5588.7,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><use data-c="7C" xlink:href="#MJX-10-TEX-N-7C"></use></g></g><g data-mml-node="mo" transform="translate(6144.5,0)"><use data-c="3C" xlink:href="#MJX-10-TEX-N-3C"></use></g><g data-mml-node="mi" transform="translate(7200.3,0)"><use data-c="1D6FF" xlink:href="#MJX-10-TEX-I-1D6FF"></use></g></g></g></svg></mjx-container>
<p>其中，<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.023ex;" xmlns="http://www.w3.org/2000/svg" width="1.005ex" height="1.645ex" role="img" focusable="false" viewBox="0 -717 444 727" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-10-TEX-I-1D6FF" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D6FF" xlink:href="#MJX-10-TEX-I-1D6FF"></use></g></g></g></svg></mjx-container>为设定的非负实数。</p>
<p><strong>水平联邦学习</strong>(<code>HFL</code>)适用于联邦学习的参与方的数据有重叠的数据特征，即数据特征在参与方之间是对齐的，但是参与方拥有的数据样本是不同的。</p>
<img data-src="/2024/07/31/artificial-intelligence/Federated_Learning_study/fl_2.png" class="">

<p><strong>垂直联邦学习</strong>(<code>VFL</code>)适用于联邦学习参与方的训练数据有重叠的数据样本，即参与方之间的数据样本是对齐的，但是在数据特征上有所不同。</p>
<img data-src="/2024/07/31/artificial-intelligence/Federated_Learning_study/fl_1.png" class="">

<p><strong>联邦迁移学习</strong>(<code>FTL</code>)适用于当两个数据集不仅在样本大小上不同，而且在特征空间上也不同时。将中国的一家银行和美国的一家电子商务公司视为两个独立的实体。由于地理限制，两家机构的用户群体重叠很小。然而，由于企业不同，两家公司的特征空间只有一小部分重叠。具体而言，通过应用受限的一般样本集来学习两个特征空间的典型描述，然后将其用于为仅具有单侧特征的样本生成预测结果。<code>FTL</code>解决了当前联合学习方法无法解决的困难，这就是为什么它是该领域的一个重要补充。</p>
<img data-src="/2024/07/31/artificial-intelligence/Federated_Learning_study/fl_3.png" class="">

<h4 id="联邦学习保护隐私"><a href="#联邦学习保护隐私" class="headerlink" title="联邦学习保护隐私"></a>联邦学习保护隐私</h4><img data-src="/2024/07/31/artificial-intelligence/Federated_Learning_study/fl_4.png" class="" title="十二个人定期合并他们的模型，以协作训练共享模型——无需共享他们的数据">

<p>大型数据集使机器学习取得了惊人的突破。但数据往往是个人或专有的，并不适合共享，这使得隐私成为集中式数据收集和模型训练的关键问题和障碍。借助<strong>联邦学习</strong>，可以使用来自多个用户的数据协作训练模型，而无需任何原始数据离开他们的设备。通过联邦学习，这些设备（如手机、手表、汽车、相机、恒温器、太阳能电池板、望远镜等等）还可以实现新技术。想想我们的汽车如何在不泄露我们行踪的情况下为自动驾驶汽车的大规模训练做出贡献。而且这种机器学习方法也可以应用于不同的组织。医院可以利用来自世界各地护理提供者的各种干预措施带来的患者结果来设计更好的治疗计划，而无需共享高度敏感的健康数据。拥有专有药物开发数据的制药公司可以合作建立关于人体如何代谢不同化合物的知识。该框架有潜力实现对复杂系统和流程的大规模聚合和建模，例如城市交通、经济市场、能源使用和发电模式、气候变化和公共卫生问题。最终，<strong>联邦学习</strong>的目标是让人们、公司、管辖区和机构能够协作提出并回答&#x2F;决策重大问题，同时保持对个人数据的所有权。</p>
<h5 id="联邦学习系统-设计"><a href="#联邦学习系统-设计" class="headerlink" title="联邦学习系统-设计"></a>联邦学习系统-设计</h5><p>举例：“拦截垃圾邮件”。邮聊天应用中的垃圾邮件令人讨厌且无处不在。机器学习提供了一种解决方案——我们可以开发一个模型，根据用户之前在其设备上标记为垃圾邮件的内容自动过滤掉传入的垃圾邮件。这听起来很棒，但有一个问题：大多数机器学习模型都是通过在数据中心上收集大量数据来训练的；而用户消息可能非常私密。为了保护隐私，是否有可能在不与数据中心共享任何潜在敏感信息的情况下训练垃圾邮件检测模型（或任何机器学习模型）？</p>
<p>为了回答这个问题，我们首先仔细看看典型的集中式训练系统，下面是一个简单的垃圾邮件检测模型。用户消息被上传到数据中心，在那里它们被一次性处理以训练<code>BoW</code>模型（是一种用于自然语言处理(<code>NLP</code>)和信息检索(<code>IR</code>)的文本表示方法。它通过将文本表示为一个无序的词集合（“袋子”），来捕捉词的频率，而忽略词的顺序和语法结构。）。点击一条消息将其标记为垃圾邮件❌或不更改上传到服务器的数据和训练模型。</p>
<img data-src="/2024/07/31/artificial-intelligence/Federated_Learning_study/fl_5.png" class="" title="通过集中训练，每个用户的数据都会上传到数据中心进行集中训练">

<p>这种模型可能在过滤垃圾邮件方面表现不错。但集中式训练有一个很大的缺点：所有消息，无论多么敏感，都需要发送到数据中心，这就要求用户信任该数据中心的所有者会保护他们的数据，不会滥用数据。如果训练是在每个用户的设备上本地进行，而不是集中收集数据，结果会怎样？智能手机的功能越来越强大，而且它们经常处于闲置状态（例如，在夜间充电时），这使得机器学习模型训练能够在不影响用户体验的情况下运行。</p>
<img data-src="/2024/07/31/artificial-intelligence/Federated_Learning_study/fl_6.png" class="" title="通过集中训练，每个用户在本地独立训练垃圾邮件模型——不与数据中心共享任何信息">

<p>在本地训练模型对于保护隐私非常有益——数据永远不会离开用户的设备！但我们可以从这里看到，一台数据有限的设备可能无法训练出高质量的模型。如果一个涉及汽车保险的新骗局开始向所有人发送垃圾邮件，那么<code>Alice</code>的手机将无法使用仅限本地的模型过滤掉有关“您的汽车保修续订”的消息，除非她将其中几条消息标记为垃圾邮件。</p>
<p>用户如何才能在不共享私人数据的情况下互相帮助并协作训练模型？一种想法是让用户共享本地训练的垃圾邮件检测模型而不是他们的消息。然后，服务器可以组合这些模型（例如通过均值）来生成每个人都可以用于垃圾邮件过滤的<strong>全局模型</strong>。</p>
<img data-src="/2024/07/31/artificial-intelligence/Federated_Learning_study/fl_7.png" class="" title="跨用户组合模型可以产生共享模型，但可能会泄露用户隐私">

<p>虽然我们已经停止将每条原始消息发送到数据中心，但上传这些本地模型仍然会泄露一些信息。在这里，数据中心可以直接访问每个用户将不同单词标记为垃圾邮件的比率，并可以推断出他们正在谈论的内容。根据用户对数据中心的信任度，他们可能不愿意让数据中心看到他们的本地模型。理想情况下，数据中心应该只看到聚合结果。我们希望开发一个尽可能减少数据的系统。</p>
<p><strong>联邦学习</strong>是一个通用框架，它利用<strong>数据最小化策略</strong>使多个实体能够协作解决机器学习问题。每个实体都将其原始数据保存在本地，并通过旨在立即聚合的重点更新来改进全局模型。在组合用户模型时限制数据暴露的第一步是不要存储单个模型 - 只存储<strong>聚合</strong>。<strong>安全聚合</strong>和<strong>安全区域</strong>可以提供更强大的保证，将许多本地模型组合成一个聚合，而不会向服务器透露任何用户的贡献。在<strong>安全聚合协议</strong>中，用户设备同意共享随机数，并保留聚合结果的方式掩盖其本地模型。数据中心不知道每个用户如何修改其模型。</p>
<img data-src="/2024/07/31/artificial-intelligence/Federated_Learning_study/fl_8.png" class="">

<p>用户的隐藏号码永远不会共享。通过<strong>安全聚合</strong>过程交换每个本地模型的所有用户提供的数字。<code>Alice、Bob</code>和<code>Carol</code>的设备使用加密技术交换随机数 — “用户实际上不会亲自接触”。</p>
<img data-src="/2024/07/31/artificial-intelligence/Federated_Learning_study/fl_9.png" class="" title="联邦学习（这里展示的是安全聚合），在保护隐私的同时生成共享模型">

<p>通过安全聚合，用户可以合并他们的模型，而无需向数据中心透露任何个人信息。总而言之，联邦学习可以实现协作模型训练，同时最大限度地减少数据暴露。</p>
<h5 id="训练联邦模型"><a href="#训练联邦模型" class="headerlink" title="训练联邦模型"></a>训练联邦模型</h5><p>虽然像垃圾邮件分类器这样的模型可以通过一轮合并本地模型来学习，但更复杂的模型需要多次迭代本地训练和<strong>联合均值</strong>。让我们看看它是如何工作的。看一个简单的“热力图”二元分类模型，该模型旨在猜测网格的哪些区域可能很热或很冷。每个用户只从少数几个位置收集了温度读数：</p>
<img data-src="/2024/07/31/artificial-intelligence/Federated_Learning_study/fl_10.png" class="">

<p>我们的目标是了解整个网格的温度分布——这样每个人都会知道哪里需要穿毛衣！——而无需任何人分享他们的位置历史。如下图所示，每个用户都在使用本地数据不断训练模型，预测网格中每个位置的温度。您可以看到，由于每个用户的模型都过度拟合了他们有限的信息，因此训练的模型差异非常大。局部训练曲线跟踪每个局部模型在地面真实数据上的准确度，表明每个局部模型学习整个网格的真实温度分布的能力。</p>
<img data-src="/2024/07/31/artificial-intelligence/Federated_Learning_study/fl_11.png" class="">

<p>运行一轮联合训练：对用户模型进行平均，并将更新后的全局模型分发给所有用户。经过多次训练和合并模型后，生成的全局模型比仅基于本地数据训练的模型更能反映地图上的整体温度分布。您可能会注意到，经过一段相当长的局部训练后，局部热图模型会逐渐分离，而最新的全局模型的准确性可能会在合并后下降。使用相对频繁的周期性平均可以避免这种情况。虽然我们绘制了局部模型准确率，以便观察这些训练动态，但实际上，运行联合训练的服务器只能访问全局模型。服务器在训练过程中可以计算和跟踪的唯一指标是全局模型准确率。</p>
<h5 id="异常值"><a href="#异常值" class="headerlink" title="异常值"></a>异常值</h5><p>当所有用户报告的温度体验一致时，这种方法效果很好。如果情况并非如此，会发生什么？也许我们的一些用户的温度计坏了，到处都报告寒冷的天气！单击四个异常值中的每一个，将它们从训练中排除，并注意模型的表现。我们也许能够更好地训练模型来预测大多数用户在没有异常值的情况下观察到的热图，但如果这些异常用户的传感器没有损坏，而他们的数据看起来不同怎么办？有些人可能对什么是“热”或“冷”有不同的看法；从训练中排除异常值可能会降低训练池中代表性较低的人群的准确性。虽然在本例中很容易发现异常值，但实际上联邦学习系统中的服务器无法直接看到用户训练数据，这使得联邦学习中的异常值检测变得很棘手。异常值的存在通常表明用户的模型质量较差。</p>
<img data-src="/2024/07/31/artificial-intelligence/Federated_Learning_study/fl_12.png" class="">

<h5 id="差分隐私"><a href="#差分隐私" class="headerlink" title="差分隐私"></a>差分隐私</h5><p>全局模型会因为单个用户的存在而发生巨大变化，这也引发了隐私问题。如果一个用户的参与会显著影响模型，那么观察最终模型的人可能会确定谁参与了训练，甚至推断出他们的本地数据。异常数据尤其可能对模型训练产生更大的影响。例如，假设我们的潜在用户群中有一个以总是穿毛衣并抱怨天气寒冷而闻名的人。如果全局模型准确率低于预期，我们可以推断，这个臭名昭著的穿毛衣的用户可能参与了训练，并且通过总是报告天气寒冷而降低了准确率。即使使用安全聚合，情况也是如此——数据中心无法直接看到哪个用户做出了什么贡献，但由此产生的全局模型仍然表明，很可能有一位认为天气总是适合穿毛衣的用户参与了训练。在联邦学习中使用差异隐私时，全局模型的整体准确性可能会下降，但在训练过程中切换包含异常值（或任何其他用户）时，结果应该保持大致相同。使用滑块调节用户报告位置的扰动程度。在较低的隐私级别下，切换包含异常值对模型的影响更大，而在较高的隐私级别下，即使包含异常值，模型质量也不会有明显差异。</p>
<img data-src="/2024/07/31/artificial-intelligence/Federated_Learning_study/fl_13.png" class="">

<p>在实践中，用户模型会被裁剪和加噪，而不是原始数据，或者噪声会被应用于许多裁剪模型的组合。集中应用噪声往往更有利于提高模型准确性，但未加噪的模型可能需要通过可信聚合器等技术进行保护。此演示说明了隐私和准确性之间的权衡，但公式中还缺少另一个因素：数据量，包括训练示例数量和用户数量。使用更多数据的成本并非免费 — 这会增加计算量 — 但这是我们可以转动的另一个旋钮，以便在所有这些维度上达到可接受的操作点。</p>
<h4 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h4><p>用<code>datasets.MNIST</code>加载<code>MNIST</code>数据集，此示例，将训练数据集拆分为三个数据集。设置三个不同的数据集，排除一些数字，如下所示：</p>
<ul>
<li><code>part_1</code>排除数字<code>1、3</code>和<code>7</code>。</li>
<li><code>part_2</code>排除数字<code>2、4</code>和<code>6</code>。</li>
<li><code>part_3</code>排除数字<code>4、6</code>和<code>9</code>。</li>
</ul>
<p>这模拟了现实世界中可能存在的不同数据集（具有缺失数据、额外数据等的数据集）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.utils</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Subset, DataLoader, random_split</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torch.utils.data</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms, datasets</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line">transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((<span class="number">0.5</span>, ), (<span class="number">0.5</span>, ))])</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">include_digits</span>(<span class="params">dataset, included_digits</span>):</span><br><span class="line">    including_indices = [idx <span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(dataset)) <span class="keyword">if</span> dataset[idx][<span class="number">1</span>] <span class="keyword">in</span> included_digits]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> torch.utils.data.Subset(dataset, including_indices)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">exclude_digits</span>(<span class="params">dataset, excluded_digits</span>):</span><br><span class="line">    including_indices = [idx <span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(dataset)) <span class="keyword">if</span> dataset[idx][<span class="number">1</span>] <span class="keyword">not</span> <span class="keyword">in</span> excluded_digits]</span><br><span class="line">    <span class="keyword">return</span> torch.utils.data.Subset(dataset, including_indices)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_distribution</span>(<span class="params">dataset, title</span>):</span><br><span class="line">    labels = [data[<span class="number">1</span>] <span class="keyword">for</span> data <span class="keyword">in</span> dataset]</span><br><span class="line">    unique_labels, label_counts = torch.unique(torch.tensor(labels), return_counts=<span class="literal">True</span>)</span><br><span class="line">    plt.figure(figsize=(<span class="number">4</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">    counts_dict = &#123;label.item(): count.item() <span class="keyword">for</span> label, count <span class="keyword">in</span> <span class="built_in">zip</span>(unique_labels, label_counts)&#125;</span><br><span class="line"></span><br><span class="line">    all_labels = np.arange(<span class="number">10</span>)</span><br><span class="line">    all_label_counts = [counts_dict.get(label, <span class="number">0</span>) <span class="keyword">for</span> label <span class="keyword">in</span> all_labels]</span><br><span class="line"></span><br><span class="line">    plt.bar(all_labels, all_label_counts)</span><br><span class="line">    plt.title(title)</span><br><span class="line">    plt.xlabel(<span class="string">&quot;Digit&quot;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&quot;Count&quot;</span>)</span><br><span class="line">    plt.xticks(all_labels)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_confusion_matrix</span>(<span class="params">model, test_set</span>):</span><br><span class="line">    <span class="comment"># Initialize lists to store true labels and predicted labels</span></span><br><span class="line">    true_labels = []</span><br><span class="line">    predicted_labels = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Iterate over the test set to get predictions</span></span><br><span class="line">    <span class="keyword">for</span> Image, label <span class="keyword">in</span> test_set:</span><br><span class="line">        <span class="comment"># Forward pass through the model to get predictions</span></span><br><span class="line">        output = model(Image.unsqueeze(<span class="number">0</span>))</span><br><span class="line">        _, predicted = torch.<span class="built_in">max</span>(output, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Append true and predicted labels to lists</span></span><br><span class="line">        true_labels.append(label)</span><br><span class="line">        predicted_labels.append(predicted.item())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Convert lists to numpy arrays</span></span><br><span class="line">    true_labels = np.array(true_labels)</span><br><span class="line">    predicted_labels = np.array(predicted_labels)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute confusion matrix</span></span><br><span class="line">    cm = confusion_matrix(true_labels, predicted_labels)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> cm</span><br><span class="line"></span><br><span class="line">train_set = datasets.MNIST(<span class="string">&quot;./MNIST_data/&quot;</span>, download=<span class="literal">True</span>, train=<span class="literal">True</span>, transform=transform)</span><br><span class="line">total_length = <span class="built_in">len</span>(train_set)</span><br><span class="line">split_size = total_length // <span class="number">3</span></span><br><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line">part_1, part_2, part_3 = random_split(train_set, [split_size] * <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">part_1 = exclude_digits(part_1, excluded_digits=[<span class="number">1</span>, <span class="number">3</span>, <span class="number">7</span>])</span><br><span class="line">part_2 = exclude_digits(part_2, excluded_digits=[<span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>])</span><br><span class="line">part_3 = exclude_digits(part_3, excluded_digits=[<span class="number">4</span>, <span class="number">6</span>, <span class="number">9</span>])</span><br><span class="line"></span><br><span class="line">plot_distribution(part_1, <span class="string">&#x27;Part 1&#x27;</span>)</span><br><span class="line">plot_distribution(part_2, <span class="string">&#x27;Part 2&#x27;</span>)</span><br><span class="line">plot_distribution(part_3, <span class="string">&#x27;Part 3&#x27;</span>)</span><br></pre></td></tr></table></figure>
<img data-src="/2024/07/31/artificial-intelligence/Federated_Learning_study/fl_14.png" class="">

<p><strong>训练模型</strong>：定义<code>SimpleModel</code>模型，并初始化化三个模型实例。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_model</span>(<span class="params">model, train_set</span>):</span><br><span class="line">    batch_size = <span class="number">64</span></span><br><span class="line">    num_epochs = <span class="number">10</span></span><br><span class="line">    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line">    criterion = nn.CrossEntropyLoss()</span><br><span class="line">    optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.01</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line">    model.train()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        running_loss = <span class="number">0.01</span></span><br><span class="line">        <span class="keyword">for</span> inputs, labels <span class="keyword">in</span> train_loader:</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            outputs = model(inputs)</span><br><span class="line">            loss = criterion(outputs, labels)</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            running_loss += loss.item()</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Epoch <span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>: Loss = <span class="subst">&#123;running_loss / <span class="built_in">len</span>(train_loader)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Training complete&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SimpleModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(SimpleModel, self).__init__()</span><br><span class="line">        self.fc = nn.Linear(<span class="number">784</span>, <span class="number">128</span>)</span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line">        self.out = nn.Linear(<span class="number">128</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = torch.flatten(<span class="number">1</span>, x)</span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        x = self.relu(x)</span><br><span class="line">        x = self.out(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">model1 = SimpleModel()</span><br><span class="line">train_model(model1, part1)</span><br><span class="line"></span><br><span class="line">model2 = SimpleModel()</span><br><span class="line">train_model(model2, part2)</span><br><span class="line"></span><br><span class="line">model3 = SimpleModel()</span><br><span class="line">train_model(model3, part3)</span><br></pre></td></tr></table></figure>
<p>结果输出为：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">Epoch 1: Loss = 0.5065847117637479</span><br><span class="line">Epoch 2: Loss = 0.24505144885390304</span><br><span class="line">Epoch 3: Loss = 0.19136880657977834</span><br><span class="line">Epoch 4: Loss = 0.15813053476533223</span><br><span class="line">Epoch 5: Loss = 0.13172560036286365</span><br><span class="line">Epoch 6: Loss = 0.11020874739403641</span><br><span class="line">Epoch 7: Loss = 0.09594884521843389</span><br><span class="line">Epoch 8: Loss = 0.08343400360990401</span><br><span class="line">Epoch 9: Loss = 0.07082434464783169</span><br><span class="line">Epoch 10: Loss = 0.06130250348965096</span><br><span class="line">Training complete</span><br><span class="line">Epoch 1: Loss = 0.5141205594174938</span><br><span class="line">Epoch 2: Loss = 0.24732008437859956</span><br><span class="line">Epoch 3: Loss = 0.20709553339778014</span><br><span class="line">Epoch 4: Loss = 0.16869308433031927</span><br><span class="line">Epoch 5: Loss = 0.14205218129574435</span><br><span class="line">Epoch 6: Loss = 0.12770977104397396</span><br><span class="line">Epoch 7: Loss = 0.11071020946195816</span><br><span class="line">Epoch 8: Loss = 0.10024585863294666</span><br><span class="line">Epoch 9: Loss = 0.08707036653882291</span><br><span class="line">Epoch 10: Loss = 0.07732414840035923</span><br><span class="line">Training complete</span><br><span class="line">Epoch 1: Loss = 0.5017504044776564</span><br><span class="line">Epoch 2: Loss = 0.2650307032734424</span><br><span class="line">Epoch 3: Loss = 0.20769038726886113</span><br><span class="line">Epoch 4: Loss = 0.1649025677050556</span><br><span class="line">Epoch 5: Loss = 0.1395505760965852</span><br><span class="line">Epoch 6: Loss = 0.12056233629114455</span><br><span class="line">Epoch 7: Loss = 0.10090371655182795</span><br><span class="line">Epoch 8: Loss = 0.09096335670969506</span><br><span class="line">Epoch 9: Loss = 0.07602779161671662</span><br><span class="line">Epoch 10: Loss = 0.07067198011923481</span><br><span class="line">Training complete</span><br></pre></td></tr></table></figure>
<p><strong>评估模型</strong>：调用<code>valuate_model</code>函数在整个测试数据集和测试数据集的特定子集上评估上面定义的每个模型(<code>model1、model2、model3</code>)。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 评估模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate_model</span>(<span class="params">model, test_set</span>):</span><br><span class="line">    model.<span class="built_in">eval</span>()  <span class="comment"># Set model to evaluation mode</span></span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    total_loss = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    test_loader = DataLoader(test_set, batch_size=<span class="number">64</span>, shuffle=<span class="literal">False</span>)</span><br><span class="line">    criterion = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> inputs, labels <span class="keyword">in</span> test_loader:</span><br><span class="line">            outputs = model(inputs)</span><br><span class="line">            _, predicted = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)</span><br><span class="line">            total += labels.size(<span class="number">0</span>)</span><br><span class="line">            correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">            loss = criterion(outputs, labels)</span><br><span class="line">            total_loss += loss.item()</span><br><span class="line"></span><br><span class="line">    accuracy = correct / total</span><br><span class="line">    average_loss = total_loss / <span class="built_in">len</span>(test_loader)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> average_loss, accuracy</span><br><span class="line"></span><br><span class="line">testset = datasets.MNIST(</span><br><span class="line">    <span class="string">&quot;./MNIST_data/&quot;</span>, download=<span class="literal">True</span>, train=<span class="literal">False</span>, transform=transform</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">testset_137 = include_digits(testset, included_digits=[<span class="number">1</span>, <span class="number">3</span>, <span class="number">7</span>])</span><br><span class="line">testset_246 = include_digits(testset, included_digits=[<span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>])</span><br><span class="line">testset_469 = include_digits(testset, included_digits=[<span class="number">4</span>, <span class="number">6</span>, <span class="number">9</span>])</span><br><span class="line"></span><br><span class="line">_, accuracy1 = evaluate_model(model1, testset)</span><br><span class="line">_, accuracy1_on_137 = evaluate_model(model1, testset_137)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Model 1-&gt; Test Accuracy on all digits: <span class="subst">&#123;accuracy1:<span class="number">.4</span>f&#125;</span>, &quot;</span><span class="string">f&quot;Test Accuracy on [1,3,7]: <span class="subst">&#123;accuracy1_on_137:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">_, accuracy2 = evaluate_model(model2, testset)</span><br><span class="line">_, accuracy2_on_246 = evaluate_model(model2, testset_246)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Model 2-&gt; Test Accuracy on all digits: <span class="subst">&#123;accuracy2:<span class="number">.4</span>f&#125;</span>, &quot;</span><span class="string">f&quot;Test Accuracy on [2,4,6]: <span class="subst">&#123;accuracy2_on_246:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">_, accuracy3 = evaluate_model(model3, testset)</span><br><span class="line">_, accuracy3_on_469 = evaluate_model(model3, testset_469)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Model 3-&gt; Test Accuracy on all digits: <span class="subst">&#123;accuracy3:<span class="number">.4</span>f&#125;</span>, &quot;</span><span class="string">f&quot;Test Accuracy on [4,6,9]: <span class="subst">&#123;accuracy3_on_469:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>结果输出为：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Model 1-&gt; Test Accuracy on all digits: 0.6571, Test Accuracy on [1,3,7]: 0.0000</span><br><span class="line">Model 2-&gt; Test Accuracy on all digits: 0.6748, Test Accuracy on [2,4,6]: 0.0000</span><br><span class="line">Model 3-&gt; Test Accuracy on all digits: 0.6845, Test Accuracy on [4,6,9]: 0.0000</span><br></pre></td></tr></table></figure>
<p>使用<code>compute_confusion_matrix</code>方法，查看刚刚训练的三个模型的“<strong>混淆矩阵</strong>”来分析：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">plot_confusion_matrix</span>(<span class="params">cm, title</span>):</span><br><span class="line">    plt.figure(figsize=(<span class="number">6</span>, <span class="number">4</span>))</span><br><span class="line">    sns.heatmap(cm, annot=<span class="literal">True</span>, cmap=<span class="string">&quot;Blues&quot;</span>, fmt=<span class="string">&#x27;d&#x27;</span>, linewidths=<span class="number">.5</span>)</span><br><span class="line">    plt.title(title)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Predicted Label&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;True Label&#x27;</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<img data-src="/2024/07/31/artificial-intelligence/Federated_Learning_study/fl_15.png" class="">

<h5 id="联邦学习（算法）"><a href="#联邦学习（算法）" class="headerlink" title="联邦学习（算法）"></a>联邦学习（算法）</h5><ul>
<li><strong>初始化</strong>：初始化数据中心的全局模型。</li>
<li><strong>通信轮次</strong>(<code>communication round</code>)：每一轮通信—— 数据中心将全局模型发送给所有参与的客户端；并且每一个客户端都收到了全局模型。</li>
<li><strong>客户端训练&amp;更新模型</strong>：每一个参与的客户端—— 在本地数据集上客户端训练接收到的模型；本地更新的模型通过客户端发送到数据中心。</li>
<li><strong>模型聚合</strong>：数据中心聚合利用<strong>聚合算法</strong>从所有客户端收到的更新模型。</li>
<li><strong>收敛检查</strong>：如果满足收敛标准，则进行FL处理；如果不满足，则进行下一个通信轮次。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> flwr.common.logger <span class="keyword">import</span> console_handler, log</span><br><span class="line"><span class="keyword">from</span> flwr.common <span class="keyword">import</span> Metrics, NDArrays, Scalar</span><br><span class="line"><span class="keyword">from</span> flwr.client <span class="keyword">import</span> Client, ClientApp, NumPyClient</span><br><span class="line"><span class="keyword">from</span> flwr.common <span class="keyword">import</span> ndarrays_to_parameters, Context</span><br><span class="line"><span class="keyword">from</span> flwr.server <span class="keyword">import</span> ServerApp, ServerConfig</span><br><span class="line"><span class="keyword">from</span> flwr.server <span class="keyword">import</span> ServerAppComponents</span><br><span class="line"><span class="keyword">from</span> flwr.server.strategy <span class="keyword">import</span> FedAvg</span><br><span class="line"><span class="keyword">from</span> flwr.simulation <span class="keyword">import</span> run_simulation</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>, <span class="type">Tuple</span>, <span class="type">Dict</span>, <span class="type">Optional</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Sets the parameters of the model</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_weights</span>(<span class="params">net, parameters</span>):</span><br><span class="line">    params_dict = <span class="built_in">zip</span>(net.state_dict().keys(), parameters)</span><br><span class="line">    state_dict = OrderedDict(&#123;k: torch.tensor(v) <span class="keyword">for</span> k, v <span class="keyword">in</span> params_dict&#125;)</span><br><span class="line">    net.load_state_dict(state_dict, strict=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Retrieves the parameters from the model</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_weights</span>(<span class="params">net</span>):</span><br><span class="line">    ndarrays = [val.cpu().numpy() <span class="keyword">for</span> _, val <span class="keyword">in</span> net.state_dict().items()]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ndarrays</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FlowerClient</span>(<span class="title class_ inherited__">NumPyClient</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, net, trainset, testset</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.net = net</span><br><span class="line">        self.trainset = trainset</span><br><span class="line">        self.testset = testset</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Train the model</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, parameters, config</span>):</span><br><span class="line">        set_weights(self.net, parameters)</span><br><span class="line">        train_model(self.net, self.trainset)</span><br><span class="line">        <span class="keyword">return</span> get_weights(self.net), <span class="built_in">len</span>(self.trainset), &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Test the model</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">self, parameters: NDArrays, config: <span class="type">Dict</span>[<span class="built_in">str</span>, Scalar]</span>):</span><br><span class="line">        set_weights(self.net, parameters)</span><br><span class="line">        loss, accuracy = evaluate_model(self.net, self.testset)</span><br><span class="line">        <span class="keyword">return</span> loss, <span class="built_in">len</span>(self.testset), &#123;<span class="string">&quot;accuracy&quot;</span>: accuracy&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">client</span>(<span class="params">context: Context</span>) -&gt; Client:</span><br><span class="line">    net = SimpleModel()</span><br><span class="line">    partition_id = <span class="built_in">int</span>(context.node_config[<span class="string">&#x27;partition-id&#x27;</span>])</span><br><span class="line">    client_train = train_set[<span class="built_in">int</span>(partition_id)]</span><br><span class="line">    client_test = testset</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> FlowerClient(net=net, trainset=client_train, testset=client_test).to_client()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create an instance of the ClientApp.</span></span><br><span class="line">client = ClientApp(client_fn=client)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">server_round, parameters, config</span>):</span><br><span class="line">    net = SimpleModel()</span><br><span class="line">    set_weights(net, parameters)</span><br><span class="line"></span><br><span class="line">    _, accuracy = evaluate_model(net, testset)</span><br><span class="line">    _, accuracy_137 = evaluate_model(net, testset_137)</span><br><span class="line">    _, accuracy_246 = evaluate_model(net, testset_246)</span><br><span class="line">    _, accuracy_469 = evaluate_model(net, testset_469)</span><br><span class="line"></span><br><span class="line">    log(INFO, <span class="string">&quot;test accuracy on all digitss: %.4f&quot;</span>, accuracy)</span><br><span class="line">    log(INFO, <span class="string">&quot;test accuracy on [1,3,7]: %.4f&quot;</span>, accuracy_137)</span><br><span class="line">    log(INFO, <span class="string">&quot;test accuracy on [2,4,6]: %.4f&quot;</span>, accuracy_246)</span><br><span class="line">    log(INFO, <span class="string">&quot;test accuracy on [4,6,9] %.4f&quot;</span>, accuracy_469)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> server_round == <span class="number">3</span>:</span><br><span class="line">        cm = compute_confusion_matrix(net, testset)</span><br><span class="line">        plot_confusion_matrix(cm, <span class="string">&quot;Final Global Model&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 策略：联邦平均</span></span><br><span class="line">net = SimpleModel()</span><br><span class="line">params = ndarrays_to_parameters(get_weights(net))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">server</span>(<span class="params">context: Context</span>):</span><br><span class="line">    strategy = FedAvg(fraction_fit=<span class="number">1.0</span>, fraction_evaluate=<span class="number">0.0</span>, initial_parameters=params, evaluate_fn=evaluate)</span><br><span class="line">    config = ServerConfig(num_rounds=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ServerAppComponents(strategy=strategy, config=config)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建SreverApp的实例</span></span><br><span class="line">server = ServerApp(server_fn=server)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始训练</span></span><br><span class="line">run_simulation(server_app=server, client_app=client, num_supernodes=<span class="number">3</span>, backend_config=backend_setup)</span><br></pre></td></tr></table></figure>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>umbrella
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://fresh88888888.github.io/2024/07/31/artificial-intelligence/Federated_Learning_study/" title="联邦学习(Federated Learning)-探析(分布式机器学习)">https://fresh88888888.github.io/2024/07/31/artificial-intelligence/Federated_Learning_study/</a>
  </li>
  <li class="post-copyright-license">
      <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/AI/" rel="tag"># AI</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2024/07/29/artificial-intelligence/MIXLORA_theory_study/" rel="prev" title="基于LoRA构建稀疏混合专家模型(MoE)的方法(MixLoRA)-探析(微调)">
                  <i class="fa fa-chevron-left"></i> 基于LoRA构建稀疏混合专家模型(MoE)的方法(MixLoRA)-探析(微调)
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2024/08/02/artificial-intelligence/sam2_theory_study/" rel="next" title="SAM2模型-探析(深度学习)">
                  SAM2模型-探析(深度学习) <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments utterances-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">辽ICP备15012817号-2 </a>
  </div>
  <div class="copyright">
    &copy; 2022 – 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">umbrella</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">3m</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">42:21</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/fresh88888888" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script size="300" alpha="0.6" zIndex="-1" src="https://cdnjs.cloudflare.com/ajax/libs/ribbon.js/1.0.2/ribbon.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.0/jquery.min.js" integrity="sha256-2Pmvv0kuTBOenSvLm6bvfBSSHrUJ+3A7x6P5Ebd07/g=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.8/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/comments.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/utils.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/motion.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/next-boot.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/pjax.min.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/search/local-search.min.js"></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdnjs.cloudflare.com/ajax/libs/pdfobject/2.2.12/pdfobject.min.js","integrity":"sha256-g2xji1rlE3KsGVClvuxTbcR0Kn2+wtQADSff2Tbb4zA="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/tags/pdf.min.js"></script>



  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/fancybox.min.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/pace.min.js"></script>


  
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  <script src="https://cdnjs.cloudflare.com/ajax/libs/quicklink/2.3.0/quicklink.umd.js" integrity="sha256-yvJQOINiH9fWemHn0vCA5lsHWJaHs6/ZmO+1Ft04SvM=" crossorigin="anonymous"></script>
  <script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":true,"archive":true,"delay":true,"timeout":5000,"priority":true,"url":"https://fresh88888888.github.io/2024/07/31/artificial-intelligence/Federated_Learning_study/"}</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/quicklink.min.js"></script>
<script class="next-config" data-name="utterances" type="application/json">{"enable":true,"repo":"fresh88888888.github.io","issue_term":"title","theme":"github-light"}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/comments/utterances.min.js"></script>

</body>
</html>
