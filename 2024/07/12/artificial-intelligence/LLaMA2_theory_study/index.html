<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.2">
<link rel="preconnect" href="https://fonts.googleapis.com" crossorigin>
<link rel="preconnect" href="https://cdnjs.cloudflare.com" crossorigin>
  <link rel="apple-touch-icon" sizes="180x180" href="/favicon.ico">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon.ico">
  <link rel="mask-icon" href="/favicon.ico" color="#222">
  <meta name="google-site-verification" content="lk2gSYFP_NyLNFob-fFnt7fm-I_n1ZYws-WZll7mshg">
  <meta name="msvalidate.01" content="6Jdc01DjYOLguhS5">
  <meta name="baidu-site-verification" content="code-NR10G09zww">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic%7Ccursive:300,300italic,400,400italic,700,700italic%7CSource+Code+Pro:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/yellow/pace-theme-minimal.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"fresh88888888.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.17.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"flat"},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":true,"nav":null},"stickytabs":true,"motion":{"enable":true,"async":true,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/local-search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":10,"unescape":false,"preload":true}}</script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/config.min.js"></script>

    <meta name="description" content="LLaMA 2是Meta AI(原Facebook AI)在2023年7月发布的大型语言模型系列,是LLaMA模型的第二代版本。模型规模：包含70亿、130亿和700亿参数三种规模的模型。比LLaMA 1增加了一个700亿参数的大型模型。训练数据：使用2万亿个tokens进行预训练,比LLaMA 1增加了40%；完全使用公开可用的数据集,不依赖专有数据。性能改进：在多数基准测试中,性能超过了同等规">
<meta property="og:type" content="article">
<meta property="og:title" content="LLaMA 2 模型—探析（PyTorch）">
<meta property="og:url" content="https://fresh88888888.github.io/2024/07/12/artificial-intelligence/LLaMA2_theory_study/index.html">
<meta property="og:site_name" content="UMBRELLA">
<meta property="og:description" content="LLaMA 2是Meta AI(原Facebook AI)在2023年7月发布的大型语言模型系列,是LLaMA模型的第二代版本。模型规模：包含70亿、130亿和700亿参数三种规模的模型。比LLaMA 1增加了一个700亿参数的大型模型。训练数据：使用2万亿个tokens进行预训练,比LLaMA 1增加了40%；完全使用公开可用的数据集,不依赖专有数据。性能改进：在多数基准测试中,性能超过了同等规">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://fresh88888888.github.io/2024/07/12/artificial-intelligence/LLaMA2_theory_study/ll_1.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/07/12/artificial-intelligence/LLaMA2_theory_study/ll_2.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/07/12/artificial-intelligence/LLaMA2_theory_study/ll_3.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/07/12/artificial-intelligence/LLaMA2_theory_study/ll_4.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/07/12/artificial-intelligence/LLaMA2_theory_study/ll_5.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/07/12/artificial-intelligence/LLaMA2_theory_study/ll_6.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/07/12/artificial-intelligence/LLaMA2_theory_study/ll_7.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/07/12/artificial-intelligence/LLaMA2_theory_study/ll_8.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/07/12/artificial-intelligence/LLaMA2_theory_study/ll_9.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/07/12/artificial-intelligence/LLaMA2_theory_study/ll_10.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/07/12/artificial-intelligence/LLaMA2_theory_study/ll_11.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/07/12/artificial-intelligence/LLaMA2_theory_study/ll_12.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/07/12/artificial-intelligence/LLaMA2_theory_study/ll_13.png">
<meta property="og:image" content="https://fresh88888888.github.io/2024/07/12/artificial-intelligence/LLaMA2_theory_study/ll_14.png">
<meta property="article:published_time" content="2024-07-12T07:00:11.000Z">
<meta property="article:modified_time" content="2024-07-12T07:00:11.000Z">
<meta property="article:author" content="umbrella">
<meta property="article:tag" content="AI">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://fresh88888888.github.io/2024/07/12/artificial-intelligence/LLaMA2_theory_study/ll_1.png">


<link rel="canonical" href="https://fresh88888888.github.io/2024/07/12/artificial-intelligence/LLaMA2_theory_study/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://fresh88888888.github.io/2024/07/12/artificial-intelligence/LLaMA2_theory_study/","path":"2024/07/12/artificial-intelligence/LLaMA2_theory_study/","title":"LLaMA 2 模型—探析（PyTorch）"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>LLaMA 2 模型—探析（PyTorch） | UMBRELLA</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">UMBRELLA</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">未雨绸缪，举重若轻</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-算法"><a href="/Algorithm/" rel="section"><i class="fa fa-calendar fa-fw"></i>算法</a></li><li class="menu-item menu-item-c++-&nbsp;编程"><a href="/Programming-C++/" rel="section"><i class="fa fa-heartbeat fa-fw"></i>C++ &nbsp;编程</a></li><li class="menu-item menu-item-rust-编程"><a href="/Programming-Rust/" rel="section"><i class="fa fa-cat fa-fw"></i>Rust 编程</a></li><li class="menu-item menu-item-go-&nbsp;&nbsp;&nbsp;编程"><a href="/Programming-Go/" rel="section"><i class="fa fa-hippo fa-fw"></i>Go &nbsp;&nbsp;&nbsp;编程</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#RMSNorm"><span class="nav-number">1.</span> <span class="nav-text">RMSNorm</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%97%8B%E8%BD%AC%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81"><span class="nav-number">2.</span> <span class="nav-text">旋转位置编码</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%97%8B%E8%BD%AC%E4%BD%8D%E7%BD%AE%E5%B5%8C%E5%85%A5-RoPE"><span class="nav-number">3.</span> <span class="nav-text">旋转位置嵌入(RoPE)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%88%86%E7%BB%84%E6%9F%A5%E8%AF%A2%E6%B3%A8%E6%84%8F%E5%8A%9B"><span class="nav-number">4.</span> <span class="nav-text">分组查询注意力</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#SwiGLU"><span class="nav-number">5.</span> <span class="nav-text">SwiGLU</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Logits"><span class="nav-number">6.</span> <span class="nav-text">Logits</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%8E%A8%E7%90%86%E7%AD%96%E7%95%A5"><span class="nav-number">7.</span> <span class="nav-text">推理策略</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="umbrella"
      src="/avatar.jpeg">
  <p class="site-author-name" itemprop="name">umbrella</p>
  <div class="site-description" itemprop="description">没事就多看看书</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">250</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">21</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">65</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/fresh88888888" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;fresh88888888" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:fresh888888@foxmail.com" title="E-Mail → mailto:fresh888888@foxmail.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
    </div>

    
    <div class="sidebar-inner sidebar-blogroll">
      <div class="links-of-blogroll animated">
        <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
          链接
        </div>
        <ul class="links-of-blogroll-list">
            <li class="links-of-blogroll-item">
              <a href="https://www.rust-lang.org/zh-CN/" title="https:&#x2F;&#x2F;www.rust-lang.org&#x2F;zh-CN&#x2F;" rel="noopener" target="_blank">Rust</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://go.dev/" title="https:&#x2F;&#x2F;go.dev&#x2F;" rel="noopener" target="_blank">Golang</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://isocpp.org/" title="https:&#x2F;&#x2F;isocpp.org&#x2F;" rel="noopener" target="_blank">C++</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://www.python.org/" title="https:&#x2F;&#x2F;www.python.org&#x2F;" rel="noopener" target="_blank">Python</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://doc.rust-lang.org/cargo/index.html" title="https:&#x2F;&#x2F;doc.rust-lang.org&#x2F;cargo&#x2F;index.html" rel="noopener" target="_blank">Cargo</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://gist.github.com/rxaviers/7360908" title="https:&#x2F;&#x2F;gist.github.com&#x2F;rxaviers&#x2F;7360908" rel="noopener" target="_blank">Emoji</a>
            </li>
        </ul>
      </div>
    </div>
        <div class="pjax">
        </div>
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://fresh88888888.github.io/2024/07/12/artificial-intelligence/LLaMA2_theory_study/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/avatar.jpeg">
      <meta itemprop="name" content="umbrella">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="UMBRELLA">
      <meta itemprop="description" content="没事就多看看书">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="LLaMA 2 模型—探析（PyTorch） | UMBRELLA">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          LLaMA 2 模型—探析（PyTorch）
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-07-12 15:00:11" itemprop="dateCreated datePublished" datetime="2024-07-12T15:00:11+08:00">2024-07-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" itemprop="url" rel="index"><span itemprop="name">人工智能</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3.1k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>10 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p><code>LLaMA 2</code>是<code>Meta AI</code>(原<code>Facebook AI</code>)在<code>2023</code>年<code>7</code>月发布的大型语言模型系列,是<code>LLaMA</code>模型的第二代版本。<strong>模型规模</strong>：包含<code>70</code>亿、<code>130</code>亿和<code>700</code>亿参数三种规模的模型。比<code>LLaMA 1</code>增加了一个<code>700</code>亿参数的大型模型。<strong>训练数据</strong>：使用<code>2</code>万亿个<code>tokens</code>进行预训练,比<code>LLaMA 1</code>增加了<code>40%</code>；完全使用公开可用的数据集,不依赖专有数据。<strong>性能改进</strong>：在多数基准测试中,性能超过了同等规模的开源模型；<code>130</code>亿参数版本在某些任务上甚至超过了<code>GPT-3</code>(<code>1750</code>亿参数)。<strong>对话优化</strong>：提供了针对对话场景优化的<code>LLaMA 2-Chat</code>版本；使用了超过<code>100</code>万人工标注进行微调。<strong>安全性</strong>：在模型训练中加入了安全性改进措施；使用<strong>人类反馈强化学习</strong>(<code>RLHF</code>)来确保安全性和有用性。<strong>技术创新</strong>：使用分组查询注意力(<code>GQA</code>)机制提高效率；上下文长度增加到<code>4096 tokens</code>,是<code>LLaMA 1</code>的两倍。</p>
<span id="more"></span>

<p><code>LLaMA 2</code>采用了经典的<code>Transformer</code>架构，但在多个方面进行了优化，以提高模型的性能和效率：</p>
<ul>
<li><code>Transformer</code>架构：<code>LLaMA 2</code>基于经典的<code>Transformer</code>架构，利用注意力机制来理解文本的上下文关系。</li>
<li>解码器结构：<code>LLaMA 2</code>采用了仅解码器的<code>Transformer</code>架构，这种架构在生成任务中表现出色。</li>
<li><code>RMSNorm(Root Mean Square Layer Normalization)</code>：取代了传统的<code>Layer Normalization</code>，<code>RMSNorm</code>有助于提高训练的稳定性和效率。</li>
<li><code>SwiGLU</code>激活函数：采用了<code>SwiGLU</code>激活函数，而不是标准的<code>ReLU</code>激活函数，这种选择有助于提升模型的表现。</li>
<li><code>RoPE(Rotary Positional Embedding)</code>位置编码：使用旋转位置编码来处理位置信息，这种方法在处理长序列时表现更好。</li>
<li><code>Grouped Query Attention(GQA)</code>：引入了<strong>分组查询注意力机制</strong>，以加速推理过程。</li>
</ul>
<img data-src="/2024/07/12/artificial-intelligence/LLaMA2_theory_study/ll_1.png" class="">

<img data-src="/2024/07/12/artificial-intelligence/LLaMA2_theory_study/ll_2.png" class="">

<h4 id="RMSNorm"><a href="#RMSNorm" class="headerlink" title="RMSNorm"></a>RMSNorm</h4><p><code>Llama 2</code>系列模型。标记计数仅指预训练数据。所有模型均使用<code>4M</code>标记的全局批处理大小进行训练。更大的模型（<code>34B</code>和<code>70B</code>）使用<strong>分组查询注意力</strong>(<code>GQA</code>)来提高推理可扩展性。</p>
<p>什么是<strong>归一化</strong>？<strong>归一化</strong>(<code>Normalization</code>)是一种数据处理技术，主要用于调整不同尺度的数据到一个共同的尺度。<strong>定义</strong>：将数据按照一定的规则转换到特定的范围内，通常是<code>[0,1]</code>或<code>[-1,1]</code>。<strong>主要目的</strong>：使不同量纲的数据可比较；消除数据的单位影响；改善数据的稳定性和可解释性。<strong>常见的归一化方法</strong>：最小-最大归一化(<code>Min-Max Normalization</code>)、<code>Z-score</code>归一化、小数定标归一化。</p>
<p><code>Root Mean Square Normalization(RMSNorm)</code>是一种数据归一化技术，主要用于信号处理、统计学和机器学习等领域。<strong>定义</strong>：<code>RMS Normalization</code>将数据缩放，使得数据的均方根值等于<code>1</code>。它是通过将每个值除以所有值平方的平均值的平方根来计算的。</p>
<img data-src="/2024/07/12/artificial-intelligence/LLaMA2_theory_study/ll_3.png" class="">

<p>就像层规范化一样，我们也有一个可学习的参数<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.489ex;" xmlns="http://www.w3.org/2000/svg" width="1.229ex" height="1.486ex" role="img" focusable="false" viewBox="0 -441 543 657" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-20-TEX-I-1D6FE" d="M31 249Q11 249 11 258Q11 275 26 304T66 365T129 418T206 441Q233 441 239 440Q287 429 318 386T371 255Q385 195 385 170Q385 166 386 166L398 193Q418 244 443 300T486 391T508 430Q510 431 524 431H537Q543 425 543 422Q543 418 522 378T463 251T391 71Q385 55 378 6T357 -100Q341 -165 330 -190T303 -216Q286 -216 286 -188Q286 -138 340 32L346 51L347 69Q348 79 348 100Q348 257 291 317Q251 355 196 355Q148 355 108 329T51 260Q49 251 47 251Q45 249 31 249Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D6FE" xlink:href="#MJX-20-TEX-I-1D6FE"></use></g></g></g></svg></mjx-container>（左边公式中的<code>g</code>），它乘以归一化的值。RMSNorm的好处：与层归一化相比，需要的计算量更少；在实践中效果更好。</p>
<h4 id="旋转位置编码"><a href="#旋转位置编码" class="headerlink" title="旋转位置编码"></a>旋转位置编码</h4><p><strong>旋转位置编码</strong>(<code>Rotary Positional Encoding</code>) 是一种用于<code>Transformer</code>模型的位置编码技术。原理：通过将绝对位置信息编码到<strong>查询</strong>(<code>query</code>)和<strong>键</strong>(<code>key</code>)向量中,实现相对位置编码的效果；使用复数旋转的方式来编码位置信息。</p>
<p>什么是<strong>旋转矩阵</strong>？<strong>旋转矩阵</strong>可以定义为对向量进行操作并产生旋转向量的变换矩阵，使得坐标轴始终保持固定。这些矩阵将向量沿逆时针方向旋转角度<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.023ex;" xmlns="http://www.w3.org/2000/svg" width="1.061ex" height="1.618ex" role="img" focusable="false" viewBox="0 -705 469 715" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-19-TEX-I-1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D703" xlink:href="#MJX-19-TEX-I-1D703"></use></g></g></g></svg></mjx-container>。旋转矩阵始终是具有实数的方阵。这意味着它始终具有相同数量的行和列。</p>
<img data-src="/2024/07/12/artificial-intelligence/LLaMA2_theory_study/ll_4.png" class="">

<p>我们看到<strong>旋转矩阵</strong>保留了原始向量的大小（或长度），如上图中<code>“r”</code>所示，唯一改变的是与<code>x</code>轴的角度。这里旋转位置编码中使用的旋转矩阵是二维旋转矩阵的多个块。如下图所示：</p>
<img data-src="/2024/07/12/artificial-intelligence/LLaMA2_theory_study/ll_5.png" class="">

<p><strong>绝对位置编码</strong>是固定向量，它们被添加到<code>token</code>的嵌入中以表示其在句子中的绝对位置。因此，它一次处理一个<code>token</code>。您可以将其视为地图上的一对（纬度，经度）：地球上的每个点都有一对唯一的<code>token</code>。绝对位置编码的缺点：它没有考虑句子中的相对位置信息。</p>
<p><strong>相对位置编码</strong>一次处理两个<code>token</code>，并且在我们计算注意力时会涉及它：由于注意力机制捕获了两个单词相互关联的“强度”，相对位置编码会告诉注意力机制其中涉及的两个单词之间的距离。因此，给定两个<code>token</code>，我们创建一个表示它们距离的向量。相对位置编码的缺点：是计算效率低下，导致成本高，不适合推理（因为每个<code>token</code>的嵌入会随着每个新的时间步长而改变）。</p>
<h4 id="旋转位置嵌入-RoPE"><a href="#旋转位置嵌入-RoPE" class="headerlink" title="旋转位置嵌入(RoPE)"></a>旋转位置嵌入(RoPE)</h4><p>旋转位置嵌入(<code>RoPE</code>)是一种新型的位置编码方法,用于<code>Transformer</code>模型中。它通过旋转矩阵编码绝对位置信息,同时在自注意力机制中自然地融入了显式的相对位置依赖关系。<strong>原理</strong>：不是添加位置向量,而是对词向量使用<strong>旋转</strong>；使用<strong>复数旋转</strong>的方式来编码位置信息。<strong>优点</strong>：结合了绝对位置编码和相对位置编码的优势；计算效率高,易于实现；对长序列有更好的处理能力。</p>
<p>旋转位置嵌入：<strong>内积</strong>，注意力机制中使用的<strong>点积</strong>是一种<strong>内积</strong>，可以将其视为点积的泛化。我们可以定义一个函数<code>g</code>，它仅取决于两个嵌入向量<code>q、k</code>及其相对距离。</p>
<img data-src="/2024/07/12/artificial-intelligence/LLaMA2_theory_study/ll_6.png" class="">

<p>利用<strong>欧拉公式</strong>，我们可以将其写成矩阵形式。</p>
<img data-src="/2024/07/12/artificial-intelligence/LLaMA2_theory_study/ll_7.png" class="">

<p>由于矩阵是稀疏的，因此用它来计算位置嵌入并不方便。给定一个具有嵌入向量<code>x</code>的<code>token</code>，以及该标记在句子内部的位置<code>m</code>，下面就是计算该<code>token</code>的位置嵌入的方式。</p>
<img data-src="/2024/07/12/artificial-intelligence/LLaMA2_theory_study/ll_8.png" class="">

<p>旋转位置嵌入：<strong>长期衰减</strong>，通过改变两个<code>token</code>之间的距离计算了<strong>内积</strong>的上限，并证明它会随着相对距离的增长而衰减。意味着，用<strong>旋转位置嵌入编码</strong>的两个<code>token</code>之间的关系“强度”会随着它们之间距离的增加而变小。<strong>旋转位置嵌入</strong>仅适用于<code>q</code>和<code>k</code>，而不适用于<code>v</code>。在注意力机制中，旋转位置嵌入是在向量<code>q</code>和<code>k</code>与<code>W</code>矩阵相乘之后使用的，而在<code>vanilla Transformer</code>中，旋转位置嵌入是在之前使用的。<strong>下一个token预测任务</strong>：在推理的每一步，我们只对模型输出的最后一个<code>token</code>感兴趣，因为我们已经有了之前的<code>token</code>。然而，模型需要访问所有之前的<code>token</code>来决定输出哪个<code>token</code>，因为构成了它的上下文（或“提示词”）。有没有办法让模型在推理过程中对已经见过的<code>token</code>进行更少的计算？有，解决方案就是<code>KV</code>缓存。</p>
<img data-src="/2024/07/12/artificial-intelligence/LLaMA2_theory_study/ll_9.png" class="">

<h4 id="分组查询注意力"><a href="#分组查询注意力" class="headerlink" title="分组查询注意力"></a>分组查询注意力</h4><p><strong>分组查询注意力</strong>(<code>Grouped Query Attention, GQA</code>)是一种介于<code>Multi-Head Attention(MHA)</code>和M<code>ulti-Query Attention(MQA)</code>之间的注意力机制。它将查询头(<code>query heads</code>)分成多个组,每组共享一个键头(<code>key head</code>)和值头(<code>value head</code>)。<strong>原理</strong>：将查询头分成G个组。每个组共享一个键头和值头。<code>GQA-G</code>表示有<code>G</code>个组的<code>GQA</code>；<code>GQA-1</code>等同于<code>MQA</code>,<code>GQA-H</code>(<code>H</code>为头的总数)等同于<code>MHA</code>；通过对原始<code>MHA</code>模型的键和值投影矩阵进行平均池化来转换为<code>GQA</code>模型。<strong>优点</strong>：相比<code>MQA</code>,降低了质量下降和训练不稳定的问题；相比<code>MHA</code>,提高了推理速度和计算效率。</p>
<table>
<thead>
<tr>
<th align="left"><code>Item</code></th>
<th align="left"><code>Features</code></th>
<th align="left"><code>Architecture</code></th>
</tr>
</thead>
<tbody><tr>
<td align="left"><code>Multi-Head Attention</code></td>
<td align="left">高质量，计算速度慢</td>
<td align="left"><img data-src="/2024/07/12/artificial-intelligence/LLaMA2_theory_study/ll_10.png" class=""></td>
</tr>
<tr>
<td align="left"><code>Grouped Multi-Query Attention</code></td>
<td align="left">质量和速度之间有很好的平衡</td>
<td align="left"><img data-src="/2024/07/12/artificial-intelligence/LLaMA2_theory_study/ll_11.png" class=""></td>
</tr>
<tr>
<td align="left"><code>Multi-Query Attention</code></td>
<td align="left">质量有损失，计算速度快</td>
<td align="left"><img data-src="/2024/07/12/artificial-intelligence/LLaMA2_theory_study/ll_12.png" class=""></td>
</tr>
</tbody></table>
<h4 id="SwiGLU"><a href="#SwiGLU" class="headerlink" title="SwiGLU"></a>SwiGLU</h4><p><code>SwiGLU(Swish-Gated Linear Unit)</code>是一种新型的激活函数，结合了<code>Swish</code>和<code>GLU(Gated Linear Unit)</code>的特点。它在深度学习模型中被用作非线性激活函数，以提高模型的表现和训练效率。<code>SwiGLU</code>激活函数公式如下：</p>
<mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -3.507ex;" xmlns="http://www.w3.org/2000/svg" width="48.987ex" height="8.145ex" role="img" focusable="false" viewBox="0 -2050 21652.1 3600" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-19-TEX-N-53" d="M55 507Q55 590 112 647T243 704H257Q342 704 405 641L426 672Q431 679 436 687T446 700L449 704Q450 704 453 704T459 705H463Q466 705 472 699V462L466 456H448Q437 456 435 459T430 479Q413 605 329 646Q292 662 254 662Q201 662 168 626T135 542Q135 508 152 480T200 435Q210 431 286 412T370 389Q427 367 463 314T500 191Q500 110 448 45T301 -21Q245 -21 201 -4T140 27L122 41Q118 36 107 21T87 -7T78 -21Q76 -22 68 -22H64Q61 -22 55 -16V101Q55 220 56 222Q58 227 76 227H89Q95 221 95 214Q95 182 105 151T139 90T205 42T305 24Q352 24 386 62T420 155Q420 198 398 233T340 281Q284 295 266 300Q261 301 239 306T206 314T174 325T141 343T112 367T85 402Q55 451 55 507Z"></path><path id="MJX-19-TEX-N-77" d="M90 368Q84 378 76 380T40 385H18V431H24L43 430Q62 430 84 429T116 428Q206 428 221 431H229V385H215Q177 383 177 368Q177 367 221 239L265 113L339 328L333 345Q323 374 316 379Q308 384 278 385H258V431H264Q270 428 348 428Q439 428 454 431H461V385H452Q404 385 404 369Q404 366 418 324T449 234T481 143L496 100L537 219Q579 341 579 347Q579 363 564 373T530 385H522V431H529Q541 428 624 428Q692 428 698 431H703V385H697Q696 385 691 385T682 384Q635 377 619 334L559 161Q546 124 528 71Q508 12 503 1T487 -11H479Q460 -11 456 -4Q455 -3 407 133L361 267Q359 263 266 -4Q261 -11 243 -11H238Q225 -11 220 -3L90 368Z"></path><path id="MJX-19-TEX-N-69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z"></path><path id="MJX-19-TEX-N-73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path id="MJX-19-TEX-N-68" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 124T102 167T103 217T103 272T103 329Q103 366 103 407T103 482T102 542T102 586T102 603Q99 622 88 628T43 637H25V660Q25 683 27 683L37 684Q47 685 66 686T103 688Q120 689 140 690T170 693T181 694H184V367Q244 442 328 442Q451 442 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path id="MJX-19-TEX-N-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path id="MJX-19-TEX-I-1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path id="MJX-19-TEX-N-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path><path id="MJX-19-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-19-TEX-N-22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path><path id="MJX-19-TEX-I-1D70E" d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z"></path><path id="MJX-19-TEX-N-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path><path id="MJX-19-TEX-N-47" d="M56 342Q56 428 89 500T174 615T283 681T391 705Q394 705 400 705T408 704Q499 704 569 636L582 624L612 663Q639 700 643 704Q644 704 647 704T653 705H657Q660 705 666 699V419L660 413H626Q620 419 619 430Q610 512 571 572T476 651Q457 658 426 658Q401 658 376 654T316 633T254 592T205 519T177 411Q173 369 173 335Q173 259 192 201T238 111T302 58T370 31T431 24Q478 24 513 45T559 100Q562 110 562 160V212Q561 213 557 216T551 220T542 223T526 225T502 226T463 227H437V273H449L609 270Q715 270 727 273H735V227H721Q674 227 668 215Q666 211 666 108V6Q660 0 657 0Q653 0 639 10Q617 25 600 42L587 54Q571 27 524 3T406 -22Q317 -22 238 22T108 151T56 342Z"></path><path id="MJX-19-TEX-N-4C" d="M128 622Q121 629 117 631T101 634T58 637H25V683H36Q48 680 182 680Q324 680 348 683H360V637H333Q273 637 258 635T233 622L232 342V129Q232 57 237 52Q243 47 313 47Q384 47 410 53Q470 70 498 110T536 221Q536 226 537 238T540 261T542 272T562 273H582V268Q580 265 568 137T554 5V0H25V46H58Q100 47 109 49T128 61V622Z"></path><path id="MJX-19-TEX-N-55" d="M128 622Q121 629 117 631T101 634T58 637H25V683H36Q57 680 180 680Q315 680 324 683H335V637H302Q262 636 251 634T233 622L232 418V291Q232 189 240 145T280 67Q325 24 389 24Q454 24 506 64T571 183Q575 206 575 410V598Q569 608 565 613T541 627T489 637H472V683H481Q496 680 598 680T715 683H724V637H707Q634 633 622 598L621 399Q620 194 617 180Q617 179 615 171Q595 83 531 31T389 -22Q304 -22 226 33T130 192Q129 201 128 412V622Z"></path><path id="MJX-19-TEX-I-1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path><path id="MJX-19-TEX-N-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path id="MJX-19-TEX-I-1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtable"><g data-mml-node="mtr" transform="translate(0,1300)"><g data-mml-node="mtd" transform="translate(1210,0)"><g data-mml-node="mtext"><use data-c="53" xlink:href="#MJX-19-TEX-N-53"></use><use data-c="77" xlink:href="#MJX-19-TEX-N-77" transform="translate(556,0)"></use><use data-c="69" xlink:href="#MJX-19-TEX-N-69" transform="translate(1278,0)"></use><use data-c="73" xlink:href="#MJX-19-TEX-N-73" transform="translate(1556,0)"></use><use data-c="68" xlink:href="#MJX-19-TEX-N-68" transform="translate(1950,0)"></use></g><g data-mml-node="mo" transform="translate(2506,0)"><use data-c="28" xlink:href="#MJX-19-TEX-N-28"></use></g><g data-mml-node="mi" transform="translate(2895,0)"><use data-c="1D465" xlink:href="#MJX-19-TEX-I-1D465"></use></g><g data-mml-node="mo" transform="translate(3467,0)"><use data-c="29" xlink:href="#MJX-19-TEX-N-29"></use></g></g><g data-mml-node="mtd" transform="translate(5066,0)"><g data-mml-node="mi"></g><g data-mml-node="mo" transform="translate(277.8,0)"><use data-c="3D" xlink:href="#MJX-19-TEX-N-3D"></use></g><g data-mml-node="mi" transform="translate(1333.6,0)"><use data-c="1D465" xlink:href="#MJX-19-TEX-I-1D465"></use></g><g data-mml-node="mo" transform="translate(2127.8,0)"><use data-c="22C5" xlink:href="#MJX-19-TEX-N-22C5"></use></g><g data-mml-node="mi" transform="translate(2628,0)"><use data-c="1D70E" xlink:href="#MJX-19-TEX-I-1D70E"></use></g><g data-mml-node="mo" transform="translate(3199,0)"><use data-c="28" xlink:href="#MJX-19-TEX-N-28"></use></g><g data-mml-node="mi" transform="translate(3588,0)"><use data-c="1D465" xlink:href="#MJX-19-TEX-I-1D465"></use></g><g data-mml-node="mo" transform="translate(4160,0)"><use data-c="29" xlink:href="#MJX-19-TEX-N-29"></use></g><g data-mml-node="mo" transform="translate(4549,0)"><use data-c="2C" xlink:href="#MJX-19-TEX-N-2C"></use></g><g data-mml-node="mstyle" transform="translate(4827,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="mstyle" transform="translate(5105,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="mstyle" transform="translate(5383,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="mtext" transform="translate(5827.7,0)"><use data-c="47" xlink:href="#MJX-19-TEX-N-47"></use><use data-c="4C" xlink:href="#MJX-19-TEX-N-4C" transform="translate(785,0)"></use><use data-c="55" xlink:href="#MJX-19-TEX-N-55" transform="translate(1410,0)"></use></g><g data-mml-node="mo" transform="translate(7987.7,0)"><use data-c="28" xlink:href="#MJX-19-TEX-N-28"></use></g><g data-mml-node="mi" transform="translate(8376.7,0)"><use data-c="1D465" xlink:href="#MJX-19-TEX-I-1D465"></use></g><g data-mml-node="mo" transform="translate(8948.7,0)"><use data-c="29" xlink:href="#MJX-19-TEX-N-29"></use></g><g data-mml-node="mo" transform="translate(9615.4,0)"><use data-c="3D" xlink:href="#MJX-19-TEX-N-3D"></use></g><g data-mml-node="mi" transform="translate(10671.2,0)"><use data-c="1D465" xlink:href="#MJX-19-TEX-I-1D465"></use></g><g data-mml-node="mo" transform="translate(11465.4,0)"><use data-c="22C5" xlink:href="#MJX-19-TEX-N-22C5"></use></g><g data-mml-node="mi" transform="translate(11965.7,0)"><use data-c="1D70E" xlink:href="#MJX-19-TEX-I-1D70E"></use></g><g data-mml-node="mo" transform="translate(12536.7,0)"><use data-c="28" xlink:href="#MJX-19-TEX-N-28"></use></g><g data-mml-node="mi" transform="translate(12925.7,0)"><use data-c="1D44A" xlink:href="#MJX-19-TEX-I-1D44A"></use></g><g data-mml-node="mi" transform="translate(13973.7,0)"><use data-c="1D465" xlink:href="#MJX-19-TEX-I-1D465"></use></g><g data-mml-node="mo" transform="translate(14767.9,0)"><use data-c="2B" xlink:href="#MJX-19-TEX-N-2B"></use></g><g data-mml-node="mi" transform="translate(15768.1,0)"><use data-c="1D44F" xlink:href="#MJX-19-TEX-I-1D44F"></use></g><g data-mml-node="mo" transform="translate(16197.1,0)"><use data-c="29" xlink:href="#MJX-19-TEX-N-29"></use></g></g></g><g data-mml-node="mtr" transform="translate(0,0)"><g data-mml-node="mtd" transform="translate(5066,0)"></g></g><g data-mml-node="mtr" transform="translate(0,-1300)"><g data-mml-node="mtd"><g data-mml-node="mtext"><use data-c="53" xlink:href="#MJX-19-TEX-N-53"></use><use data-c="77" xlink:href="#MJX-19-TEX-N-77" transform="translate(556,0)"></use><use data-c="69" xlink:href="#MJX-19-TEX-N-69" transform="translate(1278,0)"></use><use data-c="47" xlink:href="#MJX-19-TEX-N-47" transform="translate(1556,0)"></use><use data-c="4C" xlink:href="#MJX-19-TEX-N-4C" transform="translate(2341,0)"></use><use data-c="55" xlink:href="#MJX-19-TEX-N-55" transform="translate(2966,0)"></use></g><g data-mml-node="mo" transform="translate(3716,0)"><use data-c="28" xlink:href="#MJX-19-TEX-N-28"></use></g><g data-mml-node="mi" transform="translate(4105,0)"><use data-c="1D465" xlink:href="#MJX-19-TEX-I-1D465"></use></g><g data-mml-node="mo" transform="translate(4677,0)"><use data-c="29" xlink:href="#MJX-19-TEX-N-29"></use></g></g><g data-mml-node="mtd" transform="translate(5066,0)"><g data-mml-node="mi"></g><g data-mml-node="mo" transform="translate(277.8,0)"><use data-c="3D" xlink:href="#MJX-19-TEX-N-3D"></use></g><g data-mml-node="mtext" transform="translate(1333.6,0)"><use data-c="53" xlink:href="#MJX-19-TEX-N-53"></use><use data-c="77" xlink:href="#MJX-19-TEX-N-77" transform="translate(556,0)"></use><use data-c="69" xlink:href="#MJX-19-TEX-N-69" transform="translate(1278,0)"></use><use data-c="73" xlink:href="#MJX-19-TEX-N-73" transform="translate(1556,0)"></use><use data-c="68" xlink:href="#MJX-19-TEX-N-68" transform="translate(1950,0)"></use></g><g data-mml-node="mo" transform="translate(3839.6,0)"><use data-c="28" xlink:href="#MJX-19-TEX-N-28"></use></g><g data-mml-node="mi" transform="translate(4228.6,0)"><use data-c="1D465" xlink:href="#MJX-19-TEX-I-1D465"></use></g><g data-mml-node="mo" transform="translate(4800.6,0)"><use data-c="29" xlink:href="#MJX-19-TEX-N-29"></use></g><g data-mml-node="mo" transform="translate(5411.8,0)"><use data-c="22C5" xlink:href="#MJX-19-TEX-N-22C5"></use></g><g data-mml-node="mtext" transform="translate(5912,0)"><use data-c="47" xlink:href="#MJX-19-TEX-N-47"></use><use data-c="4C" xlink:href="#MJX-19-TEX-N-4C" transform="translate(785,0)"></use><use data-c="55" xlink:href="#MJX-19-TEX-N-55" transform="translate(1410,0)"></use></g><g data-mml-node="mo" transform="translate(8072,0)"><use data-c="28" xlink:href="#MJX-19-TEX-N-28"></use></g><g data-mml-node="mi" transform="translate(8461,0)"><use data-c="1D465" xlink:href="#MJX-19-TEX-I-1D465"></use></g><g data-mml-node="mo" transform="translate(9033,0)"><use data-c="29" xlink:href="#MJX-19-TEX-N-29"></use></g></g></g></g></g></g></svg></mjx-container>
<p>其中<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="4.346ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 1921 1000" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-19-TEX-I-1D70E" d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z"></path><path id="MJX-19-TEX-N-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path id="MJX-19-TEX-I-1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path id="MJX-19-TEX-N-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D70E" xlink:href="#MJX-19-TEX-I-1D70E"></use></g><g data-mml-node="mo" transform="translate(571,0)"><use data-c="28" xlink:href="#MJX-19-TEX-N-28"></use></g><g data-mml-node="mi" transform="translate(960,0)"><use data-c="1D465" xlink:href="#MJX-19-TEX-I-1D465"></use></g><g data-mml-node="mo" transform="translate(1532,0)"><use data-c="29" xlink:href="#MJX-19-TEX-N-29"></use></g></g></g></svg></mjx-container>是Sigmoid函数，<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="2.371ex" height="1.595ex" role="img" focusable="false" viewBox="0 -683 1048 705" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-18-TEX-I-1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D44A" xlink:href="#MJX-18-TEX-I-1D44A"></use></g></g></g></svg></mjx-container>和<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="0.971ex" height="1.595ex" role="img" focusable="false" viewBox="0 -694 429 705" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-18-TEX-I-1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D44F" xlink:href="#MJX-18-TEX-I-1D44F"></use></g></g></g></svg></mjx-container>是可学习的<strong>权重</strong>和<strong>偏置</strong>。<code>SwiGLU</code>特点：非线性：<code>SwiGLU</code>引入了非线性变换，能够捕捉复杂的特征；平滑性：<code>Swish</code>函数的平滑特性使得梯度流动更加稳定，有助于深层神经网络的训练；门控机制：<code>GLU</code>引入了门控机制，能够动态调整输入信号的通过量，提高模型的表达能力。<strong>优点</strong>：提高模型性能：<code>SwiGLU</code>在一些深度学习任务中表现出色，能够提高模型的准确性和泛化能力；稳定梯度：相比于<code>ReLU</code>等传统激活函数，<code>SwiGLU</code>能够更好地保持梯度的稳定性，减少梯度消失问题；灵活性：结合了<code>Swish</code>和<code>GLU</code>的优点，<code>SwiGLU</code>能够在不同任务和模型架构中灵活应用。</p>
<img data-src="/2024/07/12/artificial-intelligence/LLaMA2_theory_study/ll_13.png" class="">

<h4 id="Logits"><a href="#Logits" class="headerlink" title="Logits"></a>Logits</h4><p>在神经网络中，<code>logits</code>是指模型最后一层的输出，即在应用激活函数（如<code>softmax</code>或<code>sigmoid</code>）之前的原始、未归一化的预测值。代表了模型在最终决策之前的原始输出，尚未转换为概率。</p>
<img data-src="/2024/07/12/artificial-intelligence/LLaMA2_theory_study/ll_14.png" class="">

<h4 id="推理策略"><a href="#推理策略" class="headerlink" title="推理策略"></a>推理策略</h4><p>推理策略：<code>Greedy、Beam Search、Temperature、Random Sampling、Top K、Top P</code>。</p>
<table>
<thead>
<tr>
<th align="left"><code>Inference strategies</code></th>
<th align="left"><code>Description</code></th>
</tr>
</thead>
<tbody><tr>
<td align="left"><code>Greedy</code></td>
<td align="left">在每一步中，我们都选择概率最大的<code>token</code>，将其附加到输入中以生成下一个<code>token</code>，依此类推…。如果初始<code>token</code>恰好是错误的，则下一个<code>token</code>很可能也会是错误的。<code>Greedy</code>易于实现。在实践中表现不佳。</td>
</tr>
<tr>
<td align="left"><code>Beam Search</code></td>
<td align="left">在每一步中，我们保持前<code>K</code>条路径有效，其他所有路径均被终止。增加了推理时间，因为每一步都必须探索<code>K</code>个可能的选项。通常，比贪婪策略表现更好。</td>
</tr>
<tr>
<td align="left"><code>Temperature</code></td>
<td align="left">这个想法是在使用<code>softmax</code>之前缩放<code>logits</code>。<strong>低温</strong>使模型更可信（低概率和高概率之间的差距增加）。<strong>高温</strong>使模型可信度降低（低概率和高概率之间的差距缩小）。</td>
</tr>
<tr>
<td align="left"><code>Random Sampling</code></td>
<td align="left">我们从<code>softmax</code>输出的随机分布中抽样。第一个<code>token</code>被选中的概率为<code>12.06%</code>，第二个<code>token</code>被选中的概率为<code>7.31%</code>，最后一个<code>token</code>被选中的概率为<code>80.63%</code>。概率越高，被选中的概率就越大。<strong>问题</strong>：我们可能会以极小的概率选择完全无意义的<code>token</code>。</td>
</tr>
<tr>
<td align="left"><code>Top K</code></td>
<td align="left">在随机采样策略中，可能会发生选择到概率很小的单词的情况，这通常表示该<code>token</code>与前面的<code>token</code>无关。使用<code>Top K</code>，仅保留前<code>k</code>个最高概率的<code>token</code>，因此概率非常低的 <code>token</code>永远不会被选中。<strong>问题</strong>：给定以下分布，低概率<code>token</code>仍会进入前<code>k</code>个<code>token</code>(<code>k = 2</code>)。分布<code>1</code>：<code>0.5、0.4、0.05、0.025、0.025</code>；分布<code>2</code>：<code>0.9、0.05、0.025、0.020、0.005</code>。</td>
</tr>
<tr>
<td align="left"><code>Top P</code></td>
<td align="left">使用<code>Top P</code>，我们仅保留概率最高的<code>token</code>，使得它们的累积概率大于或等于参数<code>p</code>。这样，对于更“平坦”的分布，我们会获得更多<code>token</code>，而对于模式非常突出的分布，我们会获得更少的<code>token</code>。</td>
</tr>
</tbody></table>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>umbrella
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://fresh88888888.github.io/2024/07/12/artificial-intelligence/LLaMA2_theory_study/" title="LLaMA 2 模型—探析（PyTorch）">https://fresh88888888.github.io/2024/07/12/artificial-intelligence/LLaMA2_theory_study/</a>
  </li>
  <li class="post-copyright-license">
      <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/AI/" rel="tag"># AI</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2024/07/10/artificial-intelligence/Stable_Diffusion_theory_study/" rel="prev" title="Stable Diffusion模型—探析（PyTorch）">
                  <i class="fa fa-chevron-left"></i> Stable Diffusion模型—探析（PyTorch）
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2024/07/16/artificial-intelligence/Segment_theory_study/" rel="next" title="SAM模型—探析（PyTorch）">
                  SAM模型—探析（PyTorch） <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments utterances-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">辽ICP备15012817号-2 </a>
  </div>
  <div class="copyright">
    &copy; 2022 – 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">umbrella</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">1.3m</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">73:48</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/fresh88888888" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script size="300" alpha="0.6" zIndex="-1" src="https://cdnjs.cloudflare.com/ajax/libs/ribbon.js/1.0.2/ribbon.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.0/jquery.min.js" integrity="sha256-2Pmvv0kuTBOenSvLm6bvfBSSHrUJ+3A7x6P5Ebd07/g=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.8/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/comments.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/utils.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/motion.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/next-boot.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/pjax.min.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/search/local-search.min.js"></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdnjs.cloudflare.com/ajax/libs/pdfobject/2.2.12/pdfobject.min.js","integrity":"sha256-g2xji1rlE3KsGVClvuxTbcR0Kn2+wtQADSff2Tbb4zA="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/tags/pdf.min.js"></script>



  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/fancybox.min.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/pace.min.js"></script>


  
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  <script src="https://cdnjs.cloudflare.com/ajax/libs/quicklink/2.3.0/quicklink.umd.js" integrity="sha256-yvJQOINiH9fWemHn0vCA5lsHWJaHs6/ZmO+1Ft04SvM=" crossorigin="anonymous"></script>
  <script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":true,"archive":true,"delay":true,"timeout":5000,"priority":true,"url":"https://fresh88888888.github.io/2024/07/12/artificial-intelligence/LLaMA2_theory_study/"}</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/quicklink.min.js"></script>
<script class="next-config" data-name="utterances" type="application/json">{"enable":true,"repo":"fresh88888888.github.io","issue_term":"title","theme":"github-light"}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.17.1/third-party/comments/utterances.min.js"></script>

</body>
</html>
